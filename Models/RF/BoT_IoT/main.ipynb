{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc9518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.BoT_IoT.BoT_IoT_config import BoT_IoT_Config as Dataset_Config\n",
    "\n",
    "DATASET_NAME = \"BoT_IoT\"\n",
    "\n",
    "COLS_TO_NORM = Dataset_Config.COLS_TO_NORM\n",
    "CATEGORICAL_COLS = Dataset_Config.CATEGORICAL_COLS\n",
    "\n",
    "DROP_COLS = Dataset_Config.DROP_COLS + ['pkSeqID', 'stime', 'ltime']\n",
    "\n",
    "SOURCE_IP_COL_NAME = Dataset_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = Dataset_Config.DESTINATION_IP_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = Dataset_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = Dataset_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "csv_file_name = \"all_raw\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"{DATASET_NAME}/All/{csv_file_name}.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33f075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               pkts         bytes           dur          mean        stddev  \\\n",
      "count  3.668522e+06  3.668522e+06  3.668522e+06  3.668522e+06  3.668522e+06   \n",
      "mean   7.725963e+00  8.690501e+02  2.033479e+01  2.231063e+00  8.871499e-01   \n",
      "std    1.155876e+02  1.122667e+05  2.148764e+01  1.517728e+00  8.037139e-01   \n",
      "min    1.000000e+00  6.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    5.000000e+00  4.200000e+02  1.256256e+01  1.819670e-01  3.001900e-02   \n",
      "50%    7.000000e+00  6.000000e+02  1.550852e+01  2.690125e+00  7.938960e-01   \n",
      "75%    9.000000e+00  7.700000e+02  2.709986e+01  3.565203e+00  1.745296e+00   \n",
      "max    7.005700e+04  7.183334e+07  2.771485e+03  4.981882e+00  2.496763e+00   \n",
      "\n",
      "                sum           min           max         spkts         dpkts  \\\n",
      "count  3.668522e+06  3.668522e+06  3.668522e+06  3.668522e+06  3.668522e+06   \n",
      "mean   7.721635e+00  1.017540e+00  3.020015e+00  7.314146e+00  4.118173e-01   \n",
      "std    7.616199e+00  1.483688e+00  1.860877e+00  7.725836e+01  4.965001e+01   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
      "25%    3.445982e-01  0.000000e+00  2.806072e-01  5.000000e+00  0.000000e+00   \n",
      "50%    8.269959e+00  0.000000e+00  4.009111e+00  6.000000e+00  0.000000e+00   \n",
      "75%    1.171040e+01  2.151138e+00  4.293582e+00  8.000000e+00  0.000000e+00   \n",
      "max    1.913194e+03  4.980471e+00  4.999999e+00  3.502900e+04  3.502900e+04   \n",
      "\n",
      "       ...  TnP_PerProto  TnP_Per_Dport  AR_P_Proto_P_SrcIP  \\\n",
      "count  ...  3.668522e+06   3.668522e+06        3.668522e+06   \n",
      "mean   ...  7.535659e+02   7.369070e+02        3.327439e+02   \n",
      "std    ...  1.434385e+03   6.527134e+02        8.466031e+03   \n",
      "min    ...  1.000000e+00   1.000000e+00        0.000000e+00   \n",
      "25%    ...  5.020000e+02   5.000000e+02        2.359950e-01   \n",
      "50%    ...  7.000000e+02   7.000000e+02        3.900890e-01   \n",
      "75%    ...  9.240000e+02   9.200000e+02        5.725580e-01   \n",
      "max    ...  2.283730e+05   2.444250e+05        2.714290e+06   \n",
      "\n",
      "       AR_P_Proto_P_DstIP  N_IN_Conn_P_DstIP  N_IN_Conn_P_SrcIP  \\\n",
      "count        3.668522e+06       3.668522e+06       3.668522e+06   \n",
      "mean         2.851832e+02       9.245168e+01       8.253848e+01   \n",
      "std          4.096943e+03       1.817643e+01       2.439739e+01   \n",
      "min          0.000000e+00       1.000000e+00       1.000000e+00   \n",
      "25%          2.436680e-01       1.000000e+02       6.900000e+01   \n",
      "50%          3.986290e-01       1.000000e+02       1.000000e+02   \n",
      "75%          5.796390e-01       1.000000e+02       1.000000e+02   \n",
      "max          1.000000e+06       1.000000e+02       1.000000e+02   \n",
      "\n",
      "       AR_P_Proto_P_Sport  AR_P_Proto_P_Dport  \\\n",
      "count        3.668522e+06        3.668522e+06   \n",
      "mean         4.564945e+02        5.385196e+02   \n",
      "std          1.432917e+04        1.569824e+04   \n",
      "min          0.000000e+00        0.000000e+00   \n",
      "25%          2.314810e-01        2.457730e-01   \n",
      "50%          3.785910e-01        3.943060e-01   \n",
      "75%          5.725550e-01        5.769710e-01   \n",
      "max          3.000000e+06        2.000000e+06   \n",
      "\n",
      "       Pkts_P_State_P_Protocol_P_DestIP  Pkts_P_State_P_Protocol_P_SrcIP  \n",
      "count                      3.668522e+06                     3.668522e+06  \n",
      "mean                       6.422897e+02                     5.859984e+02  \n",
      "std                        4.533432e+02                     4.332619e+02  \n",
      "min                        1.000000e+00                     1.000000e+00  \n",
      "25%                        3.240000e+02                     2.940000e+02  \n",
      "50%                        6.000000e+02                     5.000000e+02  \n",
      "75%                        8.280000e+02                     8.000000e+02  \n",
      "max                        1.125440e+05                     1.179390e+05  \n",
      "\n",
      "[8 rows x 29 columns]\n",
      "\n",
      "✅ All other columns processed successfully.\n",
      "Feature Columns: ['pkts', 'bytes', 'dur', 'mean', 'stddev', 'sum', 'min', 'max', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'srate', 'drate', 'TnBPSrcIP', 'TnBPDstIP', 'TnP_PSrcIP', 'TnP_PDstIP', 'TnP_PerProto', 'TnP_Per_Dport', 'AR_P_Proto_P_SrcIP', 'AR_P_Proto_P_DstIP', 'N_IN_Conn_P_DstIP', 'N_IN_Conn_P_SrcIP', 'AR_P_Proto_P_Sport', 'AR_P_Proto_P_Dport', 'Pkts_P_State_P_Protocol_P_DestIP', 'Pkts_P_State_P_Protocol_P_SrcIP', 'flgs_number_1', 'flgs_number_2', 'flgs_number_3', 'flgs_number_4', 'flgs_number_5', 'flgs_number_6', 'flgs_number_7', 'flgs_number_8', 'flgs_number_9', 'state_number_1', 'state_number_2', 'state_number_3', 'state_number_4', 'state_number_5', 'state_number_6', 'state_number_7', 'state_number_8', 'state_number_9', 'state_number_10', 'state_number_11', 'proto_number_1', 'proto_number_2', 'proto_number_3', 'proto_number_4', 'proto_number_5']\n",
      "Data after normalization:\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "print(data[COLS_TO_NORM].describe()) # Check if there's any too large value\n",
    "\n",
    "# Check for numeric issues in the columns before normalization\n",
    "def check_numeric_issues(df, cols_to_norm):\n",
    "    for col in cols_to_norm:\n",
    "        try:\n",
    "            # Try to coerce to numeric\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "            print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Data type: {df[col].dtype}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "check_numeric_issues(data, COLS_TO_NORM)\n",
    "\n",
    "data[COLS_TO_NORM] = scaler.fit_transform(data[COLS_TO_NORM])\n",
    "\n",
    "data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "feature_cols = COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "print('Feature Columns:', feature_cols)\n",
    "num_features = len(feature_cols)\n",
    "\n",
    "# Save the scaler for future use\n",
    "print(\"Data after normalization:\")\n",
    "X = data.drop(columns=DROP_COLS + [SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ATTACK_CLASS_COL_NAME, IS_ATTACK_COL_NAME])\n",
    "y = data[ATTACK_CLASS_COL_NAME]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd357368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "}\n",
    "\n",
    "# # Perform Grid Search with cross-validation\n",
    "# grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "#                            param_grid=param_grid,\n",
    "#                            scoring='accuracy',\n",
    "#                            cv=3,\n",
    "#                            n_jobs=-1,\n",
    "#                            verbose=2)\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and train the model with them\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 20\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pkSeqID         stime         sport        dport         pkts  \\\n",
      "995784   9.030501e+05  1.528082e+09   8003.887972  -805.572386 -2464.803678   \n",
      "170580   8.091115e+04  1.528083e+09  24315.234851  -201.116954 -4997.262501   \n",
      "3141497  3.050831e+06  1.528101e+09  30102.835315  -857.928701  1482.529414   \n",
      "2925715  2.835977e+06  1.528098e+09  42713.171533 -4686.060604 -1267.075036   \n",
      "3614039  3.523732e+06  1.528096e+09  11981.184369   691.413464    14.740976   \n",
      "...               ...           ...           ...          ...          ...   \n",
      "235783   1.460769e+05  1.528082e+09  31323.592051  3026.981330 -2031.576847   \n",
      "1368458  1.281288e+06  1.528081e+09  60074.135986 -1135.305703 -1859.228925   \n",
      "3062847  2.971740e+06  1.528099e+09  32841.658763 -2481.887202  5873.177419   \n",
      "1165482  1.075291e+06  1.528084e+09  23112.353787 -1015.600826   175.213725   \n",
      "2903833  2.811658e+06  1.528101e+09  33393.361165 -3209.736751  -992.303619   \n",
      "\n",
      "               bytes         ltime          dur         mean       stddev  \\\n",
      "995784    122.504776  1.528087e+09  -860.442057  1862.776127   865.955074   \n",
      "170580   3072.047433  1.528081e+09  1221.140415 -1469.191517   -22.895141   \n",
      "3141497    48.136427  1.528101e+09   300.828205  -631.248141 -2121.034879   \n",
      "2925715  1113.817274  1.528101e+09  1135.594393   715.804232   942.051707   \n",
      "3614039  2314.209942  1.528101e+09 -1021.428506  1622.759968  -981.104712   \n",
      "...              ...           ...          ...          ...          ...   \n",
      "235783   -409.592950  1.528084e+09  -763.271275   745.534726 -1437.530030   \n",
      "1368458  -891.568999  1.528083e+09  2488.352147 -1137.788176   448.039819   \n",
      "3062847 -3167.109993  1.528096e+09 -2536.510991   501.615632   274.658428   \n",
      "1165482    21.452998  1.528085e+09 -2891.245810  -707.114147   664.669052   \n",
      "2903833  4002.941456  1.528101e+09 -1756.845477 -1626.634332   476.887193   \n",
      "\n",
      "         ...  state_number_7  state_number_8  state_number_9  state_number_10  \\\n",
      "995784   ...     3182.520574    -1450.590573    -1376.430431      2374.678665   \n",
      "170580   ...     -588.142881     1573.048414      617.609964     -1728.550515   \n",
      "3141497  ...     1027.316680    -1483.668282    -1808.321940     -1883.500675   \n",
      "2925715  ...     -928.107644      174.579218     1891.974278      2426.086496   \n",
      "3614039  ...    -4206.681647     4063.110741     -833.839294     -2838.783766   \n",
      "...      ...             ...             ...             ...              ...   \n",
      "235783   ...       19.087053     1559.756683    -1064.046225        83.671269   \n",
      "1368458  ...     2480.660566     1325.615316    -1993.914028      -157.757976   \n",
      "3062847  ...       86.812653     -825.127236        5.632391      -801.431667   \n",
      "1165482  ...     -224.792170     -310.434873    -3112.630843     -2887.977321   \n",
      "2903833  ...     -588.233749     1118.851557     -324.559747       498.455593   \n",
      "\n",
      "         state_number_11  proto_number_1  proto_number_2  proto_number_3  \\\n",
      "995784      -1677.551716     -180.817121     -680.061921      512.801795   \n",
      "170580       1909.067380    -4711.672575    -3291.155146      502.571901   \n",
      "3141497     -1278.417728     1676.323895     -658.976483    -1554.137728   \n",
      "2925715       102.955407     -196.884474    -1759.190638      348.946751   \n",
      "3614039     -2556.727124     2575.680478     -494.170054      544.932893   \n",
      "...                  ...             ...             ...             ...   \n",
      "235783       2330.953427     4281.363171     -446.311895     4165.805113   \n",
      "1368458      2301.707672    -2466.315523    -1065.187009     -210.389599   \n",
      "3062847      -335.619158     1549.781642    -1753.005738    -2259.601945   \n",
      "1165482      -273.942291     1190.296111    -2313.955970    -1768.090114   \n",
      "2903833       257.118300     1497.808372     3045.800447    -1443.826442   \n",
      "\n",
      "         proto_number_4  proto_number_5  \n",
      "995784      2152.465777     -516.175697  \n",
      "170580        49.006531    -1147.032832  \n",
      "3141497     3084.312153     2691.891776  \n",
      "2925715    -1524.298072     -217.077808  \n",
      "3614039        1.030381     1307.469355  \n",
      "...                 ...             ...  \n",
      "235783     -1567.485507      662.703154  \n",
      "1368458     -786.081575    -1137.609027  \n",
      "3062847     -221.301255     -181.553482  \n",
      "1165482     2339.657222      719.165066  \n",
      "2903833       15.620436    -2689.444746  \n",
      "\n",
      "[550279 rows x 59 columns]\n",
      "Test Classification Report on Perturbed Data:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS       1.00      1.00      1.00    288931\n",
      "           DoS       1.00      1.00      1.00    247760\n",
      "        Normal       0.02      0.68      0.03        72\n",
      "Reconnaissance       1.00      0.79      0.88     13508\n",
      "         Theft       0.01      1.00      0.02         8\n",
      "\n",
      "      accuracy                           0.99    550279\n",
      "     macro avg       0.60      0.89      0.59    550279\n",
      "  weighted avg       1.00      0.99      1.00    550279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Perturb the test set by adding noise\n",
    "def perturb_data(X, noise_level=0.01):\n",
    "    noise = noise_level * np.random.randn(*X.shape)\n",
    "    print(X + noise)\n",
    "    return X + noise\n",
    "X_test_perturbed = perturb_data(X_test.copy(), noise_level=2000)\n",
    "\n",
    "# Test the model on the perturbed data\n",
    "y_test_perturbed_pred = rf.predict(X_test_perturbed)\n",
    "print(\"Test Classification Report on Perturbed Data:\")\n",
    "print(classification_report(y_test, y_test_perturbed_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
