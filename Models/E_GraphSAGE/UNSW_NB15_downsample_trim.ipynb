{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fb9e1b2-1c5f-49e3-82b4-3bfe52cabad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.UNSW_NB15.UNSW_NB15_config import UNSW_NB15_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal            2218764\n",
      "Generic            215481\n",
      "Exploits            44525\n",
      "Fuzzers             24246\n",
      "DoS                 16353\n",
      "Reconnaissance      13987\n",
      "Analysis             2677\n",
      "Backdoors            2329\n",
      "Shellcode            1511\n",
      "Worms                 174\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    2218764\n",
      "1     321283\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = \"all_raw\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"UNSW_NB15/All/{csv_file_name}.csv\"))\n",
    "\n",
    "DATASET_NAME = \"UNSW_NB15\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = UNSW_NB15_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = UNSW_NB15_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = UNSW_NB15_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = UNSW_NB15_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = UNSW_NB15_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = UNSW_NB15_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = UNSW_NB15_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = UNSW_NB15_Config.TIME_COL_NAMES\n",
    "\n",
    "SOURCE_FILE_ID_COL_NAME = UNSW_NB15_Config.SOURCE_FILE_ID_COL_NAME\n",
    "\n",
    "MULTICLASS = True\n",
    "label_col = ATTACK_CLASS_COL_NAME if MULTICLASS else IS_ATTACK_COL_NAME\n",
    "\n",
    "print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "print(data[IS_ATTACK_COL_NAME].value_counts())\n",
    "\n",
    "if MULTICLASS:\n",
    "    data.drop(columns=[IS_ATTACK_COL_NAME], inplace=True)\n",
    "else:\n",
    "    data.drop(columns=[ATTACK_CLASS_COL_NAME], inplace=True)\n",
    "\n",
    "checkpoint_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, f\"main_window/checkpoints_{csv_file_name}.pth\")\n",
    "best_model_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, f\"main_window/best_model_{csv_file_name}.pth\")\n",
    "\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srcip', 'sport', 'dstip', 'dsport', 'state', 'dur', 'sbytes', 'dbytes',\n",
      "       'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts',\n",
      "       'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth',\n",
      "       'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt', 'Dintpkt',\n",
      "       'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
      "       'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src',\n",
      "       'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm',\n",
      "       'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat', 'source_file_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data.drop(columns=UNSW_NB15_Config.DROP_COLS,inplace=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "# # Combine Port and IP\n",
    "data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "# data[SOURCE_PORT_COL_NAME] = pd.to_numeric(data[SOURCE_PORT_COL_NAME], errors='coerce').fillna(0).astype(int)\n",
    "# data[DESTINATION_PORT_COL_NAME] = pd.to_numeric(data[DESTINATION_PORT_COL_NAME], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5651ef5b-0a9d-4641-aad7-5738092c46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                          srcip                    dstip state        dur  \\\n",
      "0              10.40.182.1_0:0            224.0.0.5_0:0   INT  50.004337   \n",
      "1               10.40.85.1_0:0            224.0.0.5_0:0   INT  50.004341   \n",
      "2              10.40.182.1_0:0            224.0.0.5_0:0   INT  50.004337   \n",
      "3               10.40.85.1_0:0            224.0.0.5_0:0   INT  50.004341   \n",
      "4        192.168.241.243_0:259  192.168.241.243_0:49320   URH   0.000000   \n",
      "...                        ...                      ...   ...        ...   \n",
      "2540042      59.166.0.0_3:2111       149.171.126.5_3:53   CON   0.001035   \n",
      "2540043     59.166.0.5_3:49044    149.171.126.3_3:30639   FIN   0.220630   \n",
      "2540044     59.166.0.6_3:37717    149.171.126.7_3:35667   FIN   0.031576   \n",
      "2540045      59.166.0.2_3:1768    149.171.126.7_3:64122   FIN   0.096835   \n",
      "2540046      59.166.0.9_3:7045       149.171.126.7_3:25   FIN   0.201886   \n",
      "\n",
      "         sbytes  dbytes  sttl  dttl  sloss  dloss  ...  ct_ftp_cmd  \\\n",
      "0           384       0     1     0      0      0  ...         0.0   \n",
      "1           384       0     1     0      0      0  ...         0.0   \n",
      "2           384       0     1     0      0      0  ...         0.0   \n",
      "3           384       0     1     0      0      0  ...         0.0   \n",
      "4          1780       0    64     0      0      0  ...         0.0   \n",
      "...         ...     ...   ...   ...    ...    ...  ...         ...   \n",
      "2540042     146     178    31    29      0      0  ...         NaN   \n",
      "2540043     424    8824    31    29      1      4  ...         NaN   \n",
      "2540044    2646   25564    31    29      7     15  ...         NaN   \n",
      "2540045    4862   82782    31    29      7     36  ...         NaN   \n",
      "2540046   37552    3380    31    29     18      8  ...         NaN   \n",
      "\n",
      "         ct_srv_src  ct_srv_dst  ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  \\\n",
      "0                 2           4           4           2                 2   \n",
      "1                 2           4           4           2                 2   \n",
      "2                 2           4           4           2                 2   \n",
      "3                 2           4           4           2                 2   \n",
      "4                 2           2           2           2                 1   \n",
      "...             ...         ...         ...         ...               ...   \n",
      "2540042           1           3           4           3                 1   \n",
      "2540043           3           3           3           3                 1   \n",
      "2540044           7           6           7           4                 1   \n",
      "2540045           6           6           7           7                 1   \n",
      "2540046           2           2           7           4                 1   \n",
      "\n",
      "         ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  source_file_id  \n",
      "0                       4               2      Normal               0  \n",
      "1                       4               2      Normal               0  \n",
      "2                       4               2      Normal               0  \n",
      "3                       4               2      Normal               0  \n",
      "4                       1               2      Normal               0  \n",
      "...                   ...             ...         ...             ...  \n",
      "2540042                 1               4      Normal               3  \n",
      "2540043                 1               4      Normal               3  \n",
      "2540044                 1               3      Normal               3  \n",
      "2540045                 1               2      Normal               3  \n",
      "2540046                 1               3      Normal               3  \n",
      "\n",
      "[2540047 rows x 45 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb7fb458-ca34-42ca-a8af-f8e1609aff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns = UNSW_NB15_Config.CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(UNSW_NB15_Config.CATEGORICAL_COLS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                          srcip                    dstip        dur  sbytes  \\\n",
      "0              10.40.182.1_0:0            224.0.0.5_0:0  50.004337     384   \n",
      "1               10.40.85.1_0:0            224.0.0.5_0:0  50.004341     384   \n",
      "2              10.40.182.1_0:0            224.0.0.5_0:0  50.004337     384   \n",
      "3               10.40.85.1_0:0            224.0.0.5_0:0  50.004341     384   \n",
      "4        192.168.241.243_0:259  192.168.241.243_0:49320   0.000000    1780   \n",
      "...                        ...                      ...        ...     ...   \n",
      "2540042      59.166.0.0_3:2111       149.171.126.5_3:53   0.001035     146   \n",
      "2540043     59.166.0.5_3:49044    149.171.126.3_3:30639   0.220630     424   \n",
      "2540044     59.166.0.6_3:37717    149.171.126.7_3:35667   0.031576    2646   \n",
      "2540045      59.166.0.2_3:1768    149.171.126.7_3:64122   0.096835    4862   \n",
      "2540046      59.166.0.9_3:7045       149.171.126.7_3:25   0.201886   37552   \n",
      "\n",
      "         dbytes  sttl  dttl  sloss  dloss         Sload  ...  state_INT  \\\n",
      "0             0     1     0      0      0  5.119556e+01  ...       True   \n",
      "1             0     1     0      0      0  5.119556e+01  ...       True   \n",
      "2             0     1     0      0      0  5.119556e+01  ...       True   \n",
      "3             0     1     0      0      0  5.119556e+01  ...       True   \n",
      "4             0    64     0      0      0  1.964095e+02  ...      False   \n",
      "...         ...   ...   ...    ...    ...           ...  ...        ...   \n",
      "2540042     178    31    29      0      0  5.642512e+05  ...      False   \n",
      "2540043    8824    31    29      1      4  1.345239e+04  ...      False   \n",
      "2540044   25564    31    29      7     15  6.544211e+05  ...      False   \n",
      "2540045   82782    31    29      7     36  3.969639e+05  ...      False   \n",
      "2540046    3380    31    29     18      8  1.459438e+06  ...      False   \n",
      "\n",
      "         state_MAS  state_PAR  state_REQ  state_RST  state_TST  state_TXD  \\\n",
      "0            False      False      False      False      False      False   \n",
      "1            False      False      False      False      False      False   \n",
      "2            False      False      False      False      False      False   \n",
      "3            False      False      False      False      False      False   \n",
      "4            False      False      False      False      False      False   \n",
      "...            ...        ...        ...        ...        ...        ...   \n",
      "2540042      False      False      False      False      False      False   \n",
      "2540043      False      False      False      False      False      False   \n",
      "2540044      False      False      False      False      False      False   \n",
      "2540045      False      False      False      False      False      False   \n",
      "2540046      False      False      False      False      False      False   \n",
      "\n",
      "         state_URH  state_URN  state_no  \n",
      "0            False      False     False  \n",
      "1            False      False     False  \n",
      "2            False      False     False  \n",
      "3            False      False     False  \n",
      "4             True      False     False  \n",
      "...            ...        ...       ...  \n",
      "2540042      False      False     False  \n",
      "2540043      False      False     False  \n",
      "2540044      False      False     False  \n",
      "2540045      False      False     False  \n",
      "2540046      False      False     False  \n",
      "\n",
      "[2540047 rows x 60 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "data.fillna(0,inplace = True)\n",
    "data.drop(columns=['index'],inplace=True)\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1df5c4c-70a2-4566-ae5e-ee3dcc6037a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                dur        sbytes        dbytes          sttl          dttl  \\\n",
      "count  2.540047e+06  2.540047e+06  2.540047e+06  2.540047e+06  2.540047e+06   \n",
      "mean   6.587916e-01  4.339600e+03  3.642759e+04  6.278197e+01  3.076681e+01   \n",
      "std    1.392493e+01  5.640599e+04  1.610960e+05  7.462277e+01  4.285089e+01   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    1.037000e-03  2.000000e+02  1.780000e+02  3.100000e+01  2.900000e+01   \n",
      "50%    1.586100e-02  1.470000e+03  1.820000e+03  3.100000e+01  2.900000e+01   \n",
      "75%    2.145545e-01  3.182000e+03  1.489400e+04  3.100000e+01  2.900000e+01   \n",
      "max    8.786638e+03  1.435577e+07  1.465753e+07  2.550000e+02  2.540000e+02   \n",
      "\n",
      "              sloss         dloss         Sload         Dload         Spkts  \\\n",
      "count  2.540047e+06  2.540047e+06  2.540047e+06  2.540047e+06  2.540047e+06   \n",
      "mean   5.163921e+00  1.632944e+01  3.695645e+07  2.450861e+06  3.328884e+01   \n",
      "std    2.251707e+01  5.659474e+01  1.186043e+08  4.224863e+06  7.628388e+01   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    0.000000e+00  0.000000e+00  1.353963e+05  1.191594e+04  2.000000e+00   \n",
      "50%    3.000000e+00  4.000000e+00  5.893038e+05  5.893179e+05  1.200000e+01   \n",
      "75%    7.000000e+00  1.400000e+01  2.039923e+06  2.925974e+06  4.400000e+01   \n",
      "max    5.319000e+03  5.507000e+03  5.988000e+09  1.287619e+08  1.064600e+04   \n",
      "\n",
      "       ...  ct_flw_http_mthd  is_ftp_login    ct_ftp_cmd    ct_srv_src  \\\n",
      "count  ...      2.540047e+06  2.540047e+06  2.540047e+06  2.540047e+06   \n",
      "mean   ...      1.100779e-01  1.735125e-02  9.320300e-03  9.206988e+00   \n",
      "std    ...      5.564195e-01  1.334571e-01  9.997025e-02  1.083676e+01   \n",
      "min    ...      0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00   \n",
      "25%    ...      0.000000e+00  0.000000e+00  0.000000e+00  2.000000e+00   \n",
      "50%    ...      0.000000e+00  0.000000e+00  0.000000e+00  5.000000e+00   \n",
      "75%    ...      0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+01   \n",
      "max    ...      3.600000e+01  4.000000e+00  4.000000e+00  6.700000e+01   \n",
      "\n",
      "         ct_srv_dst    ct_dst_ltm    ct_src_ltm  ct_src_dport_ltm  \\\n",
      "count  2.540047e+06  2.540047e+06  2.540047e+06      2.540047e+06   \n",
      "mean   8.988958e+00  6.439103e+00  6.900986e+00      4.642139e+00   \n",
      "std    1.082249e+01  8.162034e+00  8.205062e+00      8.477579e+00   \n",
      "min    1.000000e+00  1.000000e+00  1.000000e+00      1.000000e+00   \n",
      "25%    2.000000e+00  2.000000e+00  2.000000e+00      1.000000e+00   \n",
      "50%    5.000000e+00  3.000000e+00  4.000000e+00      1.000000e+00   \n",
      "75%    1.000000e+01  6.000000e+00  7.000000e+00      2.000000e+00   \n",
      "max    6.700000e+01  6.700000e+01  6.700000e+01      6.700000e+01   \n",
      "\n",
      "       ct_dst_sport_ltm  ct_dst_src_ltm  \n",
      "count      2.540047e+06    2.540047e+06  \n",
      "mean       3.592729e+00    6.845886e+00  \n",
      "std        6.174445e+00    1.125828e+01  \n",
      "min        1.000000e+00    1.000000e+00  \n",
      "25%        1.000000e+00    1.000000e+00  \n",
      "50%        1.000000e+00    2.000000e+00  \n",
      "75%        1.000000e+00    5.000000e+00  \n",
      "max        6.000000e+01    6.700000e+01  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "cols_to_norm = UNSW_NB15_Config.COLS_TO_NORM\n",
    "print(data[cols_to_norm].describe()) # Check if there's any too large value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All other columns processed successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_numeric_issues(df, cols_to_norm):\n",
    "    for col in cols_to_norm:\n",
    "        try:\n",
    "            # Try to coerce to numeric\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Try to clip the column\n",
    "            df[col] = df[col].clip(lower=-1e9, upper=1e9)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "            print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Data type: {df[col].dtype}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "check_numeric_issues(data, UNSW_NB15_Config.COLS_TO_NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37256006-abc1-44aa-8e74-46d05dc6ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cols_to_norm] = scaler.fit_transform(data[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analysis' 'Backdoors' 'DoS' 'Exploits' 'Fuzzers' 'Generic' 'Normal'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Attack label mapping: {'Analysis': 0, 'Backdoors': 1, 'DoS': 2, 'Exploits': 3, 'Fuzzers': 4, 'Generic': 5, 'Normal': 6, 'Reconnaissance': 7, 'Shellcode': 8, 'Worms': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "num_classes = 2\n",
    "class_map = [0, 1]\n",
    "if MULTICLASS:\n",
    "    le = LabelEncoder()\n",
    "    attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "    class_map = le.classes_\n",
    "    print(class_map)\n",
    "    print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "    data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "    num_classes = len(class_map)\n",
    "    class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'state_ACC', 'state_CLO', 'state_CON', 'state_ECO', 'state_ECR', 'state_FIN', 'state_INT', 'state_MAS', 'state_PAR', 'state_REQ', 'state_RST', 'state_TST', 'state_TXD', 'state_URH', 'state_URN', 'state_no']\n",
      "Number of Features: 54\n"
     ]
    }
   ],
   "source": [
    "# # Maintain the order of the rows in the original dataframe\n",
    "\n",
    "feature_cols = UNSW_NB15_Config.COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "print('Feature Columns:', feature_cols)\n",
    "num_features = len(feature_cols)\n",
    "print('Number of Features:', num_features)\n",
    "\n",
    "data['h'] = data[ feature_cols ].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "743e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df):\n",
    "\n",
    "    G_nx = nx.from_pandas_edgelist(df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    return G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38a1bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_graph_with_normal_traffic(df, build_graph_func, ratio=1):\n",
    "    # If contains_labels only contains benign class, it have a 90% chance of trimming \n",
    "    if random.random() < ratio:\n",
    "        labels = df[label_col].values\n",
    "        is_attack = labels != le.transform([BENIGN_CLASS_NAME])[0]\n",
    "        \n",
    "        first_attack_idx = np.argmax(is_attack)\n",
    "        last_attack_idx = len(is_attack) - np.argmax(is_attack[::-1]) - 1\n",
    "\n",
    "        original_len = len(df)\n",
    "        df_trimmed = df.iloc[first_attack_idx:last_attack_idx + 1]\n",
    "        g = build_graph_func(df_trimmed)\n",
    "        num_dropped = original_len - len(df_trimmed)\n",
    "        return g, num_dropped\n",
    "    \n",
    "    g = build_graph_func(df)\n",
    "    return g, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e650028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class StratifiedGraphDataset:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.total_count = len(self.y)\n",
    "\n",
    "        # Compute class weights\n",
    "        labels = []\n",
    "\n",
    "        for graph in self.X:\n",
    "            labels.append(graph.edge_label.tolist())\n",
    "\n",
    "        labels = np.concatenate(labels)\n",
    "\n",
    "        self.class_counts = Counter(labels)\n",
    "\n",
    "        # Compute the class weights\n",
    "        self.class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "\n",
    "    def k_fold_split(self, k: int = 5, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        cv = MultilabelStratifiedShuffleSplit(test_size=test_ratio, random_state=random_state, n_splits=k)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        y_binary = mlb.fit_transform(self.y)\n",
    "\n",
    "        return cv.split(np.zeros(len(self.X)), y_binary)\n",
    "\n",
    "    def graph_train_test_split(self, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        train_idx, test_idx = next(self.k_fold_split(k = 1, test_ratio = test_ratio, random_state = random_state))\n",
    "        \n",
    "        X_train = [self.X[i] for i in train_idx]\n",
    "        X_test = [self.X[i] for i in test_idx]\n",
    "\n",
    "        y_train = [self.y[i] for i in train_idx]\n",
    "        y_test = [self.y[i] for i in test_idx]\n",
    "\n",
    "        return StratifiedGraphDataset(X_train, y_train), StratifiedGraphDataset(X_test, y_test)\n",
    "    \n",
    "    def print_class_distribution_and_weights(self):\n",
    "        # Use the label encoder to inverse transform the class labels\n",
    "        class_counts_named = {le.inverse_transform([cls])[0]: count for cls, count in self.class_counts.items()}\n",
    "        class_weights_named = {le.inverse_transform([cls])[0]: weight for cls, weight in enumerate(self.class_weights)}\n",
    "        print(\"Class Counts and Weights:\")\n",
    "        for class_name in class_counts_named.keys():\n",
    "            count = class_counts_named[class_name]\n",
    "            weight = class_weights_named[class_name]\n",
    "            print(f\"  {class_name:<15}: Count = {count:<10}, Weight = {weight:<10.4f}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_count\n",
    "\n",
    "    def __iter__(self):\n",
    "        for g in self.X:\n",
    "            yield g\n",
    "\n",
    "\n",
    "def generate_graph_datasets(\n",
    "    df: pd.DataFrame, \n",
    "    window_size: int = 50, \n",
    "    overlap_ratio: float = 0.5, \n",
    "    time_cols=[SOURCE_FILE_ID_COL_NAME] + TIME_COLS + [ATTACK_CLASS_COL_NAME], \n",
    "    label_col=label_col,\n",
    "    build_graph_func=create_graph,\n",
    "    drop_func=trim_graph_with_normal_traffic):\n",
    "\n",
    "    print(\"Feature Columns\", df.columns)\n",
    "    print(\"Time Columns\", time_cols)\n",
    "    assert all(col in df.columns for col in time_cols), \"All timestamp columns are required\"\n",
    "    assert label_col in df.columns, \"Edge label column 'label' is required\"\n",
    "    \n",
    "    df = df.sort_values(time_cols).reset_index(drop=True)\n",
    "    # df.drop(columns=time_cols, inplace=True)\n",
    "    window_size = window_size\n",
    "    stride = int(window_size * (1 - overlap_ratio))\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    progress_bar = tqdm(range(0, len(df), stride), desc=f\"Generating graphs\")\n",
    "\n",
    "    num_dropped_samples = 0\n",
    "    dropped_samples = 0\n",
    "    for start in progress_bar:\n",
    "        window_df = df.iloc[start: min(start + window_size, len(df))]\n",
    "\n",
    "        window_df = df.iloc[start: start + window_size]\n",
    "        contains_label = window_df[label_col].unique()\n",
    "\n",
    "        if drop_func is not None:\n",
    "            G_pyg, dropped_samples = drop_func(window_df, build_graph_func)\n",
    "            num_dropped_samples += dropped_samples\n",
    "\n",
    "        else:\n",
    "            G_pyg = build_graph_func(window_df)\n",
    "\n",
    "        progress_bar.set_postfix(dropped=num_dropped_samples)\n",
    "\n",
    "        X.append(G_pyg)\n",
    "        y.append(contains_label.tolist())\n",
    "        \n",
    "        \n",
    "    print(f\"Number of Dropped Samples: {num_dropped_samples}\")\n",
    "\n",
    "    return StratifiedGraphDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "491e7421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns Index(['srcip', 'dstip', 'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss',\n",
      "       'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb',\n",
      "       'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit',\n",
      "       'Djit', 'Stime', 'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack',\n",
      "       'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm',\n",
      "       'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'attack_cat', 'source_file_id', 'state_ACC', 'state_CLO', 'state_CON',\n",
      "       'state_ECO', 'state_ECR', 'state_FIN', 'state_INT', 'state_MAS',\n",
      "       'state_PAR', 'state_REQ', 'state_RST', 'state_TST', 'state_TXD',\n",
      "       'state_URH', 'state_URN', 'state_no', 'h'],\n",
      "      dtype='object')\n",
      "Time Columns ['source_file_id', 'Stime', 'Ltime', 'attack_cat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating graphs: 100%|██████████| 50801/50801 [03:10<00:00, 266.23it/s, dropped=793398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dropped Samples: 793398\n"
     ]
    }
   ],
   "source": [
    "graph_dataset = generate_graph_datasets(data, overlap_ratio=0)\n",
    "train_graph_dataset, test_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "365fd330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 43180\n",
      "Number of testing graphs: 7621\n",
      "Class Counts and Weights:\n",
      "  Reconnaissance : Count = 13987     , Weight = 12.4877   \n",
      "  Normal         : Count = 1425366   , Weight = 0.1225    \n",
      "  Exploits       : Count = 44525     , Weight = 3.9229    \n",
      "  DoS            : Count = 16353     , Weight = 10.6809   \n",
      "  Generic        : Count = 215481    , Weight = 0.8106    \n",
      "  Shellcode      : Count = 1511      , Weight = 115.5956  \n",
      "  Fuzzers        : Count = 24246     , Weight = 7.2039    \n",
      "  Worms          : Count = 174       , Weight = 1003.8213 \n",
      "  Backdoors      : Count = 2329      , Weight = 74.9957   \n",
      "  Analysis       : Count = 2677      , Weight = 65.2465   \n",
      "Class Counts and Weights:\n",
      "  Reconnaissance : Count = 11912     , Weight = 12.4690   \n",
      "  Normal         : Count = 1212305   , Weight = 0.1225    \n",
      "  Exploits       : Count = 38013     , Weight = 3.9074    \n",
      "  DoS            : Count = 13733     , Weight = 10.8156   \n",
      "  Generic        : Count = 183054    , Weight = 0.8114    \n",
      "  Shellcode      : Count = 1282      , Weight = 115.8582  \n",
      "  Fuzzers        : Count = 20617     , Weight = 7.2043    \n",
      "  Worms          : Count = 148       , Weight = 1003.5824 \n",
      "  Backdoors      : Count = 1960      , Weight = 75.7807   \n",
      "  Analysis       : Count = 2278      , Weight = 65.2020   \n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training graphs:\", len(train_graph_dataset))\n",
    "print(\"Number of testing graphs:\", len(test_graph_dataset))\n",
    "\n",
    "graph_dataset.print_class_distribution_and_weights()\n",
    "train_graph_dataset.print_class_distribution_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3428d9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing graphs: 7621\n",
      "Class weights: [6.52020193e+01 7.57807143e+01 1.08155683e+01 3.90735275e+00\n",
      " 7.20425862e+00 8.11401007e-01 1.22518838e-01 1.24689557e+01\n",
      " 1.15858190e+02 1.00358243e+03]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Debugging the dataset generation process.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of testing graphs:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_graph_dataset))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClass weights:\u001b[39m\u001b[33m\"\u001b[39m, train_graph_dataset.class_weights)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDebugging the dataset generation process.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Debugging the dataset generation process."
     ]
    }
   ],
   "source": [
    "print(\"Number of testing graphs:\", len(test_graph_dataset))\n",
    "\n",
    "print(\"Class weights:\", train_graph_dataset.class_weights)\n",
    "\n",
    "raise ValueError(\"Debugging the dataset generation process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with learning rate: 0.005, hidden_dim: 256\n",
      "Fold 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CLASS_WEIGHTS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 109\u001b[39m\n\u001b[32m    106\u001b[39m learning_rates = [\u001b[32m0.005\u001b[39m]\n\u001b[32m    107\u001b[39m hidden_dims = [\u001b[32m256\u001b[39m, \u001b[32m512\u001b[39m, \u001b[32m1024\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_graph_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mgrid_search\u001b[39m\u001b[34m(graph_dataset, epochs, learning_rates, hidden_dims, folds)\u001b[39m\n\u001b[32m     34\u001b[39m model.apply(init_weights)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Normalize to stabilize training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m class_weights = th.FloatTensor(\u001b[43mCLASS_WEIGHTS\u001b[49m).to(device)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClass weights:\u001b[39m\u001b[33m\"\u001b[39m, class_weights)\n\u001b[32m     40\u001b[39m criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
      "\u001b[31mNameError\u001b[39m: name 'CLASS_WEIGHTS' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def grid_search(graph_dataset, epochs, learning_rates, hidden_dims, folds=3):\n",
    "    global CLASS_WEIGHTS\n",
    "    global num_features\n",
    "    \n",
    "    best_params = {}\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Precompute the train and validation graphs for all folds\n",
    "    folds_list = []\n",
    "    for i in range(folds):\n",
    "        train_graph_dataset, val_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=i)\n",
    "        folds_list.append((train_graph_dataset, val_graph_dataset))\n",
    "\n",
    "    params_results = {}\n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}\")\n",
    "            fold_f1_scores = []\n",
    "\n",
    "            for fold, (train_graph_dataset, val_graph_dataset) in enumerate(folds_list):\n",
    "                print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                model = EGraphSAGE(node_in_channels=num_features,\n",
    "                                   edge_in_channels=num_features,\n",
    "                                   hidden_channels=hidden_dim,\n",
    "                                   out_channels=num_classes).to(device)\n",
    "\n",
    "                model.apply(init_weights)\n",
    "\n",
    "                # Normalize to stabilize training\n",
    "                class_weights = th.FloatTensor(CLASS_WEIGHTS).to(device)\n",
    "                print(\"Class weights:\", class_weights)\n",
    "\n",
    "                criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "\n",
    "                for epoch in range(epochs):\n",
    "                    try:\n",
    "                        total_train_loss = 0\n",
    "                        total_val_loss = 0\n",
    "\n",
    "                        model.train()\n",
    "                        for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "                            G_pyg_train = G_pyg_train.to(device)\n",
    "\n",
    "                            G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                            G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "                            \n",
    "                            out = model(G_pyg_train)\n",
    "                            loss = criterion(out, G_pyg_train.edge_label)\n",
    "                            total_train_loss += loss.item()\n",
    "\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "\n",
    "                            optimizer.step()\n",
    "                        \n",
    "                        model.eval()\n",
    "                        total_f1 = 0\n",
    "                        with th.no_grad():\n",
    "                            for G_pyg_val in tqdm(val_graph_dataset, desc=\"Validation\", leave=False):\n",
    "\n",
    "                                G_pyg_val.to(device)\n",
    "                                G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                                G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                                out = model(G_pyg_val)\n",
    "                                loss = criterion(out, G_pyg_val.edge_label)\n",
    "                                total_val_loss += loss.item()\n",
    "\n",
    "                                total_f1 += f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='weighted')\n",
    "\n",
    "                        avg_f1 = total_f1 / len(val_graph_dataset)\n",
    "                        if avg_f1 > best_epoch_f1:\n",
    "                            best_epoch_f1 = avg_f1  # Update the best F1 score for this fold\n",
    "                            print(f\"Best F1 Score at epoch {epoch}: {best_epoch_f1:.4f}, Train Loss: {total_train_loss:.4f}, Validation Loss: {total_val_loss:.4f}, Parameters: lr={lr}, hidden_dim{hidden_dim}\")\n",
    "\n",
    "                        print(f'Epoch {epoch}, Train Loss: {total_train_loss:.4f}, Validation Loss: {total_val_loss:.4f}, Validation F1: {avg_f1:.4f}')\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                        break\n",
    "\n",
    "                fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "            \n",
    "            avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "            params_results[(lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "            print(f\"Average F1 Score for learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "            if avg_f1 > best_f1:\n",
    "                best_f1 = avg_f1\n",
    "                best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim}\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "    print(\"All results:\", params_results)\n",
    "\n",
    "\n",
    "learning_rates = [0.005]\n",
    "hidden_dims = [256, 512, 1024]\n",
    "\n",
    "grid_search(train_graph_dataset, epochs=10, learning_rates=learning_rates, hidden_dims=hidden_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train graphs:  231\n",
      "Class weights: tensor([1.8445e+01, 2.7509e+01, 9.2468e+01, 3.0195e+00, 1.1090e+00, 2.0365e+00,\n",
      "        2.2915e-01, 2.2255e-01, 3.5303e+00, 3.2679e+01, 2.8378e+02],\n",
      "       device='cuda:0')\n",
      "Resumed training from epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/231 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 205.85997266638515\n",
      "Epoch 2, Loss: 205.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 198.5308462749963\n",
      "Epoch 3, Loss: 198.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 190.5529824016021\n",
      "Epoch 4, Loss: 190.5530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 187.81704581041186\n",
      "Epoch 5, Loss: 187.8170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 182.94741404174601\n",
      "Epoch 6, Loss: 182.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 181.86611750505693\n",
      "Epoch 7, Loss: 181.8661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 177.8723961001374\n",
      "Epoch 8, Loss: 177.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 178.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 173.689441958702\n",
      "Epoch 10, Loss: 173.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 171.77075338117638\n",
      "Epoch 11, Loss: 171.7708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 170.24774501076342\n",
      "Epoch 12, Loss: 170.2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 168.90820198744325\n",
      "Epoch 13, Loss: 168.9082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 164.93952312786388\n",
      "Epoch 14, Loss: 164.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 162.7693509720039\n",
      "Epoch 15, Loss: 162.7694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 161.92309366298161\n",
      "Epoch 16, Loss: 161.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 164.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 161.3563362832986\n",
      "Epoch 18, Loss: 161.3563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 157.84928398214146\n",
      "Epoch 19, Loss: 157.8493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 154.13038092648318\n",
      "Epoch 20, Loss: 154.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 155.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 154.6428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 152.1936210675257\n",
      "Epoch 23, Loss: 152.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 149.3834681076325\n",
      "Epoch 24, Loss: 149.3835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 150.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 151.4116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 149.9590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 145.69245694624283\n",
      "Epoch 28, Loss: 145.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 144.16323033155112\n",
      "Epoch 29, Loss: 144.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 145.7490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 142.42284342605748\n",
      "Epoch 31, Loss: 142.4228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 140.4948887602967\n",
      "Epoch 32, Loss: 140.4949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 138.9841586634858\n",
      "Epoch 33, Loss: 138.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 139.2231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 136.1045540743787\n",
      "Epoch 35, Loss: 136.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 142.3975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 134.96302094593423\n",
      "Epoch 37, Loss: 134.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 136.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 134.39009580527105\n",
      "Epoch 39, Loss: 134.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 134.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 133.24340115670532\n",
      "Epoch 41, Loss: 133.2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 130.24287296859242\n",
      "Epoch 42, Loss: 130.2429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 130.3389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 149.7709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 134.5361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 129.77003862615763\n",
      "Epoch 46, Loss: 129.7700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 128.02166829517768\n",
      "Epoch 47, Loss: 128.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 126.94937335503266\n",
      "Epoch 48, Loss: 126.9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 126.05136575173641\n",
      "Epoch 49, Loss: 126.0514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 124.60657049660281\n",
      "Epoch 50, Loss: 124.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Loss: 132.4133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Loss: 128.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Loss: 126.4392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 123.99367274388982\n",
      "Epoch 54, Loss: 123.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 123.94449099977308\n",
      "Epoch 55, Loss: 123.9445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 123.31996661040067\n",
      "Epoch 56, Loss: 123.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 123.23184221528486\n",
      "Epoch 57, Loss: 123.2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Loss: 123.8234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 122.74235260021553\n",
      "Epoch 59, Loss: 122.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss: 123.8818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Loss: 124.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Loss: 123.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Loss: 123.1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 121.72864008365742\n",
      "Epoch 64, Loss: 121.7286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Loss: 129.6205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Loss: 122.5817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Loss: 122.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 120.86050204053112\n",
      "Epoch 68, Loss: 120.8605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 119.92221228322987\n",
      "Epoch 69, Loss: 119.9222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Loss: 120.6253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Loss: 120.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Loss: 120.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 119.61392538402963\n",
      "Epoch 73, Loss: 119.6139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Loss: 120.5759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 118.46795713229801\n",
      "Epoch 75, Loss: 118.4680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Loss: 119.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 116.72479962429064\n",
      "Epoch 77, Loss: 116.7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 116.15532604922359\n",
      "Epoch 78, Loss: 116.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Loss: 119.4063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Loss: 121.9028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Loss: 116.9083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Loss: 118.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Loss: 119.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 115.19917683588221\n",
      "Epoch 84, Loss: 115.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 114.16575751947828\n",
      "Epoch 85, Loss: 114.1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 113.37052055385264\n",
      "Epoch 86, Loss: 113.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Loss: 114.2373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Loss: 115.5538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Loss: 114.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Loss: 115.1920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 112.96326940480972\n",
      "Epoch 91, Loss: 112.9633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Loss: 116.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, Loss: 114.3252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 112.47395187413515\n",
      "Epoch 94, Loss: 112.4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model. Lowest Loss: 111.566766040054\n",
      "Epoch 95, Loss: 111.5668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, Loss: 115.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Loss: 113.2589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, Loss: 113.5656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Loss: 112.0957\n",
      "Model training completed and saved.\n"
     ]
    }
   ],
   "source": [
    "# Extract the best parameters from the grid search\n",
    "best_hidden_dim = 256  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.001  # Replace with the best learning_rate found\n",
    "\n",
    "print(\"Number of train graphs: \", len(train_graph_dataset))\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "model = EGraphSAGE(node_in_channels=num_features, \n",
    "                   edge_in_channels=num_features,\n",
    "                   hidden_channels=best_hidden_dim,\n",
    "                   out_channels=num_classes).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Normalize class weights\n",
    "class_weights = th.FloatTensor(CLASS_WEIGHTS).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "\n",
    "lowest_loss = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "# Load checkpoint if exists\n",
    "start_epoch = 0\n",
    "epochs = 100\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    lowest_loss = checkpoint['lowest_loss']\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "        # Move the graph data to the device\n",
    "        G_pyg_train = G_pyg_train.to(device)\n",
    "        G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "        G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(G_pyg_train)\n",
    "        loss = criterion(out, G_pyg_train.edge_label)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save the best model based on the lowest loss\n",
    "    if total_loss < lowest_loss:  # Here, lowest_loss is used to track the lowest loss\n",
    "        lowest_loss = total_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        th.save(best_model_state, best_model_path)\n",
    "        print(\"Saved best model. Lowest Loss:\", lowest_loss)\n",
    "\n",
    "    print(f'Epoch {epoch}, Loss: {total_loss:.4f}')\n",
    "\n",
    "    # Save checkpoint\n",
    "    th.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lowest_loss': lowest_loss\n",
    "    }, checkpoint_path)\n",
    "\n",
    "# Save the trained model\n",
    "print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70243f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train graphs:  231\n",
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/UNSW_NB15/main_window/best_model_all_raw_downsampled.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  23%|██▎       | 53/231 [00:00<00:00, 528.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8888\n",
      "[[   506   1292    242     76      5      1      0      0      3      8\n",
      "       2]\n",
      " [     1   1387      0     15     12      7      0      0     10     33\n",
      "      22]\n",
      " [     0     15    263      5      3      5      0      0      1      2\n",
      "       5]\n",
      " [    26   9698    280    907   1279    150     26      0    178    375\n",
      "     869]\n",
      " [   233  12275    562   1223  15131    609     16      0   1016    902\n",
      "    5515]\n",
      " [    27   1482    494    100    114  17270      5      0     33     41\n",
      "     765]\n",
      " [    95   1539     10    242   1335    173 179408      1    149    212\n",
      "    1032]\n",
      " [   251     17      0      6     99   2114      2 186360     62     31\n",
      "      54]\n",
      " [    23   1714     12    112    531     86      5      0   8201    245\n",
      "     924]\n",
      " [     0     86      0      0      8     33      0      0     72   1054\n",
      "      29]\n",
      " [     1      0      0      1     15      5      0      0      1      2\n",
      "     126]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.4351    0.2370    0.3069      2135\n",
      "      Backdoor     0.0470    0.9328    0.0895      1487\n",
      "     Backdoors     0.1412    0.8796    0.2433       299\n",
      "           DoS     0.3376    0.0658    0.1101     13788\n",
      "      Exploits     0.8165    0.4037    0.5403     37482\n",
      "       Fuzzers     0.8444    0.8494    0.8469     20331\n",
      "       Generic     0.9997    0.9740    0.9867    184196\n",
      "        Normal     1.0000    0.9861    0.9930    188996\n",
      "Reconnaissance     0.8432    0.6919    0.7601     11853\n",
      "     Shellcode     0.3628    0.8222    0.5035      1282\n",
      "         Worms     0.0135    0.8344    0.0265       151\n",
      "\n",
      "      accuracy                         0.8888    462000\n",
      "     macro avg     0.5310    0.6979    0.4915    462000\n",
      "  weighted avg     0.9460    0.8888    0.9067    462000\n",
      "\n",
      "Number of test graphs:  41\n",
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/UNSW_NB15/main_window/best_model_all_raw_downsampled.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8712\n",
      "[[  106   208   226     0     0     2     0     0     0     0     0]\n",
      " [    4   277     0     1     8     5     0     0     1     4     8]\n",
      " [    0     6   228     0     1     0     0     0     0     0     0]\n",
      " [   29  1712   229    80   225    50     0     0    31    59   150]\n",
      " [   88  2179   458    69  2717   141     3     0   151   173  1064]\n",
      " [   16   258   452    50    30  2887     1     0     0    10   211]\n",
      " [   13   255     1    22   255    39 30430     0    19    46   205]\n",
      " [   59     1     0     2    16   418     1 32366     2     6     9]\n",
      " [    8   366     2     6   101    12     1     0  1423    52   163]\n",
      " [    0    15     0     1     0    10     0     0    13   186     4]\n",
      " [    0     2     0     0     8     3     0     0     1     0     9]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.3282    0.1956    0.2451       542\n",
      "      Backdoor     0.0525    0.8994    0.0992       308\n",
      "     Backdoors     0.1429    0.9702    0.2490       235\n",
      "           DoS     0.3463    0.0312    0.0572      2565\n",
      "      Exploits     0.8084    0.3858    0.5223      7043\n",
      "       Fuzzers     0.8094    0.7374    0.7717      3915\n",
      "       Generic     0.9998    0.9727    0.9861     31285\n",
      "        Normal     1.0000    0.9844    0.9921     32880\n",
      "Reconnaissance     0.8672    0.6668    0.7539      2134\n",
      "     Shellcode     0.3470    0.8122    0.4863       229\n",
      "         Worms     0.0049    0.3913    0.0098        23\n",
      "\n",
      "      accuracy                         0.8712     81159\n",
      "     macro avg     0.5188    0.6406    0.4702     81159\n",
      "  weighted avg     0.9373    0.8712    0.8903     81159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(dataset, adversarial=False):\n",
    "\n",
    "    best_model = EGraphSAGE(node_in_channels=num_features, \n",
    "                       edge_in_channels=num_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=num_classes).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path, weights_only=True))\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "        all_pred_logits = []\n",
    "        all_test_labels = []\n",
    "        for G_pyg in tqdm(dataset, desc=\"Evaluation\", leave=False):\n",
    "            try:\n",
    "                # Move the graph data to the device\n",
    "                G_pyg = G_pyg.to(device)\n",
    "                G_pyg.edge_label = G_pyg.edge_label.to(device)\n",
    "                G_pyg.edge_attr = G_pyg.edge_attr.to(device)\n",
    "                out = best_model(G_pyg)\n",
    "                \n",
    "            except Exception as forward_error:\n",
    "                print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "            all_pred_logits.append(out.cpu())\n",
    "            all_test_labels.append(G_pyg.edge_label.cpu())\n",
    "\n",
    "        all_pred_logits = th.cat(all_pred_logits).to(device)\n",
    "        all_test_labels = th.cat(all_test_labels).to(device)\n",
    "        test_accuracy = compute_accuracy(all_pred_logits, all_test_labels)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "        pred_labels = all_pred_logits.argmax(dim=1).cpu()\n",
    "        all_test_labels = all_test_labels.cpu()\n",
    "    \n",
    "    global class_map\n",
    "    class_map_2 = class_map\n",
    "    if adversarial:\n",
    "        class_map_2 = np.append(class_map, \"Adversarial\")\n",
    "\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map_2)))\n",
    "    print(cm)\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map_2, digits=4)\n",
    "    print(report)\n",
    "\n",
    "print(\"Number of train graphs: \", len(train_graph_dataset))\n",
    "eval(train_graph_dataset)\n",
    "print(\"Number of test graphs: \", len(test_graph_dataset))\n",
    "eval(test_graph_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
