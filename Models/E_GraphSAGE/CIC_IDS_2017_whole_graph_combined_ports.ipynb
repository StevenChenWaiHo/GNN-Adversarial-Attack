{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fb9e1b2-1c5f-49e3-82b4-3bfe52cabad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====Experiment=====\n",
    "Dataset: CIC-IDS-2017 dataset\n",
    "\n",
    "Training with whole graph\n",
    "Downsampled 90% normal traffic randomly\n",
    "Split train and test randomly\n",
    "\n",
    "Combined IP and Port features\n",
    "'''\n",
    "\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.CIC_IDS_2017.CIC_IDS_2017_config import CIC_IDS_2017_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "DoS Hulk                      231073\n",
      "BENIGN                        227310\n",
      "PortScan                      158930\n",
      "DDoS                          128027\n",
      "DoS GoldenEye                  10293\n",
      "FTP-Patator                     7938\n",
      "SSH-Patator                     5897\n",
      "DoS slowloris                   5796\n",
      "DoS Slowhttptest                5499\n",
      "Bot                             1966\n",
      "Web Attack - Brute Force        1507\n",
      "Web Attack - XSS                 652\n",
      "Infiltration                      36\n",
      "Web Attack - Sql Injection        21\n",
      "Heartbleed                        11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = \"all_downsampled\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"CIC_IDS_2017/All/{csv_file_name}.csv\"))\n",
    "\n",
    "DATASET_NAME = \"CIC_IDS_2017\"\n",
    "EXPERIMENT_NAME = \"whole_graph_combined_ports\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = CIC_IDS_2017_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = CIC_IDS_2017_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = CIC_IDS_2017_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = CIC_IDS_2017_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = CIC_IDS_2017_Config.ATTACK_CLASS_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = CIC_IDS_2017_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = CIC_IDS_2017_Config.TIME_COL_NAMES\n",
    "\n",
    "print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "\n",
    "MULTICLASS = True\n",
    "\n",
    "label_col = ATTACK_CLASS_COL_NAME\n",
    "\n",
    "saves_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "checkpoint_path = os.path.join(saves_path, f\"checkpoints_{csv_file_name}.pth\")\n",
    "best_model_path = os.path.join(saves_path, f\"best_model_{csv_file_name}.pth\")\n",
    "\n",
    "os.makedirs(saves_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Flow ID', 'Source IP', 'Source Port', 'Destination IP',\n",
      "       'Destination Port', 'Protocol', 'Timestamp', 'Flow Duration',\n",
      "       'Total Length of Fwd Packets', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Std', 'Flow Packets/s', 'Flow IAT Mean',\n",
      "       'Flow IAT Std', 'Flow IAT Min', 'Fwd IAT Min', 'Bwd IAT Mean',\n",
      "       'Fwd PSH Flags', 'SYN Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
      "       'Average Packet Size', 'Fwd Header Length.1', 'Subflow Fwd Packets',\n",
      "       'Subflow Fwd Bytes', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
      "       'Active Mean', 'Active Min', 'Label', 'source_file_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data.drop(columns=CIC_IDS_2017_Config.DROP_COLS,inplace=True)\n",
    "data.drop(columns=CIC_IDS_2017_Config.TIME_COL_NAMES)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "# # Combine Port and IP\n",
    "data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "data = pd.get_dummies(data, columns = CIC_IDS_2017_Config.CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CIC_IDS_2017_Config.CATEGORICAL_COLS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5651ef5b-0a9d-4641-aad7-5738092c46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                          Flow ID              Source IP  \\\n",
      "0        192.168.10.14-23.208.79.179-51174-443-6  192.168.10.14_4:51174   \n",
      "1           192.168.10.5-72.247.71.12-53469-80-6      72.247.71.12_7:80   \n",
      "2       192.168.10.17-104.19.194.102-58257-443-6  192.168.10.17_4:58257   \n",
      "3          192.168.10.8-93.184.215.13-58377-80-6   192.168.10.8_4:58377   \n",
      "4        192.168.10.12-34.198.61.240-40382-443-6    34.198.61.240_1:443   \n",
      "...                                          ...                    ...   \n",
      "784951      172.16.0.1-192.168.10.50-42006-445-6     172.16.0.1_7:42006   \n",
      "784952       172.16.0.1-192.168.10.50-57546-80-6     172.16.0.1_7:57546   \n",
      "784953      172.16.0.1-192.168.10.50-49768-139-6     172.16.0.1_7:49768   \n",
      "784954     172.16.0.1-192.168.10.50-44870-2000-6     172.16.0.1_7:44870   \n",
      "784955       172.16.0.1-192.168.10.50-57546-80-6     172.16.0.1_7:57546   \n",
      "\n",
      "               Destination IP            Timestamp  Flow Duration  \\\n",
      "0         23.208.79.179_4:443       5/7/2017 10:09        5796235   \n",
      "1        192.168.10.5_7:53469        7/7/2017 2:11             30   \n",
      "2        104.19.194.102_4:443        5/7/2017 2:04      117057923   \n",
      "3          93.184.215.13_4:80        5/7/2017 2:36         600037   \n",
      "4       192.168.10.12_1:40382  03/07/2017 10:58:08             54   \n",
      "...                       ...                  ...            ...   \n",
      "784951    192.168.10.50_7:445        7/7/2017 3:23        6026748   \n",
      "784952     192.168.10.50_7:80        7/7/2017 3:23        6007698   \n",
      "784953    192.168.10.50_7:139        7/7/2017 3:23        8439702   \n",
      "784954   192.168.10.50_7:2000        7/7/2017 3:23             57   \n",
      "784955     192.168.10.50_7:80        7/7/2017 3:23          18632   \n",
      "\n",
      "        Total Length of Fwd Packets  Fwd Packet Length Mean  \\\n",
      "0                             378.0               42.000000   \n",
      "1                               6.0                6.000000   \n",
      "2                             996.0               71.142857   \n",
      "3                              12.0                6.000000   \n",
      "4                               0.0                0.000000   \n",
      "...                             ...                     ...   \n",
      "784951                        168.0               33.600000   \n",
      "784952                         18.0                6.000000   \n",
      "784953                         18.0                4.500000   \n",
      "784954                          0.0                0.000000   \n",
      "784955                          0.0                0.000000   \n",
      "\n",
      "        Fwd Packet Length Std  Bwd Packet Length Min  Bwd Packet Length Std  \\\n",
      "0                   68.576600                    0.0             770.816126   \n",
      "1                    0.000000                    6.0               0.000000   \n",
      "2                  126.478248                    0.0             725.951972   \n",
      "3                    0.000000                    0.0               0.000000   \n",
      "4                    0.000000                    0.0               0.000000   \n",
      "...                       ...                    ...                    ...   \n",
      "784951              75.131884                    0.0              73.323484   \n",
      "784952              10.392305                    0.0            2181.008184   \n",
      "784953               9.000000                    0.0               0.000000   \n",
      "784954               0.000000                    6.0               0.000000   \n",
      "784955               0.000000                    0.0               0.000000   \n",
      "\n",
      "        Flow Packets/s  Flow IAT Mean  Flow IAT Std  Flow IAT Min  \\\n",
      "0             2.587887   4.140168e+05  1.512442e+06          42.0   \n",
      "1         66666.666670   3.000000e+01  0.000000e+00          30.0   \n",
      "2             0.222112   4.682317e+06  1.620000e+07           1.0   \n",
      "3             3.333128   6.000370e+05  0.000000e+00      600037.0   \n",
      "4         37037.037037   5.400000e+01  0.000000e+00          54.0   \n",
      "...                ...            ...           ...           ...   \n",
      "784951        1.327416   8.609640e+05  2.268900e+06         115.0   \n",
      "784952        1.498078   7.509622e+05  2.123484e+06          44.0   \n",
      "784953        0.710926   1.687940e+06  2.633799e+06         118.0   \n",
      "784954    35087.719300   5.700000e+01  0.000000e+00          57.0   \n",
      "784955      268.355517   4.658000e+03  8.755321e+03         174.0   \n",
      "\n",
      "        Fwd IAT Min  Bwd IAT Mean  Fwd PSH Flags  SYN Flag Count  \\\n",
      "0              48.0       10920.6              0               0   \n",
      "1               0.0           0.0              0               0   \n",
      "2               4.0    10600000.0              0               0   \n",
      "3          600037.0           0.0              0               0   \n",
      "4               0.0           0.0              0               0   \n",
      "...             ...           ...            ...             ...   \n",
      "784951        596.0     3004400.5              0               0   \n",
      "784952        606.0     1201521.4              0               0   \n",
      "784953        598.0     6007023.0              0               0   \n",
      "784954          0.0           0.0              0               0   \n",
      "784955        174.0           0.0              0               0   \n",
      "\n",
      "        PSH Flag Count  ACK Flag Count  Average Packet Size  \\\n",
      "0                    1               0           337.800000   \n",
      "1                    0               1             9.000000   \n",
      "2                    1               0           273.961539   \n",
      "3                    0               1             9.000000   \n",
      "4                    0               1             0.000000   \n",
      "...                ...             ...                  ...   \n",
      "784951               1               0            36.875000   \n",
      "784952               1               0          1290.333333   \n",
      "784953               1               0             3.000000   \n",
      "784954               1               0             3.000000   \n",
      "784955               0               1             0.000000   \n",
      "\n",
      "        Fwd Header Length.1  Subflow Fwd Packets  Subflow Fwd Bytes  \\\n",
      "0                       192                    9                378   \n",
      "1                        20                    1                  6   \n",
      "2                       300                   14                996   \n",
      "3                        40                    2                 12   \n",
      "4                        32                    1                  0   \n",
      "...                     ...                  ...                ...   \n",
      "784951                  168                    5                168   \n",
      "784952                  104                    3                 18   \n",
      "784953                  136                    4                 18   \n",
      "784954                   40                    1                  0   \n",
      "784955                  160                    5                  0   \n",
      "\n",
      "        Subflow Bwd Bytes  Init_Win_bytes_forward  Active Mean  Active Min  \\\n",
      "0                    4689                    8192     127600.0    127600.0   \n",
      "1                       6                    1013          0.0         0.0   \n",
      "2                    6127                   29200      71936.5     15365.0   \n",
      "3                       0                   16425          0.0         0.0   \n",
      "4                       0                     115          0.0         0.0   \n",
      "...                   ...                     ...          ...         ...   \n",
      "784951                127                   29200        596.0       596.0   \n",
      "784952              11595                   29200        606.0       606.0   \n",
      "784953                  0                   29200        598.0       598.0   \n",
      "784954                  6                   64240          0.0         0.0   \n",
      "784955                  0                     251          0.0         0.0   \n",
      "\n",
      "           Label  source_file_id  Protocol_0  Protocol_6  Protocol_17  \n",
      "0         BENIGN               4       False        True        False  \n",
      "1         BENIGN               7       False        True        False  \n",
      "2         BENIGN               4       False        True        False  \n",
      "3         BENIGN               4       False        True        False  \n",
      "4         BENIGN               1       False        True        False  \n",
      "...          ...             ...         ...         ...          ...  \n",
      "784951  PortScan               7       False        True        False  \n",
      "784952  PortScan               7       False        True        False  \n",
      "784953  PortScan               7       False        True        False  \n",
      "784954  PortScan               7       False        True        False  \n",
      "784955  PortScan               7       False        True        False  \n",
      "\n",
      "[784956 rows x 33 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                          Flow ID              Source IP  \\\n",
      "0        192.168.10.14-23.208.79.179-51174-443-6  192.168.10.14_4:51174   \n",
      "1           192.168.10.5-72.247.71.12-53469-80-6      72.247.71.12_7:80   \n",
      "2       192.168.10.17-104.19.194.102-58257-443-6  192.168.10.17_4:58257   \n",
      "3          192.168.10.8-93.184.215.13-58377-80-6   192.168.10.8_4:58377   \n",
      "4        192.168.10.12-34.198.61.240-40382-443-6    34.198.61.240_1:443   \n",
      "...                                          ...                    ...   \n",
      "784951      172.16.0.1-192.168.10.50-42006-445-6     172.16.0.1_7:42006   \n",
      "784952       172.16.0.1-192.168.10.50-57546-80-6     172.16.0.1_7:57546   \n",
      "784953      172.16.0.1-192.168.10.50-49768-139-6     172.16.0.1_7:49768   \n",
      "784954     172.16.0.1-192.168.10.50-44870-2000-6     172.16.0.1_7:44870   \n",
      "784955       172.16.0.1-192.168.10.50-57546-80-6     172.16.0.1_7:57546   \n",
      "\n",
      "               Destination IP            Timestamp  Flow Duration  \\\n",
      "0         23.208.79.179_4:443       5/7/2017 10:09        5796235   \n",
      "1        192.168.10.5_7:53469        7/7/2017 2:11             30   \n",
      "2        104.19.194.102_4:443        5/7/2017 2:04      117057923   \n",
      "3          93.184.215.13_4:80        5/7/2017 2:36         600037   \n",
      "4       192.168.10.12_1:40382  03/07/2017 10:58:08             54   \n",
      "...                       ...                  ...            ...   \n",
      "784951    192.168.10.50_7:445        7/7/2017 3:23        6026748   \n",
      "784952     192.168.10.50_7:80        7/7/2017 3:23        6007698   \n",
      "784953    192.168.10.50_7:139        7/7/2017 3:23        8439702   \n",
      "784954   192.168.10.50_7:2000        7/7/2017 3:23             57   \n",
      "784955     192.168.10.50_7:80        7/7/2017 3:23          18632   \n",
      "\n",
      "        Total Length of Fwd Packets  Fwd Packet Length Mean  \\\n",
      "0                             378.0               42.000000   \n",
      "1                               6.0                6.000000   \n",
      "2                             996.0               71.142857   \n",
      "3                              12.0                6.000000   \n",
      "4                               0.0                0.000000   \n",
      "...                             ...                     ...   \n",
      "784951                        168.0               33.600000   \n",
      "784952                         18.0                6.000000   \n",
      "784953                         18.0                4.500000   \n",
      "784954                          0.0                0.000000   \n",
      "784955                          0.0                0.000000   \n",
      "\n",
      "        Fwd Packet Length Std  Bwd Packet Length Min  Bwd Packet Length Std  \\\n",
      "0                   68.576600                    0.0             770.816126   \n",
      "1                    0.000000                    6.0               0.000000   \n",
      "2                  126.478248                    0.0             725.951972   \n",
      "3                    0.000000                    0.0               0.000000   \n",
      "4                    0.000000                    0.0               0.000000   \n",
      "...                       ...                    ...                    ...   \n",
      "784951              75.131884                    0.0              73.323484   \n",
      "784952              10.392305                    0.0            2181.008184   \n",
      "784953               9.000000                    0.0               0.000000   \n",
      "784954               0.000000                    6.0               0.000000   \n",
      "784955               0.000000                    0.0               0.000000   \n",
      "\n",
      "        Flow Packets/s  Flow IAT Mean  Flow IAT Std  Flow IAT Min  \\\n",
      "0             2.587887   4.140168e+05  1.512442e+06          42.0   \n",
      "1         66666.666670   3.000000e+01  0.000000e+00          30.0   \n",
      "2             0.222112   4.682317e+06  1.620000e+07           1.0   \n",
      "3             3.333128   6.000370e+05  0.000000e+00      600037.0   \n",
      "4         37037.037037   5.400000e+01  0.000000e+00          54.0   \n",
      "...                ...            ...           ...           ...   \n",
      "784951        1.327416   8.609640e+05  2.268900e+06         115.0   \n",
      "784952        1.498078   7.509622e+05  2.123484e+06          44.0   \n",
      "784953        0.710926   1.687940e+06  2.633799e+06         118.0   \n",
      "784954    35087.719300   5.700000e+01  0.000000e+00          57.0   \n",
      "784955      268.355517   4.658000e+03  8.755321e+03         174.0   \n",
      "\n",
      "        Fwd IAT Min  Bwd IAT Mean  Fwd PSH Flags  SYN Flag Count  \\\n",
      "0              48.0       10920.6              0               0   \n",
      "1               0.0           0.0              0               0   \n",
      "2               4.0    10600000.0              0               0   \n",
      "3          600037.0           0.0              0               0   \n",
      "4               0.0           0.0              0               0   \n",
      "...             ...           ...            ...             ...   \n",
      "784951        596.0     3004400.5              0               0   \n",
      "784952        606.0     1201521.4              0               0   \n",
      "784953        598.0     6007023.0              0               0   \n",
      "784954          0.0           0.0              0               0   \n",
      "784955        174.0           0.0              0               0   \n",
      "\n",
      "        PSH Flag Count  ACK Flag Count  Average Packet Size  \\\n",
      "0                    1               0           337.800000   \n",
      "1                    0               1             9.000000   \n",
      "2                    1               0           273.961539   \n",
      "3                    0               1             9.000000   \n",
      "4                    0               1             0.000000   \n",
      "...                ...             ...                  ...   \n",
      "784951               1               0            36.875000   \n",
      "784952               1               0          1290.333333   \n",
      "784953               1               0             3.000000   \n",
      "784954               1               0             3.000000   \n",
      "784955               0               1             0.000000   \n",
      "\n",
      "        Fwd Header Length.1  Subflow Fwd Packets  Subflow Fwd Bytes  \\\n",
      "0                       192                    9                378   \n",
      "1                        20                    1                  6   \n",
      "2                       300                   14                996   \n",
      "3                        40                    2                 12   \n",
      "4                        32                    1                  0   \n",
      "...                     ...                  ...                ...   \n",
      "784951                  168                    5                168   \n",
      "784952                  104                    3                 18   \n",
      "784953                  136                    4                 18   \n",
      "784954                   40                    1                  0   \n",
      "784955                  160                    5                  0   \n",
      "\n",
      "        Subflow Bwd Bytes  Init_Win_bytes_forward  Active Mean  Active Min  \\\n",
      "0                    4689                    8192     127600.0    127600.0   \n",
      "1                       6                    1013          0.0         0.0   \n",
      "2                    6127                   29200      71936.5     15365.0   \n",
      "3                       0                   16425          0.0         0.0   \n",
      "4                       0                     115          0.0         0.0   \n",
      "...                   ...                     ...          ...         ...   \n",
      "784951                127                   29200        596.0       596.0   \n",
      "784952              11595                   29200        606.0       606.0   \n",
      "784953                  0                   29200        598.0       598.0   \n",
      "784954                  6                   64240          0.0         0.0   \n",
      "784955                  0                     251          0.0         0.0   \n",
      "\n",
      "           Label  source_file_id  Protocol_0  Protocol_6  Protocol_17  \n",
      "0         BENIGN               4       False        True        False  \n",
      "1         BENIGN               7       False        True        False  \n",
      "2         BENIGN               4       False        True        False  \n",
      "3         BENIGN               4       False        True        False  \n",
      "4         BENIGN               1       False        True        False  \n",
      "...          ...             ...         ...         ...          ...  \n",
      "784951  PortScan               7       False        True        False  \n",
      "784952  PortScan               7       False        True        False  \n",
      "784953  PortScan               7       False        True        False  \n",
      "784954  PortScan               7       False        True        False  \n",
      "784955  PortScan               7       False        True        False  \n",
      "\n",
      "[784956 rows x 33 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "data.fillna(0,inplace = True)\n",
    "data.drop(columns=['index'],inplace=True)\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1df5c4c-70a2-4566-ae5e-ee3dcc6037a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Bwd Packet Length Min  Subflow Fwd Packets  \\\n",
      "count          784956.000000        784956.000000   \n",
      "mean               16.079970             5.867280   \n",
      "std                47.215745           423.380115   \n",
      "min                 0.000000             1.000000   \n",
      "25%                 0.000000             1.000000   \n",
      "50%                 0.000000             3.000000   \n",
      "75%                 6.000000             6.000000   \n",
      "max              2896.000000        209916.000000   \n",
      "\n",
      "       Total Length of Fwd Packets  Fwd Packet Length Mean  \\\n",
      "count                 7.849560e+05           784956.000000   \n",
      "mean                  3.177689e+02               36.806877   \n",
      "std                   6.370183e+03              124.200090   \n",
      "min                   0.000000e+00                0.000000   \n",
      "25%                   2.000000e+00                2.000000   \n",
      "50%                   2.600000e+01                8.666667   \n",
      "75%                   3.220000e+02               47.000000   \n",
      "max                   2.866110e+06             5940.857143   \n",
      "\n",
      "       Total Length of Fwd Packets  Fwd Packet Length Std   Fwd IAT Min  \\\n",
      "count                 7.849560e+05          784956.000000  7.849560e+05   \n",
      "mean                  3.177689e+02              54.092176  7.200132e+05   \n",
      "std                   6.370183e+03             179.832306  7.480002e+06   \n",
      "min                   0.000000e+00               0.000000 -1.200000e+01   \n",
      "25%                   2.000000e+00               0.000000  0.000000e+00   \n",
      "50%                   2.600000e+01               0.000000  2.000000e+00   \n",
      "75%                   3.220000e+02             108.187337  4.800000e+01   \n",
      "max                   2.866110e+06            7049.469004  1.200000e+08   \n",
      "\n",
      "       Flow IAT Min  Flow IAT Mean  Bwd Packet Length Std  Subflow Fwd Bytes  \\\n",
      "count  7.849560e+05   7.849560e+05          784956.000000       7.849560e+05   \n",
      "mean   2.010515e+05   2.314479e+06             888.199204       3.177689e+02   \n",
      "std    3.538292e+06   5.260519e+06            1386.441838       6.370183e+03   \n",
      "min   -1.300000e+01  -1.200000e+01               0.000000       0.000000e+00   \n",
      "25%    2.000000e+00   5.400000e+01               0.000000       2.000000e+00   \n",
      "50%    5.000000e+00   1.789056e+04               0.000000       2.600000e+01   \n",
      "75%    4.900000e+01   2.917921e+06            1760.597234       3.220000e+02   \n",
      "max    1.200000e+08   1.200000e+08            8194.660487       2.866110e+06   \n",
      "\n",
      "       Flow Duration  Flow IAT Std    Active Min   Active Mean  Bwd IAT Mean  \\\n",
      "count   7.849560e+05  7.849560e+05  7.849560e+05  7.849560e+05  7.849560e+05   \n",
      "mean    2.405880e+07  6.416623e+06  7.710097e+04  9.422461e+04  1.870857e+06   \n",
      "std     3.998816e+07  1.126197e+07  6.095774e+05  6.588593e+05  8.011958e+06   \n",
      "min    -1.200000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%     5.800000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%     6.012300e+04  1.389412e+04  0.000000e+00  0.000000e+00  1.000000e+00   \n",
      "75%     3.680226e+07  4.796936e+06  8.080000e+02  8.800000e+02  3.511512e+04   \n",
      "max     1.200000e+08  8.478172e+07  1.020000e+08  1.020000e+08  1.200000e+08   \n",
      "\n",
      "       Subflow Bwd Bytes  Init_Win_bytes_forward  ACK Flag Count  \\\n",
      "count       7.849560e+05           784956.000000   784956.000000   \n",
      "mean        8.760160e+03             7237.375389        0.390531   \n",
      "std         1.244004e+06            12679.556553        0.487870   \n",
      "min         0.000000e+00               -1.000000        0.000000   \n",
      "25%         0.000000e+00              251.000000        0.000000   \n",
      "50%         7.400000e+01              274.000000        0.000000   \n",
      "75%         1.159500e+04             8192.000000        1.000000   \n",
      "max         6.176585e+08            65535.000000        1.000000   \n",
      "\n",
      "       Fwd PSH Flags  SYN Flag Count  Flow Packets/s  PSH Flag Count  \\\n",
      "count  784956.000000   784956.000000    7.849560e+05   784956.000000   \n",
      "mean        0.024274        0.024274    8.658184e+04        0.402430   \n",
      "std         0.153899        0.153899    2.892078e+05        0.490388   \n",
      "min         0.000000        0.000000   -2.000000e+06        0.000000   \n",
      "25%         0.000000        0.000000    3.988248e-01        0.000000   \n",
      "50%         0.000000        0.000000    7.268762e+01        0.000000   \n",
      "75%         0.000000        0.000000    3.508772e+04        1.000000   \n",
      "max         1.000000        1.000000    3.000000e+06        1.000000   \n",
      "\n",
      "       Average Packet Size  \n",
      "count        784956.000000  \n",
      "mean            368.879063  \n",
      "std             502.979522  \n",
      "min               0.000000  \n",
      "25%               4.500000  \n",
      "50%              54.250000  \n",
      "75%             853.571429  \n",
      "max            2847.000000  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "cols_to_norm = CIC_IDS_2017_Config.COLS_TO_NORM\n",
    "print(data[cols_to_norm].describe()) # Check if there's any too large value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All other columns processed successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_numeric_issues(df, cols_to_norm):\n",
    "    for col in cols_to_norm:\n",
    "        try:\n",
    "            # Try to coerce to numeric\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Try to clip the column\n",
    "            df[col] = df[col].clip(lower=-1e9, upper=1e9)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "            print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Data type: {df[col].dtype}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "check_numeric_issues(data, CIC_IDS_2017_Config.COLS_TO_NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37256006-abc1-44aa-8e74-46d05dc6ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cols_to_norm] = scaler.fit_transform(data[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "Attack label mapping: {'BENIGN': 0, 'Bot': 1, 'DDoS': 2, 'DoS GoldenEye': 3, 'DoS Hulk': 4, 'DoS Slowhttptest': 5, 'DoS slowloris': 6, 'FTP-Patator': 7, 'Heartbleed': 8, 'Infiltration': 9, 'PortScan': 10, 'SSH-Patator': 11, 'Web Attack - Brute Force': 12, 'Web Attack - Sql Injection': 13, 'Web Attack - XSS': 14}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "num_classes = 2\n",
    "class_map = [0, 1]\n",
    "if MULTICLASS:\n",
    "    le = LabelEncoder()\n",
    "    attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "    class_map = le.classes_\n",
    "    print(class_map)\n",
    "    print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "    data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "    num_classes = len(class_map)\n",
    "    class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n",
    "\n",
    "BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "ADVERSARIAL_CLASS_LABEL = len(class_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: ['Bwd Packet Length Min', 'Subflow Fwd Packets', 'Total Length of Fwd Packets', 'Fwd Packet Length Mean', 'Total Length of Fwd Packets', 'Fwd Packet Length Std', 'Fwd IAT Min', 'Flow IAT Min', 'Flow IAT Mean', 'Bwd Packet Length Std', 'Subflow Fwd Bytes', 'Flow Duration', 'Flow IAT Std', 'Active Min', 'Active Mean', 'Bwd IAT Mean', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'ACK Flag Count', 'Fwd PSH Flags', 'SYN Flag Count', 'Flow Packets/s', 'PSH Flag Count', 'Average Packet Size', 'Protocol_0', 'Protocol_6', 'Protocol_17']\n",
      "Number of training samples: 667212\n",
      "Label\n",
      "4     196412\n",
      "0     193213\n",
      "10    135090\n",
      "2     108823\n",
      "3       8749\n",
      "7       6747\n",
      "11      5013\n",
      "6       4927\n",
      "5       4674\n",
      "1       1671\n",
      "12      1281\n",
      "14       554\n",
      "9         31\n",
      "13        18\n",
      "8          9\n",
      "Name: count, dtype: int64\n",
      "Number of test samples: 117744\n",
      "Label\n",
      "4     34661\n",
      "0     34097\n",
      "10    23840\n",
      "2     19204\n",
      "3      1544\n",
      "7      1191\n",
      "11      884\n",
      "6       869\n",
      "5       825\n",
      "1       295\n",
      "12      226\n",
      "14       98\n",
      "9         5\n",
      "13        3\n",
      "8         2\n",
      "Name: count, dtype: int64\n",
      "                                        Flow ID              Source IP  \\\n",
      "65904   192.168.10.17-54.192.37.109-46076-443-6  192.168.10.17_4:46076   \n",
      "151735   192.168.10.14-52.16.178.12-62176-443-6  192.168.10.14_6:62176   \n",
      "779369    172.16.0.1-192.168.10.50-58056-8087-6     172.16.0.1_7:58056   \n",
      "303497      172.16.0.1-192.168.10.50-52212-80-6     172.16.0.1_0:52212   \n",
      "191544  192.168.10.12-52.84.141.138-58038-443-6  192.168.10.12_1:58038   \n",
      "\n",
      "              Destination IP            Timestamp  Flow Duration  \\\n",
      "65904    54.192.37.109_4:443        5/7/2017 2:31       2.339358   \n",
      "151735    52.16.178.12_6:443        4/7/2017 4:34      -0.601649   \n",
      "779369  192.168.10.50_7:8087        7/7/2017 3:22      -0.601647   \n",
      "303497    192.168.10.50_0:80        7/7/2017 4:08      -0.400515   \n",
      "191544   52.84.141.138_1:443  03/07/2017 11:03:33      -0.493467   \n",
      "\n",
      "        Total Length of Fwd Packets  Fwd Packet Length Mean  \\\n",
      "65904                      0.790438                0.583237   \n",
      "151735                    -0.049884               -0.296352   \n",
      "779369                    -0.049570               -0.280249   \n",
      "303497                    -0.042035               -0.238841   \n",
      "191544                    -0.030575               -0.098284   \n",
      "\n",
      "        Fwd Packet Length Std  Bwd Packet Length Min  Bwd Packet Length Std  \\\n",
      "65904                1.222754              -0.340564              -0.166192   \n",
      "151735              -0.300793              -0.340564              -0.640633   \n",
      "779369              -0.300793              -0.213488              -0.640633   \n",
      "303497              -0.266903              -0.340564               3.539495   \n",
      "191544              -0.171357               0.633688              -0.640633   \n",
      "\n",
      "        Flow Packets/s  Flow IAT Mean  Flow IAT Std  Flow IAT Min  \\\n",
      "65904        -0.299373      -0.232970     -0.297567     -0.056821   \n",
      "151735        2.005773      -0.439971     -0.569760     -0.056821   \n",
      "779369       -0.158245      -0.439963     -0.569760     -0.056808   \n",
      "303497       -0.299371      -0.287079     -0.397987     -0.056820   \n",
      "191544       -0.299371      -0.275501     -0.400227     -0.056821   \n",
      "\n",
      "        Fwd IAT Min  Bwd IAT Mean  Fwd PSH Flags  SYN Flag Count  \\\n",
      "65904     -0.096258      0.003697      -0.157727       -0.157727   \n",
      "151735    -0.096258     -0.233508      -0.157727       -0.157727   \n",
      "779369    -0.096258     -0.233508      -0.157727       -0.157727   \n",
      "303497    -0.096245     -0.229389      -0.157727       -0.157727   \n",
      "191544    -0.096258     -0.233508       6.340062        6.340062   \n",
      "\n",
      "        PSH Flag Count  ACK Flag Count  Average Packet Size  \\\n",
      "65904         1.218566       -0.800483             0.501875   \n",
      "151735       -0.820637        1.249245            -0.733388   \n",
      "779369        1.218566       -0.800483            -0.723448   \n",
      "303497       -0.820637        1.249245             1.374597   \n",
      "191544       -0.820637        1.249245            -0.662146   \n",
      "\n",
      "        Fwd Header Length.1  Subflow Fwd Packets  Subflow Fwd Bytes  \\\n",
      "65904                  1576             0.101877           0.790438   \n",
      "151735                   20            -0.011496          -0.049884   \n",
      "779369                   24            -0.011496          -0.049570   \n",
      "303497                  152             0.002675          -0.042035   \n",
      "191544                  160            -0.002048          -0.030575   \n",
      "\n",
      "        Subflow Bwd Bytes  Init_Win_bytes_forward  Active Mean  Active Min  \\\n",
      "65904            0.043095                1.732130     0.108035   -0.075895   \n",
      "151735          -0.007042               -0.550680    -0.143012   -0.126483   \n",
      "779369          -0.007037               -0.490031    -0.143012   -0.126483   \n",
      "303497           0.002288               -0.550601     2.740093    2.989709   \n",
      "191544          -0.007005               -0.520632    -0.143012   -0.126483   \n",
      "\n",
      "        Label  source_file_id  Protocol_0  Protocol_6  Protocol_17  \\\n",
      "65904       0               4       False        True        False   \n",
      "151735      0               6       False        True        False   \n",
      "779369     10               7       False        True        False   \n",
      "303497      2               0       False        True        False   \n",
      "191544      0               1       False        True        False   \n",
      "\n",
      "                                                        h  \n",
      "65904   [-0.3405639403067529, 0.10187712059587015, 0.7...  \n",
      "151735  [-0.3405639403067529, -0.011496249797737843, -...  \n",
      "779369  [-0.2134876067861102, -0.011496249797737843, -...  \n",
      "303497  [-0.3405639403067529, 0.0026754215014631565, -...  \n",
      "191544  [0.6336879500181745, -0.0020484689316038435, -...  \n"
     ]
    }
   ],
   "source": [
    "# 70% train, 15% validation, 15% test\n",
    "train_full_df, test_df = train_test_split(\n",
    "     data, test_size=0.15, random_state=42, stratify=data[label_col])\n",
    "\n",
    "\n",
    "feature_cols = cols_to_norm + converted_categorical_cols\n",
    "\n",
    "print('Feature Columns:', feature_cols)\n",
    "\n",
    "train_full_df['h'] = train_full_df[ feature_cols ].values.tolist()\n",
    "test_df['h'] = test_df[ feature_cols ].values.tolist()\n",
    "\n",
    "y_train = train_full_df[label_col]\n",
    "y_test = test_df[label_col]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_full_df))\n",
    "print(y_train.value_counts())\n",
    "print(\"Number of test samples:\", len(test_df))\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(train_full_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f83bd73-531f-42a0-9f73-e1fd98dce1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df, source_ip_col, destination_ip_col, edge_attr, create_using=nx.MultiDiGraph(), **kwargs):\n",
    "    G_nx = nx.from_pandas_edgelist(df, source_ip_col, destination_ip_col, edge_attr, create_using=create_using, **kwargs)\n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    print(\"Number of edges in G_pyg:\", num_edges)\n",
    "    print(\"Number of node in G_pyg:\", num_nodes)\n",
    "    print(\"Shape of node in G_pyg:\", G_pyg.x.shape)\n",
    "    print(\"Shape of edge attr in G_pyg:\", G_pyg.edge_attr.shape)\n",
    "    print(\"Shape of edge label in G_pyg:\", G_pyg.edge_label.shape)\n",
    "\n",
    "    return G_nx, G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c8f9cdb-1316-461a-a927-8d67d90d6144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 117744\n",
      "Number of node in G_pyg: 82944\n",
      "Shape of node in G_pyg: torch.Size([82944, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([117744, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([117744])\n"
     ]
    }
   ],
   "source": [
    "G_nx_test, G_pyg_test = create_graph(test_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 444808\n",
      "Number of node in G_pyg: 210429\n",
      "Shape of node in G_pyg: torch.Size([210429, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([444808, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([444808])\n",
      "Number of edges in G_pyg: 222404\n",
      "Number of node in G_pyg: 131014\n",
      "Shape of node in G_pyg: torch.Size([131014, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([222404, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([222404])\n",
      "Number of edges in G_pyg: 444808\n",
      "Number of node in G_pyg: 210327\n",
      "Shape of node in G_pyg: torch.Size([210327, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([444808, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([444808])\n",
      "Number of edges in G_pyg: 222404\n",
      "Number of node in G_pyg: 130990\n",
      "Shape of node in G_pyg: torch.Size([130990, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([222404, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([222404])\n",
      "Number of edges in G_pyg: 444808\n",
      "Number of node in G_pyg: 210307\n",
      "Shape of node in G_pyg: torch.Size([210307, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([444808, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([444808])\n",
      "Number of edges in G_pyg: 222404\n",
      "Number of node in G_pyg: 130970\n",
      "Shape of node in G_pyg: torch.Size([130970, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([222404, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([222404])\n",
      "Testing with learning rate: 0.05, hidden_dim: 128, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1436, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.3208, Validation Loss: 17.5981, Validation F1: 0.1436\n",
      "Best F1 Score at epoch 5: 0.3283, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 6: 0.5795, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 7: 0.6083, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 13: 0.6483, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 15: 0.8315, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 23: 0.8727, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 28: 0.8954, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 48: 0.9150, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 61: 0.9197, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 66: 0.9260, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 98: 0.9310, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 2.1266, Validation Loss: 1.7151, Validation F1: 0.6570\n",
      "Best F1 Score at epoch 104: 0.9342, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 105: 0.9361, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 111: 0.9429, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 140: 0.9444, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 4.6085, Validation Loss: 37.2293, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 3: 0.1822, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 9: 0.2365, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 10: 0.6562, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 31: 0.8612, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 3.8310, Validation Loss: 4.5153, Validation F1: 0.2387\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0490, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.9576, Validation Loss: 11.2997, Validation F1: 0.0490\n",
      "Best F1 Score at epoch 4: 0.1091, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 5: 0.1529, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.1803, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 9: 0.3981, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 10: 0.7116, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 36: 0.8249, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 53: 0.8622, Parameters: lr=0.05, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 1.9510, Validation Loss: 2.2732, Validation F1: 0.1520\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.05, hidden_dim 128: 0.8893\n",
      "Testing with learning rate: 0.05, hidden_dim: 128, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1801, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.7947, Validation Loss: 12.9900, Validation F1: 0.1801\n",
      "Best F1 Score at epoch 4: 0.1852, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.2786, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.4649, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.7659, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 92: 0.7713, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 1.4661, Validation Loss: 3.0346, Validation F1: 0.4510\n",
      "Best F1 Score at epoch 152: 0.8224, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0000, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.9504, Validation Loss: 21.9669, Validation F1: 0.0000\n",
      "Best F1 Score at epoch 1: 0.1312, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.2192, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.6049, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.6771, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 13: 0.7707, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.8143, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 26: 0.8282, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 27: 0.8302, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 40: 0.8330, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 44: 0.8504, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 46: 0.8567, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 61: 0.8608, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 64: 0.8779, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 3.7522, Validation Loss: 4.2698, Validation F1: 0.6135\n",
      "Best F1 Score at epoch 109: 0.8884, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 125: 0.8901, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 150: 0.9033, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 152: 0.9039, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 155: 0.9101, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 157: 0.9120, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 177: 0.9156, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 182: 0.9161, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.7478, Validation Loss: 19.7355, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 1: 0.1698, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.2821, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.3005, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.3641, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.3901, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 26: 0.7083, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 34: 0.7572, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 39: 0.7941, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 40: 0.8076, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 41: 0.8080, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 48: 0.8083, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 66: 0.8197, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.8799, Validation Loss: 1.1013, Validation F1: 0.5801\n",
      "Best F1 Score at epoch 122: 0.8476, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 123: 0.8563, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 151: 0.8879, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 163: 0.8904, Parameters: lr=0.05, hidden_dim=128, drop_out=0.3\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.05, hidden_dim 128: 0.8763\n",
      "Testing with learning rate: 0.05, hidden_dim: 128, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0458, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.7425, Validation Loss: 17.6994, Validation F1: 0.0458\n",
      "Best F1 Score at epoch 1: 0.0681, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 2: 0.1077, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.1176, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.1765, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.2502, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 8: 0.4153, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 12: 0.5365, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 13: 0.5534, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 14: 0.5654, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 23: 0.6562, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 26: 0.8525, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 47: 0.8578, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 68: 0.8897, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 80: 0.9089, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 81: 0.9099, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 99: 0.9110, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 3.3241, Validation Loss: 2.8493, Validation F1: 0.6354\n",
      "Best F1 Score at epoch 104: 0.9128, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 118: 0.9382, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 119: 0.9393, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 124: 0.9407, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 125: 0.9413, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 4.4061, Validation Loss: 36.7203, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 7: 0.2000, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 9: 0.2163, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.3734, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 2.5090, Validation Loss: 2.5174, Validation F1: 0.0070\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0685, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.6657, Validation Loss: 18.2872, Validation F1: 0.0685\n",
      "Best F1 Score at epoch 2: 0.1299, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.2018, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.2289, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.2683, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 8: 0.3205, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 9: 0.5062, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 11: 0.5913, Parameters: lr=0.05, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 2.4324, Validation Loss: 2.6610, Validation F1: 0.0565\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.05, hidden_dim 128: 0.6353\n",
      "Testing with learning rate: 0.05, hidden_dim: 256, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.8377, Validation Loss: 102.0284, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 7: 0.6040, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.6156, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 16: 0.6169, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.6927, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 27: 0.7623, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 2.2236, Validation Loss: 4.7741, Validation F1: 0.2308\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1300, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.5915, Validation Loss: 114.9500, Validation F1: 0.1300\n",
      "Best F1 Score at epoch 3: 0.1705, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 6: 0.3741, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 10: 0.4974, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 11: 0.6153, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 17: 0.7828, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 23: 0.8685, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 61: 0.8713, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 69: 0.8912, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 78: 0.8914, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 81: 0.8929, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 97: 0.8983, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 99: 0.9082, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 21.7050, Validation Loss: 28.5382, Validation F1: 0.9079\n",
      "Best F1 Score at epoch 136: 0.9308, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0284, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.6794, Validation Loss: 42.9152, Validation F1: 0.0284\n",
      "Best F1 Score at epoch 2: 0.2737, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 6: 0.3670, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.4371, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 13: 0.6767, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 40: 0.8024, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 48: 0.8672, Parameters: lr=0.05, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 7.1378, Validation Loss: 13.8297, Validation F1: 0.2459\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.05, hidden_dim 256: 0.8534\n",
      "Testing with learning rate: 0.05, hidden_dim: 256, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1304, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.7234, Validation Loss: 62.3535, Validation F1: 0.1304\n",
      "Best F1 Score at epoch 7: 0.1968, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.2065, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.2664, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 14: 0.3407, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.4458, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.4933, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 26: 0.6187, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 27: 0.7000, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 16.0922, Validation Loss: 34.4087, Validation F1: 0.2194\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1312, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.2382, Validation Loss: 107.7427, Validation F1: 0.1312\n",
      "Best F1 Score at epoch 3: 0.1853, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.5990, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.8153, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 29: 0.8738, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 59: 0.8774, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 93: 0.9000, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 57.1048, Validation Loss: 65.0627, Validation F1: 0.5855\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.1975, Validation Loss: 154.6289, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 4: 0.1613, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.1740, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.2045, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.5550, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.5605, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 36: 0.6717, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 42: 0.7157, Parameters: lr=0.05, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 2.3774, Validation Loss: 3.2994, Validation F1: 0.2509\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.05, hidden_dim 256: 0.7719\n",
      "Testing with learning rate: 0.05, hidden_dim: 256, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.1566, Validation Loss: 67.3689, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 4: 0.1775, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 9: 0.5220, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 24: 0.5624, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 41: 0.5995, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 95: 0.8349, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 96: 0.8351, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 97: 0.8372, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 98: 0.8407, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 99: 0.8500, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 100: 0.8544, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 2.1191, Validation Loss: 1.3783, Validation F1: 0.8544\n",
      "Best F1 Score at epoch 101: 0.8606, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 102: 0.8661, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 103: 0.8686, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 104: 0.8686, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1724, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.3436, Validation Loss: 29.2021, Validation F1: 0.1724\n",
      "Best F1 Score at epoch 3: 0.2696, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.3276, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 8: 0.3550, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 14: 0.3854, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 15: 0.7244, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 24: 0.8338, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 30: 0.8783, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 59: 0.8857, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 60: 0.8882, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 73: 0.9017, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 79: 0.9192, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 100: 0.9274, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 9.3940, Validation Loss: 36.5965, Validation F1: 0.9274\n",
      "Best F1 Score at epoch 101: 0.9291, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.1035, Validation Loss: 91.1774, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 2: 0.1450, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.1996, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.2670, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 12: 0.2978, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 16: 0.3456, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 21: 0.4241, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 22: 0.5687, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 27: 0.8131, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 67: 0.8140, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 68: 0.8149, Parameters: lr=0.05, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 2.9643, Validation Loss: 3.3656, Validation F1: 0.3894\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.05, hidden_dim 256: 0.8709\n",
      "Testing with learning rate: 0.05, hidden_dim: 512, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0648, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.6986, Validation Loss: 122.0317, Validation F1: 0.0648\n",
      "Best F1 Score at epoch 2: 0.1153, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 7: 0.3451, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 16: 0.4367, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 48.5633, Validation Loss: 73.5655, Validation F1: 0.1156\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1524, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.7185, Validation Loss: 327.6342, Validation F1: 0.1524\n",
      "Best F1 Score at epoch 5: 0.4423, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 13: 0.4928, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.5113, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 22: 0.5693, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 25: 0.6149, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 37: 0.8015, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 38: 0.8023, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 39: 0.8554, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 51: 0.8960, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 52: 0.8982, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 53: 0.9046, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 75: 0.9110, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 76: 0.9133, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 90: 0.9294, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 99: 0.9346, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 1.6295, Validation Loss: 3.1190, Validation F1: 0.6583\n",
      "Best F1 Score at epoch 101: 0.9364, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 102: 0.9368, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 117: 0.9411, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 121: 0.9413, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 122: 0.9415, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 134: 0.9429, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 135: 0.9432, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 138: 0.9433, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0301, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.0281, Validation Loss: 249.8349, Validation F1: 0.0301\n",
      "Best F1 Score at epoch 1: 0.2873, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 11: 0.3637, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 13: 0.3829, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 16: 0.5553, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.6116, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 21: 0.6162, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 30: 0.6600, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 34: 0.8298, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 38: 0.8421, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 57: 0.8542, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 58: 0.8563, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 68: 0.8727, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 70: 0.8745, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 82: 0.8751, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 11.3738, Validation Loss: 27.8885, Validation F1: 0.8600\n",
      "Best F1 Score at epoch 103: 0.8779, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 104: 0.8816, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 108: 0.8964, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 118: 0.9125, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 119: 0.9130, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 128: 0.9178, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 134: 0.9206, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 135: 0.9222, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 136: 0.9233, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 139: 0.9262, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 140: 0.9267, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 145: 0.9267, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 146: 0.9269, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 147: 0.9271, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 148: 0.9277, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 149: 0.9286, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 150: 0.9303, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 152: 0.9303, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 153: 0.9308, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 154: 0.9312, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 155: 0.9313, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 175: 0.9315, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 176: 0.9315, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 177: 0.9316, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 178: 0.9316, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 179: 0.9316, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 180: 0.9316, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 181: 0.9316, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 182: 0.9317, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 183: 0.9317, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 184: 0.9317, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 185: 0.9317, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 186: 0.9317, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 189: 0.9317, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 190: 0.9318, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 191: 0.9318, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 195: 0.9318, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 197: 0.9318, Parameters: lr=0.05, hidden_dim=512, drop_out=0.2\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.05, hidden_dim 512: 0.7706\n",
      "Testing with learning rate: 0.05, hidden_dim: 512, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.7793, Validation Loss: 405.5722, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 6: 0.1761, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.1770, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.5379, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8398, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 27: 0.8443, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 42: 0.8659, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 44: 0.8736, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 50: 0.8753, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 53: 0.8975, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 54: 0.9041, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 72: 0.9126, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 73: 0.9133, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 6.1392, Validation Loss: 3.8631, Validation F1: 0.6445\n",
      "Best F1 Score at epoch 108: 0.9227, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 109: 0.9238, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1304, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.2179, Validation Loss: 467.3031, Validation F1: 0.1304\n",
      "Best F1 Score at epoch 5: 0.1456, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.1461, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.3451, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.4803, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 13: 0.6526, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 17: 0.7928, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 22: 0.8022, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 40: 0.8382, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 57: 0.8439, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 58: 0.8507, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 59: 0.8688, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 77: 0.8790, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 84: 0.8812, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 90: 0.9010, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 92: 0.9128, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 93: 0.9161, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 99: 0.9295, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 30.8558, Validation Loss: 37.1133, Validation F1: 0.6520\n",
      "Best F1 Score at epoch 105: 0.9425, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1341, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.8241, Validation Loss: 316.6413, Validation F1: 0.1341\n",
      "Best F1 Score at epoch 6: 0.1612, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.4395, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.7287, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 26: 0.7838, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 34: 0.8476, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 35: 0.8570, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 38: 0.8609, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 57: 0.8712, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 65: 0.9203, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 74: 0.9329, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 8.2658, Validation Loss: 12.5923, Validation F1: 0.6300\n",
      "Best F1 Score at epoch 106: 0.9355, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 107: 0.9371, Parameters: lr=0.05, hidden_dim=512, drop_out=0.3\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.05, hidden_dim 512: 0.9345\n",
      "Testing with learning rate: 0.05, hidden_dim: 512, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1301, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.2048, Validation Loss: 725.2520, Validation F1: 0.1301\n",
      "Best F1 Score at epoch 1: 0.2009, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 8: 0.4130, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 4.2140, Validation Loss: 3.0352, Validation F1: 0.0229\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1228, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.5865, Validation Loss: 223.9412, Validation F1: 0.1228\n",
      "Best F1 Score at epoch 6: 0.2164, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.3717, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 17: 0.4503, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 21: 0.4814, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 22: 0.7397, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 35: 0.8110, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 57208.0312, Validation Loss: 141.2557, Validation F1: 0.2274\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0805, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.9611, Validation Loss: 171.9825, Validation F1: 0.0805\n",
      "Best F1 Score at epoch 1: 0.1236, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.2104, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.2130, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.2712, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 12: 0.3027, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 22: 0.3721, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 24: 0.6006, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 25: 0.6521, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 26: 0.7128, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 28: 0.7249, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 58: 0.7252, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 84: 0.8239, Parameters: lr=0.05, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 19.2355, Validation Loss: 262.0018, Validation F1: 0.3017\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.05, hidden_dim 512: 0.6826\n",
      "Best Parameters: {'learning_rate': 0.05, 'hidden_dim': 512, 'drop_out': 0.3}, Best F1 Score: 0.9345\n",
      "All results: {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}}\n",
      "Testing with learning rate: 0.01, hidden_dim: 128, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1271, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.5732, Validation Loss: 2.3986, Validation F1: 0.1271\n",
      "Best F1 Score at epoch 2: 0.2197, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.6363, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 4: 0.6701, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.8218, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 36: 0.8285, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 44: 0.8439, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 45: 0.8572, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6519, Validation Loss: 0.7652, Validation F1: 0.5298\n",
      "Best F1 Score at epoch 109: 0.8739, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0172, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.3350, Validation Loss: 2.3633, Validation F1: 0.0172\n",
      "Best F1 Score at epoch 1: 0.2196, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 2: 0.2330, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.3957, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 5: 0.6367, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 6: 0.7908, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 10: 0.8686, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 16: 0.8703, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 17: 0.8844, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 28: 0.9058, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 35: 0.9113, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 41: 0.9250, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 51: 0.9318, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 52: 0.9339, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 60: 0.9341, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6455, Validation Loss: 0.7538, Validation F1: 0.9274\n",
      "Best F1 Score at epoch 113: 0.9373, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2692, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.9592, Validation Loss: 2.2121, Validation F1: 0.2692\n",
      "Best F1 Score at epoch 1: 0.5091, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.6502, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.6653, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.6728, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 13: 0.8729, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 14: 0.8781, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 22: 0.8975, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 44: 0.9257, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 52: 0.9315, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 61: 0.9333, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 63: 0.9360, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 69: 0.9378, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 71: 0.9387, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 72: 0.9398, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 74: 0.9402, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6237, Validation Loss: 0.6476, Validation F1: 0.6597\n",
      "Best F1 Score at epoch 115: 0.9426, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 117: 0.9442, Parameters: lr=0.01, hidden_dim=128, drop_out=0.2\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.01, hidden_dim 128: 0.9184\n",
      "Testing with learning rate: 0.01, hidden_dim: 128, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2749, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.5056, Validation Loss: 2.4326, Validation F1: 0.2749\n",
      "Best F1 Score at epoch 2: 0.3142, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.5936, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.7900, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 14: 0.8591, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 37: 0.8640, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6346, Validation Loss: 0.7688, Validation F1: 0.5354\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2439, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 4.2549, Validation Loss: 2.3351, Validation F1: 0.2439\n",
      "Best F1 Score at epoch 2: 0.4197, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.5823, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.6061, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.7920, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 14: 0.8628, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.8635, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 22: 0.9069, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 54: 0.9181, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 64: 0.9278, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6600, Validation Loss: 0.8316, Validation F1: 0.9273\n",
      "Best F1 Score at epoch 111: 0.9288, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2172, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.9060, Validation Loss: 2.3299, Validation F1: 0.2172\n",
      "Best F1 Score at epoch 1: 0.2801, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.4534, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.5761, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 13: 0.6075, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 14: 0.8451, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.8836, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 34: 0.9049, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 35: 0.9056, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 43: 0.9266, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 57: 0.9269, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 93: 0.9278, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6577, Validation Loss: 0.6618, Validation F1: 0.6572\n",
      "Best F1 Score at epoch 101: 0.9361, Parameters: lr=0.01, hidden_dim=128, drop_out=0.3\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.01, hidden_dim 128: 0.9096\n",
      "Testing with learning rate: 0.01, hidden_dim: 128, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2785, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.6816, Validation Loss: 2.4114, Validation F1: 0.2785\n",
      "Best F1 Score at epoch 1: 0.4840, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.6946, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.7843, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 51: 0.8429, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 52: 0.8487, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6115, Validation Loss: 0.7018, Validation F1: 0.5596\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2547, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.8140, Validation Loss: 2.2927, Validation F1: 0.2547\n",
      "Best F1 Score at epoch 1: 0.2741, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 2: 0.3714, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.4974, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.8043, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 8: 0.8495, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 17: 0.8597, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 23: 0.8821, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 36: 0.9072, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 49: 0.9180, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 60: 0.9211, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 83: 0.9381, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6165, Validation Loss: 0.6918, Validation F1: 0.9369\n",
      "Best F1 Score at epoch 101: 0.9391, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 117: 0.9421, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0983, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.3128, Validation Loss: 2.1788, Validation F1: 0.0983\n",
      "Best F1 Score at epoch 1: 0.2860, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 2: 0.3551, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.3996, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 9: 0.8257, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 25: 0.8624, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 26: 0.8733, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 33: 0.9127, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 53: 0.9220, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6102, Validation Loss: 1.3796, Validation F1: 0.6603\n",
      "Best F1 Score at epoch 106: 0.9241, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 118: 0.9323, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 135: 0.9362, Parameters: lr=0.01, hidden_dim=128, drop_out=0.4\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.01, hidden_dim 128: 0.9090\n",
      "Testing with learning rate: 0.01, hidden_dim: 256, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1484, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.5684, Validation Loss: 2.7798, Validation F1: 0.1484\n",
      "Best F1 Score at epoch 2: 0.2537, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.4296, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 4: 0.6991, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 7: 0.7388, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 11: 0.8417, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 19: 0.8618, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.8705, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 35: 0.8872, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 87: 0.9062, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.9342, Validation Loss: 0.9281, Validation F1: 0.6155\n",
      "Best F1 Score at epoch 117: 0.9296, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 129: 0.9316, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 132: 0.9339, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2555, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.0421, Validation Loss: 2.5857, Validation F1: 0.2555\n",
      "Best F1 Score at epoch 1: 0.2852, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.3903, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 4: 0.6595, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 9: 0.8193, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 17: 0.8644, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 24: 0.8783, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 29: 0.8830, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 36: 0.8896, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 37: 0.8934, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 43: 0.9272, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 44: 0.9287, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 45: 0.9301, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 63: 0.9314, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6792, Validation Loss: 0.8110, Validation F1: 0.6600\n",
      "Best F1 Score at epoch 151: 0.9333, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1767, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.8598, Validation Loss: 2.6857, Validation F1: 0.1767\n",
      "Best F1 Score at epoch 3: 0.2193, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 4: 0.5242, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 5: 0.5838, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 11: 0.6238, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.9106, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 45: 0.9177, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 71: 0.9203, Parameters: lr=0.01, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.7212, Validation Loss: 0.9024, Validation F1: 0.6565\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.01, hidden_dim 256: 0.9292\n",
      "Testing with learning rate: 0.01, hidden_dim: 256, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2718, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.6715, Validation Loss: 2.2229, Validation F1: 0.2718\n",
      "Best F1 Score at epoch 3: 0.5160, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.5260, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.8544, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 27: 0.8634, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 47: 0.8742, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.7149, Validation Loss: 0.8677, Validation F1: 0.8426\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1358, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.3542, Validation Loss: 3.1412, Validation F1: 0.1358\n",
      "Best F1 Score at epoch 1: 0.1914, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.2554, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.5239, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.5745, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8162, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8892, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 34: 0.9081, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 42: 0.9144, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 48: 0.9186, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 51: 0.9237, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 52: 0.9256, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 66: 0.9320, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 88: 0.9348, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 89: 0.9397, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.7587, Validation Loss: 1.0614, Validation F1: 0.6329\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0103, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.2761, Validation Loss: 2.3195, Validation F1: 0.0103\n",
      "Best F1 Score at epoch 1: 0.2997, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.3307, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.5567, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.5682, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.5835, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.8373, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 19: 0.8415, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 24: 0.8689, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.8723, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 26: 0.8832, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 27: 0.8878, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 34: 0.8966, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 36: 0.9097, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 37: 0.9127, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 53: 0.9201, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 74: 0.9383, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 100: 0.9410, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6305, Validation Loss: 0.6572, Validation F1: 0.9410\n",
      "Best F1 Score at epoch 101: 0.9410, Parameters: lr=0.01, hidden_dim=256, drop_out=0.3\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.01, hidden_dim 256: 0.9183\n",
      "Testing with learning rate: 0.01, hidden_dim: 256, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0651, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.3830, Validation Loss: 2.4929, Validation F1: 0.0651\n",
      "Best F1 Score at epoch 1: 0.3842, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.6280, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.6812, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.7231, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 18: 0.8429, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 19: 0.8545, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 63: 0.9054, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.8217, Validation Loss: 0.8556, Validation F1: 0.8568\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0616, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.6638, Validation Loss: 2.2660, Validation F1: 0.0616\n",
      "Best F1 Score at epoch 2: 0.3697, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.4286, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.6538, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.7054, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.8292, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 31: 0.8863, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 32: 0.9002, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 45: 0.9079, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 58: 0.9137, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 60: 0.9200, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 61: 0.9224, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 82: 0.9272, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 83: 0.9272, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 89: 0.9350, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 90: 0.9379, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 1.0054, Validation Loss: 1.0968, Validation F1: 0.6406\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1293, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.9466, Validation Loss: 2.9525, Validation F1: 0.1293\n",
      "Best F1 Score at epoch 2: 0.1325, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.4322, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.5595, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.8587, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 12: 0.8591, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 22: 0.8678, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 43: 0.8882, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 51: 0.9065, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 72: 0.9076, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 73: 0.9128, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 92: 0.9160, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 100: 0.9196, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.7775, Validation Loss: 0.7747, Validation F1: 0.9196\n",
      "Best F1 Score at epoch 101: 0.9241, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 115: 0.9258, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 116: 0.9275, Parameters: lr=0.01, hidden_dim=256, drop_out=0.4\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.01, hidden_dim 256: 0.9236\n",
      "Testing with learning rate: 0.01, hidden_dim: 512, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.6077, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.0696, Validation Loss: 3.1677, Validation F1: 0.6077\n",
      "Best F1 Score at epoch 6: 0.6465, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 14: 0.7363, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 18: 0.8173, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 61: 0.8395, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 74: 0.8628, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 81: 0.8669, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 1.3539, Validation Loss: 1.3710, Validation F1: 0.7948\n",
      "Best F1 Score at epoch 104: 0.9127, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 105: 0.9268, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 106: 0.9269, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1298, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.2219, Validation Loss: 7.8183, Validation F1: 0.1298\n",
      "Best F1 Score at epoch 2: 0.1340, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.2202, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 5: 0.2283, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 7: 0.2993, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.3032, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 11: 0.6988, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 17: 0.8477, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 23: 0.8856, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 29: 0.8950, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 30: 0.9120, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 34: 0.9179, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 41: 0.9181, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 1.6094, Validation Loss: 1.9893, Validation F1: 0.8798\n",
      "Best F1 Score at epoch 157: 0.9223, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 183: 0.9224, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 184: 0.9228, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 186: 0.9234, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 187: 0.9238, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 193: 0.9241, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 194: 0.9255, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2230, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.9570, Validation Loss: 2.4538, Validation F1: 0.2230\n",
      "Best F1 Score at epoch 5: 0.3056, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 6: 0.7349, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 7: 0.7451, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.7913, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 10: 0.8480, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 17: 0.8568, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.8904, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 21: 0.8930, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 24: 0.8941, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 27: 0.9132, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 31: 0.9139, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 40: 0.9249, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.7171, Validation Loss: 0.7763, Validation F1: 0.6447\n",
      "Best F1 Score at epoch 183: 0.9293, Parameters: lr=0.01, hidden_dim=512, drop_out=0.2\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.01, hidden_dim 512: 0.9273\n",
      "Testing with learning rate: 0.01, hidden_dim: 512, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0532, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.6198, Validation Loss: 3.9704, Validation F1: 0.0532\n",
      "Best F1 Score at epoch 1: 0.2344, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.4070, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.4705, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.7938, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.8398, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 67: 0.8413, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 70: 0.8601, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 75: 0.8775, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 76: 0.8879, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.7986, Validation Loss: 2.6319, Validation F1: 0.4949\n",
      "Best F1 Score at epoch 133: 0.8943, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1299, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.8934, Validation Loss: 7.4423, Validation F1: 0.1299\n",
      "Best F1 Score at epoch 1: 0.3654, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.5798, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.6530, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.8527, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 23: 0.9008, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 72: 0.9039, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 1.1011, Validation Loss: 1.4539, Validation F1: 0.6209\n",
      "Best F1 Score at epoch 111: 0.9315, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 119: 0.9341, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 138: 0.9360, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 139: 0.9389, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1338, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.7807, Validation Loss: 4.9368, Validation F1: 0.1338\n",
      "Best F1 Score at epoch 3: 0.1669, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.2339, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.4824, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.5702, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.8340, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 22: 0.9038, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 23: 0.9284, Parameters: lr=0.01, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 1.6048, Validation Loss: 1.3415, Validation F1: 0.8860\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.01, hidden_dim 512: 0.9205\n",
      "Testing with learning rate: 0.01, hidden_dim: 512, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1346, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.8593, Validation Loss: 8.0895, Validation F1: 0.1346\n",
      "Best F1 Score at epoch 2: 0.3196, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.6128, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.8286, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 13: 0.8312, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 15: 0.8532, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 23: 0.8538, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 26: 0.8846, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 30: 0.8859, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 66: 0.9064, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 72: 0.9142, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 83: 0.9143, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 87: 0.9260, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 93: 0.9312, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 1.1149, Validation Loss: 0.9516, Validation F1: 0.6485\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0688, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.9578, Validation Loss: 6.5246, Validation F1: 0.0688\n",
      "Best F1 Score at epoch 2: 0.1343, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.3510, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 8: 0.3543, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 9: 0.4818, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.5169, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 11: 0.5282, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 12: 0.7940, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 20: 0.8294, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 21: 0.8348, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 34: 0.8852, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 76: 0.9090, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 89: 0.9119, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 2.9930, Validation Loss: 2.6425, Validation F1: 0.8937\n",
      "Best F1 Score at epoch 112: 0.9190, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 140: 0.9232, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 141: 0.9256, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 144: 0.9262, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 148: 0.9302, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 149: 0.9303, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 152: 0.9316, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1274, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.1536, Validation Loss: 7.3740, Validation F1: 0.1274\n",
      "Best F1 Score at epoch 2: 0.3348, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.5961, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.7823, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.8404, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 19: 0.8502, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 26: 0.9039, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 27: 0.9141, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 34: 0.9280, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 1.5093, Validation Loss: 1.2859, Validation F1: 0.9240\n",
      "Best F1 Score at epoch 115: 0.9340, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 149: 0.9362, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 156: 0.9379, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 157: 0.9379, Parameters: lr=0.01, hidden_dim=512, drop_out=0.4\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.01, hidden_dim 512: 0.9336\n",
      "Best Parameters: {'learning_rate': 0.05, 'hidden_dim': 512, 'drop_out': 0.3}, Best F1 Score: 0.9345\n",
      "All results: {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}}\n",
      "Testing with learning rate: 0.001, hidden_dim: 128, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0052, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.7593, Validation Loss: 2.5016, Validation F1: 0.0052\n",
      "Best F1 Score at epoch 1: 0.1920, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 5: 0.3709, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.4218, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 9: 0.5069, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 11: 0.6432, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 14: 0.6719, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 15: 0.6923, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 26: 0.6962, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 39: 0.8100, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 55: 0.8487, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 89: 0.8592, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 91: 0.8593, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6923, Validation Loss: 0.7935, Validation F1: 0.5750\n",
      "Best F1 Score at epoch 157: 0.8608, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 160: 0.8621, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0084, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.6149, Validation Loss: 2.6502, Validation F1: 0.0084\n",
      "Best F1 Score at epoch 1: 0.1809, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 2: 0.3467, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.3651, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 13: 0.3838, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 14: 0.4198, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 15: 0.4386, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 16: 0.4667, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 17: 0.5022, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 18: 0.5420, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 19: 0.5962, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.6639, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 21: 0.6691, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 23: 0.7133, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 33: 0.7335, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 34: 0.7568, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 35: 0.7811, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 42: 0.8456, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 49: 0.8559, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 52: 0.8669, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 68: 0.8810, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 93: 0.8890, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6811, Validation Loss: 1.0550, Validation F1: 0.6098\n",
      "Best F1 Score at epoch 129: 0.8942, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 162: 0.9001, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2238, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.9939, Validation Loss: 2.5014, Validation F1: 0.2238\n",
      "Best F1 Score at epoch 1: 0.3363, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.3801, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 9: 0.5043, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.7349, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 17: 0.8028, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.8070, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 21: 0.8138, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 26: 0.8306, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 43: 0.8550, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 66: 0.8742, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 77: 0.8800, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 96: 0.8815, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 97: 0.8972, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6837, Validation Loss: 0.7359, Validation F1: 0.6954\n",
      "Best F1 Score at epoch 124: 0.9103, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 125: 0.9113, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 126: 0.9122, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Best F1 Score at epoch 151: 0.9137, Parameters: lr=0.001, hidden_dim=128, drop_out=0.2\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.001, hidden_dim 128: 0.8919\n",
      "Testing with learning rate: 0.001, hidden_dim: 128, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0029, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.0225, Validation Loss: 2.4708, Validation F1: 0.0029\n",
      "Best F1 Score at epoch 1: 0.0137, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.0599, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.1106, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.1565, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.1986, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.2775, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.3495, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.4977, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.5135, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.5236, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 14: 0.7318, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 53: 0.8420, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 65: 0.8624, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.7053, Validation Loss: 0.8041, Validation F1: 0.5426\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0882, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 4.2985, Validation Loss: 2.8109, Validation F1: 0.0882\n",
      "Best F1 Score at epoch 1: 0.1066, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.1256, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.1292, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.2886, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.3875, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.5028, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.6084, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.7132, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.7140, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 37: 0.8195, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 40: 0.8301, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 55: 0.8642, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 76: 0.8681, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.7267, Validation Loss: 0.8561, Validation F1: 0.6032\n",
      "Best F1 Score at epoch 122: 0.8682, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 124: 0.8882, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.3167, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.6387, Validation Loss: 3.1658, Validation F1: 0.3167\n",
      "Best F1 Score at epoch 1: 0.3625, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.4834, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.5125, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.5369, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.6867, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 16: 0.7076, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.7118, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 26: 0.7760, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 28: 0.8102, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 43: 0.8281, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 55: 0.8317, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 72: 0.8633, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 73: 0.8829, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Best F1 Score at epoch 99: 0.8872, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.7002, Validation Loss: 0.7518, Validation F1: 0.7144\n",
      "Best F1 Score at epoch 195: 0.9013, Parameters: lr=0.001, hidden_dim=128, drop_out=0.3\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.001, hidden_dim 128: 0.8840\n",
      "Testing with learning rate: 0.001, hidden_dim: 128, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1076, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.7103, Validation Loss: 2.6044, Validation F1: 0.1076\n",
      "Best F1 Score at epoch 4: 0.1748, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.2664, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 9: 0.3117, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 11: 0.3625, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 15: 0.3812, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 16: 0.4424, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 19: 0.5174, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 20: 0.6859, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 21: 0.7332, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 43: 0.7333, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 48: 0.7797, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 49: 0.8082, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 50: 0.8406, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.7024, Validation Loss: 0.7691, Validation F1: 0.6555\n",
      "Best F1 Score at epoch 111: 0.8445, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 168: 0.8618, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1646, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.9868, Validation Loss: 2.7502, Validation F1: 0.1646\n",
      "Best F1 Score at epoch 2: 0.3157, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.4151, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.6114, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 11: 0.6229, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 15: 0.6532, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 19: 0.6745, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 24: 0.7203, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 36: 0.8201, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 50: 0.8361, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 53: 0.8562, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 54: 0.8577, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 67: 0.8665, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 98: 0.8882, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6985, Validation Loss: 0.8297, Validation F1: 0.8350\n",
      "Best F1 Score at epoch 115: 0.8958, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0714, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.6555, Validation Loss: 2.4595, Validation F1: 0.0714\n",
      "Best F1 Score at epoch 2: 0.1613, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.1924, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.3394, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.5955, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 11: 0.6837, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 12: 0.7064, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 23: 0.7072, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 25: 0.7416, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 26: 0.7672, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 28: 0.7951, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 37: 0.7962, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 46: 0.8625, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 61: 0.8653, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 70: 0.8669, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 77: 0.8824, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.7229, Validation Loss: 0.8011, Validation F1: 0.6054\n",
      "Best F1 Score at epoch 106: 0.8922, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 113: 0.8934, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 141: 0.8936, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 170: 0.8952, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 177: 0.9003, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Best F1 Score at epoch 199: 0.9007, Parameters: lr=0.001, hidden_dim=128, drop_out=0.4\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}, (0.4, 0.001, 128): {'folds': [0.8617934656721742, 0.8958051398374304, 0.9006998826210953], 'avg_f1': 0.8860994960435665}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.001, hidden_dim 128: 0.8861\n",
      "Testing with learning rate: 0.001, hidden_dim: 256, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0783, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.7490, Validation Loss: 2.3948, Validation F1: 0.0783\n",
      "Best F1 Score at epoch 1: 0.3612, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 2: 0.3963, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 4: 0.4544, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 5: 0.7261, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.7499, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 14: 0.8248, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 63: 0.8480, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6321, Validation Loss: 0.7355, Validation F1: 0.5971\n",
      "Best F1 Score at epoch 109: 0.8509, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 124: 0.8611, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 132: 0.8630, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0139, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.0056, Validation Loss: 2.4725, Validation F1: 0.0139\n",
      "Best F1 Score at epoch 1: 0.1351, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.2715, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 4: 0.3547, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 5: 0.4519, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 7: 0.4761, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.4777, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 9: 0.4839, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 11: 0.5249, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.6395, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 15: 0.6926, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.8412, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 28: 0.8510, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 35: 0.8744, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 40: 0.8812, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 58: 0.8894, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 62: 0.9086, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 72: 0.9163, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 73: 0.9189, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 84: 0.9250, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6314, Validation Loss: 0.7004, Validation F1: 0.6975\n",
      "Best F1 Score at epoch 107: 0.9293, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 127: 0.9314, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 160: 0.9329, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 195: 0.9330, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1394, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.8996, Validation Loss: 2.3511, Validation F1: 0.1394\n",
      "Best F1 Score at epoch 1: 0.3347, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.4280, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 7: 0.5002, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.5626, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 9: 0.6215, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 10: 0.8076, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.8107, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 17: 0.8360, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 19: 0.8360, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 20: 0.8574, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 27: 0.8701, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 35: 0.8837, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 43: 0.8940, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 53: 0.8990, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 77: 0.9173, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 96: 0.9267, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6399, Validation Loss: 0.6673, Validation F1: 0.6905\n",
      "Best F1 Score at epoch 119: 0.9271, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 127: 0.9315, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 128: 0.9330, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 130: 0.9346, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 146: 0.9347, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 147: 0.9355, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 148: 0.9362, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Best F1 Score at epoch 149: 0.9375, Parameters: lr=0.001, hidden_dim=256, drop_out=0.2\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}, (0.4, 0.001, 128): {'folds': [0.8617934656721742, 0.8958051398374304, 0.9006998826210953], 'avg_f1': 0.8860994960435665}, (0.2, 0.001, 256): {'folds': [0.8630187919514543, 0.93304862976844, 0.9375430036595797], 'avg_f1': 0.9112034751264914}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.001, hidden_dim 256: 0.9112\n",
      "Testing with learning rate: 0.001, hidden_dim: 256, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1992, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.8214, Validation Loss: 2.3827, Validation F1: 0.1992\n",
      "Best F1 Score at epoch 1: 0.4994, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.6518, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.7297, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 13: 0.7378, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 38: 0.8205, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 54: 0.8313, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 66: 0.8579, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 67: 0.8602, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 68: 0.8615, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 69: 0.8628, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 93: 0.8735, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6327, Validation Loss: 0.7454, Validation F1: 0.5769\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0893, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.7028, Validation Loss: 2.5001, Validation F1: 0.0893\n",
      "Best F1 Score at epoch 1: 0.3780, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.4232, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.5892, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.7595, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 23: 0.8322, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 27: 0.8556, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 34: 0.8642, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 49: 0.8809, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 58: 0.8948, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 63: 0.8965, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 70: 0.9002, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 79: 0.9128, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 93: 0.9215, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6477, Validation Loss: 0.7826, Validation F1: 0.6903\n",
      "Best F1 Score at epoch 107: 0.9250, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 142: 0.9282, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 144: 0.9284, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1679, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.0094, Validation Loss: 2.3886, Validation F1: 0.1679\n",
      "Best F1 Score at epoch 1: 0.3142, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.4065, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.7662, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.8056, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 18: 0.8324, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 21: 0.8350, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 32: 0.8543, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 34: 0.8614, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 47: 0.8753, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 48: 0.8799, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 65: 0.9001, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 66: 0.9027, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 73: 0.9143, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 90: 0.9170, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6446, Validation Loss: 0.7005, Validation F1: 0.6504\n",
      "Best F1 Score at epoch 109: 0.9243, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 110: 0.9245, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 111: 0.9299, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 126: 0.9308, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 133: 0.9328, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Best F1 Score at epoch 141: 0.9360, Parameters: lr=0.001, hidden_dim=256, drop_out=0.3\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}, (0.4, 0.001, 128): {'folds': [0.8617934656721742, 0.8958051398374304, 0.9006998826210953], 'avg_f1': 0.8860994960435665}, (0.2, 0.001, 256): {'folds': [0.8630187919514543, 0.93304862976844, 0.9375430036595797], 'avg_f1': 0.9112034751264914}, (0.3, 0.001, 256): {'folds': [0.8734592142885237, 0.9284128046146357, 0.936036914726875], 'avg_f1': 0.9126363112100115}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.001, hidden_dim 256: 0.9126\n",
      "Testing with learning rate: 0.001, hidden_dim: 256, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2311, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 3.0558, Validation Loss: 2.3863, Validation F1: 0.2311\n",
      "Best F1 Score at epoch 1: 0.4259, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.4732, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 9: 0.5485, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.5502, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 11: 0.5857, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 14: 0.7202, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 17: 0.7405, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 22: 0.7971, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 28: 0.8006, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 29: 0.8187, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 37: 0.8822, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6706, Validation Loss: 0.7213, Validation F1: 0.6061\n",
      "Best F1 Score at epoch 111: 0.8894, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 132: 0.8900, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 156: 0.8934, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 183: 0.8963, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 192: 0.8981, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0658, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 4.0253, Validation Loss: 2.6524, Validation F1: 0.0658\n",
      "Best F1 Score at epoch 1: 0.2384, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 3: 0.3080, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.3215, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.3300, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 7: 0.5200, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 8: 0.5901, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 13: 0.6112, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 14: 0.7664, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 16: 0.7715, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 18: 0.7767, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 24: 0.8376, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 37: 0.8514, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 48: 0.8646, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 49: 0.8684, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 58: 0.8959, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 75: 0.9046, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 80: 0.9053, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6551, Validation Loss: 0.9153, Validation F1: 0.6364\n",
      "Best F1 Score at epoch 105: 0.9069, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 137: 0.9197, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1855, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.8961, Validation Loss: 2.5137, Validation F1: 0.1855\n",
      "Best F1 Score at epoch 1: 0.2163, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 2: 0.2648, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 3: 0.3625, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.4224, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.4739, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 8: 0.4920, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 10: 0.7655, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 19: 0.8144, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 21: 0.8208, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 28: 0.8465, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 29: 0.8658, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 31: 0.8672, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 52: 0.8692, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 61: 0.8808, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 73: 0.8991, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 95: 0.9116, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6741, Validation Loss: 0.7022, Validation F1: 0.6436\n",
      "Best F1 Score at epoch 158: 0.9149, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Best F1 Score at epoch 159: 0.9284, Parameters: lr=0.001, hidden_dim=256, drop_out=0.4\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}, (0.4, 0.001, 128): {'folds': [0.8617934656721742, 0.8958051398374304, 0.9006998826210953], 'avg_f1': 0.8860994960435665}, (0.2, 0.001, 256): {'folds': [0.8630187919514543, 0.93304862976844, 0.9375430036595797], 'avg_f1': 0.9112034751264914}, (0.3, 0.001, 256): {'folds': [0.8734592142885237, 0.9284128046146357, 0.936036914726875], 'avg_f1': 0.9126363112100115}, (0.4, 0.001, 256): {'folds': [0.8981057796345016, 0.9197229970219831, 0.9283890035898796], 'avg_f1': 0.9154059267487881}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.001, hidden_dim 256: 0.9154\n",
      "Testing with learning rate: 0.001, hidden_dim: 512, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0870, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.0938, Validation Loss: 2.2875, Validation F1: 0.0870\n",
      "Best F1 Score at epoch 1: 0.2391, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 2: 0.3423, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.7026, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 7: 0.7027, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 11: 0.7937, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 52: 0.8024, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 54: 0.8072, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 59: 0.8265, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 94: 0.8562, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6215, Validation Loss: 0.7392, Validation F1: 0.6465\n",
      "Best F1 Score at epoch 106: 0.8686, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 107: 0.8704, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 153: 0.8711, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.4639, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 3.2927, Validation Loss: 2.2464, Validation F1: 0.4639\n",
      "Best F1 Score at epoch 1: 0.6121, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 2: 0.7654, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.8019, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 8: 0.8531, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 12: 0.8593, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 16: 0.8722, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 19: 0.8919, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 29: 0.8967, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 36: 0.8989, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 37: 0.9031, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 53: 0.9161, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 65: 0.9232, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 73: 0.9279, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 76: 0.9302, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 84: 0.9363, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 93: 0.9372, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6280, Validation Loss: 0.7061, Validation F1: 0.6613\n",
      "Best F1 Score at epoch 102: 0.9381, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 103: 0.9411, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 107: 0.9424, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 151: 0.9458, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.3022, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Epoch 0, Train Loss: 2.6838, Validation Loss: 2.2451, Validation F1: 0.3022\n",
      "Best F1 Score at epoch 1: 0.6286, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 3: 0.6837, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 5: 0.7418, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 10: 0.8535, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 25: 0.8853, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 31: 0.9135, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 40: 0.9140, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 49: 0.9170, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 50: 0.9229, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 58: 0.9303, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 59: 0.9321, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 68: 0.9324, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 69: 0.9332, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 79: 0.9396, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 80: 0.9413, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Best F1 Score at epoch 81: 0.9415, Parameters: lr=0.001, hidden_dim=512, drop_out=0.2\n",
      "Epoch 100, Train Loss: 0.6245, Validation Loss: 0.6353, Validation F1: 0.6584\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}, (0.4, 0.001, 128): {'folds': [0.8617934656721742, 0.8958051398374304, 0.9006998826210953], 'avg_f1': 0.8860994960435665}, (0.2, 0.001, 256): {'folds': [0.8630187919514543, 0.93304862976844, 0.9375430036595797], 'avg_f1': 0.9112034751264914}, (0.3, 0.001, 256): {'folds': [0.8734592142885237, 0.9284128046146357, 0.936036914726875], 'avg_f1': 0.9126363112100115}, (0.4, 0.001, 256): {'folds': [0.8981057796345016, 0.9197229970219831, 0.9283890035898796], 'avg_f1': 0.9154059267487881}, (0.2, 0.001, 512): {'folds': [0.8710556782765814, 0.9457655046476018, 0.9415066294675296], 'avg_f1': 0.9194426041305709}}\n",
      "Average F1 Score for dropout 0.2, learning rate 0.001, hidden_dim 512: 0.9194\n",
      "Testing with learning rate: 0.001, hidden_dim: 512, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1807, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.9246, Validation Loss: 2.3048, Validation F1: 0.1807\n",
      "Best F1 Score at epoch 1: 0.3086, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.3421, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.7212, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.7491, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.7966, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.8075, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 42: 0.8477, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 79: 0.8559, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 84: 0.8596, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 93: 0.8641, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6384, Validation Loss: 0.7364, Validation F1: 0.8590\n",
      "Best F1 Score at epoch 124: 0.8719, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 139: 0.8754, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 144: 0.8782, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.4166, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 3.5416, Validation Loss: 2.2977, Validation F1: 0.4166\n",
      "Best F1 Score at epoch 1: 0.5103, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.6018, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.8418, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.8486, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 21: 0.8494, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 23: 0.8696, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 24: 0.8820, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 38: 0.8954, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 48: 0.9187, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 58: 0.9263, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 59: 0.9290, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 79: 0.9303, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 80: 0.9307, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 81: 0.9309, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 91: 0.9371, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6125, Validation Loss: 1.2214, Validation F1: 0.7203\n",
      "Best F1 Score at epoch 126: 0.9414, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 146: 0.9423, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 160: 0.9428, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 166: 0.9428, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 171: 0.9435, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.3972, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.7732, Validation Loss: 2.3134, Validation F1: 0.3972\n",
      "Best F1 Score at epoch 2: 0.6201, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.7112, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.7592, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8479, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 18: 0.8623, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 23: 0.8733, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 41: 0.8954, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 44: 0.9186, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 53: 0.9246, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 54: 0.9254, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 64: 0.9331, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 77: 0.9350, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 89: 0.9389, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.6261, Validation Loss: 0.6620, Validation F1: 0.9340\n",
      "Best F1 Score at epoch 116: 0.9402, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 134: 0.9409, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Best F1 Score at epoch 137: 0.9413, Parameters: lr=0.001, hidden_dim=512, drop_out=0.3\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}, (0.4, 0.001, 128): {'folds': [0.8617934656721742, 0.8958051398374304, 0.9006998826210953], 'avg_f1': 0.8860994960435665}, (0.2, 0.001, 256): {'folds': [0.8630187919514543, 0.93304862976844, 0.9375430036595797], 'avg_f1': 0.9112034751264914}, (0.3, 0.001, 256): {'folds': [0.8734592142885237, 0.9284128046146357, 0.936036914726875], 'avg_f1': 0.9126363112100115}, (0.4, 0.001, 256): {'folds': [0.8981057796345016, 0.9197229970219831, 0.9283890035898796], 'avg_f1': 0.9154059267487881}, (0.2, 0.001, 512): {'folds': [0.8710556782765814, 0.9457655046476018, 0.9415066294675296], 'avg_f1': 0.9194426041305709}, (0.3, 0.001, 512): {'folds': [0.8781882418918148, 0.9434933464307231, 0.941322704045839], 'avg_f1': 0.9210014307894591}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.001, hidden_dim 512: 0.9210\n",
      "Testing with learning rate: 0.001, hidden_dim: 512, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.4739, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.5874, Validation Loss: 2.3194, Validation F1: 0.4739\n",
      "Best F1 Score at epoch 4: 0.7667, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 9: 0.7863, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 14: 0.7984, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 38: 0.8677, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6318, Validation Loss: 0.7310, Validation F1: 0.5857\n",
      "Best F1 Score at epoch 161: 0.8731, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Fold 2\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0875e-01, 5.0847e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0271e+00, 6.5927e+00, 4.9423e+03, 1.4121e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0363e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.2631, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.6904, Validation Loss: 2.3433, Validation F1: 0.2631\n",
      "Best F1 Score at epoch 1: 0.3310, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 2: 0.4742, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 3: 0.7242, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 18: 0.8694, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 45: 0.8930, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 64: 0.9127, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 98: 0.9309, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6210, Validation Loss: 0.7059, Validation F1: 0.6516\n",
      "Best F1 Score at epoch 113: 0.9356, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 131: 0.9363, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 156: 0.9370, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 157: 0.9373, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 182: 0.9378, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Fold 3\n",
      "Class weights: tensor([2.3022e-01, 2.6619e+01, 4.0874e-01, 5.0838e+00, 2.2647e-01, 9.5166e+00,\n",
      "        9.0298e+00, 6.5927e+00, 4.9423e+03, 1.4827e+03, 3.2927e-01, 8.8731e+00,\n",
      "        3.4723e+01, 2.4712e+03, 8.0146e+01], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.1807, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Epoch 0, Train Loss: 2.5670, Validation Loss: 2.2720, Validation F1: 0.1807\n",
      "Best F1 Score at epoch 1: 0.3286, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 3: 0.4077, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 4: 0.4132, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 5: 0.4833, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 6: 0.8079, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 23: 0.8547, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 30: 0.8669, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 31: 0.8799, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 44: 0.8829, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 49: 0.9048, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 63: 0.9201, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 65: 0.9224, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 67: 0.9262, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 90: 0.9287, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Epoch 100, Train Loss: 0.6262, Validation Loss: 0.6615, Validation F1: 0.6569\n",
      "Best F1 Score at epoch 119: 0.9356, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 121: 0.9388, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 131: 0.9394, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 164: 0.9408, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Best F1 Score at epoch 176: 0.9419, Parameters: lr=0.001, hidden_dim=512, drop_out=0.4\n",
      "Current Results:  {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}, (0.4, 0.001, 128): {'folds': [0.8617934656721742, 0.8958051398374304, 0.9006998826210953], 'avg_f1': 0.8860994960435665}, (0.2, 0.001, 256): {'folds': [0.8630187919514543, 0.93304862976844, 0.9375430036595797], 'avg_f1': 0.9112034751264914}, (0.3, 0.001, 256): {'folds': [0.8734592142885237, 0.9284128046146357, 0.936036914726875], 'avg_f1': 0.9126363112100115}, (0.4, 0.001, 256): {'folds': [0.8981057796345016, 0.9197229970219831, 0.9283890035898796], 'avg_f1': 0.9154059267487881}, (0.2, 0.001, 512): {'folds': [0.8710556782765814, 0.9457655046476018, 0.9415066294675296], 'avg_f1': 0.9194426041305709}, (0.3, 0.001, 512): {'folds': [0.8781882418918148, 0.9434933464307231, 0.941322704045839], 'avg_f1': 0.9210014307894591}, (0.4, 0.001, 512): {'folds': [0.8731120999726238, 0.9378283820175047, 0.9419460819625343], 'avg_f1': 0.9176288546508876}}\n",
      "Average F1 Score for dropout 0.4, learning rate 0.001, hidden_dim 512: 0.9176\n",
      "Best Parameters: {'learning_rate': 0.05, 'hidden_dim': 512, 'drop_out': 0.3}, Best F1 Score: 0.9345\n",
      "All results: {(0.2, 0.05, 128): {'folds': [0.9443653573856006, 0.8612343118798144, 0.8621932100444398], 'avg_f1': 0.8892642931032849}, (0.3, 0.05, 128): {'folds': [0.8223699024034871, 0.9161402954324136, 0.8903812754961214], 'avg_f1': 0.8762971577773406}, (0.4, 0.05, 128): {'folds': [0.9413214818348266, 0.3733500074313815, 0.5912978186901099], 'avg_f1': 0.635323102652106}, (0.2, 0.05, 256): {'folds': [0.7623430650429159, 0.9307876723662308, 0.8672113378645763], 'avg_f1': 0.8534473584245744}, (0.3, 0.05, 256): {'folds': [0.6999995810223298, 0.8999845772537286, 0.7156656975106617], 'avg_f1': 0.77188328526224}, (0.4, 0.05, 256): {'folds': [0.8686000644271483, 0.9290919380584729, 0.814933226975612], 'avg_f1': 0.8708750764870777}, (0.2, 0.05, 512): {'folds': [0.43666638792088347, 0.9432906348149378, 0.9317729135738183], 'avg_f1': 0.7705766454365466}, (0.3, 0.05, 512): {'folds': [0.9237987054517229, 0.9424911365659544, 0.9371457396011399], 'avg_f1': 0.9344785272062724}, (0.4, 0.05, 512): {'folds': [0.4130142817347628, 0.8109675908908874, 0.8238859411816446], 'avg_f1': 0.6826226046024316}, (0.2, 0.01, 128): {'folds': [0.8739064826635456, 0.9372773969918007, 0.9441660766551115], 'avg_f1': 0.9184499854368192}, (0.3, 0.01, 128): {'folds': [0.8640228846921889, 0.9287550820323415, 0.9361054744474965], 'avg_f1': 0.9096278137240089}, (0.4, 0.01, 128): {'folds': [0.8487486326187099, 0.942083570015382, 0.9361749208743413], 'avg_f1': 0.9090023745028111}, (0.2, 0.01, 256): {'folds': [0.9339282390692252, 0.9332681155847803, 0.9202691571245377], 'avg_f1': 0.9291551705928477}, (0.3, 0.01, 256): {'folds': [0.87421257750641, 0.9397146707461623, 0.9410203946786956], 'avg_f1': 0.9183158809770893}, (0.4, 0.01, 256): {'folds': [0.9054315438987147, 0.9378818331103275, 0.927541016629062], 'avg_f1': 0.9236181312127014}, (0.2, 0.01, 512): {'folds': [0.926901192174016, 0.9255336507528034, 0.9293157180195862], 'avg_f1': 0.9272501869821351}, (0.3, 0.01, 512): {'folds': [0.894272729670765, 0.93890507433465, 0.9283527036877105], 'avg_f1': 0.9205101692310418}, (0.4, 0.01, 512): {'folds': [0.9311616649293321, 0.9316255543132238, 0.9379267655632147], 'avg_f1': 0.9335713282685902}, (0.2, 0.001, 128): {'folds': [0.8620658867548725, 0.900097889789889, 0.9136572922404272], 'avg_f1': 0.8919403562617295}, (0.3, 0.001, 128): {'folds': [0.8623640471606265, 0.8882337692621509, 0.9013218798621246], 'avg_f1': 0.8839732320949674}, (0.4, 0.001, 128): {'folds': [0.8617934656721742, 0.8958051398374304, 0.9006998826210953], 'avg_f1': 0.8860994960435665}, (0.2, 0.001, 256): {'folds': [0.8630187919514543, 0.93304862976844, 0.9375430036595797], 'avg_f1': 0.9112034751264914}, (0.3, 0.001, 256): {'folds': [0.8734592142885237, 0.9284128046146357, 0.936036914726875], 'avg_f1': 0.9126363112100115}, (0.4, 0.001, 256): {'folds': [0.8981057796345016, 0.9197229970219831, 0.9283890035898796], 'avg_f1': 0.9154059267487881}, (0.2, 0.001, 512): {'folds': [0.8710556782765814, 0.9457655046476018, 0.9415066294675296], 'avg_f1': 0.9194426041305709}, (0.3, 0.001, 512): {'folds': [0.8781882418918148, 0.9434933464307231, 0.941322704045839], 'avg_f1': 0.9210014307894591}, (0.4, 0.001, 512): {'folds': [0.8731120999726238, 0.9378283820175047, 0.9419460819625343], 'avg_f1': 0.9176288546508876}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def grid_search(data, epochs, learning_rates, hidden_dims, drop_outs):\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    best_params = {}\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Precompute the train and validation graphs for all folds\n",
    "    folds = []\n",
    "    for train_idx, val_idx in skf.split(data, data[label_col]):\n",
    "        train_df = data.iloc[train_idx]\n",
    "        val_df = data.iloc[val_idx]\n",
    "\n",
    "        G_nx_train, G_pyg_train = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "        G_nx_val, G_pyg_val = create_graph(val_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "\n",
    "        G_pyg_train = G_pyg_train.to(device)\n",
    "        G_pyg_val = G_pyg_val.to(device)\n",
    "\n",
    "        G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "        G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "        G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "        G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "        folds.append((G_pyg_train, G_pyg_val))\n",
    "\n",
    "    params_results = {}\n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            for drop_out in drop_outs:\n",
    "                print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}, drop_out: {drop_out}\")\n",
    "                fold_f1_scores = []\n",
    "\n",
    "                for fold, (G_pyg_train, G_pyg_val) in enumerate(folds):\n",
    "                    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                    model = EGraphSAGE(node_in_channels=G_pyg_train.num_node_features,\n",
    "                                    edge_in_channels=G_pyg_train.num_edge_features,\n",
    "                                    hidden_channels=hidden_dim,\n",
    "                                    dropout=drop_out,\n",
    "                                    out_channels=num_classes).to(device)\n",
    "\n",
    "                    model.apply(init_weights)\n",
    "\n",
    "                    labels = G_pyg_train.edge_label.cpu().numpy()\n",
    "                    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                                    classes=np.unique(labels),\n",
    "                                                                    y=labels)\n",
    "\n",
    "                    # Normalize to stabilize training\n",
    "                    class_weights = th.FloatTensor(class_weights).to(device)\n",
    "                    print(\"Class weights:\", class_weights)\n",
    "\n",
    "                    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                    optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "                    scheduler = th.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "\n",
    "                    best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "\n",
    "                    for epoch in range(epochs):\n",
    "                        train_loss = 0\n",
    "                        val_loss = 0\n",
    "\n",
    "                        try:\n",
    "                            model.train()\n",
    "                            out = model(G_pyg_train)\n",
    "                            \n",
    "                            optimizer.zero_grad()\n",
    "                            loss = criterion(out, G_pyg_train.edge_label)\n",
    "                            train_loss = loss.item()\n",
    "\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            scheduler.step()\n",
    "\n",
    "                            model.eval()\n",
    "                            with th.no_grad():\n",
    "                                out = model(G_pyg_val)\n",
    "                                loss = criterion(out, G_pyg_val.edge_label)\n",
    "                                val_loss = loss.item()\n",
    "\n",
    "                            val_f1 = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='weighted')\n",
    "\n",
    "                            if val_f1 > best_epoch_f1:\n",
    "                                best_epoch_f1 = val_f1  # Update the best F1 score for this fold\n",
    "                                print(f\"Best F1 Score at epoch {epoch}: {best_epoch_f1:.4f}, Parameters: lr={lr}, hidden_dim={hidden_dim}, drop_out={drop_out}\")\n",
    "\n",
    "                            if epoch % 100 == 0:\n",
    "                                print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}')\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                            break\n",
    "\n",
    "                    fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "                \n",
    "                avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "                params_results[(drop_out, lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "                print(\"Current Results: \", params_results)\n",
    "                print(f\"Average F1 Score for dropout {drop_out}, learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "                if avg_f1 > best_f1:\n",
    "                    best_f1 = avg_f1\n",
    "                    best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim, 'drop_out': drop_out}\n",
    "\n",
    "        print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "        print(\"All results:\", params_results)\n",
    "\n",
    "\n",
    "learning_rates = [0.05, 0.01, 0.001]\n",
    "hidden_dims = [128, 256, 512]\n",
    "drop_outs = [0.2, 0.3, 0.4]\n",
    "\n",
    "grid_search(train_full_df, epochs=200, learning_rates=learning_rates, hidden_dims=hidden_dims, drop_outs=drop_outs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 567130\n",
      "Number of node in G_pyg: 246698\n",
      "Shape of node in G_pyg: torch.Size([246698, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([567130, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([567130])\n",
      "Number of edges in G_pyg: 100082\n",
      "Number of node in G_pyg: 73716\n",
      "Shape of node in G_pyg: torch.Size([73716, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([100082, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([100082])\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "     train_full_df, test_size=0.15, random_state=42, stratify=train_full_df[label_col])\n",
    "\n",
    "G_nx_train, G_pyg_train = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "G_nx_val, G_pyg_val = create_graph(val_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adc36f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_progress(epoch, model, optimizer, best_f1, train_loss_history, val_loss_history, val_f1_history, saved_model_epochs):\n",
    "    global checkpoint_path, train_loss_history_path, val_loss_history_path, val_f1_history_path, saved_model_epochs_path\n",
    "\n",
    "    # Save checkpoint\n",
    "    th.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_f1': best_f1\n",
    "    }, checkpoint_path)\n",
    "    with open(train_loss_history_path, 'wb') as f:\n",
    "        pickle.dump(train_loss_history, f)\n",
    "    with open(val_loss_history_path, 'wb') as f:\n",
    "        pickle.dump(val_loss_history, f)\n",
    "    with open(val_f1_history_path, 'wb') as f:\n",
    "        pickle.dump(val_f1_history, f)\n",
    "    with open(saved_model_epochs_path, 'wb') as f:\n",
    "        pickle.dump(saved_model_epochs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88bdffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([2.3022e-01, 2.6626e+01, 4.0874e-01, 5.0839e+00, 2.2647e-01, 9.5164e+00,\n",
      "        9.0279e+00, 6.5926e+00, 4.7261e+03, 1.4542e+03, 3.2927e-01, 8.8732e+00,\n",
      "        3.4719e+01, 2.5206e+03, 8.0273e+01], device='cuda:0')\n",
      "Epoch 0 Saved best model. Best F1: 0.2571016620963626\n",
      "Epoch 0, Train Loss: 2.7890, Validation Loss: 2.6797, Validation F1: 0.2571\n",
      "Epoch 3 Saved best model. Best F1: 0.4387425614379881\n",
      "Epoch 6 Saved best model. Best F1: 0.4600938033840539\n",
      "Epoch 8 Saved best model. Best F1: 0.4756714192000096\n",
      "Epoch 9 Saved best model. Best F1: 0.7002458485099385\n",
      "Epoch 10, Train Loss: 1.2235, Validation Loss: 1.1883, Validation F1: 0.4942\n",
      "Epoch 13 Saved best model. Best F1: 0.7521367175512521\n",
      "Epoch 20, Train Loss: 0.9194, Validation Loss: 0.9915, Validation F1: 0.4728\n",
      "Epoch 30, Train Loss: 0.8178, Validation Loss: 1.0396, Validation F1: 0.4646\n",
      "Epoch 38 Saved best model. Best F1: 0.755095022701912\n",
      "Epoch 40, Train Loss: 0.6719, Validation Loss: 0.9641, Validation F1: 0.5054\n",
      "Epoch 41 Saved best model. Best F1: 0.7798624745366659\n",
      "Epoch 42 Saved best model. Best F1: 0.7910865272302854\n",
      "Epoch 44 Saved best model. Best F1: 0.7911045353960029\n",
      "Epoch 50, Train Loss: 0.6723, Validation Loss: 71.6903, Validation F1: 0.7865\n",
      "Epoch 60, Train Loss: 0.9595, Validation Loss: 1.6733, Validation F1: 0.4975\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     81\u001b[39m optimizer.zero_grad()\n\u001b[32m     82\u001b[39m loss = criterion(out, G_pyg_train.edge_label)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m train_loss = \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m loss.backward()\n\u001b[32m     86\u001b[39m optimizer.step()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Extract the best parameters from the grid search\n",
    "best_hidden_dim = 256  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.01  # Replace with the best learning_rate found\n",
    "best_dropout = 0.3  # Replace with the best dropout found\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "model = EGraphSAGE(node_in_channels=G_pyg_train.num_node_features,\n",
    "                   edge_in_channels=G_pyg_train.num_edge_features,\n",
    "                   hidden_channels=best_hidden_dim,\n",
    "                   dropout=best_dropout,\n",
    "                   out_channels=num_classes).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Compute class weights for the training dataset\n",
    "labels = G_pyg_train.edge_label.cpu().numpy()\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(labels),\n",
    "                                                  y=labels)\n",
    "\n",
    "# Normalize class weights\n",
    "class_weights = th.FloatTensor(class_weights).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "scheduler = th.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "\n",
    "# Move the graph data to the device\n",
    "G_pyg_train = G_pyg_train.to(device)\n",
    "G_pyg_val = G_pyg_val.to(device)\n",
    "\n",
    "G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "# ===== Load checkpoint if exists =====\n",
    "best_f1 = 0\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_f1 = checkpoint['best_f1']\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "val_f1_history = []\n",
    "saved_model_epochs = []\n",
    "\n",
    "train_loss_history_path = os.path.join(saves_path, 'train_loss_history.pkl')\n",
    "val_loss_history_path = os.path.join(saves_path, 'val_loss_history.pkl')\n",
    "val_f1_history_path = os.path.join(saves_path, 'val_f1_history.pkl')\n",
    "saved_model_epochs_path = os.path.join(saves_path, 'saved_model_epochs.pkl')\n",
    "\n",
    "if os.path.exists(train_loss_history_path) and os.path.exists(val_loss_history_path) and os.path.exists(val_f1_history_path) and os.path.exists(saved_model_epochs_path):\n",
    "    with open(train_loss_history_path, 'rb') as f:\n",
    "        train_loss_history = pickle.load(f)\n",
    "    with open(val_loss_history_path, 'rb') as f:\n",
    "        val_loss_history = pickle.load(f)\n",
    "    with open(val_f1_history_path, 'rb') as f:\n",
    "        val_f1_history = pickle.load(f)\n",
    "    with open(saved_model_epochs_path, 'rb') as f:\n",
    "        saved_model_epochs = pickle.load(f)\n",
    "\n",
    "# ===== Start Training =====\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    out = model(G_pyg_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, G_pyg_train.edge_label)\n",
    "    train_loss = loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        out = model(G_pyg_val)\n",
    "        loss = criterion(out, G_pyg_val.edge_label)\n",
    "        val_loss = loss.item()\n",
    "\n",
    "    val_f1 = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='weighted')\n",
    "    val_f1_micro = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='micro')\n",
    "    val_f1_macro = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='macro')\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_f1_history.append((val_f1, val_f1_micro, val_f1_macro))\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1  # Update the best F1 score for this fold\n",
    "        best_model_state = model.state_dict()\n",
    "        saved_model_epochs.append(epoch)\n",
    "\n",
    "        save_progress(epoch, model, optimizer, best_f1, train_loss_history, val_loss_history, val_f1_history, saved_model_epochs)\n",
    "        th.save(best_model_state, best_model_path)\n",
    "        print(f\"Epoch {epoch} Saved best model. Best F1:\", best_f1)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        # Save checkpoint\n",
    "        print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}')\n",
    "        save_progress(epoch, model, optimizer, best_f1, train_loss_history, val_loss_history, val_f1_history, saved_model_epochs)\n",
    "\n",
    "# Save the trained model\n",
    "print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a82c058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_process(train_losses, val_losses, val_f1, saved_model_epochs):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Plot Train Loss\n",
    "    axs[0].plot(train_losses, label='Train Loss', color='blue')\n",
    "    axs[0].plot(val_losses, label='Validation Loss', color='red')\n",
    "    axs[0].set_ylabel('Train Loss')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    val_f1_weighted_history = []\n",
    "    val_f1_micro_history = []\n",
    "    val_f1_macro_history = []\n",
    "\n",
    "    for val_f1_weighted, val_f1_micro, val_f1_macro in val_f1:\n",
    "        val_f1_weighted_history.append(val_f1_weighted)\n",
    "        val_f1_micro_history.append(val_f1_micro)\n",
    "        val_f1_macro_history.append(val_f1_macro)\n",
    "    \n",
    "    # Plot Validation F1\n",
    "\n",
    "    axs[1].plot(val_f1_weighted_history, label='Validation F1 Weighted', color='green')\n",
    "    axs[1].plot(val_f1_micro_history, label='Validation F1 Micro', color='blue')\n",
    "    axs[1].plot(val_f1_macro_history, label='Validation F1 Macro', color='red')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Validation F1')\n",
    "    axs[1].set_title('Validation F1 Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    # Add scatter for saved model epochs (e.g., F1 weighted here)\n",
    "    axs[1].scatter(saved_model_epochs, [val_f1_weighted_history[i] for i in saved_model_epochs],\n",
    "                   color='black', marker='o', label='Saved Model')\n",
    "    axs[1].legend()\n",
    "\n",
    "    print(len(train_losses))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df26e7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_process(train_loss_history, val_loss_history, val_f1_history, saved_model_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8368fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 117744\n",
      "Number of node in G_pyg: 82944\n",
      "Shape of node in G_pyg: torch.Size([82944, 27])\n",
      "Shape of edge attr in G_pyg: torch.Size([117744, 27])\n",
      "Shape of edge label in G_pyg: torch.Size([117744])\n"
     ]
    }
   ],
   "source": [
    "G_nx_test, G_pyg_test = create_graph(test_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/CIC_IDS_2017/whole_graph_combined_ports/best_model_all_downsampled.pth\n",
      "inference start\n",
      "inference done\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[27323   614    87     2     6     1     0  1154     3    52   210  4173\n",
      "      9    72   391]\n",
      " [    0   295     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0 19203     0     0     0     1     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0  1541     1     2     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0    12 34510    12   127     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0   818     0     7     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0   858     0    11     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0  1191     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     2     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     5     0     0\n",
      "      0     0     0]\n",
      " [  337     4     0     0     0     0     0     0     0     0  6977  1177\n",
      "     40     0 15305]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0   884\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0   225     1]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     3     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0    97     1]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.9878    0.8013    0.8849     34097\n",
      "                       Bot     0.3231    1.0000    0.4884       295\n",
      "                      DDoS     0.9955    0.9999    0.9977     19204\n",
      "             DoS GoldenEye     0.0000    0.0000    0.0000      1544\n",
      "                  DoS Hulk     0.9146    0.9956    0.9534     34661\n",
      "          DoS Slowhttptest     0.0000    0.0000    0.0000       825\n",
      "             DoS slowloris     0.0743    0.0127    0.0216       869\n",
      "               FTP-Patator     0.5079    1.0000    0.6736      1191\n",
      "                Heartbleed     0.4000    1.0000    0.5714         2\n",
      "              Infiltration     0.0877    1.0000    0.1613         5\n",
      "                  PortScan     0.9708    0.2927    0.4497     23840\n",
      "               SSH-Patator     0.1418    1.0000    0.2484       884\n",
      "  Web Attack - Brute Force     0.0000    0.0000    0.0000       226\n",
      "Web Attack - Sql Injection     0.0076    1.0000    0.0150         3\n",
      "          Web Attack - XSS     0.0001    0.0102    0.0001        98\n",
      "\n",
      "                  accuracy                         0.7678    117744\n",
      "                 macro avg     0.3607    0.6075    0.3644    117744\n",
      "              weighted avg     0.9218    0.7678    0.8008    117744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(G_pyg_test, adversarial=False):\n",
    "\n",
    "    G_pyg_test = G_pyg_test.to(device)\n",
    "    G_pyg_test.edge_label = G_pyg_test.edge_label.to(device)\n",
    "    G_pyg_test.edge_attr = G_pyg_test.edge_attr.to(device)\n",
    "\n",
    "    best_model = EGraphSAGE(node_in_channels=G_pyg_test.num_node_features, \n",
    "                       edge_in_channels=G_pyg_test.num_edge_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=num_classes).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path))\n",
    "    best_model = best_model.to(device)\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "            \n",
    "        try:\n",
    "            out = best_model(G_pyg_test)\n",
    "            \n",
    "        except Exception as forward_error:\n",
    "            print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "    print(\"inference done\")\n",
    "\n",
    "    pred_labels = out.argmax(dim=1).cpu()\n",
    "    all_test_labels = G_pyg_test.edge_label.cpu()\n",
    "\n",
    "    if adversarial:\n",
    "\n",
    "        # Create a boolean mask where the label is NOT equal to the adversarial class\n",
    "        adversarial_mask = all_test_labels == ADVERSARIAL_CLASS_LABEL\n",
    "\n",
    "        # Print the class that the adversarial samples are classified as\n",
    "        cm_adversarial = confusion_matrix(all_test_labels[adversarial_mask], pred_labels[adversarial_mask], labels=range(len(class_map) + 1))\n",
    "        print(\"Adversarial confusion matrix:\", cm_adversarial)\n",
    "\n",
    "        # Apply the mask to both labels and predictions\n",
    "        all_test_labels = all_test_labels[~adversarial_mask]\n",
    "        pred_labels = pred_labels[~adversarial_mask]\n",
    "        \n",
    "        \n",
    "\n",
    "    print(\"class_map\", class_map)\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map)))\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4)\n",
    "    print(report)\n",
    "\n",
    "    \n",
    "eval(G_pyg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcb5e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_traffic_to_attacker(graph, ratio=0.1, num_injected_nodes=1, is_attack=False):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    # 1. Identify attacker nodes\n",
    "    attacker_edges = (edge_label != BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "    attacker_nodes = th.unique(edge_index[:, attacker_edges])\n",
    "    if attacker_nodes.numel() == 0:\n",
    "        raise ValueError(\"No attacker nodes found.\")\n",
    "\n",
    "    # 2. Sample benign edge feature pool\n",
    "    if is_attack:\n",
    "        attack_edges = (edge_label != BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "        inject_edge_attr_pool = edge_attr[attack_edges]\n",
    "    else:\n",
    "        benign_edges = (edge_label == BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "        inject_edge_attr_pool = edge_attr[benign_edges]\n",
    "\n",
    "    # 3. Inject new nodes\n",
    "    original_num_nodes = x.size(0)\n",
    "\n",
    "    new_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "    x = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "    # 4. Inject edges from injected nodes to attacker nodes\n",
    "    num_to_inject = max(1, int(ratio * num_edges))\n",
    "    new_edges = []\n",
    "    new_attrs = []\n",
    "    new_labels = []\n",
    "\n",
    "    \n",
    "    for _ in range(num_to_inject):\n",
    "        src = random.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "\n",
    "        dst = attacker_nodes[random.randint(0, len(attacker_nodes) - 1)].item()\n",
    "\n",
    "        new_edges.append([src, dst])\n",
    "        attr = inject_edge_attr_pool[random.randint(0, len(inject_edge_attr_pool) - 1)]\n",
    "        new_attrs.append(attr)\n",
    "        new_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    # Create a new empty graph to store the injected edges\n",
    "    new_graph = Data()\n",
    "\n",
    "    # 5. Merge into graph\n",
    "    if new_edges:\n",
    "        new_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "        new_attrs = th.stack(new_attrs)\n",
    "        new_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "        new_graph.edge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "        new_graph.edge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "        new_graph.edge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "        new_graph.x = x\n",
    "\n",
    "        # new_graph.first_injected_node_idx = original_num_nodes # Store injected node indices\n",
    "\n",
    "    return new_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "632c5bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/CIC_IDS_2017/whole_graph_combined_ports/best_model_all_downsampled.pth\n",
      "inference start\n",
      "inference done\n",
      "Adversarial confusion matrix: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [2743   31 1572  239 2806  152  188  110    0   20  278 1991    1   36\n",
      "  1607    0]]\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[27412   584    95     1     5     3     0  1175     2    55   212  4075\n",
      "     20    64   394]\n",
      " [   20   275     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [ 3532    20 15624     0     0     9    19     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [  257     0     0     2     6  1246    33     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [ 5580     0     0    28   146 28100   805     0     0     0     0     2\n",
      "      0     0     0]\n",
      " [  117     0     0     1     3   684    20     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [  150     0     0     2     2   684    31     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [  101     0     0     0     0     0     0  1090     0     0     0     0\n",
      "      0     0     0]\n",
      " [    2     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     5     0     0\n",
      "      0     0     0]\n",
      " [ 4210    89     1     0     0     0     0     0     0     0 11122    39\n",
      "    241   385  7753]\n",
      " [  190   692     0     0     0     0     1     1     0     0     0     0\n",
      "      0     0     0]\n",
      " [    7     0     0     0     0     0     0     0     0     0     0     0\n",
      "      6   183    30]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     3     0]\n",
      " [    6     0     0     0     0     0     0     0     0     0     0     0\n",
      "      4    73    15]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.6592    0.8039    0.7244     34097\n",
      "                       Bot     0.1657    0.9322    0.2813       295\n",
      "                      DDoS     0.9939    0.8136    0.8947     19204\n",
      "             DoS GoldenEye     0.0588    0.0013    0.0025      1544\n",
      "                  DoS Hulk     0.9012    0.0042    0.0084     34661\n",
      "          DoS Slowhttptest     0.0223    0.8291    0.0434       825\n",
      "             DoS slowloris     0.0341    0.0357    0.0349       869\n",
      "               FTP-Patator     0.4810    0.9152    0.6306      1191\n",
      "                Heartbleed     0.0000    0.0000    0.0000         2\n",
      "              Infiltration     0.0833    1.0000    0.1538         5\n",
      "                  PortScan     0.9813    0.4665    0.6324     23840\n",
      "               SSH-Patator     0.0000    0.0000    0.0000       884\n",
      "  Web Attack - Brute Force     0.0221    0.0265    0.0241       226\n",
      "Web Attack - Sql Injection     0.0042    1.0000    0.0084         3\n",
      "          Web Attack - XSS     0.0018    0.1531    0.0036        98\n",
      "\n",
      "                  accuracy                         0.4791    117744\n",
      "                 macro avg     0.2939    0.4654    0.2295    117744\n",
      "              weighted avg     0.8235    0.4791    0.4940    117744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "G_pyg_test = G_pyg_test.cpu()\n",
    "injected_graph = inject_traffic_to_attacker(G_pyg_test, 0.1, num_injected_nodes=1, is_attack=True)\n",
    "eval(injected_graph, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64c37b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/CIC_IDS_2017/whole_graph_combined_ports/best_model_all_downsampled.pth\n",
      "inference start\n",
      "inference done\n",
      "Adversarial confusion matrix: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [9291   64   35    0    1    3    0  570    6   18  314 1230    8   17\n",
      "   217    0]]\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[27157   586    95     0     6     1     0  1194     3    47   232  4330\n",
      "     25    47   374]\n",
      " [    8   287     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [ 4085    67 15031     0     4     6    10     0     0     0     0     1\n",
      "      0     0     0]\n",
      " [  182     0     1     0    53  1293    15     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [ 4496    11     5     2  1105 28700   341     0     0     0     0     1\n",
      "      0     0     0]\n",
      " [  113     0     0     0    39   664     9     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [  125     0     0     0    38   694    12     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [   56     0     0     0     0     0     0  1135     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     2     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     5     0     0\n",
      "      0     0     0]\n",
      " [ 3479   311    25     0     0     0     0     0     0     0 15483    19\n",
      "    149   103  4271]\n",
      " [  104   776     2     0     0     0     0     2     0     0     0     0\n",
      "      0     0     0]\n",
      " [   11     0     0     0     0     0     0     0     0     0     0     0\n",
      "      1   168    46]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     3     0]\n",
      " [    2     1     0     0     0     0     0     0     0     0     0     0\n",
      "      1    75    19]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.6820    0.7965    0.7348     34097\n",
      "                       Bot     0.1408    0.9729    0.2459       295\n",
      "                      DDoS     0.9916    0.7827    0.8748     19204\n",
      "             DoS GoldenEye     0.0000    0.0000    0.0000      1544\n",
      "                  DoS Hulk     0.8876    0.0319    0.0615     34661\n",
      "          DoS Slowhttptest     0.0212    0.8048    0.0413       825\n",
      "             DoS slowloris     0.0310    0.0138    0.0191       869\n",
      "               FTP-Patator     0.4869    0.9530    0.6445      1191\n",
      "                Heartbleed     0.4000    1.0000    0.5714         2\n",
      "              Infiltration     0.0962    1.0000    0.1754         5\n",
      "                  PortScan     0.9852    0.6495    0.7829     23840\n",
      "               SSH-Patator     0.0000    0.0000    0.0000       884\n",
      "  Web Attack - Brute Force     0.0057    0.0044    0.0050       226\n",
      "Web Attack - Sql Injection     0.0076    1.0000    0.0150         3\n",
      "          Web Attack - XSS     0.0040    0.1939    0.0079        98\n",
      "\n",
      "                  accuracy                         0.5173    117744\n",
      "                 macro avg     0.3160    0.5469    0.2786    117744\n",
      "              weighted avg     0.8257    0.5173    0.5397    117744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject BENIGN Traffic to Attacker Nodes\n",
    "injected_graph = inject_traffic_to_attacker(G_pyg_test, 0.1, num_injected_nodes=1, is_attack=False)\n",
    "eval(injected_graph, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bf0e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_random_nodes(graph, ratio=0.1, num_injected_nodes=1):\n",
    "\tedge_index = graph.edge_index.clone()\n",
    "\tedge_attr = graph.edge_attr.clone()\n",
    "\tedge_label = graph.edge_label.clone()\n",
    "\tx = graph.x.clone()\n",
    "\n",
    "\tnum_edges = edge_index.size(1)\n",
    "\tfeature_dim = graph.x.size(1)\n",
    "\n",
    "\t# 1. Inject new nodes\n",
    "\toriginal_num_nodes = x.size(0)\n",
    "\tnew_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "\tx = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "\t# 2. Inject random edges\n",
    "\tnum_to_inject = max(1, int(ratio * num_edges))\n",
    "\tnew_edges = []\n",
    "\tnew_attrs = []\n",
    "\tnew_labels = []\n",
    "\n",
    "\tfor _ in range(num_to_inject):\n",
    "\t\tsrc = random.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "\t\tdst = random.randint(0, original_num_nodes - 1)  # to existing nodes\n",
    "\n",
    "\t\tnew_edges.append([src, dst])\n",
    "\t\tattr = edge_attr[random.randint(0, len(edge_attr) - 1)]  # Randomly sample edge attributes\n",
    "\t\tnew_attrs.append(attr)\n",
    "\t\tnew_labels.append(ADVERSARIAL_CLASS_LABEL)  # Assign benign class label to new edges\n",
    "\n",
    "\t# 3. Merge into graph\n",
    "\tif new_edges:\n",
    "\t\tnew_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "\t\tnew_attrs = th.stack(new_attrs)\n",
    "\t\tnew_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "\t\tedge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "\t\tedge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "\t\tedge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "\n",
    "\t# Create a new graph with the injected nodes and edges\n",
    "\tnew_graph = Data(\n",
    "\t\tedge_index=edge_index,\n",
    "\t\tedge_attr=edge_attr,\n",
    "\t\tedge_label=edge_label,\n",
    "\t\tx=x\n",
    "\t)\n",
    "\n",
    "\treturn new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abb63898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/CIC_IDS_2017/whole_graph_combined_ports/best_model_all_downsampled.pth\n",
      "inference start\n",
      "inference done\n",
      "Adversarial confusion matrix: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [5018  213  958  157 1823  108   82  323    1   23  140 1815   10   22\n",
      "  1081    0]]\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[27788  1198   147    66    46    36    22   990     2    53   251  3086\n",
      "      7    81   324]\n",
      " [   13   282     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [ 1196     0 17998     0     0     5     4     0     0     0     0     1\n",
      "      0     0     0]\n",
      " [   85     0     0     0    34  1405    20     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [ 2088     0     0    23   820 31311   419     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [   52     0     0     1    22   737    13     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [   57     0     0     0    17   779    16     0     0     0     0     0\n",
      "      0     0     0]\n",
      " [   52     0     0     0     0     0     0  1139     0     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     2     0     0     0\n",
      "      0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     5     0     0\n",
      "      0     0     0]\n",
      " [ 2053    46     3     0     0     5     0     0     0     0  9553   247\n",
      "    241   113 11579]\n",
      " [   86     4     1     0     0     0     2     0     0     0     0   791\n",
      "      0     0     0]\n",
      " [    7     0     0     0     0     0     0     0     0     0     0     0\n",
      "      1   202    16]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     3     0]\n",
      " [    3     0     0     0     0     0     0     0     0     0     0     0\n",
      "      1    85     9]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.8300    0.8150    0.8224     34097\n",
      "                       Bot     0.1843    0.9559    0.3090       295\n",
      "                      DDoS     0.9917    0.9372    0.9637     19204\n",
      "             DoS GoldenEye     0.0000    0.0000    0.0000      1544\n",
      "                  DoS Hulk     0.8733    0.0237    0.0461     34661\n",
      "          DoS Slowhttptest     0.0215    0.8933    0.0420       825\n",
      "             DoS slowloris     0.0323    0.0184    0.0234       869\n",
      "               FTP-Patator     0.5350    0.9563    0.6861      1191\n",
      "                Heartbleed     0.5000    1.0000    0.6667         2\n",
      "              Infiltration     0.0862    1.0000    0.1587         5\n",
      "                  PortScan     0.9744    0.4007    0.5679     23840\n",
      "               SSH-Patator     0.1918    0.8948    0.3158       884\n",
      "  Web Attack - Brute Force     0.0040    0.0044    0.0042       226\n",
      "Web Attack - Sql Injection     0.0062    1.0000    0.0123         3\n",
      "          Web Attack - XSS     0.0008    0.0918    0.0015        98\n",
      "\n",
      "                  accuracy                         0.5023    117744\n",
      "                 macro avg     0.3488    0.5994    0.3080    117744\n",
      "              weighted avg     0.8642    0.5023    0.5345    117744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Random Nodes in the graph\n",
    "injected_graph = inject_random_nodes(G_pyg_test, 0.1, num_injected_nodes=1)\n",
    "eval(injected_graph, adversarial=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
