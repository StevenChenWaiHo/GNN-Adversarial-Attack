{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb9e1b2-1c5f-49e3-82b4-3bfe52cabad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.UNSW_NB15.UNSW_NB15_config import UNSW_NB15_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1654293/595646350.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"UNSW_NB15/All/{csv_file_name}.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal            221876\n",
      "Generic           215481\n",
      "Exploits           44525\n",
      "Fuzzers            24246\n",
      "DoS                16353\n",
      "Reconnaissance     13987\n",
      "Analysis            2677\n",
      "Backdoor            1795\n",
      "Shellcode           1511\n",
      "Backdoors            534\n",
      "Worms                174\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    321283\n",
      "0    221876\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = \"all_raw_downsampled\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"UNSW_NB15/All/{csv_file_name}.csv\"))\n",
    "\n",
    "DATASET_NAME = \"UNSW_NB15\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = UNSW_NB15_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = UNSW_NB15_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = UNSW_NB15_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = UNSW_NB15_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = UNSW_NB15_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = UNSW_NB15_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = UNSW_NB15_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = UNSW_NB15_Config.TIME_COL_NAMES\n",
    "\n",
    "MULTICLASS = True\n",
    "label_col = ATTACK_CLASS_COL_NAME if MULTICLASS else IS_ATTACK_COL_NAME\n",
    "\n",
    "print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "print(data[IS_ATTACK_COL_NAME].value_counts())\n",
    "\n",
    "if MULTICLASS:\n",
    "    data.drop(columns=[IS_ATTACK_COL_NAME], inplace=True)\n",
    "else:\n",
    "    data.drop(columns=[ATTACK_CLASS_COL_NAME], inplace=True)\n",
    "\n",
    "checkpoint_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, f\"no_batch/checkpoints_{csv_file_name}_no_batch.pth\")\n",
    "best_model_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, f\"no_batch/best_model_{csv_file_name}_no_batch.pth\")\n",
    "final_epoch_model_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, f\"no_batch/final_epoch{csv_file_name}_no_batch.pth\")\n",
    "\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=UNSW_NB15_Config.DROP_COLS,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "# # Combine Port and IP\n",
    "data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "# data[SOURCE_PORT_COL_NAME] = pd.to_numeric(data[SOURCE_PORT_COL_NAME], errors='coerce').fillna(0).astype(int)\n",
    "# data[DESTINATION_PORT_COL_NAME] = pd.to_numeric(data[DESTINATION_PORT_COL_NAME], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5651ef5b-0a9d-4641-aad7-5738092c46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      srcip               dstip state        dur  sbytes  \\\n",
      "0             10.40.85.1:0         224.0.0.5:0   INT  50.004341     384   \n",
      "1          59.166.0.6:2142    149.171.126.4:53   CON   0.001134     132   \n",
      "2       175.45.176.0:13284   149.171.126.16:80   FIN   2.390390    1362   \n",
      "3         59.166.0.3:42587    149.171.126.8:25   FIN  34.077175   37358   \n",
      "4            10.40.170.2:0       10.40.170.2:0   INT   0.000000      46   \n",
      "...                    ...                 ...   ...        ...     ...   \n",
      "543154  175.45.176.0:47439   149.171.126.10:53   INT   0.000001     114   \n",
      "543155  175.45.176.0:47439   149.171.126.10:53   INT   0.000001     114   \n",
      "543156    59.166.0.5:53521    149.171.126.7:21   CON   1.086072    1940   \n",
      "543157  175.45.176.0:17293  149.171.126.17:110   CON   0.942984     574   \n",
      "543158  175.45.176.0:17293  149.171.126.17:110   CON   0.942984     574   \n",
      "\n",
      "        dbytes  sttl  dttl  sloss  dloss  ...  is_ftp_login  ct_ftp_cmd  \\\n",
      "0            0     1     0      0      0  ...           0.0         0.0   \n",
      "1          164    31    29      0      0  ...           0.0         0.0   \n",
      "2          268   254   252      6      1  ...           0.0         0.0   \n",
      "3         3380    31    29     18      8  ...           0.0         0.0   \n",
      "4            0     0     0      0      0  ...           0.0         0.0   \n",
      "...        ...   ...   ...    ...    ...  ...           ...         ...   \n",
      "543154       0   254     0      0      0  ...           0.0         NaN   \n",
      "543155       0   254     0      0      0  ...           0.0         NaN   \n",
      "543156    2404    31    29      8     10  ...           2.0         2.0   \n",
      "543157     676    62   252      5      6  ...           0.0         NaN   \n",
      "543158     676    62   252      5      6  ...           0.0         NaN   \n",
      "\n",
      "        ct_srv_src  ct_srv_dst  ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  \\\n",
      "0                2           4           4           2                 2   \n",
      "1               12           7           1           2                 2   \n",
      "2                5           2           2           1                 1   \n",
      "3                1           1          12          10                 1   \n",
      "4                2           2           2           2                 2   \n",
      "...            ...         ...         ...         ...               ...   \n",
      "543154          15          15          15          15                15   \n",
      "543155          15          15          15          15                15   \n",
      "543156           2           2           3           3                 2   \n",
      "543157           2           1           2           4                 2   \n",
      "543158           1           1           2           4                 2   \n",
      "\n",
      "        ct_dst_sport_ltm  ct_dst_src_ltm      attack_cat  \n",
      "0                      4               2          Normal  \n",
      "1                      1               1          Normal  \n",
      "2                      1               1  Reconnaissance  \n",
      "3                      1               2          Normal  \n",
      "4                      2               2          Normal  \n",
      "...                  ...             ...             ...  \n",
      "543154                15              15         Generic  \n",
      "543155                15              15         Generic  \n",
      "543156                 2               3          Normal  \n",
      "543157                 2               2        Exploits  \n",
      "543158                 2               2        Exploits  \n",
      "\n",
      "[543159 rows x 44 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7fb458-ca34-42ca-a8af-f8e1609aff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns = UNSW_NB15_Config.CATEGORICAL_COLS) # One Hot Encoding for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      srcip               dstip        dur  sbytes  dbytes  \\\n",
      "0             10.40.85.1:0         224.0.0.5:0  50.004341     384       0   \n",
      "1          59.166.0.6:2142    149.171.126.4:53   0.001134     132     164   \n",
      "2       175.45.176.0:13284   149.171.126.16:80   2.390390    1362     268   \n",
      "3         59.166.0.3:42587    149.171.126.8:25  34.077175   37358    3380   \n",
      "4            10.40.170.2:0       10.40.170.2:0   0.000000      46       0   \n",
      "...                    ...                 ...        ...     ...     ...   \n",
      "543154  175.45.176.0:47439   149.171.126.10:53   0.000001     114       0   \n",
      "543155  175.45.176.0:47439   149.171.126.10:53   0.000001     114       0   \n",
      "543156    59.166.0.5:53521    149.171.126.7:21   1.086072    1940    2404   \n",
      "543157  175.45.176.0:17293  149.171.126.17:110   0.942984     574     676   \n",
      "543158  175.45.176.0:17293  149.171.126.17:110   0.942984     574     676   \n",
      "\n",
      "        sttl  dttl  sloss  dloss         Sload  ...  state_ECO  state_FIN  \\\n",
      "0          1     0      0      0  5.119556e+01  ...      False      False   \n",
      "1         31    29      0      0  4.656085e+05  ...      False      False   \n",
      "2        254   252      6      1  4.233619e+03  ...      False       True   \n",
      "3         31    29     18      8  8.601652e+03  ...      False       True   \n",
      "4          0     0      0      0  0.000000e+00  ...      False      False   \n",
      "...      ...   ...    ...    ...           ...  ...        ...        ...   \n",
      "543154   254     0      0      0  4.560000e+08  ...      False      False   \n",
      "543155   254     0      0      0  4.560000e+08  ...      False      False   \n",
      "543156    31    29      8     10  1.387017e+04  ...      False      False   \n",
      "543157    62   252      5      6  4.470914e+03  ...      False      False   \n",
      "543158    62   252      5      6  4.470914e+03  ...      False      False   \n",
      "\n",
      "        state_INT  state_MAS  state_PAR  state_REQ  state_RST  state_TST  \\\n",
      "0            True      False      False      False      False      False   \n",
      "1           False      False      False      False      False      False   \n",
      "2           False      False      False      False      False      False   \n",
      "3           False      False      False      False      False      False   \n",
      "4            True      False      False      False      False      False   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "543154       True      False      False      False      False      False   \n",
      "543155       True      False      False      False      False      False   \n",
      "543156      False      False      False      False      False      False   \n",
      "543157      False      False      False      False      False      False   \n",
      "543158      False      False      False      False      False      False   \n",
      "\n",
      "        state_TXD  state_URH  \n",
      "0           False      False  \n",
      "1           False      False  \n",
      "2           False      False  \n",
      "3           False      False  \n",
      "4           False      False  \n",
      "...           ...        ...  \n",
      "543154      False      False  \n",
      "543155      False      False  \n",
      "543156      False      False  \n",
      "543157      False      False  \n",
      "543158      False      False  \n",
      "\n",
      "[543159 rows x 56 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "data.fillna(0,inplace = True)\n",
    "data.drop(columns=['index'],inplace=True)\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1df5c4c-70a2-4566-ae5e-ee3dcc6037a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dur        sbytes        dbytes           sttl  \\\n",
      "count  543159.000000  5.431590e+05  5.431590e+05  543159.000000   \n",
      "mean        0.706760  5.136572e+03  1.936909e+04     157.197364   \n",
      "std        12.637229  1.202311e+05  1.390925e+05     108.452474   \n",
      "min         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
      "25%         0.000007  1.140000e+02  0.000000e+00      31.000000   \n",
      "50%         0.000011  2.000000e+02  0.000000e+00     254.000000   \n",
      "75%         0.072088  1.580000e+03  1.940000e+03     254.000000   \n",
      "max      8760.776367  1.435577e+07  1.465753e+07     255.000000   \n",
      "\n",
      "                dttl          sloss          dloss         Sload  \\\n",
      "count  543159.000000  543159.000000  543159.000000  5.431590e+05   \n",
      "mean       38.850764       3.800661       8.729770  6.877595e+07   \n",
      "std        77.034389      45.616565      50.136204  1.420534e+08   \n",
      "min         0.000000       0.000000       0.000000  0.000000e+00   \n",
      "25%         0.000000       0.000000       0.000000  3.705672e+05   \n",
      "50%         0.000000       0.000000       0.000000  4.560000e+07   \n",
      "75%        29.000000       3.000000       4.000000  8.888889e+07   \n",
      "max       254.000000    5319.000000    5507.000000  5.988000e+09   \n",
      "\n",
      "              Dload          Spkts  ...  ct_flw_http_mthd   is_ftp_login  \\\n",
      "count  5.431590e+05  543159.000000  ...     543159.000000  543159.000000   \n",
      "mean   1.148111e+06      20.369921  ...          0.088724       0.011490   \n",
      "std    3.127653e+06     101.923505  ...          0.566327       0.109623   \n",
      "min    0.000000e+00       0.000000  ...          0.000000       0.000000   \n",
      "25%    0.000000e+00       2.000000  ...          0.000000       0.000000   \n",
      "50%    0.000000e+00       2.000000  ...          0.000000       0.000000   \n",
      "75%    4.087816e+05      14.000000  ...          0.000000       0.000000   \n",
      "max    2.274587e+07   10646.000000  ...         36.000000       4.000000   \n",
      "\n",
      "          ct_ftp_cmd     ct_srv_src     ct_srv_dst     ct_dst_ltm  \\\n",
      "count  543159.000000  543159.000000  543159.000000  543159.000000   \n",
      "mean        0.013029      15.008556      14.833110      10.306825   \n",
      "std         0.141497      14.229735      14.305878      10.989668   \n",
      "min         0.000000       1.000000       1.000000       1.000000   \n",
      "25%         0.000000       3.000000       3.000000       2.000000   \n",
      "50%         0.000000       9.000000       8.000000       5.000000   \n",
      "75%         0.000000      26.000000      26.000000      17.000000   \n",
      "max         8.000000      67.000000      67.000000      67.000000   \n",
      "\n",
      "          ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \n",
      "count  543159.000000     543159.000000     543159.000000   543159.000000  \n",
      "mean       10.837838          9.343288          7.209839       13.766985  \n",
      "std        10.967546         11.391238          8.069018       14.972826  \n",
      "min         1.000000          1.000000          1.000000        1.000000  \n",
      "25%         2.000000          1.000000          1.000000        1.000000  \n",
      "50%         6.000000          2.000000          2.000000        5.000000  \n",
      "75%        17.000000         17.000000         15.000000       26.000000  \n",
      "max        67.000000         67.000000         60.000000       67.000000  \n",
      "\n",
      "[8 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "cols_to_norm = UNSW_NB15_Config.COLS_TO_NORM\n",
    "print(data[cols_to_norm].describe()) # Check if there's any too large value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All other columns processed successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_numeric_issues(df, cols_to_norm):\n",
    "    for col in cols_to_norm:\n",
    "        try:\n",
    "            # Try to coerce to numeric\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Try to clip the column\n",
    "            df[col] = df[col].clip(lower=-1e9, upper=1e9)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "            print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Data type: {df[col].dtype}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "check_numeric_issues(data, UNSW_NB15_Config.COLS_TO_NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37256006-abc1-44aa-8e74-46d05dc6ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cols_to_norm] = scaler.fit_transform(data[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analysis' 'Backdoor' 'Backdoors' 'DoS' 'Exploits' 'Fuzzers' 'Generic'\n",
      " 'Normal' 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Attack label mapping: {'Analysis': 0, 'Backdoor': 1, 'Backdoors': 2, 'DoS': 3, 'Exploits': 4, 'Fuzzers': 5, 'Generic': 6, 'Normal': 7, 'Reconnaissance': 8, 'Shellcode': 9, 'Worms': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "num_classes = 2\n",
    "class_map = [0, 1]\n",
    "if MULTICLASS:\n",
    "    le = LabelEncoder()\n",
    "    attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "    class_map = le.classes_\n",
    "    print(class_map)\n",
    "    print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "    data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "    num_classes = len(class_map)\n",
    "    class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'state_ACC', 'state_CLO', 'state_CON', 'state_ECO', 'state_FIN', 'state_INT', 'state_MAS', 'state_PAR', 'state_REQ', 'state_RST', 'state_TST', 'state_TXD', 'state_URH']\n",
      "Number of training samples: 380211\n",
      "attack_cat\n",
      "7     155313\n",
      "6     150837\n",
      "4      31167\n",
      "5      16972\n",
      "3      11447\n",
      "8       9791\n",
      "0       1874\n",
      "1       1256\n",
      "9       1058\n",
      "2        374\n",
      "10       122\n",
      "Name: count, dtype: int64\n",
      "Number of validation samples: 81474\n",
      "attack_cat\n",
      "7     33282\n",
      "6     32322\n",
      "4      6679\n",
      "5      3637\n",
      "3      2453\n",
      "8      2098\n",
      "0       402\n",
      "1       269\n",
      "9       226\n",
      "2        80\n",
      "10       26\n",
      "Name: count, dtype: int64\n",
      "Number of test samples: 81474\n",
      "attack_cat\n",
      "7     33282\n",
      "6     32322\n",
      "4      6679\n",
      "5      3637\n",
      "3      2453\n",
      "8      2098\n",
      "0       402\n",
      "1       269\n",
      "9       226\n",
      "2        80\n",
      "10       26\n",
      "Name: count, dtype: int64\n",
      "                     srcip                dstip       dur    sbytes    dbytes  \\\n",
      "353743      175.45.176.1:0     149.171.126.17:0 -0.055926 -0.041059 -0.139253   \n",
      "400917    59.166.0.9:52225     149.171.126.6:80  0.031109 -0.028716 -0.066151   \n",
      "154000   175.45.176.0:1043    149.171.126.12:53 -0.055926 -0.041774 -0.139253   \n",
      "488357  175.45.176.0:45254  149.171.126.14:5060  0.050908 -0.007341 -0.136708   \n",
      "500299      175.45.176.2:0     149.171.126.17:0 -0.055926 -0.041059 -0.139253   \n",
      "\n",
      "            sttl      dttl     sloss     dloss     Sload     Dload     Spkts  \\\n",
      "353743  0.892582 -0.504331 -0.083318 -0.174121  0.106433 -0.367084 -0.180233   \n",
      "400917 -1.163620 -0.127875 -0.017552 -0.074393 -0.555068 -0.344750 -0.062497   \n",
      "154000  0.892582 -0.504331 -0.083318 -0.174121  0.199056 -0.367084 -0.180233   \n",
      "488357  0.892582  2.766939 -0.017552 -0.154176 -0.554971 -0.366497 -0.082120   \n",
      "500299  0.892582 -0.504331 -0.083318 -0.174121  0.179944 -0.367084 -0.180233   \n",
      "\n",
      "           Dpkts      swin      dwin     stcpb     dtcpb   smeansz   dmeansz  \\\n",
      "353743 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619 -0.065470 -0.526921   \n",
      "400917 -0.046980  1.301681  1.303441  0.299750  0.302046  0.063214  1.479209   \n",
      "154000 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619 -0.342141 -0.526921   \n",
      "488357 -0.140947  1.301681  1.303441  1.482943 -0.361645  1.575254 -0.370691   \n",
      "500299 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619 -0.065470 -0.526921   \n",
      "\n",
      "        trans_depth  res_bdy_len      Sjit      Djit  Stime  Ltime   Sintpkt  \\\n",
      "353743    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060832   \n",
      "400917     1.819878     0.035127  0.261390  2.929229    0.0    0.0 -0.017963   \n",
      "154000    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060834   \n",
      "488357    -0.134353    -0.054182  0.227610 -0.078170    0.0    0.0  0.000364   \n",
      "500299    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060832   \n",
      "\n",
      "         Dintpkt    tcprtt    synack    ackdat  is_sm_ips_ports  ct_state_ttl  \\\n",
      "353743 -0.055697 -0.293130 -0.270319 -0.288797        -0.027818      0.926467   \n",
      "400917  0.006760 -0.281998 -0.253781 -0.284558        -0.027818     -1.123447   \n",
      "154000 -0.055697 -0.293130 -0.270319 -0.288797        -0.027818      0.926467   \n",
      "488357  0.119245  3.651394  2.599703  4.420921        -0.027818     -0.098490   \n",
      "500299 -0.055697 -0.293130 -0.270319 -0.288797        -0.027818      0.926467   \n",
      "\n",
      "        ct_flw_http_mthd  is_ftp_login  ct_ftp_cmd  ct_srv_src  ct_srv_dst  \\\n",
      "353743         -0.156665     -0.104815   -0.092082   -0.492529   -0.477644   \n",
      "400917          1.609100     -0.104815   -0.092082   -0.843907   -0.897052   \n",
      "154000         -0.156665     -0.104815   -0.092082    0.702153    0.850483   \n",
      "488357         -0.156665     -0.104815   -0.092082   -0.773631   -0.897052   \n",
      "500299         -0.156665     -0.104815   -0.092082   -0.914182   -0.897052   \n",
      "\n",
      "        ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
      "353743   -0.664882   -0.714640         -0.644644         -0.645660   \n",
      "400917   -0.573887   -0.349927         -0.644644         -0.769591   \n",
      "154000    0.609043    0.561855          0.672159          0.097925   \n",
      "488357   -0.846871   -0.896996         -0.732431         -0.769591   \n",
      "500299   -0.846871   -0.805818         -0.732431         -0.769591   \n",
      "\n",
      "        ct_dst_src_ltm  attack_cat  state_ACC  state_CLO  state_CON  \\\n",
      "353743       -0.118013           4      False      False      False   \n",
      "400917       -0.785890           7      False      False      False   \n",
      "154000        0.750227           6      False      False      False   \n",
      "488357       -0.785890           4      False      False      False   \n",
      "500299       -0.785890           4      False      False      False   \n",
      "\n",
      "        state_ECO  state_FIN  state_INT  state_MAS  state_PAR  state_REQ  \\\n",
      "353743      False      False       True      False      False      False   \n",
      "400917      False       True      False      False      False      False   \n",
      "154000      False      False       True      False      False      False   \n",
      "488357      False       True      False      False      False      False   \n",
      "500299      False      False       True      False      False      False   \n",
      "\n",
      "        state_RST  state_TST  state_TXD  state_URH  \\\n",
      "353743      False      False      False      False   \n",
      "400917      False      False      False      False   \n",
      "154000      False      False      False      False   \n",
      "488357      False      False      False      False   \n",
      "500299      False      False      False      False   \n",
      "\n",
      "                                                        h  \n",
      "353743  [-0.055926079960930894, -0.041059064818655, -0...  \n",
      "400917  [0.03110866337143625, -0.028716155990272666, -...  \n",
      "154000  [-0.0559264756176422, -0.041774354683372567, -...  \n",
      "488357  [0.050907879124617354, -0.007340633288828872, ...  \n",
      "500299  [-0.05592615909227315, -0.041059064818655, -0....  \n"
     ]
    }
   ],
   "source": [
    "# 70% train, 15% validation, 15% test\n",
    "train_df, temp_df = train_test_split(\n",
    "     data, test_size=0.3, random_state=42, stratify=data[label_col])\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "     temp_df, test_size=0.5, random_state=42, stratify=temp_df[label_col])\n",
    "\n",
    "\n",
    "# Maintain the order of the rows in the original dataframe\n",
    "train_df = train_df.sort_values(by=UNSW_NB15_Config.TIME_COL_NAMES)\n",
    "val_df = val_df.sort_values(by=UNSW_NB15_Config.TIME_COL_NAMES)\n",
    "test_df = test_df.sort_values(by=UNSW_NB15_Config.TIME_COL_NAMES)\n",
    "\n",
    "feature_cols = [col for col in data.columns if col not in [label_col, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME]]\n",
    "\n",
    "print('Feature Columns:', feature_cols)\n",
    "\n",
    "train_df['h'] = train_df[ feature_cols ].values.tolist()\n",
    "val_df['h'] = val_df[ feature_cols ].values.tolist()\n",
    "test_df['h'] = test_df[ feature_cols ].values.tolist()\n",
    "\n",
    "# X_train = train_df.drop(columns=[label_col])\n",
    "# X_val = val_df.drop(columns=[label_col])\n",
    "# X_test = test_df.drop(columns=[label_col])\n",
    "\n",
    "y_train = train_df[label_col]\n",
    "y_val = test_df[label_col]\n",
    "y_test = test_df[label_col]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_df))\n",
    "print(y_train.value_counts())\n",
    "print(\"Number of validation samples:\", len(val_df))\n",
    "print(y_val.value_counts())\n",
    "print(\"Number of test samples:\", len(test_df))\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f83bd73-531f-42a0-9f73-e1fd98dce1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df, source_ip_col, destination_ip_col, edge_attr, create_using=nx.MultiDiGraph(), **kwargs):\n",
    "    G_nx = nx.from_pandas_edgelist(df, source_ip_col, destination_ip_col, edge_attr, create_using=create_using, **kwargs)\n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    print(\"Number of edges in G_pyg:\", num_edges)\n",
    "    print(\"Number of node in G_pyg:\", num_nodes)\n",
    "    print(\"Shape of node in G_pyg:\", G_pyg.x.shape)\n",
    "    print(\"Shape of edge attr in G_pyg:\", G_pyg.edge_attr.shape)\n",
    "    print(\"Shape of edge label in G_pyg:\", G_pyg.edge_label.shape)\n",
    "\n",
    "    return G_nx, G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c8f9cdb-1316-461a-a927-8d67d90d6144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 380211\n",
      "Number of node in G_pyg: 220487\n",
      "Shape of node in G_pyg: torch.Size([220487, 53])\n",
      "Shape of edge attr in G_pyg: torch.Size([380211, 53])\n",
      "Shape of edge label in G_pyg: torch.Size([380211])\n",
      "Number of edges in G_pyg: 81474\n",
      "Number of node in G_pyg: 52568\n",
      "Shape of node in G_pyg: torch.Size([52568, 53])\n",
      "Shape of edge attr in G_pyg: torch.Size([81474, 53])\n",
      "Shape of edge label in G_pyg: torch.Size([81474])\n"
     ]
    }
   ],
   "source": [
    "G_nx_train, G_pyg_train = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "G_nx_val, G_pyg_val = create_graph(val_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGraphSAGEConv(MessagePassing):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, out_channels):\n",
    "        super(EGraphSAGEConv, self).__init__(aggr='mean')  # mean aggregation\n",
    "        self.lin_node = nn.Linear(node_in_channels, out_channels)\n",
    "        self.lin_edge = nn.Linear(edge_in_channels, out_channels)\n",
    "        self.lin_update = nn.Linear(node_in_channels + out_channels, out_channels) # out_channels * 2\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: Node features, edge_attr: Edge features, edge_index: Connectivity\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        if edge_attr is not None:\n",
    "            if edge_attr.size(0) != edge_index.size(1):\n",
    "                loop_attr = th.zeros((edge_index.size(1) - edge_attr.size(0), edge_attr.size(1))).to(edge_attr.device)\n",
    "                edge_attr = th.cat([edge_attr, loop_attr], dim=0)\n",
    "        else:\n",
    "            print(\"edge_attr is unexist\")\n",
    "        \n",
    "        # Propagate and aggregate neighbor information\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j represents the adjacent nodes of x\n",
    "        # Compute messages by combining node and edge features\n",
    "        return self.lin_node(x_j) + self.lin_edge(edge_attr)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # Update node features after message passing\n",
    "        return self.lin_update(th.cat([x, aggr_out], dim=1))\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.conv1 = EGraphSAGEConv(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = EGraphSAGEConv(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([4.3677e-01, 6.5168e-01, 2.1885e+00, 7.1504e-02, 2.6262e-02, 4.8227e-02,\n",
      "        5.4265e-03, 5.2701e-03, 8.3598e-02, 7.7364e-01, 6.7091e+00],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = EGraphSAGE(node_in_channels=G_pyg_train.num_node_features, \n",
    "                   edge_in_channels=G_pyg_train.num_edge_features,\n",
    "                   hidden_channels=128, \n",
    "                   out_channels=num_classes).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "labels = G_pyg_train.edge_label.cpu().numpy()\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(labels),\n",
    "                                                  y=labels)\n",
    "\n",
    "# Normalise to stabilise training\n",
    "class_weights = class_weights / np.mean(class_weights)\n",
    "\n",
    "class_weights = th.FloatTensor(class_weights).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed training from epoch 10056\n",
      "Epoch 10100, Train Loss: 0.8234, Validation Loss: 0.9552, Validation F1: 0.8974\n",
      "Epoch 10200, Train Loss: 0.8214, Validation Loss: 0.9376, Validation F1: 0.9023\n",
      "Epoch 10300, Train Loss: 0.8228, Validation Loss: 0.9565, Validation F1: 0.8982\n",
      "Epoch 10400, Train Loss: 0.8234, Validation Loss: 0.9589, Validation F1: 0.8974\n",
      "Epoch 10500, Train Loss: 0.8237, Validation Loss: 0.9433, Validation F1: 0.9022\n",
      "Epoch 10600, Train Loss: 0.8208, Validation Loss: 0.9515, Validation F1: 0.9024\n",
      "Epoch 10700, Train Loss: 0.8216, Validation Loss: 0.9494, Validation F1: 0.8981\n",
      "Saved best model. F1 Score: 0.9191974782695332\n",
      "Epoch 10800, Train Loss: 0.8230, Validation Loss: 0.9397, Validation F1: 0.8999\n",
      "Epoch 10900, Train Loss: 0.8252, Validation Loss: 0.9178, Validation F1: 0.8963\n",
      "Epoch 11000, Train Loss: 0.8233, Validation Loss: 0.9412, Validation F1: 0.8987\n",
      "Epoch 11100, Train Loss: 0.8225, Validation Loss: 0.9463, Validation F1: 0.9024\n",
      "Epoch 11200, Train Loss: 0.8197, Validation Loss: 0.9640, Validation F1: 0.9026\n",
      "Epoch 11300, Train Loss: 0.8218, Validation Loss: 0.9454, Validation F1: 0.9023\n",
      "Epoch 11400, Train Loss: 0.8211, Validation Loss: 0.9321, Validation F1: 0.8990\n",
      "Epoch 11500, Train Loss: 0.8188, Validation Loss: 0.9625, Validation F1: 0.8990\n",
      "Epoch 11600, Train Loss: 0.8191, Validation Loss: 0.9432, Validation F1: 0.8980\n",
      "Epoch 11700, Train Loss: 0.8196, Validation Loss: 0.9385, Validation F1: 0.8987\n",
      "Epoch 11800, Train Loss: 0.8207, Validation Loss: 0.9529, Validation F1: 0.9023\n",
      "Epoch 11900, Train Loss: 0.8180, Validation Loss: 0.9507, Validation F1: 0.9029\n",
      "Epoch 12000, Train Loss: 0.8195, Validation Loss: 0.9447, Validation F1: 0.9040\n",
      "Epoch 12100, Train Loss: 0.8360, Validation Loss: 0.9651, Validation F1: 0.9098\n",
      "Epoch 12200, Train Loss: 0.8165, Validation Loss: 0.9606, Validation F1: 0.9023\n",
      "Epoch 12300, Train Loss: 0.8197, Validation Loss: 0.9911, Validation F1: 0.9019\n",
      "Epoch 12400, Train Loss: 0.8210, Validation Loss: 0.9281, Validation F1: 0.9003\n",
      "Epoch 12500, Train Loss: 0.8167, Validation Loss: 0.9776, Validation F1: 0.9050\n",
      "Epoch 12600, Train Loss: 0.8182, Validation Loss: 0.9323, Validation F1: 0.8987\n",
      "Epoch 12700, Train Loss: 0.8179, Validation Loss: 0.9586, Validation F1: 0.9021\n",
      "Epoch 12800, Train Loss: 0.8171, Validation Loss: 0.9762, Validation F1: 0.9029\n",
      "Epoch 12900, Train Loss: 0.8157, Validation Loss: 0.9817, Validation F1: 0.9033\n",
      "Epoch 13000, Train Loss: 0.8174, Validation Loss: 0.9667, Validation F1: 0.9002\n",
      "Epoch 13100, Train Loss: 0.8153, Validation Loss: 0.9780, Validation F1: 0.9027\n",
      "Epoch 13200, Train Loss: 0.8173, Validation Loss: 0.9343, Validation F1: 0.8985\n",
      "Epoch 13300, Train Loss: 0.8203, Validation Loss: 0.9325, Validation F1: 0.9051\n",
      "Epoch 13400, Train Loss: 0.8153, Validation Loss: 0.9457, Validation F1: 0.9008\n",
      "Epoch 13500, Train Loss: 0.8132, Validation Loss: 1.0151, Validation F1: 0.9031\n",
      "Epoch 13600, Train Loss: 0.8169, Validation Loss: 0.9786, Validation F1: 0.9000\n",
      "Epoch 13700, Train Loss: 0.8172, Validation Loss: 0.9864, Validation F1: 0.9047\n",
      "Epoch 13800, Train Loss: 0.8172, Validation Loss: 0.9639, Validation F1: 0.9003\n",
      "Epoch 13900, Train Loss: 0.8178, Validation Loss: 0.9931, Validation F1: 0.9026\n",
      "Epoch 14000, Train Loss: 0.8168, Validation Loss: 0.9502, Validation F1: 0.9007\n",
      "Epoch 14100, Train Loss: 1.3961, Validation Loss: 1.6539, Validation F1: 0.8984\n",
      "Epoch 14200, Train Loss: 0.8379, Validation Loss: 0.9266, Validation F1: 0.8999\n",
      "Epoch 14300, Train Loss: 0.8321, Validation Loss: 0.9353, Validation F1: 0.9004\n",
      "Epoch 14400, Train Loss: 0.8282, Validation Loss: 0.9685, Validation F1: 0.9007\n",
      "Epoch 14500, Train Loss: 0.8308, Validation Loss: 0.9392, Validation F1: 0.9005\n",
      "Epoch 14600, Train Loss: 0.8250, Validation Loss: 0.9593, Validation F1: 0.8998\n",
      "Epoch 14700, Train Loss: 0.8253, Validation Loss: 0.9524, Validation F1: 0.9006\n",
      "Epoch 14800, Train Loss: 0.8259, Validation Loss: 0.9596, Validation F1: 0.9004\n",
      "Epoch 14900, Train Loss: 0.8236, Validation Loss: 0.9262, Validation F1: 0.9030\n",
      "Training is over\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "G_pyg_train.to(device)\n",
    "G_pyg_val.to(device)\n",
    "\n",
    "G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "best_f1 = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Load checkpoint if exists\n",
    "start_epoch = 0\n",
    "epochs = 15000\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_f1 = checkpoint['best_f1']\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    train_loss = 0\n",
    "\n",
    "    val_loss = 0\n",
    "    \n",
    "    try:\n",
    "        model.train()\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            out = model(G_pyg_train)\n",
    "\n",
    "            loss = criterion(out, G_pyg_train.edge_label)\n",
    "            train_loss = loss.item()\n",
    "            if th.isnan(loss):\n",
    "                print(f\"loss: {loss}\")\n",
    "                print(f\"out: {out}\")\n",
    "                print(f\"edge_labels: {G_pyg_train.edge_label}\")\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        except Exception as forward_error:\n",
    "            print(f\"Error during forward/backward pass at Epoch {epoch}: {forward_error}\")\n",
    "            continue\n",
    "        \n",
    "        model.eval()\n",
    "        with th.no_grad():\n",
    "                \n",
    "            try:\n",
    "                out = model(G_pyg_val)\n",
    "\n",
    "                loss = criterion(out, G_pyg_val.edge_label)\n",
    "                val_loss = loss.item()\n",
    "                \n",
    "            except Exception as forward_error:\n",
    "                print(f\"Error during validation at Epoch {epoch}: {forward_error}\")\n",
    "                continue\n",
    "\n",
    "        val_f1 = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='weighted')\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}')\n",
    "\n",
    "        # Save the best model\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model_state = model.state_dict()\n",
    "            th.save(best_model_state, best_model_path)\n",
    "            print(\"Saved best model. F1 Score:\", best_f1)\n",
    "\n",
    "        # Save checkpoint\n",
    "        th.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_f1': best_f1\n",
    "        }, checkpoint_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred at epoch {epoch} {str(e)}\")\n",
    "print(\"Training is over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac63f9fc-02a2-4e16-94c6-bef7bf80ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model.state_dict(), final_epoch_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8db72-643a-476a-8c99-5c711869c1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg_test: 81474\n",
      "Number of node in G_pyg_test: 52280\n",
      "Shape of node in G_pyg_test: torch.Size([52280, 53])\n",
      "Shape of edge attr in G_pyg_test: torch.Size([81474, 53])\n",
      "Shape of edge label in G_pyg_test: torch.Size([81474])\n",
      "inference start\n",
      "inference done\n",
      "Test Accuracy: 0.8798\n",
      "[[   41   157    68    36    26     0     0     0     0     0    74]\n",
      " [    4   165     8    69    10     0     0     0     0     6     7]\n",
      " [    0     4    72     1     1     0     0     0     0     1     1]\n",
      " [  231  1257   116   339   203    13    17     1    40    47   189]\n",
      " [  475  1422   236   621  2225    47    61     0   186   165  1241]\n",
      " [   40   182   153    80   139  2831     0     0    15     0   197]\n",
      " [   39   167    11   111   200     8 31487     2    28    29   240]\n",
      " [    0     6     1     2    30   367     0 32812     0     0    64]\n",
      " [   41   217    10    68    74     1     4     0  1471     9   203]\n",
      " [    0     0     2     0     0     1     0     0     0   222     1]\n",
      " [    0     0     0     0     7     0     0     0     3     1    15]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.0471    0.1020    0.0644       402\n",
      "      Backdoor     0.0461    0.6134    0.0858       269\n",
      "     Backdoors     0.1064    0.9000    0.1902        80\n",
      "           DoS     0.2555    0.1382    0.1794      2453\n",
      "      Exploits     0.7633    0.3331    0.4638      6679\n",
      "       Fuzzers     0.8663    0.7784    0.8200      3637\n",
      "       Generic     0.9974    0.9742    0.9856     32322\n",
      "        Normal     0.9999    0.9859    0.9928     33282\n",
      "Reconnaissance     0.8439    0.7011    0.7659      2098\n",
      "     Shellcode     0.4625    0.9823    0.6289       226\n",
      "         Worms     0.0067    0.5769    0.0133        26\n",
      "\n",
      "      accuracy                         0.8798     81474\n",
      "     macro avg     0.4905    0.6441    0.4718     81474\n",
      "  weighted avg     0.9366    0.8798    0.8989     81474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "\n",
    "\n",
    "def eval(dataframe, adversarial=False):\n",
    "    G_nx_test = nx.from_pandas_edgelist(dataframe, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "\n",
    "    G_pyg_test = from_networkx(G_nx_test)\n",
    "\n",
    "    test_num_nodes = G_pyg_test.num_nodes\n",
    "    test_num_edges = G_pyg_test.num_edges\n",
    "\n",
    "    G_pyg_test.x = th.ones(test_num_nodes, len(test_df['h'].iloc[0]))\n",
    "\n",
    "    test_edge_attr_list = []\n",
    "    test_edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx_test.edges(keys=True, data=True):\n",
    "        test_edge_attr_list.append(data['h']) \n",
    "        test_edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg_test.edge_attr = th.tensor(test_edge_attr_list, dtype=th.float32)\n",
    "    G_pyg_test.edge_label = th.tensor(test_edge_label_list, dtype=th.long)\n",
    "\n",
    "    G_pyg_test = G_pyg_test.to(device)\n",
    "    G_pyg_test.edge_label = G_pyg_test.edge_label.to(device)\n",
    "    G_pyg_test.edge_attr = G_pyg_test.edge_attr.to(device)\n",
    "\n",
    "    print(\"Number of edges in G_pyg_test:\", G_pyg_test.num_edges)\n",
    "    print(\"Number of node in G_pyg_test:\", G_pyg_test.num_nodes)\n",
    "    print(\"Shape of node in G_pyg_test:\", G_pyg_test.x.shape)\n",
    "    print(\"Shape of edge attr in G_pyg_test:\", G_pyg_test.edge_attr.shape)\n",
    "    print(\"Shape of edge label in G_pyg_test:\", G_pyg_test.edge_label.shape)\n",
    "    \n",
    "    new_model_2 = EGraphSAGE(node_in_channels=G_pyg_test.num_node_features, \n",
    "                       edge_in_channels=G_pyg_test.num_edge_features,\n",
    "                       hidden_channels=128, \n",
    "                       out_channels=num_classes).to(device)\n",
    "\n",
    "    new_model_2.load_state_dict(th.load(best_model_path, weights_only=True))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "            \n",
    "        try:\n",
    "            out = model(G_pyg_test)\n",
    "            \n",
    "        except Exception as forward_error:\n",
    "            print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "    print(\"inference done\")\n",
    "\n",
    "    test_accuracy = compute_accuracy(out, G_pyg_test.edge_label)\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "    \n",
    "    pred_labels = out.argmax(dim=1).cpu()\n",
    "    all_test_labels = G_pyg_test.edge_label.cpu()\n",
    "\n",
    "    \n",
    "    global class_map\n",
    "    class_map_2 = class_map\n",
    "    if adversarial:\n",
    "        class_map_2 = np.append(class_map, \"Adversarial\")\n",
    "\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map_2)))\n",
    "    print(cm)\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map_2, digits=4)\n",
    "    print(report)\n",
    "\n",
    "eval(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f83fbbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled attack flows: 8147\n",
      "Labels of sampled attack flows: attack_cat\n",
      "6     5483\n",
      "4     1136\n",
      "5      602\n",
      "3      405\n",
      "8      361\n",
      "0       66\n",
      "1       46\n",
      "9       35\n",
      "2        8\n",
      "10       5\n",
      "Name: count, dtype: int64\n",
      "               srcip               dstip       dur    sbytes    dbytes  \\\n",
      "0  192.168.1.1:42518   175.45.176.1:1043 -0.055927 -0.041774 -0.139253   \n",
      "1  192.168.1.1:26892  175.45.176.1:47439 -0.055926 -0.041774 -0.139253   \n",
      "2  192.168.1.1:44663  175.45.176.1:47439 -0.055926 -0.041774 -0.139253   \n",
      "3  192.168.1.1:58368   175.45.176.1:1043 -0.055927 -0.041774 -0.139253   \n",
      "4  192.168.1.1:41066  175.45.176.1:47439 -0.055926 -0.041774 -0.139253   \n",
      "\n",
      "       sttl      dttl     sloss     dloss     Sload     Dload     Spkts  \\\n",
      "0  0.892582 -0.504331 -0.083318 -0.174121  0.387611 -0.367084 -0.180233   \n",
      "1  0.892582 -0.504331 -0.083318 -0.174121 -0.083775 -0.367084 -0.180233   \n",
      "2  0.892582 -0.504331 -0.083318 -0.174121 -0.178053 -0.367084 -0.180233   \n",
      "3  0.892582 -0.504331 -0.083318 -0.174121  0.701869 -0.367084 -0.180233   \n",
      "4  0.892582 -0.504331 -0.083318 -0.174121 -0.178053 -0.367084 -0.180233   \n",
      "\n",
      "      Dpkts      swin      dwin     stcpb     dtcpb   smeansz   dmeansz  \\\n",
      "0 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619 -0.342141 -0.526921   \n",
      "1 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619 -0.342141 -0.526921   \n",
      "2 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619 -0.342141 -0.526921   \n",
      "3 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619 -0.342141 -0.526921   \n",
      "4 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619 -0.342141 -0.526921   \n",
      "\n",
      "   trans_depth  res_bdy_len      Sjit      Djit  Stime  Ltime   Sintpkt  \\\n",
      "0    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060835   \n",
      "1    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060833   \n",
      "2    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060832   \n",
      "3    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060835   \n",
      "4    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060832   \n",
      "\n",
      "    Dintpkt   tcprtt    synack    ackdat  is_sm_ips_ports  ct_state_ttl  \\\n",
      "0 -0.055697 -0.29313 -0.270319 -0.288797        -0.027818      0.926467   \n",
      "1 -0.055697 -0.29313 -0.270319 -0.288797        -0.027818      0.926467   \n",
      "2 -0.055697 -0.29313 -0.270319 -0.288797        -0.027818      0.926467   \n",
      "3 -0.055697 -0.29313 -0.270319 -0.288797        -0.027818      0.926467   \n",
      "4 -0.055697 -0.29313 -0.270319 -0.288797        -0.027818      0.926467   \n",
      "\n",
      "   ct_flw_http_mthd  is_ftp_login  ct_ftp_cmd  ct_srv_src  ct_srv_dst  \\\n",
      "0         -0.156665     -0.104815   -0.092082    0.983255    0.990286   \n",
      "1         -0.156665     -0.104815   -0.092082    0.139950    0.151469   \n",
      "2         -0.156665     -0.104815   -0.092082    1.194081    1.199990   \n",
      "3         -0.156665     -0.104815   -0.092082    1.123806    1.130088   \n",
      "4         -0.156665     -0.104815   -0.092082    0.491327    0.500976   \n",
      "\n",
      "   ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
      "0    1.246006    1.200102          1.286667          2.080820        1.017378   \n",
      "1   -0.300903   -0.258749         -0.205710         -0.397798       -0.451952   \n",
      "2    0.427054    0.470677          0.496585          0.965442        1.217742   \n",
      "3    1.246006    1.200102          1.286667          2.080820        1.150954   \n",
      "4   -0.391898   -0.258749         -0.293497         -0.149936        0.549864   \n",
      "\n",
      "   attack_cat  state_ACC  state_CLO  state_CON  state_ECO  state_FIN  \\\n",
      "0          11      False      False      False      False      False   \n",
      "1          11      False      False      False      False      False   \n",
      "2          11      False      False      False      False      False   \n",
      "3          11      False      False      False      False      False   \n",
      "4          11      False      False      False      False      False   \n",
      "\n",
      "   state_INT  state_MAS  state_PAR  state_REQ  state_RST  state_TST  \\\n",
      "0       True      False      False      False      False      False   \n",
      "1       True      False      False      False      False      False   \n",
      "2       True      False      False      False      False      False   \n",
      "3       True      False      False      False      False      False   \n",
      "4       True      False      False      False      False      False   \n",
      "\n",
      "   state_TXD  state_URH                                                  h  \n",
      "0      False      False  [-0.05592655474898446, -0.041774354683372567, ...  \n",
      "1      False      False  [-0.055926238223615414, -0.041774354683372567,...  \n",
      "2      False      False  [-0.055926079960930894, -0.041774354683372567,...  \n",
      "3      False      False  [-0.055926633880326725, -0.041774354683372567,...  \n",
      "4      False      False  [-0.055926079960930894, -0.041774354683372567,...  \n",
      "Number of edges in G_pyg_test: 89621\n",
      "Number of node in G_pyg_test: 59925\n",
      "Shape of node in G_pyg_test: torch.Size([59925, 53])\n",
      "Shape of edge attr in G_pyg_test: torch.Size([89621, 53])\n",
      "Shape of edge label in G_pyg_test: torch.Size([89621])\n",
      "inference start\n",
      "inference done\n",
      "Test Accuracy: 0.6233\n",
      "[[    1     0     0     2    33     2     0   314    50     0     0     0]\n",
      " [    0    18     1     1    10    11     0   200    18    10     0     0]\n",
      " [    0     4     0     0     1     0     0    73     1     1     0     0]\n",
      " [    0    28     9    31   261    49    20  1700   298    49     8     0]\n",
      " [    6   229    37    45  2421    90    52  2967   639   175    18     0]\n",
      " [    0     9     0    11   292  2074     0  1178    63     0    10     0]\n",
      " [    1    30     3    35   249    20 16666 15168    64    37    49     0]\n",
      " [    0     7     1     1    66   283     0 32924     0     0     0     0]\n",
      " [    0     3     2     9   143    15     4   408  1504     9     1     0]\n",
      " [    0     0     2     0     0     1     0     0     0   222     1     0]\n",
      " [    0     0     0     1    11     0     0    12     0     1     1     0]\n",
      " [  597   850    22    14   525    15  5343    15     1   729    36     0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.0017    0.0025    0.0020       402\n",
      "      Backdoor     0.0153    0.0669    0.0249       269\n",
      "     Backdoors     0.0000    0.0000    0.0000        80\n",
      "           DoS     0.2067    0.0126    0.0238      2453\n",
      "      Exploits     0.6034    0.3625    0.4529      6679\n",
      "       Fuzzers     0.8102    0.5703    0.6694      3637\n",
      "       Generic     0.7546    0.5156    0.6126     32322\n",
      "        Normal     0.5991    0.9892    0.7462     33282\n",
      "Reconnaissance     0.5701    0.7169    0.6351      2098\n",
      "     Shellcode     0.1800    0.9823    0.3043       226\n",
      "         Worms     0.0081    0.0385    0.0133        26\n",
      "   Adversarial     0.0000    0.0000    0.0000      8147\n",
      "\n",
      "      accuracy                         0.6233     89621\n",
      "     macro avg     0.3124    0.3548    0.2904     89621\n",
      "  weighted avg     0.5920    0.6233    0.5754     89621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def attack_attacker(dataframe, ratio, num_injected_nodes):\n",
    "    attack_eval = dataframe[dataframe[label_col] != class_dict[UNSW_NB15_Config.BENIGN_CLASS_NAME]]\n",
    "    num_injected = int(ratio * len(dataframe))\n",
    "\n",
    "    # Sample attack rows\n",
    "    sampled_attack_flows = attack_eval.sample(n=num_injected, random_state=42).copy().reset_index(drop=True)\n",
    "    \n",
    "    injected_rows = sampled_attack_flows.copy()\n",
    "    print(\"Sampled attack flows:\", len(sampled_attack_flows))\n",
    "    print(\"Labels of sampled attack flows:\", sampled_attack_flows[label_col].value_counts())\n",
    "\n",
    "    node_ips = [f\"192.168.1.{i+1}\" for i in range(num_injected_nodes)]\n",
    "    injected_rows[UNSW_NB15_Config.DESTINATION_IP_COL_NAME] = injected_rows[UNSW_NB15_Config.SOURCE_IP_COL_NAME] # Target the Real Attacker Nodes\n",
    "    injected_rows[UNSW_NB15_Config.SOURCE_IP_COL_NAME] = [f\"{node_ips[i % len(node_ips)]}:{random.randint(1024, 65535)}\" for i in range(num_injected)]\n",
    "    # injected_rows['pkSeqID'] = [f'Injected-{i}' for i in range(num_injected)]\n",
    "    injected_rows[label_col] = len(class_map) # Assign a new class for injected samples\n",
    "    print(injected_rows[0:5])\n",
    "\n",
    "    # Append and reorder\n",
    "    combined_df = pd.concat([dataframe, injected_rows], ignore_index=True)\n",
    "\n",
    "    # Sort using this datetime column\n",
    "    combined_df = combined_df.sort_values(by=UNSW_NB15_Config.TIME_COL_NAMES).reset_index(drop=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Inject adversarial samples\n",
    "attack_attacker_df = attack_attacker(test_df, 0.1, num_injected_nodes=1)\n",
    "eval(attack_attacker_df, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a6707d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Flows: 33282\n",
      "Attack Flows: 48192\n",
      "               srcip               dstip       dur    sbytes    dbytes  \\\n",
      "0  192.168.1.1:34193   175.45.176.1:1043 -0.026753  0.266765 -0.115701   \n",
      "1  192.168.1.1:29250  175.45.176.1:47439 -0.052112  0.031535 -0.136205   \n",
      "2   192.168.1.1:5090  175.45.176.1:47439 -0.026270 -0.001003 -0.117110   \n",
      "3  192.168.1.1:33072   175.45.176.1:1043  0.060097 -0.010717 -0.002050   \n",
      "4   192.168.1.1:3145  175.45.176.1:47439 -0.055836 -0.041508 -0.137974   \n",
      "\n",
      "      sttl      dttl     sloss     dloss     Sload     Dload     Spkts  \\\n",
      "0 -1.16362 -0.127875  0.311276 -0.014556 -0.548613 -0.344918  0.310332   \n",
      "1 -1.16362 -0.127875  0.004370 -0.154176 -0.543784 -0.347401 -0.062497   \n",
      "2 -1.16362 -0.127875  0.070136 -0.034501 -0.554308 -0.346760  0.074861   \n",
      "3 -1.16362 -0.127875  0.157823  0.125064 -0.554992 -0.334432  0.290709   \n",
      "4 -1.16362 -0.127875 -0.083318 -0.174121 -0.550951 -0.168612 -0.180233   \n",
      "\n",
      "      Dpkts      swin      dwin     stcpb     dtcpb   smeansz   dmeansz  \\\n",
      "0  0.159748  1.301681  1.303441  1.482943  1.483089  3.898006 -0.235765   \n",
      "1 -0.140947  1.301681  1.303441  0.012242  0.709179  3.396137 -0.338735   \n",
      "2  0.065781  1.301681  1.303441  1.482943  1.483089  0.442833 -0.161201   \n",
      "3  0.272509  1.301681  1.303441  1.482943  1.483089 -0.213457  0.776176   \n",
      "4 -0.197327 -0.768239 -0.767201 -0.721514 -0.721619 -0.239194 -0.210911   \n",
      "\n",
      "   trans_depth  res_bdy_len      Sjit      Djit  Stime  Ltime   Sintpkt  \\\n",
      "0    -0.134353    -0.054182 -0.053997 -0.179664    0.0    0.0 -0.057176   \n",
      "1    -0.134353    -0.054182 -0.064980 -0.182356    0.0    0.0 -0.058957   \n",
      "2    -0.134353    -0.054182 -0.048724 -0.180431    0.0    0.0 -0.053808   \n",
      "3    -0.134353    -0.054182 -0.006169  0.572507    0.0    0.0 -0.045673   \n",
      "4    -0.134353    -0.054182 -0.080649 -0.189023    0.0    0.0 -0.060832   \n",
      "\n",
      "    Dintpkt    tcprtt    synack    ackdat  is_sm_ips_ports  ct_state_ttl  \\\n",
      "0 -0.046581 -0.279889 -0.250705 -0.283696        -0.027818     -1.123447   \n",
      "1 -0.049131 -0.281409 -0.253222 -0.283996        -0.027818     -1.123447   \n",
      "2 -0.043233 -0.280383 -0.252208 -0.283058        -0.027818     -1.123447   \n",
      "3 -0.027941 -0.281010 -0.252942 -0.283508        -0.027818     -1.123447   \n",
      "4 -0.055690 -0.293130 -0.270319 -0.288797        -0.027818     -1.123447   \n",
      "\n",
      "   ct_flw_http_mthd  is_ftp_login  ct_ftp_cmd  ct_srv_src  ct_srv_dst  \\\n",
      "0         -0.156665     -0.104815   -0.092082   -0.914182   -0.966954   \n",
      "1         -0.156665     -0.104815   -0.092082   -0.843907   -0.617447   \n",
      "2         -0.156665     -0.104815   -0.092082    0.280501   -0.198038   \n",
      "3         -0.156665     -0.104815   -0.092082   -0.281703   -0.547545   \n",
      "4         -0.156665     -0.104815   -0.092082   -0.914182   -0.966954   \n",
      "\n",
      "   ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
      "0   -0.755877   -0.258749         -0.644644         -0.769591       -0.852678   \n",
      "1   -0.482893   -0.532283         -0.732431         -0.769591       -0.719102   \n",
      "2    0.063075    0.288320         -0.556857         -0.521729       -0.451952   \n",
      "3   -0.755877   -0.532283         -0.732431         -0.769591       -0.852678   \n",
      "4   -0.664882   -0.714640         -0.732431         -0.769591       -0.852678   \n",
      "\n",
      "   attack_cat  state_ACC  state_CLO  state_CON  state_ECO  state_FIN  \\\n",
      "0          11      False      False      False      False       True   \n",
      "1          11      False      False      False      False       True   \n",
      "2          11      False      False      False      False       True   \n",
      "3          11      False      False      False      False       True   \n",
      "4          11      False      False       True      False      False   \n",
      "\n",
      "   state_INT  state_MAS  state_PAR  state_REQ  state_RST  state_TST  \\\n",
      "0      False      False      False      False      False      False   \n",
      "1      False      False      False      False      False      False   \n",
      "2      False      False      False      False      False      False   \n",
      "3      False      False      False      False      False      False   \n",
      "4      False      False      False      False      False      False   \n",
      "\n",
      "   state_TXD  state_URH                                                  h  \n",
      "0      False      False  [-0.02675280714078786, 0.2667650967301523, -0....  \n",
      "1      False      False  [-0.052111791001250164, 0.03153453912617046, -...  \n",
      "2      False      False  [-0.026270105952993734, -0.0010028323944708299...  \n",
      "3      False      False  [0.06009708537605681, -0.010717466836216492, -...  \n",
      "4      False      False  [-0.05583610762477976, -0.04150820031510557, -...  \n",
      "Number of edges in G_pyg_test: 89621\n",
      "Number of node in G_pyg_test: 59912\n",
      "Shape of node in G_pyg_test: torch.Size([59912, 53])\n",
      "Shape of edge attr in G_pyg_test: torch.Size([89621, 53])\n",
      "Shape of edge label in G_pyg_test: torch.Size([89621])\n",
      "inference start\n",
      "inference done\n",
      "Test Accuracy: 0.4265\n",
      "[[    0     0     0    15    21     0     0   324     0     0    42     0]\n",
      " [    1    14     1     1    13     0     0   231     0     8     0     0]\n",
      " [    0     4     0     0     2     0     0    74     0     0     0     0]\n",
      " [    0    16     9    61   275    10    14  1969     4    42    53     0]\n",
      " [    4   165    30   318  2516    19    46  3103     5   164   309     0]\n",
      " [    3     9     3   197   300  1767     1  1283     0     0    74     0]\n",
      " [    0    25     2    76   281     9     9 31802     3    34    81     0]\n",
      " [    0     4     1    39    36   245     0 32924     0     0    33     0]\n",
      " [    2     2     3   432   220     2     2   670   711    10    44     0]\n",
      " [    0     0     2     0     4     1     0     5     0   213     1     0]\n",
      " [    0     0     0     3     8     0     0     7     0     1     7     0]\n",
      " [    0    77     3    30    14     0    32  7967     0    11    13     0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.0000    0.0000    0.0000       402\n",
      "      Backdoor     0.0443    0.0520    0.0479       269\n",
      "     Backdoors     0.0000    0.0000    0.0000        80\n",
      "           DoS     0.0520    0.0249    0.0337      2453\n",
      "      Exploits     0.6818    0.3767    0.4853      6679\n",
      "       Fuzzers     0.8607    0.4858    0.6211      3637\n",
      "       Generic     0.0865    0.0003    0.0006     32322\n",
      "        Normal     0.4097    0.9892    0.5794     33282\n",
      "Reconnaissance     0.9834    0.3389    0.5041      2098\n",
      "     Shellcode     0.4410    0.9425    0.6008       226\n",
      "         Worms     0.0107    0.2692    0.0205        26\n",
      "   Adversarial     0.0000    0.0000    0.0000      8147\n",
      "\n",
      "      accuracy                         0.4265     89621\n",
      "     macro avg     0.2975    0.2900    0.2411     89621\n",
      "  weighted avg     0.2948    0.4265    0.2911     89621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def normalise_attacker(dataframe, ratio, num_injected_nodes):\n",
    "\n",
    "    normal_eval = dataframe[dataframe[label_col] == class_dict[UNSW_NB15_Config.BENIGN_CLASS_NAME]]\n",
    "    attack_eval = dataframe[dataframe[label_col] != class_dict[UNSW_NB15_Config.BENIGN_CLASS_NAME]]\n",
    "    print(\"Normal Flows:\", len(normal_eval))\n",
    "    print(\"Attack Flows:\", len(attack_eval))\n",
    "    num_injected = int(ratio * len(dataframe))\n",
    "\n",
    "    sampled_normal_flows = normal_eval.sample(n=num_injected, random_state=42).copy().reset_index(drop=True)\n",
    "    sampled_attack_flows = attack_eval.sample(n=num_injected, random_state=42).copy().reset_index(drop=True)\n",
    "\n",
    "    injected_rows = sampled_normal_flows.copy()\n",
    "    node_ips = [f\"192.168.1.{i+1}\" for i in range(num_injected_nodes)]\n",
    "    injected_rows[UNSW_NB15_Config.DESTINATION_IP_COL_NAME] = sampled_attack_flows[UNSW_NB15_Config.SOURCE_IP_COL_NAME] # Direct BENGIN Traffic to the Real Attacker Nodes\n",
    "    injected_rows[UNSW_NB15_Config.SOURCE_IP_COL_NAME] = [f\"{node_ips[i % len(node_ips)]}:{random.randint(1024, 65535)}\" for i in range(num_injected)]\n",
    "    injected_rows[label_col] = len(class_map)\n",
    "    print(injected_rows[0:5])\n",
    "\n",
    "    combined_df = pd.concat([dataframe, injected_rows], ignore_index=True)\n",
    "\n",
    "    # Sort using this datetime column\n",
    "    combined_df = combined_df.sort_values(by=UNSW_NB15_Config.TIME_COL_NAMES).reset_index(drop=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Inject adversarial samples\n",
    "normalise_attacker_df = normalise_attacker(test_df, 0.1, 1)\n",
    "eval(normalise_attacker_df, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d6bfe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "injected rows: 8147\n",
      "Number of edges in G_pyg_test: 89621\n",
      "Number of node in G_pyg_test: 52281\n",
      "Shape of node in G_pyg_test: torch.Size([52281, 53])\n",
      "Shape of edge attr in G_pyg_test: torch.Size([89621, 53])\n",
      "Shape of edge label in G_pyg_test: torch.Size([89621])\n",
      "inference start\n",
      "inference done\n",
      "Test Accuracy: 0.7998\n",
      "[[   41   157    68    36    26     0     0     0     0     0    74     0]\n",
      " [    4   165     8    69    10     0     0     0     0     6     7     0]\n",
      " [    0     4    72     1     1     0     0     0     0     1     1     0]\n",
      " [  231  1257   116   339   203    13    17     1    40    47   189     0]\n",
      " [  475  1422   236   621  2225    47    61     0   186   165  1241     0]\n",
      " [   40   182   153    80   139  2831     0     0    15     0   197     0]\n",
      " [   39   167    11   111   200     8 31487     2    28    29   240     0]\n",
      " [    0     6     1     2    30   367     0 32812     0     0    64     0]\n",
      " [   41   217    10    68    74     1     4     0  1471     9   203     0]\n",
      " [    0     0     2     0     0     1     0     0     0   222     1     0]\n",
      " [    0     0     0     0     7     0     0     0     3     1    15     0]\n",
      " [    0     0     0     0     0     0     0  8147     0     0     0     0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.0471    0.1020    0.0644       402\n",
      "      Backdoor     0.0461    0.6134    0.0858       269\n",
      "     Backdoors     0.1064    0.9000    0.1902        80\n",
      "           DoS     0.2555    0.1382    0.1794      2453\n",
      "      Exploits     0.7633    0.3331    0.4638      6679\n",
      "       Fuzzers     0.8663    0.7784    0.8200      3637\n",
      "       Generic     0.9974    0.9742    0.9856     32322\n",
      "        Normal     0.8010    0.9859    0.8839     33282\n",
      "Reconnaissance     0.8439    0.7011    0.7659      2098\n",
      "     Shellcode     0.4625    0.9823    0.6289       226\n",
      "         Worms     0.0067    0.5769    0.0133        26\n",
      "   Adversarial     0.0000    0.0000    0.0000      8147\n",
      "\n",
      "      accuracy                         0.7998     89621\n",
      "     macro avg     0.4330    0.5905    0.4234     89621\n",
      "  weighted avg     0.7776    0.7998    0.7767     89621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def random_connection(dataframe, ratio, num_injected_nodes):\n",
    "\n",
    "    normal_eval = dataframe[dataframe[label_col] == class_dict[UNSW_NB15_Config.BENIGN_CLASS_NAME]]\n",
    "\n",
    "    num_injected = int(ratio * len(dataframe))\n",
    "    print(\"injected rows:\", num_injected)\n",
    "\n",
    "    sampled_normal_flows = normal_eval.sample(n=num_injected, random_state=42).copy().reset_index(drop=True)\n",
    "\n",
    "    injected_rows = sampled_normal_flows.copy()\n",
    "    node_ips = [f\"192.168.1.{i+1}\" for i in range(num_injected_nodes)]\n",
    "    injected_rows[UNSW_NB15_Config.DESTINATION_IP_COL_NAME] = [node_ips[i % len(node_ips)] for i in range(num_injected)]\n",
    "    injected_rows[UNSW_NB15_Config.SOURCE_IP_COL_NAME] = [node_ips[(i + 1) % len(node_ips)] for i in range(num_injected)]\n",
    "    injected_rows[label_col] = len(class_map)\n",
    "\n",
    "    combined_df = pd.concat([dataframe, injected_rows], ignore_index=True)\n",
    "\n",
    "    # Sort using this datetime column\n",
    "    combined_df = combined_df.sort_values(by=UNSW_NB15_Config.TIME_COL_NAMES).reset_index(drop=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Inject adversarial samples\n",
    "random_connection_df = random_connection(test_df, 0.1, 1)\n",
    "eval(random_connection_df, adversarial=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
