{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec16c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====Experiment=====\n",
    "'''\n",
    "DATASET_NAME = \"BoT_IoT\"\n",
    "\n",
    "GRAPH_CONSTRUCTION = 'endpoint'\n",
    "WINDOW_SIZE = 3500\n",
    "\n",
    "MULTICLASS = True\n",
    "\n",
    "LOAD_SAVED = True\n",
    "\n",
    "FIRST_RUN = not LOAD_SAVED\n",
    "\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import joblib\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.BoT_IoT.BoT_IoT_config import BoT_IoT_Config as Dataset_Config\n",
    "\n",
    "EXPERIMENT_NAME = f\"strat_window_{GRAPH_CONSTRUCTION}_{WINDOW_SIZE}\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = Dataset_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = Dataset_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = Dataset_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = Dataset_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = Dataset_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = Dataset_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = Dataset_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = Dataset_Config.TIME_COL_NAMES\n",
    "\n",
    "DROP_COLS = Dataset_Config.DROP_COLS\n",
    "\n",
    "COLS_TO_NORM = Dataset_Config.COLS_TO_NORM\n",
    "CATEGORICAL_COLS = Dataset_Config.CATEGORICAL_COLS\n",
    "\n",
    "if MULTICLASS:\n",
    "    label_col = ATTACK_CLASS_COL_NAME\n",
    "else:\n",
    "    label_col = IS_ATTACK_COL_NAME\n",
    "\n",
    "save_path = os.path.join(project_root, f\"Models/E_GraphSAGE/{DATASET_NAME}/saved\", EXPERIMENT_NAME)\n",
    "\n",
    "checkpoint_path = os.path.join(save_path, f\"checkpoints.pth\")\n",
    "best_model_path = os.path.join(save_path, f\"best_model.pth\")\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    csv_file_name = \"all_raw\"\n",
    "\n",
    "    data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"{DATASET_NAME}/All/{csv_file_name}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ee112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "    print(data[IS_ATTACK_COL_NAME].value_counts())\n",
    "\n",
    "    if MULTICLASS:\n",
    "        data.drop(columns=[IS_ATTACK_COL_NAME], inplace=True)\n",
    "    else:\n",
    "        data.drop(columns=[ATTACK_CLASS_COL_NAME], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    data.drop(columns=DROP_COLS,inplace=True)\n",
    "    print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    if GRAPH_CONSTRUCTION == 'endpoint':\n",
    "        data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "        data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "        # # Combine Port and IP\n",
    "        data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "        data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "        data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "        data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "        data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "        data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "        converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "\n",
    "    elif GRAPH_CONSTRUCTION == 'host':\n",
    "        data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "        converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "        COLS_TO_NORM = COLS_TO_NORM + [SOURCE_PORT_COL_NAME, DESTINATION_PORT_COL_NAME]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GRAPH_CONSTRUCTION value. Use 'host' or 'endpoint'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    # Clean NaN values\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "    data.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SAVED:\n",
    "    # Normalize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    print(data[COLS_TO_NORM].describe()) # Check if there's any too large value\n",
    "\n",
    "    # Check for numeric issues in the columns before normalization\n",
    "    def check_numeric_issues(df, cols_to_norm):\n",
    "        for col in cols_to_norm:\n",
    "            try:\n",
    "                # Try to coerce to numeric\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "                print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "                print(f\"  - Data type: {df[col].dtype}\")\n",
    "                continue\n",
    "\n",
    "        print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "    check_numeric_issues(data, COLS_TO_NORM)\n",
    "\n",
    "    data[COLS_TO_NORM] = scaler.fit_transform(data[COLS_TO_NORM])\n",
    "\n",
    "    # Save the scaler for future use\n",
    "    scaler_path = os.path.join(save_path, \"scaler.pkl\")\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(\"Data after normalization:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4382030",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED:\n",
    "    # load scaler\n",
    "    scaler_path = os.path.join(save_path, \"scaler.pkl\")\n",
    "    scaler = joblib.load(scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    num_classes = 2\n",
    "    class_map = [0, 1]\n",
    "    if MULTICLASS:\n",
    "        le = LabelEncoder()\n",
    "        attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "        class_map = le.classes_\n",
    "        print(class_map)\n",
    "        print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "        data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "        num_classes = len(class_map)\n",
    "        class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n",
    "\n",
    "    class_map_path = os.path.join(save_path, \"class_map.pkl\")\n",
    "    labeller_path = os.path.join(save_path, \"labeller.pkl\")\n",
    "\n",
    "    joblib.dump(le, labeller_path)\n",
    "    joblib.dump(class_map, class_map_path)\n",
    "\n",
    "    BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "    ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75c715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED:\n",
    "    # Save the class map BENIGN_CLASS_LABEL, ADVERSARIAL_CLASS_LABEL\n",
    "    class_map_path = os.path.join(save_path, \"class_map.pkl\")\n",
    "    labeller_path = os.path.join(save_path, \"labeller.pkl\")\n",
    "\n",
    "    class_map = joblib.load(class_map_path)\n",
    "    le = joblib.load(labeller_path)\n",
    "\n",
    "    BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "    ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SAVED:\n",
    "    # Maintain the order of the rows in the original dataframe\n",
    "    feature_cols = COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "    print('Feature Columns:', feature_cols)\n",
    "    num_features = len(feature_cols)\n",
    "    print('Number of Features:', num_features)\n",
    "\n",
    "    data['h'] = data[ feature_cols ].values.tolist()\n",
    "    print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df):\n",
    "\n",
    "    G_nx = nx.from_pandas_edgelist(df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "    \n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    assert num_edges == G_nx.number_of_edges(), \"Number of edges in PyG graph does not match NetworkX graph.\"\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    return G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e650028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class StratifiedGraphDataset:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.total_count = len(self.y)\n",
    "\n",
    "        # Compute class weights\n",
    "        labels = []\n",
    "\n",
    "        for graph in self.X:\n",
    "            labels.append(graph.edge_label.tolist())\n",
    "\n",
    "        labels = np.concatenate(labels)\n",
    "\n",
    "        self.class_counts = Counter(labels)\n",
    "\n",
    "        # Compute the class weights\n",
    "        self.class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "\n",
    "    def k_fold_split(self, k: int = 5, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        cv = MultilabelStratifiedShuffleSplit(test_size=test_ratio, random_state=random_state, n_splits=k)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        y_binary = mlb.fit_transform(self.y)\n",
    "\n",
    "        return cv.split(np.zeros(len(self.X)), y_binary)\n",
    "\n",
    "    def graph_train_test_split(self, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        train_idx, test_idx = next(self.k_fold_split(k = 1, test_ratio = test_ratio, random_state = random_state))\n",
    "        \n",
    "        X_train = [self.X[i] for i in train_idx]\n",
    "        X_test = [self.X[i] for i in test_idx]\n",
    "\n",
    "        y_train = [self.y[i] for i in train_idx]\n",
    "        y_test = [self.y[i] for i in test_idx]\n",
    "\n",
    "        return StratifiedGraphDataset(X_train, y_train), StratifiedGraphDataset(X_test, y_test)\n",
    "    \n",
    "    def print_class_distribution_and_weights(self):\n",
    "        # Use the label encoder to inverse transform the class labels\n",
    "        class_counts_named = {cls: count for cls, count in self.class_counts.items()}\n",
    "        class_weights_named = {cls: weight for cls, weight in enumerate(self.class_weights)}\n",
    "        print(\"Class Counts and Weights:\")\n",
    "        for cls_label in class_counts_named.keys():\n",
    "            count = class_counts_named[cls_label]\n",
    "            weight = class_weights_named[cls_label]\n",
    "            print(f\"{cls_label:<2}  {le.inverse_transform([cls_label])[0]:<15}: Count = {count:<10}, Weight = {weight:<10.4f}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_count\n",
    "\n",
    "    def __iter__(self):\n",
    "        for g in self.X:\n",
    "            yield g\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.X[idx], self.y[idx]\n",
    "        elif isinstance(idx, slice):\n",
    "            return [self.X[i] for i in range(len(self.X))][idx], [self.y[i] for i in range(len(self.y))][idx]\n",
    "        else:\n",
    "            raise TypeError(\"Index must be an integer or a slice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8988bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    def generate_graph_datasets(\n",
    "        df: pd.DataFrame, \n",
    "        window_size: int = WINDOW_SIZE, \n",
    "        feature_cols=feature_cols,\n",
    "        ordering_cols= TIME_COLS, \n",
    "        label_col=label_col,\n",
    "        build_graph_func=create_graph,\n",
    "        ):\n",
    "\n",
    "        print(\"All Columns: \", df.columns)\n",
    "        print(\"Ordering Columns: \", ordering_cols)\n",
    "        assert all(col in df.columns for col in ordering_cols), \"All timestamp columns are required\"\n",
    "        assert label_col in df.columns, \"Edge label column 'label' is required\"\n",
    "        \n",
    "        df = df.sort_values(ordering_cols).reset_index(drop=True)\n",
    "        window_size = int(window_size)\n",
    "        \n",
    "        df.drop(columns=set(df.columns) - set(feature_cols) - set(label_col))\n",
    "\n",
    "        print(\"Final Columns: \", df.columns)\n",
    "        \n",
    "        label_counts_list = []\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        progress_bar = tqdm(range(0, len(df), window_size), desc=f\"Generating graphs\")\n",
    "        for start in progress_bar:\n",
    "            window_df = df[start: min(start + window_size, len(df))]\n",
    "            contains_label = window_df[label_col].unique()\n",
    "\n",
    "            G_pyg = build_graph_func(window_df)\n",
    "\n",
    "            label_counts = window_df[label_col].value_counts()\n",
    "\n",
    "            label_counts_list.append(label_counts)\n",
    "            X.append(G_pyg)\n",
    "            y.append(contains_label.tolist())\n",
    "\n",
    "        return StratifiedGraphDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491e7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph_dataset_path = os.path.join(save_path, \"test_graph_dataset.pth\")\n",
    "if FIRST_RUN:\n",
    "    graph_dataset = generate_graph_datasets(data)\n",
    "    full_train_graph_dataset, test_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)\n",
    "    th.save(test_graph_dataset, test_graph_dataset_path)\n",
    "\n",
    "if LOAD_SAVED:\n",
    "    # Save or Load test_graph_dataset\n",
    "    if os.path.exists(test_graph_dataset_path):  \n",
    "        test_graph_dataset = th.load(test_graph_dataset_path, weights_only=False)\n",
    "    else:       \n",
    "        raise FileNotFoundError(f\"File {test_graph_dataset_path} does not exist. Please run the code to generate the dataset first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365fd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    print(\"Class Distrubution:\", data[label_col].value_counts())\n",
    "\n",
    "    print(\"Number of graphs after downsampling:\", len(graph_dataset))\n",
    "    graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "    print(\"Number of training graphs:\", len(full_train_graph_dataset))\n",
    "    full_train_graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "    print(\"Number of testing graphs:\", len(test_graph_dataset))\n",
    "    test_graph_dataset.print_class_distribution_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00a2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    def grid_search(graph_dataset, patience, max_epochs, learning_rates, hidden_dims, drop_outs, folds=3):\n",
    "        global num_features\n",
    "        \n",
    "        best_params = {}\n",
    "        best_f1 = 0\n",
    "        params_results = {}\n",
    "\n",
    "        # Precompute the train and validation graphs for all folds\n",
    "        folds_list = []\n",
    "        for i in range(folds):\n",
    "            train_graph_dataset, val_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=i)\n",
    "            folds_list.append((train_graph_dataset, val_graph_dataset))\n",
    "\n",
    "        for lr in learning_rates:\n",
    "            for hidden_dim in hidden_dims:\n",
    "                for drop_out in drop_outs:\n",
    "                    print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}, drop_out: {drop_out}\")\n",
    "                    fold_f1_scores = []\n",
    "\n",
    "                    for fold, (train_graph_dataset, val_graph_dataset) in enumerate(folds_list):\n",
    "                        print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                        model = EGraphSAGE(node_in_channels=num_features,\n",
    "                                        edge_in_channels=num_features,\n",
    "                                        hidden_channels=hidden_dim,\n",
    "                                        dropout = drop_out,\n",
    "                                        out_channels=num_classes).to(device)\n",
    "\n",
    "                        model.apply(init_weights)\n",
    "\n",
    "                        # Normalize to stabilize training\n",
    "                        class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "                        print(\"Class weights:\", class_weights)\n",
    "\n",
    "                        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                        optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "                        scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                            optimizer,\n",
    "                            mode='min',\n",
    "                            factor=0.6,\n",
    "                            patience=5,\n",
    "                            min_lr=1e-6,\n",
    "                        )\n",
    "\n",
    "                        best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "                        best_val_loss = float('inf')  # Track the best val_loss for this fold\n",
    "                        patience_counter = 0\n",
    "\n",
    "                        for epoch in range(max_epochs):\n",
    "                            try:\n",
    "                                train_loss = 0\n",
    "                                val_loss = 0\n",
    "                                num_train_graphs = len(train_graph_dataset)\n",
    "                                num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "                                model.train()\n",
    "                                optimizer.zero_grad()\n",
    "                                for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "                                    G_pyg_train = G_pyg_train.to(device)\n",
    "                                    G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                                    G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "                                    \n",
    "                                    out = model(G_pyg_train)\n",
    "                                    loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                                    train_loss += loss.item()\n",
    "\n",
    "                                    loss.backward()\n",
    "\n",
    "                                optimizer.step()\n",
    "                                \n",
    "\n",
    "                                test_label_list = []\n",
    "                                pred_label_list = []\n",
    "\n",
    "                                model.eval()\n",
    "                                with th.no_grad():\n",
    "                                    for G_pyg_val in tqdm(val_graph_dataset, desc=\"Validation\", leave=False):\n",
    "\n",
    "                                        G_pyg_val = G_pyg_val.to(device)\n",
    "                                        G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                                        G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                                        out = model(G_pyg_val)\n",
    "                                        loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                                        val_loss += loss.item()\n",
    "\n",
    "                                        test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                                        pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "                                test_label = th.cat(test_label_list)\n",
    "                                pred_label = th.cat(pred_label_list)\n",
    "\n",
    "                                val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "                                val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "                                val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "                                # Schedule step\n",
    "                                scheduler.step(val_loss)\n",
    "\n",
    "                                if val_f1 > best_epoch_f1:\n",
    "                                    best_epoch_f1 = val_f1\n",
    "                                    print(f\"Epoch {epoch}/{max_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                                    f\"Val F1 (weighted): {val_f1:.4f}, Micro: {val_f1_micro:.4f}, Macro: {val_f1_macro:.4f} \"\n",
    "                                    f\"(Best Weighted F1 so far: {best_epoch_f1:.4f})\")\n",
    "\n",
    "                                # Early stopping condition\n",
    "                                if val_loss < best_val_loss:\n",
    "                                    best_val_loss = val_loss\n",
    "                                    patience_counter = 0\n",
    "                                else:\n",
    "                                    patience_counter += 1\n",
    "\n",
    "                                if patience_counter >= patience:\n",
    "                                    print(f\"\\n🛑 Early stopping triggered at epoch {epoch}.\")\n",
    "                                    break\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                                break\n",
    "\n",
    "                        fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "                    \n",
    "                    avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "                    params_results[(drop_out, lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "                    print(f\"Average F1 Score for drop_out {drop_out}, learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "                    if avg_f1 > best_f1:\n",
    "                        best_f1 = avg_f1\n",
    "                        best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim, 'drop_out': drop_out}\n",
    "\n",
    "        print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "        print(\"All results:\", params_results)\n",
    "\n",
    "    # grid_search(\n",
    "    #     full_train_graph_dataset, \n",
    "    #     patience=10,\n",
    "    #     max_epochs=200,\n",
    "    #     learning_rates=[0.001, 0.005, 0.01, 0.05], \n",
    "    #     hidden_dims=[128, 256, 512], \n",
    "    #     drop_outs=[0.2, 0.3, 0.4],\n",
    "    #     folds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b158d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    train_graph_dataset, val_graph_dataset = full_train_graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ec4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint():\n",
    "    global epoch, model, optimizer, scheduler, train_loss_history, val_loss_history, val_f1_history, saved_model_epochs, best_f1, patience_counter, best_val_loss, train_ended, max_epochs, patience\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss_history': train_loss_history,\n",
    "        'val_loss_history': val_loss_history,\n",
    "        'val_f1_history': val_f1_history,\n",
    "        'saved_model_epochs': saved_model_epochs,\n",
    "        'best_f1': best_f1,\n",
    "        # 'patience_counter': patience_counter,\n",
    "        # 'best_val_loss': best_val_loss,\n",
    "        'train_ended': train_ended,\n",
    "        'max_epochs': max_epochs,\n",
    "        # 'patience': patience\n",
    "    }\n",
    "    \n",
    "    th.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters from the grid search\n",
    "best_hidden_dim = 256  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.01  # Replace with the best learning_rate found\n",
    "best_drop_out = 0.3  # Replace with the best drop_out found\n",
    "if FIRST_RUN:\n",
    "\n",
    "    max_epochs = 200\n",
    "    # patience = 10\n",
    "\n",
    "    print(\"Number of train graphs: \", len(train_graph_dataset))\n",
    "\n",
    "    # Initialize the model with the best parameters\n",
    "    model = EGraphSAGE(node_in_channels=num_features, \n",
    "                    edge_in_channels=num_features,\n",
    "                    hidden_channels=best_hidden_dim,\n",
    "                    dropout = best_drop_out,\n",
    "                    out_channels=num_classes).to(device)\n",
    "\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # Normalize class weights\n",
    "    class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.6,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "    )\n",
    "\n",
    "    # ===== Load checkpoint if exists =====\n",
    "    start_epoch = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    # patience_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    train_ended = False\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_f1_history = []\n",
    "    saved_model_epochs = []\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = th.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "        train_ended = checkpoint['train_ended']\n",
    "        best_f1 = checkpoint['best_f1']\n",
    "\n",
    "        assert max_epochs == checkpoint['max_epochs'], \"Checkpoint max_epochs does not match the current setting.\"\n",
    "        # assert patience == checkpoint['patience'], \"Checkpoint patience does not match the current setting.\"\n",
    "\n",
    "        # patience_counter = checkpoint['patience_counter']\n",
    "        # best_val_loss = checkpoint['best_val_loss']\n",
    "\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "        train_loss_history = checkpoint['train_loss_history']\n",
    "        val_loss_history = checkpoint['val_loss_history']\n",
    "        val_f1_history = checkpoint['val_f1_history']\n",
    "        saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "        print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "    if train_ended:\n",
    "        model.load_state_dict(th.load(best_model_path))\n",
    "        print(\"Training has already ended. Loaded the best model state.\")\n",
    "        print(\"Training history loaded successfully.\")\n",
    "\n",
    "    else:\n",
    "        # ===== Start Training =====\n",
    "        num_train_graphs = len(train_graph_dataset)\n",
    "        num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "        for epoch in range(start_epoch, max_epochs):\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "                # Move the graph data to the device\n",
    "                G_pyg_train = G_pyg_train.to(device)\n",
    "                G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "                out = model(G_pyg_train)\n",
    "                loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            test_label_list = []\n",
    "            pred_label_list = []\n",
    "\n",
    "            model.eval()\n",
    "            with th.no_grad():\n",
    "                for G_pyg_val in tqdm(val_graph_dataset, desc=\"Evaluation\", leave=False):\n",
    "                    G_pyg_val = G_pyg_val.to(device)\n",
    "                    G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                    G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                    out = model(G_pyg_val)\n",
    "                    loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                    pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "            test_label = th.cat(test_label_list)\n",
    "            pred_label = th.cat(pred_label_list)\n",
    "\n",
    "            val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "            val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "            val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "            train_loss_history.append(train_loss)\n",
    "            val_loss_history.append(val_loss)\n",
    "            val_f1_history.append((val_f1, val_f1_micro, val_f1_macro))\n",
    "\n",
    "            # Schedule step\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1  # Update the best F1 score for this fold\n",
    "                best_model_state = model.state_dict()\n",
    "                saved_model_epochs.append(epoch)\n",
    "\n",
    "                save_checkpoint()\n",
    "                th.save(best_model_state, best_model_path)\n",
    "                print(f\"Epoch {epoch} Saved best model. Best F1:\", best_f1)\n",
    "\n",
    "            print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}, Validation F1 Micro: {val_f1_micro:.4f}, Validation F1 Macro: {val_f1_macro:.4f}')\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                save_checkpoint()\n",
    "\n",
    "            # # Early stopping condition\n",
    "            # if val_loss < best_val_loss:\n",
    "            #     best_val_loss = val_loss\n",
    "            #     patience_counter = 0\n",
    "            # else:\n",
    "            #     patience_counter += 1\n",
    "\n",
    "            # if patience_counter >= patience:\n",
    "            #     print(f\"\\n🛑 Early stopping triggered at epoch {epoch}.\")\n",
    "            #     train_ended = True\n",
    "            #     break\n",
    "\n",
    "        # Save the trained model\n",
    "        train_ended = True\n",
    "        save_checkpoint()\n",
    "        print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_process():\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    val_loss_history = checkpoint['val_loss_history']\n",
    "    val_f1_history = checkpoint['val_f1_history']\n",
    "    saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Plot Train Loss\n",
    "    axs[0].plot(train_loss_history, label='Train Loss', color='blue')\n",
    "    axs[0].plot(val_loss_history, label='Validation Loss', color='red')\n",
    "    axs[0].set_ylabel('Train Loss')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    val_f1_weighted_history = []\n",
    "    val_f1_micro_history = []\n",
    "    val_f1_macro_history = []\n",
    "\n",
    "    for val_f1_weighted, val_f1_micro, val_f1_macro in val_f1_history:\n",
    "        val_f1_weighted_history.append(val_f1_weighted)\n",
    "        val_f1_micro_history.append(val_f1_micro)\n",
    "        val_f1_macro_history.append(val_f1_macro)\n",
    "    \n",
    "    # Plot Validation F1\n",
    "\n",
    "    axs[1].plot(val_f1_weighted_history, label='Validation F1 Weighted', color='green')\n",
    "    axs[1].plot(val_f1_micro_history, label='Validation F1 Micro', color='blue')\n",
    "    axs[1].plot(val_f1_macro_history, label='Validation F1 Macro', color='red')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Validation F1')\n",
    "    axs[1].set_title('Validation F1 Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    # Add scatter for saved model epochs (e.g., F1 weighted here)\n",
    "    axs[1].scatter(saved_model_epochs, [val_f1_weighted_history[i] for i in saved_model_epochs],\n",
    "                   color='black', marker='o', label='Saved Model')\n",
    "    axs[1].legend()\n",
    "\n",
    "    print(len(train_loss_history))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2572f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f060684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average, Min, and Max Degrees Across All Graphs:\n",
      "  Attack Class ['DDoS']:\n",
      "    Avg Out-Degree (src): 1.0043 | Min: 1 | Max: 541\n",
      "    Avg In-Degree (dst): 217.9295 | Min: 1 | Max: 3500\n",
      "    Influence: 0.0000 | Min: 0.0000 | Max: 83.6231\n",
      "  Attack Class ['DoS']:\n",
      "    Avg Out-Degree (src): 1.0000 | Min: 1 | Max: 1\n",
      "    Avg In-Degree (dst): 990.0398 | Min: 1 | Max: 3500\n",
      "    Influence: 0.0000 | Min: 0.0000 | Max: 0.0003\n",
      "  Attack Class ['Normal']:\n",
      "    Avg Out-Degree (src): 1.0000 | Min: 1 | Max: 1\n",
      "    Avg In-Degree (dst): 1.6316 | Min: 1 | Max: 4\n",
      "    Influence: 0.0002 | Min: 0.0001 | Max: 0.0003\n",
      "  Attack Class ['Reconnaissance']:\n",
      "    Avg Out-Degree (src): 8.1738 | Min: 1 | Max: 1063\n",
      "    Avg In-Degree (dst): 2.3282 | Min: 1 | Max: 760\n",
      "    Influence: 0.0082 | Min: 0.0000 | Max: 322.8480\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import degree\n",
    "from collections import defaultdict\n",
    "\n",
    "def check_global_avg_degrees_per_class(graph_dataset):\n",
    "    # Dictionaries to hold total degree sums and counts per class\n",
    "    total_out_deg = defaultdict(float)\n",
    "    total_in_deg = defaultdict(float)\n",
    "    count_out_nodes = defaultdict(int)\n",
    "    count_in_nodes = defaultdict(int)\n",
    "    min_out_deg = defaultdict(lambda: float('inf'))\n",
    "    max_out_deg = defaultdict(lambda: float('-inf'))\n",
    "    min_in_deg = defaultdict(lambda: float('inf'))\n",
    "    max_in_deg = defaultdict(lambda: float('-inf'))\n",
    "\n",
    "    for graph in graph_dataset:\n",
    "        edge_index = graph.edge_index\n",
    "        edge_label = graph.edge_label\n",
    "        num_nodes = graph.num_nodes\n",
    "\n",
    "        unique_classes = torch.unique(edge_label)\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            cls = int(cls)\n",
    "            mask = (edge_label == cls)\n",
    "\n",
    "            src_nodes = edge_index[0][mask]\n",
    "            dst_nodes = edge_index[1][mask]\n",
    "\n",
    "            out_deg = degree(src_nodes, num_nodes=num_nodes)\n",
    "            in_deg = degree(dst_nodes, num_nodes=num_nodes)\n",
    "\n",
    "            involved_src = out_deg > 0\n",
    "            involved_dst = in_deg > 0\n",
    "\n",
    "            total_out_deg[cls] += out_deg[involved_src].sum().item()\n",
    "            total_in_deg[cls] += in_deg[involved_dst].sum().item()\n",
    "            count_out_nodes[cls] += involved_src.sum().item()\n",
    "            count_in_nodes[cls] += involved_dst.sum().item()\n",
    "\n",
    "            if involved_src.any():\n",
    "                min_out_deg[cls] = min(min_out_deg[cls], out_deg[involved_src].min().item())\n",
    "                max_out_deg[cls] = max(max_out_deg[cls], out_deg[involved_src].max().item())\n",
    "            if involved_dst.any():\n",
    "                min_in_deg[cls] = min(min_in_deg[cls], in_deg[involved_dst].min().item())\n",
    "                max_in_deg[cls] = max(max_in_deg[cls], in_deg[involved_dst].max().item())\n",
    "\n",
    "    print(\"Average, Min, and Max Degrees Across All Graphs:\")\n",
    "    class_degree_report = {}\n",
    "    for cls in sorted(total_out_deg.keys()):\n",
    "        avg_out = total_out_deg[cls] / count_out_nodes[cls] if count_out_nodes[cls] > 0 else 0.0\n",
    "        avg_in = total_in_deg[cls] / count_in_nodes[cls] if count_in_nodes[cls] > 0 else 0.0\n",
    "        min_out = min_out_deg[cls] if min_out_deg[cls] != float('inf') else 0.0\n",
    "        max_out = max_out_deg[cls] if max_out_deg[cls] != float('-inf') else 0.0\n",
    "        min_in = min_in_deg[cls] if min_in_deg[cls] != float('inf') else 0.0\n",
    "        max_in = max_in_deg[cls] if max_in_deg[cls] != float('-inf') else 0.0\n",
    "\n",
    "        epsilon = 1e-6 # to avoid division by zero\n",
    "        avg_influence = (avg_out ** 2) / ((avg_in + epsilon) * WINDOW_SIZE)\n",
    "        max_influence = (max_out ** 2) / ((min_in + epsilon) * WINDOW_SIZE)\n",
    "        min_influence = (min_out ** 2) / ((max_in + epsilon) * WINDOW_SIZE)\n",
    "\n",
    "        print(f\"  Attack Class {le.inverse_transform([cls])}:\")\n",
    "        print(f\"    Avg Out-Degree (src): {avg_out:.4f} | Min: {min_out:.0f} | Max: {max_out:.0f}\")\n",
    "        print(f\"    Avg In-Degree (dst): {avg_in:.4f} | Min: {min_in:.0f} | Max: {max_in:.0f}\")\n",
    "        print(f\"    Influence: {avg_influence:.4f} | Min: {min_influence:.4f} | Max: {max_influence:.4f}\")\n",
    "\n",
    "        class_degree_report[le.inverse_transform([cls])[0]] = {\n",
    "            \"avg_out\": avg_out,\n",
    "            \"min_out\": min_out,\n",
    "            \"max_out\": max_out,\n",
    "            \"avg_in\": avg_in,\n",
    "            \"min_in\": min_in,\n",
    "            \"max_in\": max_in,\n",
    "            \"avg_influence\": avg_influence,\n",
    "            \"min_influence\": min_influence,\n",
    "            \"max_influence\": max_influence\n",
    "        }\n",
    "\n",
    "    return class_degree_report\n",
    "\n",
    "class_degree_report = check_global_avg_degrees_per_class(test_graph_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test graphs:  158\n",
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_3500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9803\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[283495   7000      0      5      0]\n",
      " [  3500 244990     10      0      0]\n",
      " [     0      0     31      0      0]\n",
      " [    76    259     42  13586      6]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9875    0.9759    0.9817    290500\n",
      "           DoS     0.9712    0.9859    0.9785    248500\n",
      "        Normal     0.3735    1.0000    0.5439        31\n",
      "Reconnaissance     0.9996    0.9726    0.9859     13969\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9803    553000\n",
      "     macro avg     0.6664    0.7869    0.6980    553000\n",
      "  weighted avg     0.9805    0.9803    0.9803    553000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(dataset, adversarial=False):\n",
    "\n",
    "    # Check if dataset is a list of (data, label) tuples or just data objects\n",
    "    if isinstance(dataset[0], (list, tuple)):\n",
    "        data_obj = dataset[0][0]\n",
    "    else:\n",
    "        data_obj = dataset[0]\n",
    "\n",
    "    num_features = data_obj.edge_attr.shape[1]\n",
    "    best_model = EGraphSAGE(node_in_channels=num_features, \n",
    "                       edge_in_channels=num_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=len(class_map)).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path))\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "        all_pred_logits = []\n",
    "        all_test_labels = []\n",
    "        for G_pyg in tqdm(dataset, desc=\"Evaluation\", leave=False):\n",
    "            try:\n",
    "                # Move the graph data to the device\n",
    "                G_pyg = G_pyg.to(device)\n",
    "                G_pyg.edge_label = G_pyg.edge_label.to(device)\n",
    "                G_pyg.edge_attr = G_pyg.edge_attr.to(device)\n",
    "                out = best_model(G_pyg)\n",
    "                \n",
    "            except Exception as forward_error:\n",
    "                print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "            all_pred_logits.append(out.cpu())\n",
    "            all_test_labels.append(G_pyg.edge_label.cpu())\n",
    "\n",
    "        all_pred_logits = th.cat(all_pred_logits).to(device)\n",
    "        all_test_labels = th.cat(all_test_labels).to(device)\n",
    "        test_accuracy = compute_accuracy(all_pred_logits, all_test_labels)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "        pred_labels = all_pred_logits.argmax(dim=1).cpu()\n",
    "        all_test_labels = all_test_labels.cpu()\n",
    "    \n",
    "    if adversarial:\n",
    "\n",
    "        # Create a boolean mask where the label is NOT equal to the adversarial class\n",
    "        adversarial_mask = all_test_labels == ADVERSARIAL_CLASS_LABEL\n",
    "\n",
    "        # Print the class that the adversarial samples are classified as\n",
    "        cm_adversarial = confusion_matrix(all_test_labels[adversarial_mask], pred_labels[adversarial_mask], labels=range(len(class_map) + 1))\n",
    "        print(\"Adversarial confusion matrix:\", cm_adversarial)\n",
    "\n",
    "        # Apply the mask to both labels and predictions\n",
    "        all_test_labels = all_test_labels[~adversarial_mask]\n",
    "        pred_labels = pred_labels[~adversarial_mask]\n",
    "\n",
    "    print(\"class_map\", class_map)\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map)))\n",
    "    print(cm)\n",
    "\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, labels=range(len(class_map)))\n",
    "    print(report)\n",
    "    \n",
    "    return classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, output_dict=True, labels=range(len(class_map)))\n",
    "\n",
    "\n",
    "print(\"Number of test graphs: \", len(test_graph_dataset))\n",
    "normal_report = eval(test_graph_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cff736d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_traffic_to_node(graph, ratio=0.1, num_injected_nodes=1, to_node_type='both', random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    # Get all src nodes\n",
    "    if to_node_type == 'src':\n",
    "         to_nodes = edge_index[0]\n",
    "\n",
    "    elif to_node_type == 'dst':\n",
    "         to_nodes = edge_index[1]\n",
    "\n",
    "    elif to_node_type == 'both':\n",
    "         to_nodes = th.cat([edge_index[0], edge_index[1]])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"to_node_type must be 'src', 'dst', or 'both'.\")\n",
    "\n",
    "    original_num_nodes = x.size(0)\n",
    "\n",
    "    new_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "    x = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "    # 4. Inject edges from injected nodes to attacker nodes\n",
    "    num_to_inject = max(1, int(ratio * num_edges))\n",
    "    new_edges = []\n",
    "    new_attrs = []\n",
    "    new_labels = []\n",
    "    \n",
    "    for i in range(num_to_inject):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per iteration\n",
    "        src = rng.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "        dst = rng.choice(to_nodes.tolist())  # to existing nodes\n",
    "\n",
    "        new_edges.append([src, dst])\n",
    "        attr = th.rand(feature_dim)  # random feature for the new edge\n",
    "        new_attrs.append(attr)\n",
    "        new_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    # Create a new empty graph to store the injected edges\n",
    "    new_graph = Data()\n",
    "\n",
    "    # 5. Merge into graph\n",
    "    if new_edges:\n",
    "        new_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "        new_attrs = th.stack(new_attrs)\n",
    "        new_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "        new_graph.edge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "        new_graph.edge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "        new_graph.edge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "        new_graph.x = x\n",
    "\n",
    "    return new_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0a4cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_3500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8872\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [14198 12631     2 28469     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[283496   6694      5    305      0]\n",
      " [   400 246484   1316    300      0]\n",
      " [     0      0     31      0      0]\n",
      " [  4250      1     11   9702      5]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9839    0.9759    0.9799    290500\n",
      "           DoS     0.9736    0.9919    0.9826    248500\n",
      "        Normal     0.0227    1.0000    0.0445        31\n",
      "Reconnaissance     0.9413    0.6945    0.7993     13969\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9760    553000\n",
      "     macro avg     0.5843    0.7325    0.5613    553000\n",
      "  weighted avg     0.9781    0.9760    0.9765    553000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_both_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='both') for g in test_graph_dataset]\n",
    "inject_both_report = eval(inject_both_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90b60cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_3500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8787\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [  243     0     0 55057     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[280179   9842     27    452      0]\n",
      " [   311 245161   2879    149      0]\n",
      " [     0      0     31      0      0]\n",
      " [  4806      0     11   9146      6]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9821    0.9645    0.9732    290500\n",
      "           DoS     0.9614    0.9866    0.9738    248500\n",
      "        Normal     0.0105    1.0000    0.0208        31\n",
      "Reconnaissance     0.9383    0.6547    0.7713     13969\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9666    553000\n",
      "     macro avg     0.5785    0.7212    0.5478    553000\n",
      "  weighted avg     0.9716    0.9666    0.9683    553000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_src_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='src') for g in test_graph_dataset]\n",
    "inject_src_report = eval(inject_src_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70287333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_3500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8970\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [29050 24855     1  1393     1     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[286995   3500      0      5      0]\n",
      " [  3500 244990      8      2      0]\n",
      " [     0      0     31      0      0]\n",
      " [    65    228     42  13628      6]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9877    0.9879    0.9878    290500\n",
      "           DoS     0.9850    0.9859    0.9854    248500\n",
      "        Normal     0.3827    1.0000    0.5536        31\n",
      "Reconnaissance     0.9995    0.9756    0.9874     13969\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9867    553000\n",
      "     macro avg     0.6710    0.7899    0.7028    553000\n",
      "  weighted avg     0.9868    0.9867    0.9867    553000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_dst_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='dst') for g in test_graph_dataset]\n",
    "inject_dst_report = eval(inject_dst_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "579e0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Attribute Perturbation\n",
    "def perturb_edge_attributes(graph, affected_edge_ratio=0.1, perturbation_ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = edge_attr.size(1)\n",
    "\n",
    "    # Randomly select edges to perturb\n",
    "    num_to_perturb = max(1, int(affected_edge_ratio * num_edges))\n",
    "    rng = random.Random(random_seed)\n",
    "    indices_to_perturb = rng.sample(range(num_edges), num_to_perturb)\n",
    "\n",
    "    for idx in indices_to_perturb:\n",
    "        # Perturb the edge attributes by adding noise\n",
    "        noise = th.randn(feature_dim) * perturbation_ratio  # Adjust the scale of noise as needed\n",
    "        edge_attr[idx] += noise\n",
    "\n",
    "    # Create a new graph with perturbed attributes\n",
    "    perturbed_graph = Data(edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label, x=graph.x)\n",
    "\n",
    "    return perturbed_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb68c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_3500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9452\n",
      "Adversarial confusion matrix: [[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[282816   7311    179    192      2]\n",
      " [  8287 231565      6   8642      0]\n",
      " [     0      2     29      0      0]\n",
      " [  1754   1138   2562   8307    208]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9657    0.9735    0.9696    290500\n",
      "           DoS     0.9648    0.9319    0.9480    248500\n",
      "        Normal     0.0104    0.9355    0.0207        31\n",
      "Reconnaissance     0.4846    0.5947    0.5340     13969\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9452    553000\n",
      "     macro avg     0.4851    0.6871    0.4945    553000\n",
      "  weighted avg     0.9531    0.9452    0.9489    553000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Edge Attribute Perturbation\n",
    "edge_perturb_graph_dataset = [perturb_edge_attributes(g.cpu(), affected_edge_ratio=1, perturbation_ratio=5) for g in test_graph_dataset]\n",
    "edge_perturb_report = eval(edge_perturb_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc04f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject Random Edges\n",
    "def inject_random_edges(graph, ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_nodes = x.size(0)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    new_edge_indices = []\n",
    "    new_edge_attrs = []\n",
    "    new_edge_labels = []\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    num_injected_edges = max(1, int(ratio * num_edges))\n",
    "\n",
    "    for i in range(num_injected_edges):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per edge\n",
    "        src = rng.randint(0, num_nodes - 1)  # Random source node\n",
    "        dst = rng.randint(0, num_nodes - 1)  # Random destination node\n",
    "\n",
    "        new_edge_indices.append([src, dst])\n",
    "        new_edge_attrs.append(th.rand(feature_dim))  # Random feature for the new edge\n",
    "        new_edge_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    if new_edge_indices:\n",
    "        new_edge_indices = th.tensor(new_edge_indices, dtype=th.long).t().contiguous()\n",
    "        new_edge_attrs = th.stack(new_edge_attrs)\n",
    "        new_edge_labels = th.tensor(new_edge_labels, dtype=th.long)\n",
    "\n",
    "        edge_index = th.cat([edge_index, new_edge_indices], dim=1)\n",
    "        edge_attr = th.cat([edge_attr, new_edge_attrs], dim=0)\n",
    "        edge_label = th.cat([edge_label, new_edge_labels], dim=0)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b25073bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_3500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8815\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [ 2448    23    93 52736     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[278707   9806     38   1949      0]\n",
      " [   264 243874   3796    566      0]\n",
      " [     0      0     31      0      0]\n",
      " [    70    222     50  13614     13]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9988    0.9594    0.9787    290500\n",
      "           DoS     0.9605    0.9814    0.9708    248500\n",
      "        Normal     0.0079    1.0000    0.0157        31\n",
      "Reconnaissance     0.8441    0.9746    0.9046     13969\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9697    553000\n",
      "     macro avg     0.5623    0.7831    0.5740    553000\n",
      "  weighted avg     0.9776    0.9697    0.9732    553000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Random Edges\n",
    "random_edge_graph_dataset = [inject_random_edges(g.cpu(), 0.1) for g in test_graph_dataset]\n",
    "random_edge_report = eval(random_edge_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8c66190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Overall Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6e798\">\n",
       "  <caption>Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e798_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_6e798_level0_col1\" class=\"col_heading level0 col1\" >Min Influence</th>\n",
       "      <th id=\"T_6e798_level0_col2\" class=\"col_heading level0 col2\" >Avg Influence</th>\n",
       "      <th id=\"T_6e798_level0_col3\" class=\"col_heading level0 col3\" >Max Influence</th>\n",
       "      <th id=\"T_6e798_level0_col4\" class=\"col_heading level0 col4\" >Normal precision</th>\n",
       "      <th id=\"T_6e798_level0_col5\" class=\"col_heading level0 col5\" >To Both precision</th>\n",
       "      <th id=\"T_6e798_level0_col6\" class=\"col_heading level0 col6\" >To Both precision Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col7\" class=\"col_heading level0 col7\" >To Src precision</th>\n",
       "      <th id=\"T_6e798_level0_col8\" class=\"col_heading level0 col8\" >To Src precision Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col9\" class=\"col_heading level0 col9\" >To Dst precision</th>\n",
       "      <th id=\"T_6e798_level0_col10\" class=\"col_heading level0 col10\" >To Dst precision Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col11\" class=\"col_heading level0 col11\" >Edge Perturbation precision</th>\n",
       "      <th id=\"T_6e798_level0_col12\" class=\"col_heading level0 col12\" >Edge Perturbation precision Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col13\" class=\"col_heading level0 col13\" >Random Edge precision</th>\n",
       "      <th id=\"T_6e798_level0_col14\" class=\"col_heading level0 col14\" >Random Edge precision Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col15\" class=\"col_heading level0 col15\" >Normal recall</th>\n",
       "      <th id=\"T_6e798_level0_col16\" class=\"col_heading level0 col16\" >To Both recall</th>\n",
       "      <th id=\"T_6e798_level0_col17\" class=\"col_heading level0 col17\" >To Both recall Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col18\" class=\"col_heading level0 col18\" >To Src recall</th>\n",
       "      <th id=\"T_6e798_level0_col19\" class=\"col_heading level0 col19\" >To Src recall Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col20\" class=\"col_heading level0 col20\" >To Dst recall</th>\n",
       "      <th id=\"T_6e798_level0_col21\" class=\"col_heading level0 col21\" >To Dst recall Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col22\" class=\"col_heading level0 col22\" >Edge Perturbation recall</th>\n",
       "      <th id=\"T_6e798_level0_col23\" class=\"col_heading level0 col23\" >Edge Perturbation recall Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col24\" class=\"col_heading level0 col24\" >Random Edge recall</th>\n",
       "      <th id=\"T_6e798_level0_col25\" class=\"col_heading level0 col25\" >Random Edge recall Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col26\" class=\"col_heading level0 col26\" >Normal f1-score</th>\n",
       "      <th id=\"T_6e798_level0_col27\" class=\"col_heading level0 col27\" >To Both f1-score</th>\n",
       "      <th id=\"T_6e798_level0_col28\" class=\"col_heading level0 col28\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col29\" class=\"col_heading level0 col29\" >To Src f1-score</th>\n",
       "      <th id=\"T_6e798_level0_col30\" class=\"col_heading level0 col30\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col31\" class=\"col_heading level0 col31\" >To Dst f1-score</th>\n",
       "      <th id=\"T_6e798_level0_col32\" class=\"col_heading level0 col32\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col33\" class=\"col_heading level0 col33\" >Edge Perturbation f1-score</th>\n",
       "      <th id=\"T_6e798_level0_col34\" class=\"col_heading level0 col34\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col35\" class=\"col_heading level0 col35\" >Random Edge f1-score</th>\n",
       "      <th id=\"T_6e798_level0_col36\" class=\"col_heading level0 col36\" >Random Edge f1-score Drop (%)</th>\n",
       "      <th id=\"T_6e798_level0_col37\" class=\"col_heading level0 col37\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e798_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6e798_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_6e798_row0_col1\" class=\"data row0 col1\" >0.00</td>\n",
       "      <td id=\"T_6e798_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_6e798_row0_col3\" class=\"data row0 col3\" >83.62</td>\n",
       "      <td id=\"T_6e798_row0_col4\" class=\"data row0 col4\" >0.99</td>\n",
       "      <td id=\"T_6e798_row0_col5\" class=\"data row0 col5\" >0.98</td>\n",
       "      <td id=\"T_6e798_row0_col6\" class=\"data row0 col6\" >0.37</td>\n",
       "      <td id=\"T_6e798_row0_col7\" class=\"data row0 col7\" >0.98</td>\n",
       "      <td id=\"T_6e798_row0_col8\" class=\"data row0 col8\" >0.55</td>\n",
       "      <td id=\"T_6e798_row0_col9\" class=\"data row0 col9\" >0.99</td>\n",
       "      <td id=\"T_6e798_row0_col10\" class=\"data row0 col10\" >-0.02</td>\n",
       "      <td id=\"T_6e798_row0_col11\" class=\"data row0 col11\" >0.97</td>\n",
       "      <td id=\"T_6e798_row0_col12\" class=\"data row0 col12\" >2.21</td>\n",
       "      <td id=\"T_6e798_row0_col13\" class=\"data row0 col13\" >1.00</td>\n",
       "      <td id=\"T_6e798_row0_col14\" class=\"data row0 col14\" >-1.14</td>\n",
       "      <td id=\"T_6e798_row0_col15\" class=\"data row0 col15\" >0.98</td>\n",
       "      <td id=\"T_6e798_row0_col16\" class=\"data row0 col16\" >0.98</td>\n",
       "      <td id=\"T_6e798_row0_col17\" class=\"data row0 col17\" >-0.00</td>\n",
       "      <td id=\"T_6e798_row0_col18\" class=\"data row0 col18\" >0.96</td>\n",
       "      <td id=\"T_6e798_row0_col19\" class=\"data row0 col19\" >1.17</td>\n",
       "      <td id=\"T_6e798_row0_col20\" class=\"data row0 col20\" >0.99</td>\n",
       "      <td id=\"T_6e798_row0_col21\" class=\"data row0 col21\" >-1.23</td>\n",
       "      <td id=\"T_6e798_row0_col22\" class=\"data row0 col22\" >0.97</td>\n",
       "      <td id=\"T_6e798_row0_col23\" class=\"data row0 col23\" >0.24</td>\n",
       "      <td id=\"T_6e798_row0_col24\" class=\"data row0 col24\" >0.96</td>\n",
       "      <td id=\"T_6e798_row0_col25\" class=\"data row0 col25\" >1.69</td>\n",
       "      <td id=\"T_6e798_row0_col26\" class=\"data row0 col26\" >0.98</td>\n",
       "      <td id=\"T_6e798_row0_col27\" class=\"data row0 col27\" >0.98</td>\n",
       "      <td id=\"T_6e798_row0_col28\" class=\"data row0 col28\" >0.19</td>\n",
       "      <td id=\"T_6e798_row0_col29\" class=\"data row0 col29\" >0.97</td>\n",
       "      <td id=\"T_6e798_row0_col30\" class=\"data row0 col30\" >0.87</td>\n",
       "      <td id=\"T_6e798_row0_col31\" class=\"data row0 col31\" >0.99</td>\n",
       "      <td id=\"T_6e798_row0_col32\" class=\"data row0 col32\" >-0.63</td>\n",
       "      <td id=\"T_6e798_row0_col33\" class=\"data row0 col33\" >0.97</td>\n",
       "      <td id=\"T_6e798_row0_col34\" class=\"data row0 col34\" >1.23</td>\n",
       "      <td id=\"T_6e798_row0_col35\" class=\"data row0 col35\" >0.98</td>\n",
       "      <td id=\"T_6e798_row0_col36\" class=\"data row0 col36\" >0.30</td>\n",
       "      <td id=\"T_6e798_row0_col37\" class=\"data row0 col37\" >290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e798_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6e798_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_6e798_row1_col1\" class=\"data row1 col1\" >0.00</td>\n",
       "      <td id=\"T_6e798_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_6e798_row1_col3\" class=\"data row1 col3\" >0.00</td>\n",
       "      <td id=\"T_6e798_row1_col4\" class=\"data row1 col4\" >0.97</td>\n",
       "      <td id=\"T_6e798_row1_col5\" class=\"data row1 col5\" >0.97</td>\n",
       "      <td id=\"T_6e798_row1_col6\" class=\"data row1 col6\" >-0.24</td>\n",
       "      <td id=\"T_6e798_row1_col7\" class=\"data row1 col7\" >0.96</td>\n",
       "      <td id=\"T_6e798_row1_col8\" class=\"data row1 col8\" >1.01</td>\n",
       "      <td id=\"T_6e798_row1_col9\" class=\"data row1 col9\" >0.99</td>\n",
       "      <td id=\"T_6e798_row1_col10\" class=\"data row1 col10\" >-1.42</td>\n",
       "      <td id=\"T_6e798_row1_col11\" class=\"data row1 col11\" >0.96</td>\n",
       "      <td id=\"T_6e798_row1_col12\" class=\"data row1 col12\" >0.66</td>\n",
       "      <td id=\"T_6e798_row1_col13\" class=\"data row1 col13\" >0.96</td>\n",
       "      <td id=\"T_6e798_row1_col14\" class=\"data row1 col14\" >1.10</td>\n",
       "      <td id=\"T_6e798_row1_col15\" class=\"data row1 col15\" >0.99</td>\n",
       "      <td id=\"T_6e798_row1_col16\" class=\"data row1 col16\" >0.99</td>\n",
       "      <td id=\"T_6e798_row1_col17\" class=\"data row1 col17\" >-0.61</td>\n",
       "      <td id=\"T_6e798_row1_col18\" class=\"data row1 col18\" >0.99</td>\n",
       "      <td id=\"T_6e798_row1_col19\" class=\"data row1 col19\" >-0.07</td>\n",
       "      <td id=\"T_6e798_row1_col20\" class=\"data row1 col20\" >0.99</td>\n",
       "      <td id=\"T_6e798_row1_col21\" class=\"data row1 col21\" >0.00</td>\n",
       "      <td id=\"T_6e798_row1_col22\" class=\"data row1 col22\" >0.93</td>\n",
       "      <td id=\"T_6e798_row1_col23\" class=\"data row1 col23\" >5.48</td>\n",
       "      <td id=\"T_6e798_row1_col24\" class=\"data row1 col24\" >0.98</td>\n",
       "      <td id=\"T_6e798_row1_col25\" class=\"data row1 col25\" >0.46</td>\n",
       "      <td id=\"T_6e798_row1_col26\" class=\"data row1 col26\" >0.98</td>\n",
       "      <td id=\"T_6e798_row1_col27\" class=\"data row1 col27\" >0.98</td>\n",
       "      <td id=\"T_6e798_row1_col28\" class=\"data row1 col28\" >-0.42</td>\n",
       "      <td id=\"T_6e798_row1_col29\" class=\"data row1 col29\" >0.97</td>\n",
       "      <td id=\"T_6e798_row1_col30\" class=\"data row1 col30\" >0.48</td>\n",
       "      <td id=\"T_6e798_row1_col31\" class=\"data row1 col31\" >0.99</td>\n",
       "      <td id=\"T_6e798_row1_col32\" class=\"data row1 col32\" >-0.71</td>\n",
       "      <td id=\"T_6e798_row1_col33\" class=\"data row1 col33\" >0.95</td>\n",
       "      <td id=\"T_6e798_row1_col34\" class=\"data row1 col34\" >3.11</td>\n",
       "      <td id=\"T_6e798_row1_col35\" class=\"data row1 col35\" >0.97</td>\n",
       "      <td id=\"T_6e798_row1_col36\" class=\"data row1 col36\" >0.78</td>\n",
       "      <td id=\"T_6e798_row1_col37\" class=\"data row1 col37\" >248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e798_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6e798_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_6e798_row2_col1\" class=\"data row2 col1\" >0.00</td>\n",
       "      <td id=\"T_6e798_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_6e798_row2_col3\" class=\"data row2 col3\" >0.00</td>\n",
       "      <td id=\"T_6e798_row2_col4\" class=\"data row2 col4\" >0.37</td>\n",
       "      <td id=\"T_6e798_row2_col5\" class=\"data row2 col5\" >0.02</td>\n",
       "      <td id=\"T_6e798_row2_col6\" class=\"data row2 col6\" >93.91</td>\n",
       "      <td id=\"T_6e798_row2_col7\" class=\"data row2 col7\" >0.01</td>\n",
       "      <td id=\"T_6e798_row2_col8\" class=\"data row2 col8\" >97.18</td>\n",
       "      <td id=\"T_6e798_row2_col9\" class=\"data row2 col9\" >0.38</td>\n",
       "      <td id=\"T_6e798_row2_col10\" class=\"data row2 col10\" >-2.47</td>\n",
       "      <td id=\"T_6e798_row2_col11\" class=\"data row2 col11\" >0.01</td>\n",
       "      <td id=\"T_6e798_row2_col12\" class=\"data row2 col12\" >97.20</td>\n",
       "      <td id=\"T_6e798_row2_col13\" class=\"data row2 col13\" >0.01</td>\n",
       "      <td id=\"T_6e798_row2_col14\" class=\"data row2 col14\" >97.88</td>\n",
       "      <td id=\"T_6e798_row2_col15\" class=\"data row2 col15\" >1.00</td>\n",
       "      <td id=\"T_6e798_row2_col16\" class=\"data row2 col16\" >1.00</td>\n",
       "      <td id=\"T_6e798_row2_col17\" class=\"data row2 col17\" >0.00</td>\n",
       "      <td id=\"T_6e798_row2_col18\" class=\"data row2 col18\" >1.00</td>\n",
       "      <td id=\"T_6e798_row2_col19\" class=\"data row2 col19\" >0.00</td>\n",
       "      <td id=\"T_6e798_row2_col20\" class=\"data row2 col20\" >1.00</td>\n",
       "      <td id=\"T_6e798_row2_col21\" class=\"data row2 col21\" >0.00</td>\n",
       "      <td id=\"T_6e798_row2_col22\" class=\"data row2 col22\" >0.94</td>\n",
       "      <td id=\"T_6e798_row2_col23\" class=\"data row2 col23\" >6.45</td>\n",
       "      <td id=\"T_6e798_row2_col24\" class=\"data row2 col24\" >1.00</td>\n",
       "      <td id=\"T_6e798_row2_col25\" class=\"data row2 col25\" >0.00</td>\n",
       "      <td id=\"T_6e798_row2_col26\" class=\"data row2 col26\" >0.54</td>\n",
       "      <td id=\"T_6e798_row2_col27\" class=\"data row2 col27\" >0.04</td>\n",
       "      <td id=\"T_6e798_row2_col28\" class=\"data row2 col28\" >91.82</td>\n",
       "      <td id=\"T_6e798_row2_col29\" class=\"data row2 col29\" >0.02</td>\n",
       "      <td id=\"T_6e798_row2_col30\" class=\"data row2 col30\" >96.17</td>\n",
       "      <td id=\"T_6e798_row2_col31\" class=\"data row2 col31\" >0.55</td>\n",
       "      <td id=\"T_6e798_row2_col32\" class=\"data row2 col32\" >-1.79</td>\n",
       "      <td id=\"T_6e798_row2_col33\" class=\"data row2 col33\" >0.02</td>\n",
       "      <td id=\"T_6e798_row2_col34\" class=\"data row2 col34\" >96.20</td>\n",
       "      <td id=\"T_6e798_row2_col35\" class=\"data row2 col35\" >0.02</td>\n",
       "      <td id=\"T_6e798_row2_col36\" class=\"data row2 col36\" >97.11</td>\n",
       "      <td id=\"T_6e798_row2_col37\" class=\"data row2 col37\" >31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e798_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6e798_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_6e798_row3_col1\" class=\"data row3 col1\" >0.00</td>\n",
       "      <td id=\"T_6e798_row3_col2\" class=\"data row3 col2\" >0.01</td>\n",
       "      <td id=\"T_6e798_row3_col3\" class=\"data row3 col3\" >322.85</td>\n",
       "      <td id=\"T_6e798_row3_col4\" class=\"data row3 col4\" >1.00</td>\n",
       "      <td id=\"T_6e798_row3_col5\" class=\"data row3 col5\" >0.94</td>\n",
       "      <td id=\"T_6e798_row3_col6\" class=\"data row3 col6\" >5.84</td>\n",
       "      <td id=\"T_6e798_row3_col7\" class=\"data row3 col7\" >0.94</td>\n",
       "      <td id=\"T_6e798_row3_col8\" class=\"data row3 col8\" >6.13</td>\n",
       "      <td id=\"T_6e798_row3_col9\" class=\"data row3 col9\" >1.00</td>\n",
       "      <td id=\"T_6e798_row3_col10\" class=\"data row3 col10\" >0.01</td>\n",
       "      <td id=\"T_6e798_row3_col11\" class=\"data row3 col11\" >0.48</td>\n",
       "      <td id=\"T_6e798_row3_col12\" class=\"data row3 col12\" >51.52</td>\n",
       "      <td id=\"T_6e798_row3_col13\" class=\"data row3 col13\" >0.84</td>\n",
       "      <td id=\"T_6e798_row3_col14\" class=\"data row3 col14\" >15.56</td>\n",
       "      <td id=\"T_6e798_row3_col15\" class=\"data row3 col15\" >0.97</td>\n",
       "      <td id=\"T_6e798_row3_col16\" class=\"data row3 col16\" >0.69</td>\n",
       "      <td id=\"T_6e798_row3_col17\" class=\"data row3 col17\" >28.59</td>\n",
       "      <td id=\"T_6e798_row3_col18\" class=\"data row3 col18\" >0.65</td>\n",
       "      <td id=\"T_6e798_row3_col19\" class=\"data row3 col19\" >32.68</td>\n",
       "      <td id=\"T_6e798_row3_col20\" class=\"data row3 col20\" >0.98</td>\n",
       "      <td id=\"T_6e798_row3_col21\" class=\"data row3 col21\" >-0.31</td>\n",
       "      <td id=\"T_6e798_row3_col22\" class=\"data row3 col22\" >0.59</td>\n",
       "      <td id=\"T_6e798_row3_col23\" class=\"data row3 col23\" >38.86</td>\n",
       "      <td id=\"T_6e798_row3_col24\" class=\"data row3 col24\" >0.97</td>\n",
       "      <td id=\"T_6e798_row3_col25\" class=\"data row3 col25\" >-0.21</td>\n",
       "      <td id=\"T_6e798_row3_col26\" class=\"data row3 col26\" >0.99</td>\n",
       "      <td id=\"T_6e798_row3_col27\" class=\"data row3 col27\" >0.80</td>\n",
       "      <td id=\"T_6e798_row3_col28\" class=\"data row3 col28\" >18.93</td>\n",
       "      <td id=\"T_6e798_row3_col29\" class=\"data row3 col29\" >0.77</td>\n",
       "      <td id=\"T_6e798_row3_col30\" class=\"data row3 col30\" >21.77</td>\n",
       "      <td id=\"T_6e798_row3_col31\" class=\"data row3 col31\" >0.99</td>\n",
       "      <td id=\"T_6e798_row3_col32\" class=\"data row3 col32\" >-0.15</td>\n",
       "      <td id=\"T_6e798_row3_col33\" class=\"data row3 col33\" >0.53</td>\n",
       "      <td id=\"T_6e798_row3_col34\" class=\"data row3 col34\" >45.83</td>\n",
       "      <td id=\"T_6e798_row3_col35\" class=\"data row3 col35\" >0.90</td>\n",
       "      <td id=\"T_6e798_row3_col36\" class=\"data row3 col36\" >8.24</td>\n",
       "      <td id=\"T_6e798_row3_col37\" class=\"data row3 col37\" >13969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e798_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6e798_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_6e798_row4_col1\" class=\"data row4 col1\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col10\" class=\"data row4 col10\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col11\" class=\"data row4 col11\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col12\" class=\"data row4 col12\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col13\" class=\"data row4 col13\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col14\" class=\"data row4 col14\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col15\" class=\"data row4 col15\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col16\" class=\"data row4 col16\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col17\" class=\"data row4 col17\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col18\" class=\"data row4 col18\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col19\" class=\"data row4 col19\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col20\" class=\"data row4 col20\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col21\" class=\"data row4 col21\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col22\" class=\"data row4 col22\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col23\" class=\"data row4 col23\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col24\" class=\"data row4 col24\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col25\" class=\"data row4 col25\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col26\" class=\"data row4 col26\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col27\" class=\"data row4 col27\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col28\" class=\"data row4 col28\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col29\" class=\"data row4 col29\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col30\" class=\"data row4 col30\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col31\" class=\"data row4 col31\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col32\" class=\"data row4 col32\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col33\" class=\"data row4 col33\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col34\" class=\"data row4 col34\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col35\" class=\"data row4 col35\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col36\" class=\"data row4 col36\" >0.00</td>\n",
       "      <td id=\"T_6e798_row4_col37\" class=\"data row4 col37\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e798_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6e798_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_6e798_row5_col1\" class=\"data row5 col1\" >0.00</td>\n",
       "      <td id=\"T_6e798_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_6e798_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_6e798_row5_col4\" class=\"data row5 col4\" >0.67</td>\n",
       "      <td id=\"T_6e798_row5_col5\" class=\"data row5 col5\" >0.58</td>\n",
       "      <td id=\"T_6e798_row5_col6\" class=\"data row5 col6\" >12.32</td>\n",
       "      <td id=\"T_6e798_row5_col7\" class=\"data row5 col7\" >0.58</td>\n",
       "      <td id=\"T_6e798_row5_col8\" class=\"data row5 col8\" >13.19</td>\n",
       "      <td id=\"T_6e798_row5_col9\" class=\"data row5 col9\" >0.67</td>\n",
       "      <td id=\"T_6e798_row5_col10\" class=\"data row5 col10\" >-0.69</td>\n",
       "      <td id=\"T_6e798_row5_col11\" class=\"data row5 col11\" >0.49</td>\n",
       "      <td id=\"T_6e798_row5_col12\" class=\"data row5 col12\" >27.20</td>\n",
       "      <td id=\"T_6e798_row5_col13\" class=\"data row5 col13\" >0.56</td>\n",
       "      <td id=\"T_6e798_row5_col14\" class=\"data row5 col14\" >15.62</td>\n",
       "      <td id=\"T_6e798_row5_col15\" class=\"data row5 col15\" >0.79</td>\n",
       "      <td id=\"T_6e798_row5_col16\" class=\"data row5 col16\" >0.73</td>\n",
       "      <td id=\"T_6e798_row5_col17\" class=\"data row5 col17\" >6.91</td>\n",
       "      <td id=\"T_6e798_row5_col18\" class=\"data row5 col18\" >0.72</td>\n",
       "      <td id=\"T_6e798_row5_col19\" class=\"data row5 col19\" >8.35</td>\n",
       "      <td id=\"T_6e798_row5_col20\" class=\"data row5 col20\" >0.79</td>\n",
       "      <td id=\"T_6e798_row5_col21\" class=\"data row5 col21\" >-0.38</td>\n",
       "      <td id=\"T_6e798_row5_col22\" class=\"data row5 col22\" >0.69</td>\n",
       "      <td id=\"T_6e798_row5_col23\" class=\"data row5 col23\" >12.68</td>\n",
       "      <td id=\"T_6e798_row5_col24\" class=\"data row5 col24\" >0.78</td>\n",
       "      <td id=\"T_6e798_row5_col25\" class=\"data row5 col25\" >0.48</td>\n",
       "      <td id=\"T_6e798_row5_col26\" class=\"data row5 col26\" >0.70</td>\n",
       "      <td id=\"T_6e798_row5_col27\" class=\"data row5 col27\" >0.56</td>\n",
       "      <td id=\"T_6e798_row5_col28\" class=\"data row5 col28\" >19.59</td>\n",
       "      <td id=\"T_6e798_row5_col29\" class=\"data row5 col29\" >0.55</td>\n",
       "      <td id=\"T_6e798_row5_col30\" class=\"data row5 col30\" >21.51</td>\n",
       "      <td id=\"T_6e798_row5_col31\" class=\"data row5 col31\" >0.70</td>\n",
       "      <td id=\"T_6e798_row5_col32\" class=\"data row5 col32\" >-0.70</td>\n",
       "      <td id=\"T_6e798_row5_col33\" class=\"data row5 col33\" >0.49</td>\n",
       "      <td id=\"T_6e798_row5_col34\" class=\"data row5 col34\" >29.16</td>\n",
       "      <td id=\"T_6e798_row5_col35\" class=\"data row5 col35\" >0.57</td>\n",
       "      <td id=\"T_6e798_row5_col36\" class=\"data row5 col36\" >17.77</td>\n",
       "      <td id=\"T_6e798_row5_col37\" class=\"data row5 col37\" >553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e798_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6e798_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_6e798_row6_col1\" class=\"data row6 col1\" >0.00</td>\n",
       "      <td id=\"T_6e798_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_6e798_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_6e798_row6_col4\" class=\"data row6 col4\" >0.98</td>\n",
       "      <td id=\"T_6e798_row6_col5\" class=\"data row6 col5\" >0.98</td>\n",
       "      <td id=\"T_6e798_row6_col6\" class=\"data row6 col6\" >0.24</td>\n",
       "      <td id=\"T_6e798_row6_col7\" class=\"data row6 col7\" >0.97</td>\n",
       "      <td id=\"T_6e798_row6_col8\" class=\"data row6 col8\" >0.90</td>\n",
       "      <td id=\"T_6e798_row6_col9\" class=\"data row6 col9\" >0.99</td>\n",
       "      <td id=\"T_6e798_row6_col10\" class=\"data row6 col10\" >-0.64</td>\n",
       "      <td id=\"T_6e798_row6_col11\" class=\"data row6 col11\" >0.95</td>\n",
       "      <td id=\"T_6e798_row6_col12\" class=\"data row6 col12\" >2.79</td>\n",
       "      <td id=\"T_6e798_row6_col13\" class=\"data row6 col13\" >0.98</td>\n",
       "      <td id=\"T_6e798_row6_col14\" class=\"data row6 col14\" >0.29</td>\n",
       "      <td id=\"T_6e798_row6_col15\" class=\"data row6 col15\" >0.98</td>\n",
       "      <td id=\"T_6e798_row6_col16\" class=\"data row6 col16\" >0.98</td>\n",
       "      <td id=\"T_6e798_row6_col17\" class=\"data row6 col17\" >0.44</td>\n",
       "      <td id=\"T_6e798_row6_col18\" class=\"data row6 col18\" >0.97</td>\n",
       "      <td id=\"T_6e798_row6_col19\" class=\"data row6 col19\" >1.40</td>\n",
       "      <td id=\"T_6e798_row6_col20\" class=\"data row6 col20\" >0.99</td>\n",
       "      <td id=\"T_6e798_row6_col21\" class=\"data row6 col21\" >-0.65</td>\n",
       "      <td id=\"T_6e798_row6_col22\" class=\"data row6 col22\" >0.95</td>\n",
       "      <td id=\"T_6e798_row6_col23\" class=\"data row6 col23\" >3.58</td>\n",
       "      <td id=\"T_6e798_row6_col24\" class=\"data row6 col24\" >0.97</td>\n",
       "      <td id=\"T_6e798_row6_col25\" class=\"data row6 col25\" >1.08</td>\n",
       "      <td id=\"T_6e798_row6_col26\" class=\"data row6 col26\" >0.98</td>\n",
       "      <td id=\"T_6e798_row6_col27\" class=\"data row6 col27\" >0.98</td>\n",
       "      <td id=\"T_6e798_row6_col28\" class=\"data row6 col28\" >0.39</td>\n",
       "      <td id=\"T_6e798_row6_col29\" class=\"data row6 col29\" >0.97</td>\n",
       "      <td id=\"T_6e798_row6_col30\" class=\"data row6 col30\" >1.23</td>\n",
       "      <td id=\"T_6e798_row6_col31\" class=\"data row6 col31\" >0.99</td>\n",
       "      <td id=\"T_6e798_row6_col32\" class=\"data row6 col32\" >-0.65</td>\n",
       "      <td id=\"T_6e798_row6_col33\" class=\"data row6 col33\" >0.95</td>\n",
       "      <td id=\"T_6e798_row6_col34\" class=\"data row6 col34\" >3.21</td>\n",
       "      <td id=\"T_6e798_row6_col35\" class=\"data row6 col35\" >0.97</td>\n",
       "      <td id=\"T_6e798_row6_col36\" class=\"data row6 col36\" >0.72</td>\n",
       "      <td id=\"T_6e798_row6_col37\" class=\"data row6 col37\" >553000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x717e18489250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_overall_metrics(baseline_report, adversarial_reports, class_degree_report):\n",
    "    rows = []   \n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    eplison = 1e-10  # To avoid division by zero\n",
    "\n",
    "    for label in list(class_map) + ['macro avg', 'weighted avg']:\n",
    "        row = {\"Class\": label}\n",
    "        row['Class'] = label\n",
    "        row['Min Influence'] = class_degree_report[label]['min_influence'] if label in class_degree_report else 0.0\n",
    "        row['Avg Influence'] = class_degree_report[label]['avg_influence'] if label in class_degree_report else 0.0\n",
    "        row['Max Influence'] = class_degree_report[label]['max_influence'] if label in class_degree_report else 0.0\n",
    "        for metric in metrics:\n",
    "            baseline_val = baseline_report[label][metric]\n",
    "            row[f\"Normal {metric}\"] = baseline_val\n",
    "            for name, report in adversarial_reports.items():\n",
    "                adv_val = report[label][metric]\n",
    "                row[f\"{name} {metric}\"] = adv_val\n",
    "                row[f\"{name} {metric} Drop (%)\"] = ((baseline_val - adv_val) / (baseline_val + eplison)) * 100\n",
    "        row['support'] = int(baseline_report[label]['support'])\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "adversarial_reports = {\n",
    "    \"To Both\": inject_both_report,\n",
    "    \"To Src\": inject_src_report,\n",
    "    \"To Dst\": inject_dst_report,\n",
    "    \"Edge Perturbation\": edge_perturb_report,\n",
    "    \"Random Edge\": random_edge_report,\n",
    "}\n",
    "\n",
    "comparison_df = compare_overall_metrics(normal_report, adversarial_reports, class_degree_report)\n",
    "\n",
    "class_col = comparison_df['Class']\n",
    "support_df = comparison_df['support']\n",
    "normal_cols = [col for col in comparison_df.columns if col.startswith('Normal')] \n",
    "influence_cols = [col for col in comparison_df.columns if col.endswith('Influence')] \n",
    "influence_df = comparison_df[influence_cols]\n",
    "f1_cols = [col for col in comparison_df.columns if col.endswith('f1-score')]\n",
    "f1_drop_cols = [col for col in comparison_df.columns if col.endswith('f1-score Drop (%)')]\n",
    "\n",
    "baselines_df = pd.concat([class_col, support_df, influence_df], axis=1)\n",
    "\n",
    "f1_df = pd.concat([baselines_df, comparison_df[f1_cols]], axis=1)\n",
    "f1_drop_df = pd.concat([baselines_df, comparison_df[f1_drop_cols]], axis=1)\n",
    "\n",
    "print(\"Comparison of Overall Metrics:\")\n",
    "display(comparison_df.style.set_caption(\"Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3725caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f9688_row0_col5, #T_f9688_row1_col5, #T_f9688_row6_col5, #T_f9688_row6_col6, #T_f9688_row6_col7, #T_f9688_row6_col10 {\n",
       "  background-color: #00451c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row0_col6, #T_f9688_row0_col7, #T_f9688_row0_col8, #T_f9688_row0_col9, #T_f9688_row0_col10, #T_f9688_row1_col6, #T_f9688_row1_col7, #T_f9688_row1_col8, #T_f9688_row3_col5, #T_f9688_row3_col8, #T_f9688_row6_col8 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row1_col9, #T_f9688_row6_col9 {\n",
       "  background-color: #004a1e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row1_col10 {\n",
       "  background-color: #00471c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row2_col5 {\n",
       "  background-color: #5eb96b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row2_col6 {\n",
       "  background-color: #f1faee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9688_row2_col7, #T_f9688_row2_col9 {\n",
       "  background-color: #f4fbf2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9688_row2_col8 {\n",
       "  background-color: #5bb86a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row2_col10 {\n",
       "  background-color: #f5fbf2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9688_row3_col6 {\n",
       "  background-color: #117b38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row3_col7 {\n",
       "  background-color: #17813d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row3_col9 {\n",
       "  background-color: #60ba6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row3_col10 {\n",
       "  background-color: #005c25;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row4_col5, #T_f9688_row4_col6, #T_f9688_row4_col7, #T_f9688_row4_col8, #T_f9688_row4_col9, #T_f9688_row4_col10 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9688_row5_col5 {\n",
       "  background-color: #2d954d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row5_col6 {\n",
       "  background-color: #56b567;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row5_col7 {\n",
       "  background-color: #5ab769;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row5_col8 {\n",
       "  background-color: #2c944c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f9688_row5_col9 {\n",
       "  background-color: #70c274;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f9688_row5_col10 {\n",
       "  background-color: #50b264;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f9688\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f9688_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_f9688_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_f9688_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_f9688_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_f9688_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_f9688_level0_col5\" class=\"col_heading level0 col5\" >Normal f1-score</th>\n",
       "      <th id=\"T_f9688_level0_col6\" class=\"col_heading level0 col6\" >To Both f1-score</th>\n",
       "      <th id=\"T_f9688_level0_col7\" class=\"col_heading level0 col7\" >To Src f1-score</th>\n",
       "      <th id=\"T_f9688_level0_col8\" class=\"col_heading level0 col8\" >To Dst f1-score</th>\n",
       "      <th id=\"T_f9688_level0_col9\" class=\"col_heading level0 col9\" >Edge Perturbation f1-score</th>\n",
       "      <th id=\"T_f9688_level0_col10\" class=\"col_heading level0 col10\" >Random Edge f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f9688_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f9688_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_f9688_row0_col1\" class=\"data row0 col1\" >290500</td>\n",
       "      <td id=\"T_f9688_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_f9688_row0_col3\" class=\"data row0 col3\" >0.00</td>\n",
       "      <td id=\"T_f9688_row0_col4\" class=\"data row0 col4\" >83.62</td>\n",
       "      <td id=\"T_f9688_row0_col5\" class=\"data row0 col5\" >0.98</td>\n",
       "      <td id=\"T_f9688_row0_col6\" class=\"data row0 col6\" >0.98</td>\n",
       "      <td id=\"T_f9688_row0_col7\" class=\"data row0 col7\" >0.97</td>\n",
       "      <td id=\"T_f9688_row0_col8\" class=\"data row0 col8\" >0.99</td>\n",
       "      <td id=\"T_f9688_row0_col9\" class=\"data row0 col9\" >0.97</td>\n",
       "      <td id=\"T_f9688_row0_col10\" class=\"data row0 col10\" >0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9688_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f9688_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_f9688_row1_col1\" class=\"data row1 col1\" >248500</td>\n",
       "      <td id=\"T_f9688_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_f9688_row1_col3\" class=\"data row1 col3\" >0.00</td>\n",
       "      <td id=\"T_f9688_row1_col4\" class=\"data row1 col4\" >0.00</td>\n",
       "      <td id=\"T_f9688_row1_col5\" class=\"data row1 col5\" >0.98</td>\n",
       "      <td id=\"T_f9688_row1_col6\" class=\"data row1 col6\" >0.98</td>\n",
       "      <td id=\"T_f9688_row1_col7\" class=\"data row1 col7\" >0.97</td>\n",
       "      <td id=\"T_f9688_row1_col8\" class=\"data row1 col8\" >0.99</td>\n",
       "      <td id=\"T_f9688_row1_col9\" class=\"data row1 col9\" >0.95</td>\n",
       "      <td id=\"T_f9688_row1_col10\" class=\"data row1 col10\" >0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9688_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f9688_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_f9688_row2_col1\" class=\"data row2 col1\" >31</td>\n",
       "      <td id=\"T_f9688_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_f9688_row2_col3\" class=\"data row2 col3\" >0.00</td>\n",
       "      <td id=\"T_f9688_row2_col4\" class=\"data row2 col4\" >0.00</td>\n",
       "      <td id=\"T_f9688_row2_col5\" class=\"data row2 col5\" >0.54</td>\n",
       "      <td id=\"T_f9688_row2_col6\" class=\"data row2 col6\" >0.04</td>\n",
       "      <td id=\"T_f9688_row2_col7\" class=\"data row2 col7\" >0.02</td>\n",
       "      <td id=\"T_f9688_row2_col8\" class=\"data row2 col8\" >0.55</td>\n",
       "      <td id=\"T_f9688_row2_col9\" class=\"data row2 col9\" >0.02</td>\n",
       "      <td id=\"T_f9688_row2_col10\" class=\"data row2 col10\" >0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9688_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f9688_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_f9688_row3_col1\" class=\"data row3 col1\" >13969</td>\n",
       "      <td id=\"T_f9688_row3_col2\" class=\"data row3 col2\" >0.00</td>\n",
       "      <td id=\"T_f9688_row3_col3\" class=\"data row3 col3\" >0.01</td>\n",
       "      <td id=\"T_f9688_row3_col4\" class=\"data row3 col4\" >322.85</td>\n",
       "      <td id=\"T_f9688_row3_col5\" class=\"data row3 col5\" >0.99</td>\n",
       "      <td id=\"T_f9688_row3_col6\" class=\"data row3 col6\" >0.80</td>\n",
       "      <td id=\"T_f9688_row3_col7\" class=\"data row3 col7\" >0.77</td>\n",
       "      <td id=\"T_f9688_row3_col8\" class=\"data row3 col8\" >0.99</td>\n",
       "      <td id=\"T_f9688_row3_col9\" class=\"data row3 col9\" >0.53</td>\n",
       "      <td id=\"T_f9688_row3_col10\" class=\"data row3 col10\" >0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9688_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f9688_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_f9688_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_f9688_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_f9688_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_f9688_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_f9688_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_f9688_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_f9688_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_f9688_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_f9688_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "      <td id=\"T_f9688_row4_col10\" class=\"data row4 col10\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9688_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f9688_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_f9688_row5_col1\" class=\"data row5 col1\" >553000</td>\n",
       "      <td id=\"T_f9688_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_f9688_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_f9688_row5_col4\" class=\"data row5 col4\" >0.00</td>\n",
       "      <td id=\"T_f9688_row5_col5\" class=\"data row5 col5\" >0.70</td>\n",
       "      <td id=\"T_f9688_row5_col6\" class=\"data row5 col6\" >0.56</td>\n",
       "      <td id=\"T_f9688_row5_col7\" class=\"data row5 col7\" >0.55</td>\n",
       "      <td id=\"T_f9688_row5_col8\" class=\"data row5 col8\" >0.70</td>\n",
       "      <td id=\"T_f9688_row5_col9\" class=\"data row5 col9\" >0.49</td>\n",
       "      <td id=\"T_f9688_row5_col10\" class=\"data row5 col10\" >0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9688_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f9688_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_f9688_row6_col1\" class=\"data row6 col1\" >553000</td>\n",
       "      <td id=\"T_f9688_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_f9688_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_f9688_row6_col4\" class=\"data row6 col4\" >0.00</td>\n",
       "      <td id=\"T_f9688_row6_col5\" class=\"data row6 col5\" >0.98</td>\n",
       "      <td id=\"T_f9688_row6_col6\" class=\"data row6 col6\" >0.98</td>\n",
       "      <td id=\"T_f9688_row6_col7\" class=\"data row6 col7\" >0.97</td>\n",
       "      <td id=\"T_f9688_row6_col8\" class=\"data row6 col8\" >0.99</td>\n",
       "      <td id=\"T_f9688_row6_col9\" class=\"data row6 col9\" >0.95</td>\n",
       "      <td id=\"T_f9688_row6_col10\" class=\"data row6 col10\" >0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x717e1849ab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check F1 Scores\n",
    "display(f1_df.style.background_gradient(cmap='Greens', subset=f1_cols, axis=0).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e5c86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_71d76_row0_col5 {\n",
       "  background-color: #fcb499;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71d76_row0_col6 {\n",
       "  background-color: #fb6e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_71d76_row0_col7 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71d76_row0_col8 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_71d76_row0_col9 {\n",
       "  background-color: #fc9879;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_71d76\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_71d76_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_71d76_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_71d76_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_71d76_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_71d76_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_71d76_level0_col5\" class=\"col_heading level0 col5\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_71d76_level0_col6\" class=\"col_heading level0 col6\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_71d76_level0_col7\" class=\"col_heading level0 col7\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_71d76_level0_col8\" class=\"col_heading level0 col8\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_71d76_level0_col9\" class=\"col_heading level0 col9\" >Random Edge f1-score Drop (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_71d76_level0_row0\" class=\"row_heading level0 row0\" >6</th>\n",
       "      <td id=\"T_71d76_row0_col0\" class=\"data row0 col0\" >weighted avg</td>\n",
       "      <td id=\"T_71d76_row0_col1\" class=\"data row0 col1\" >553000</td>\n",
       "      <td id=\"T_71d76_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_71d76_row0_col3\" class=\"data row0 col3\" >0.00</td>\n",
       "      <td id=\"T_71d76_row0_col4\" class=\"data row0 col4\" >0.00</td>\n",
       "      <td id=\"T_71d76_row0_col5\" class=\"data row0 col5\" >0.39</td>\n",
       "      <td id=\"T_71d76_row0_col6\" class=\"data row0 col6\" >1.23</td>\n",
       "      <td id=\"T_71d76_row0_col7\" class=\"data row0 col7\" >-0.65</td>\n",
       "      <td id=\"T_71d76_row0_col8\" class=\"data row0 col8\" >3.21</td>\n",
       "      <td id=\"T_71d76_row0_col9\" class=\"data row0 col9\" >0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x717e1a430290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Drops per Adversarial Attack\n",
    "display(f1_drop_df[f1_drop_df['Class'] == 'weighted avg'].style.background_gradient(cmap='Reds', subset=f1_drop_cols, axis=None).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb8033d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1f25_row0_col5, #T_b1f25_row1_col6, #T_b1f25_row4_col5, #T_b1f25_row6_col9 {\n",
       "  background-color: #fff4ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row0_col6, #T_b1f25_row1_col9, #T_b1f25_row6_col5 {\n",
       "  background-color: #fff4ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row0_col7 {\n",
       "  background-color: #e83429;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1f25_row0_col8, #T_b1f25_row6_col6 {\n",
       "  background-color: #fff3ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row0_col9, #T_b1f25_row1_col5, #T_b1f25_row2_col7, #T_b1f25_row4_col6, #T_b1f25_row4_col8, #T_b1f25_row4_col9 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row1_col7 {\n",
       "  background-color: #f14331;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1f25_row1_col8, #T_b1f25_row6_col8 {\n",
       "  background-color: #fff0e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row2_col5, #T_b1f25_row2_col6, #T_b1f25_row2_col8, #T_b1f25_row2_col9, #T_b1f25_row4_col7 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1f25_row3_col5 {\n",
       "  background-color: #fdc7b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row3_col6, #T_b1f25_row5_col6 {\n",
       "  background-color: #fcc3ab;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row3_col7 {\n",
       "  background-color: #900a12;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1f25_row3_col8 {\n",
       "  background-color: #fb7252;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1f25_row3_col9 {\n",
       "  background-color: #fee7dc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row5_col5 {\n",
       "  background-color: #fdc5ae;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row5_col7 {\n",
       "  background-color: #f0402f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b1f25_row5_col8 {\n",
       "  background-color: #fcaa8d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row5_col9 {\n",
       "  background-color: #fdd0bc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b1f25_row6_col7 {\n",
       "  background-color: #ec382b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1f25\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b1f25_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_b1f25_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_b1f25_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_b1f25_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_b1f25_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_b1f25_level0_col5\" class=\"col_heading level0 col5\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_b1f25_level0_col6\" class=\"col_heading level0 col6\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_b1f25_level0_col7\" class=\"col_heading level0 col7\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_b1f25_level0_col8\" class=\"col_heading level0 col8\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_b1f25_level0_col9\" class=\"col_heading level0 col9\" >Random Edge f1-score Drop (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b1f25_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b1f25_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_b1f25_row0_col1\" class=\"data row0 col1\" >290500</td>\n",
       "      <td id=\"T_b1f25_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row0_col3\" class=\"data row0 col3\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row0_col4\" class=\"data row0 col4\" >83.62</td>\n",
       "      <td id=\"T_b1f25_row0_col5\" class=\"data row0 col5\" >0.19</td>\n",
       "      <td id=\"T_b1f25_row0_col6\" class=\"data row0 col6\" >0.87</td>\n",
       "      <td id=\"T_b1f25_row0_col7\" class=\"data row0 col7\" >-0.63</td>\n",
       "      <td id=\"T_b1f25_row0_col8\" class=\"data row0 col8\" >1.23</td>\n",
       "      <td id=\"T_b1f25_row0_col9\" class=\"data row0 col9\" >0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1f25_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b1f25_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_b1f25_row1_col1\" class=\"data row1 col1\" >248500</td>\n",
       "      <td id=\"T_b1f25_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row1_col3\" class=\"data row1 col3\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row1_col4\" class=\"data row1 col4\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row1_col5\" class=\"data row1 col5\" >-0.42</td>\n",
       "      <td id=\"T_b1f25_row1_col6\" class=\"data row1 col6\" >0.48</td>\n",
       "      <td id=\"T_b1f25_row1_col7\" class=\"data row1 col7\" >-0.71</td>\n",
       "      <td id=\"T_b1f25_row1_col8\" class=\"data row1 col8\" >3.11</td>\n",
       "      <td id=\"T_b1f25_row1_col9\" class=\"data row1 col9\" >0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1f25_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b1f25_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_b1f25_row2_col1\" class=\"data row2 col1\" >31</td>\n",
       "      <td id=\"T_b1f25_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row2_col3\" class=\"data row2 col3\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row2_col4\" class=\"data row2 col4\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row2_col5\" class=\"data row2 col5\" >91.82</td>\n",
       "      <td id=\"T_b1f25_row2_col6\" class=\"data row2 col6\" >96.17</td>\n",
       "      <td id=\"T_b1f25_row2_col7\" class=\"data row2 col7\" >-1.79</td>\n",
       "      <td id=\"T_b1f25_row2_col8\" class=\"data row2 col8\" >96.20</td>\n",
       "      <td id=\"T_b1f25_row2_col9\" class=\"data row2 col9\" >97.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1f25_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b1f25_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_b1f25_row3_col1\" class=\"data row3 col1\" >13969</td>\n",
       "      <td id=\"T_b1f25_row3_col2\" class=\"data row3 col2\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row3_col3\" class=\"data row3 col3\" >0.01</td>\n",
       "      <td id=\"T_b1f25_row3_col4\" class=\"data row3 col4\" >322.85</td>\n",
       "      <td id=\"T_b1f25_row3_col5\" class=\"data row3 col5\" >18.93</td>\n",
       "      <td id=\"T_b1f25_row3_col6\" class=\"data row3 col6\" >21.77</td>\n",
       "      <td id=\"T_b1f25_row3_col7\" class=\"data row3 col7\" >-0.15</td>\n",
       "      <td id=\"T_b1f25_row3_col8\" class=\"data row3 col8\" >45.83</td>\n",
       "      <td id=\"T_b1f25_row3_col9\" class=\"data row3 col9\" >8.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1f25_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b1f25_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_b1f25_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_b1f25_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1f25_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b1f25_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_b1f25_row5_col1\" class=\"data row5 col1\" >553000</td>\n",
       "      <td id=\"T_b1f25_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row5_col4\" class=\"data row5 col4\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row5_col5\" class=\"data row5 col5\" >19.59</td>\n",
       "      <td id=\"T_b1f25_row5_col6\" class=\"data row5 col6\" >21.51</td>\n",
       "      <td id=\"T_b1f25_row5_col7\" class=\"data row5 col7\" >-0.70</td>\n",
       "      <td id=\"T_b1f25_row5_col8\" class=\"data row5 col8\" >29.16</td>\n",
       "      <td id=\"T_b1f25_row5_col9\" class=\"data row5 col9\" >17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1f25_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b1f25_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_b1f25_row6_col1\" class=\"data row6 col1\" >553000</td>\n",
       "      <td id=\"T_b1f25_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row6_col4\" class=\"data row6 col4\" >0.00</td>\n",
       "      <td id=\"T_b1f25_row6_col5\" class=\"data row6 col5\" >0.39</td>\n",
       "      <td id=\"T_b1f25_row6_col6\" class=\"data row6 col6\" >1.23</td>\n",
       "      <td id=\"T_b1f25_row6_col7\" class=\"data row6 col7\" >-0.65</td>\n",
       "      <td id=\"T_b1f25_row6_col8\" class=\"data row6 col8\" >3.21</td>\n",
       "      <td id=\"T_b1f25_row6_col9\" class=\"data row6 col9\" >0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x717e184c1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Drops per Class\n",
    "display(f1_drop_df.style.background_gradient(cmap='Reds', subset=f1_drop_cols).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "852b5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DDoS': {'influence': (0.0, 0.0, 83.62),\n",
      "          'out_degree': (1.0, 1.0, 541.0),\n",
      "          'in_degree': (1.0, 217.93, 3500.0),\n",
      "          'normal_f1': 0.98,\n",
      "          'to_both_f1': 0.98,\n",
      "          'to_src_f1': 0.97,\n",
      "          'to_dst_f1': 0.99,\n",
      "          'edge_perturb_f1': 0.97,\n",
      "          'random_edge_f1': 0.98},\n",
      " 'DoS': {'influence': (0.0, 0.0, 0.0),\n",
      "         'out_degree': (1.0, 1.0, 1.0),\n",
      "         'in_degree': (1.0, 990.04, 3500.0),\n",
      "         'normal_f1': 0.98,\n",
      "         'to_both_f1': 0.98,\n",
      "         'to_src_f1': 0.97,\n",
      "         'to_dst_f1': 0.99,\n",
      "         'edge_perturb_f1': 0.95,\n",
      "         'random_edge_f1': 0.97},\n",
      " 'Normal': {'influence': (0.0, 0.0, 0.0),\n",
      "            'out_degree': (1.0, 1.0, 1.0),\n",
      "            'in_degree': (1.0, 1.63, 4.0),\n",
      "            'normal_f1': 0.54,\n",
      "            'to_both_f1': 0.04,\n",
      "            'to_src_f1': 0.02,\n",
      "            'to_dst_f1': 0.55,\n",
      "            'edge_perturb_f1': 0.02,\n",
      "            'random_edge_f1': 0.02},\n",
      " 'Reconnaissance': {'influence': (0.0, 0.01, 322.85),\n",
      "                    'out_degree': (1.0, 8.17, 1063.0),\n",
      "                    'in_degree': (1.0, 2.33, 760.0),\n",
      "                    'normal_f1': 0.99,\n",
      "                    'to_both_f1': 0.8,\n",
      "                    'to_src_f1': 0.77,\n",
      "                    'to_dst_f1': 0.99,\n",
      "                    'edge_perturb_f1': 0.53,\n",
      "                    'random_edge_f1': 0.9},\n",
      " 'Theft': {'normal_f1': 0.0,\n",
      "           'to_both_f1': 0.0,\n",
      "           'to_src_f1': 0.0,\n",
      "           'to_dst_f1': 0.0,\n",
      "           'edge_perturb_f1': 0.0,\n",
      "           'random_edge_f1': 0.0},\n",
      " 'macro avg': {'normal_f1': 0.7,\n",
      "               'to_both_f1': 0.56,\n",
      "               'to_src_f1': 0.55,\n",
      "               'to_dst_f1': 0.7,\n",
      "               'edge_perturb_f1': 0.49,\n",
      "               'random_edge_f1': 0.57},\n",
      " 'Weighted Average': {'normal_f1': 0.98,\n",
      "                      'to_both_f1': 0.98,\n",
      "                      'to_src_f1': 0.97,\n",
      "                      'to_dst_f1': 0.99,\n",
      "                      'edge_perturb_f1': 0.95,\n",
      "                      'random_edge_f1': 0.97}}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pformat\n",
    "\n",
    "def round_tuple(t):\n",
    "    return tuple(round(x, 2) for x in t)\n",
    "\n",
    "def print_results(class_degree_report, comparison_df):\n",
    "    report_dict = defaultdict(dict)\n",
    "\n",
    "    for class_name, metrics in class_degree_report.items():\n",
    "        report_dict[class_name] = {\n",
    "            \"influence\": round_tuple((metrics['min_influence'], metrics['avg_influence'], metrics['max_influence'])),\n",
    "            \"out_degree\": round_tuple((metrics['min_out'], metrics['avg_out'], metrics['max_out'])),\n",
    "            \"in_degree\": round_tuple((metrics['min_in'], metrics['avg_in'], metrics['max_in']))\n",
    "        }\n",
    "\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        class_name = row['Class']\n",
    "        if class_name == 'weighted avg':\n",
    "            class_name = 'Weighted Average'\n",
    "        report_dict[class_name].update({\n",
    "            \"normal_f1\": round(row['Normal f1-score'], 2),\n",
    "            \"to_both_f1\": round(row['To Both f1-score'], 2),\n",
    "            \"to_src_f1\": round(row['To Src f1-score'], 2),\n",
    "            \"to_dst_f1\": round(row['To Dst f1-score'], 2),\n",
    "            \"edge_perturb_f1\": round(row['Edge Perturbation f1-score'], 2),\n",
    "            \"random_edge_f1\": round(row['Random Edge f1-score'], 2),\n",
    "        })\n",
    "\n",
    "    print(pformat(dict(report_dict), sort_dicts=False, indent=1))\n",
    "\n",
    "print_results(class_degree_report, comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
