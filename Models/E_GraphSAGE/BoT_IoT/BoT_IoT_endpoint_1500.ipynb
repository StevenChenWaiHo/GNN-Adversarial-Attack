{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====Experiment=====\n",
    "Dataset: BoT-IoT dataset\n",
    "\n",
    "Host-Level Graph Construction\n",
    "'''\n",
    "DATASET_NAME = \"BoT_IoT\"\n",
    "\n",
    "GRAPH_CONSTRUCTION = 'endpoint'\n",
    "WINDOW_SIZE = 1500\n",
    "\n",
    "MULTICLASS = True\n",
    "\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.BoT_IoT.BoT_IoT_config import BoT_IoT_Config as Dataset_Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = \"all_raw\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"{DATASET_NAME}/All/{csv_file_name}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "DDoS              1926624\n",
      "DoS               1650260\n",
      "Reconnaissance      91082\n",
      "Normal                477\n",
      "Theft                  79\n",
      "Name: count, dtype: int64\n",
      "attack\n",
      "1    3668045\n",
      "0        477\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = f\"strat_window_{GRAPH_CONSTRUCTION}_{WINDOW_SIZE}\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = Dataset_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = Dataset_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = Dataset_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = Dataset_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = Dataset_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = Dataset_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = Dataset_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = Dataset_Config.TIME_COL_NAMES\n",
    "\n",
    "DROP_COLS = Dataset_Config.DROP_COLS\n",
    "\n",
    "COLS_TO_NORM = Dataset_Config.COLS_TO_NORM\n",
    "CATEGORICAL_COLS = Dataset_Config.CATEGORICAL_COLS\n",
    "\n",
    "print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "print(data[IS_ATTACK_COL_NAME].value_counts())\n",
    "\n",
    "if MULTICLASS:\n",
    "    label_col = ATTACK_CLASS_COL_NAME\n",
    "    data.drop(columns=[IS_ATTACK_COL_NAME], inplace=True)\n",
    "else:\n",
    "    label_col = IS_ATTACK_COL_NAME\n",
    "    data.drop(columns=[ATTACK_CLASS_COL_NAME], inplace=True)\n",
    "\n",
    "save_path = os.path.join(project_root, \"Models/E_GraphSAGE/saved\", EXPERIMENT_NAME)\n",
    "\n",
    "checkpoint_path = os.path.join(save_path, f\"checkpoints_{csv_file_name}.pth\")\n",
    "best_model_path = os.path.join(save_path, f\"best_model_{csv_file_name}.pth\")\n",
    "\n",
    "graph_datasets_path = os.path.join(save_path, GRAPH_CONSTRUCTION, str(WINDOW_SIZE))\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(graph_datasets_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pkSeqID', 'stime', 'flgs_number', 'proto_number', 'saddr', 'sport',\n",
      "       'daddr', 'dport', 'pkts', 'bytes', 'state_number', 'ltime', 'dur',\n",
      "       'mean', 'stddev', 'sum', 'min', 'max', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'srate', 'drate', 'TnBPSrcIP', 'TnBPDstIP',\n",
      "       'TnP_PSrcIP', 'TnP_PDstIP', 'TnP_PerProto', 'TnP_Per_Dport',\n",
      "       'AR_P_Proto_P_SrcIP', 'AR_P_Proto_P_DstIP', 'N_IN_Conn_P_DstIP',\n",
      "       'N_IN_Conn_P_SrcIP', 'AR_P_Proto_P_Sport', 'AR_P_Proto_P_Dport',\n",
      "       'Pkts_P_State_P_Protocol_P_DestIP', 'Pkts_P_State_P_Protocol_P_SrcIP',\n",
      "       'category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data.drop(columns=DROP_COLS,inplace=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GRAPH_CONSTRUCTION == 'host':\n",
    "    data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "    data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "    # # Combine Port and IP\n",
    "    data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "    data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "    data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "    data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "    data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "    data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "    converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "\n",
    "elif GRAPH_CONSTRUCTION == 'endpoint':\n",
    "    data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "    converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "    COLS_TO_NORM = COLS_TO_NORM + [SOURCE_PORT_COL_NAME, DESTINATION_PORT_COL_NAME]\n",
    "else:\n",
    "    raise ValueError(\"Invalid GRAPH_CONSTRUCTION value. Use 'host' or 'endpoint'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean NaN values\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "data.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               pkts         bytes           dur          mean        stddev  \\\n",
      "count  3.668522e+06  3.668522e+06  3.668522e+06  3.668522e+06  3.668522e+06   \n",
      "mean   7.725963e+00  8.690501e+02  2.033479e+01  2.231063e+00  8.871499e-01   \n",
      "std    1.155876e+02  1.122667e+05  2.148764e+01  1.517728e+00  8.037139e-01   \n",
      "min    1.000000e+00  6.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    5.000000e+00  4.200000e+02  1.256256e+01  1.819670e-01  3.001900e-02   \n",
      "50%    7.000000e+00  6.000000e+02  1.550852e+01  2.690125e+00  7.938960e-01   \n",
      "75%    9.000000e+00  7.700000e+02  2.709986e+01  3.565203e+00  1.745296e+00   \n",
      "max    7.005700e+04  7.183334e+07  2.771485e+03  4.981882e+00  2.496763e+00   \n",
      "\n",
      "                sum           min           max         spkts         dpkts  \\\n",
      "count  3.668522e+06  3.668522e+06  3.668522e+06  3.668522e+06  3.668522e+06   \n",
      "mean   7.721635e+00  1.017540e+00  3.020015e+00  7.314146e+00  4.118173e-01   \n",
      "std    7.616199e+00  1.483688e+00  1.860877e+00  7.725836e+01  4.965001e+01   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
      "25%    3.445982e-01  0.000000e+00  2.806072e-01  5.000000e+00  0.000000e+00   \n",
      "50%    8.269959e+00  0.000000e+00  4.009111e+00  6.000000e+00  0.000000e+00   \n",
      "75%    1.171040e+01  2.151138e+00  4.293582e+00  8.000000e+00  0.000000e+00   \n",
      "max    1.913194e+03  4.980471e+00  4.999999e+00  3.502900e+04  3.502900e+04   \n",
      "\n",
      "       ...  TnP_PerProto  TnP_Per_Dport  AR_P_Proto_P_SrcIP  \\\n",
      "count  ...  3.668522e+06   3.668522e+06        3.668522e+06   \n",
      "mean   ...  7.535659e+02   7.369070e+02        3.327439e+02   \n",
      "std    ...  1.434385e+03   6.527134e+02        8.466031e+03   \n",
      "min    ...  1.000000e+00   1.000000e+00        0.000000e+00   \n",
      "25%    ...  5.020000e+02   5.000000e+02        2.359950e-01   \n",
      "50%    ...  7.000000e+02   7.000000e+02        3.900890e-01   \n",
      "75%    ...  9.240000e+02   9.200000e+02        5.725580e-01   \n",
      "max    ...  2.283730e+05   2.444250e+05        2.714290e+06   \n",
      "\n",
      "       AR_P_Proto_P_DstIP  N_IN_Conn_P_DstIP  N_IN_Conn_P_SrcIP  \\\n",
      "count        3.668522e+06       3.668522e+06       3.668522e+06   \n",
      "mean         2.851832e+02       9.245168e+01       8.253848e+01   \n",
      "std          4.096943e+03       1.817643e+01       2.439739e+01   \n",
      "min          0.000000e+00       1.000000e+00       1.000000e+00   \n",
      "25%          2.436680e-01       1.000000e+02       6.900000e+01   \n",
      "50%          3.986290e-01       1.000000e+02       1.000000e+02   \n",
      "75%          5.796390e-01       1.000000e+02       1.000000e+02   \n",
      "max          1.000000e+06       1.000000e+02       1.000000e+02   \n",
      "\n",
      "       AR_P_Proto_P_Sport  AR_P_Proto_P_Dport  \\\n",
      "count        3.668522e+06        3.668522e+06   \n",
      "mean         4.564945e+02        5.385196e+02   \n",
      "std          1.432917e+04        1.569824e+04   \n",
      "min          0.000000e+00        0.000000e+00   \n",
      "25%          2.314810e-01        2.457730e-01   \n",
      "50%          3.785910e-01        3.943060e-01   \n",
      "75%          5.725550e-01        5.769710e-01   \n",
      "max          3.000000e+06        2.000000e+06   \n",
      "\n",
      "       Pkts_P_State_P_Protocol_P_DestIP  Pkts_P_State_P_Protocol_P_SrcIP  \n",
      "count                      3.668522e+06                     3.668522e+06  \n",
      "mean                       6.422897e+02                     5.859984e+02  \n",
      "std                        4.533432e+02                     4.332619e+02  \n",
      "min                        1.000000e+00                     1.000000e+00  \n",
      "25%                        3.240000e+02                     2.940000e+02  \n",
      "50%                        6.000000e+02                     5.000000e+02  \n",
      "75%                        8.280000e+02                     8.000000e+02  \n",
      "max                        1.125440e+05                     1.179390e+05  \n",
      "\n",
      "[8 rows x 29 columns]\n",
      "\n",
      "✅ All other columns processed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Normalize numerical columns\n",
    "scaler = StandardScaler()\n",
    "print(data[COLS_TO_NORM].describe()) # Check if there's any too large value\n",
    "\n",
    "# Check for numeric issues in the columns before normalization\n",
    "def check_numeric_issues(df, cols_to_norm):\n",
    "    for col in cols_to_norm:\n",
    "        try:\n",
    "            # Try to coerce to numeric\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "            print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Data type: {df[col].dtype}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "check_numeric_issues(data, COLS_TO_NORM)\n",
    "\n",
    "data[COLS_TO_NORM] = scaler.fit_transform(data[COLS_TO_NORM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "Attack label mapping: {'DDoS': 0, 'DoS': 1, 'Normal': 2, 'Reconnaissance': 3, 'Theft': 4}\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "class_map = [0, 1]\n",
    "if MULTICLASS:\n",
    "    le = LabelEncoder()\n",
    "    attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "    class_map = le.classes_\n",
    "    print(class_map)\n",
    "    print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "    data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "    num_classes = len(class_map)\n",
    "    class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n",
    "\n",
    "BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: ['pkts', 'bytes', 'dur', 'mean', 'stddev', 'sum', 'min', 'max', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'srate', 'drate', 'TnBPSrcIP', 'TnBPDstIP', 'TnP_PSrcIP', 'TnP_PDstIP', 'TnP_PerProto', 'TnP_Per_Dport', 'AR_P_Proto_P_SrcIP', 'AR_P_Proto_P_DstIP', 'N_IN_Conn_P_DstIP', 'N_IN_Conn_P_SrcIP', 'AR_P_Proto_P_Sport', 'AR_P_Proto_P_Dport', 'Pkts_P_State_P_Protocol_P_DestIP', 'Pkts_P_State_P_Protocol_P_SrcIP', 'flgs_number_1', 'flgs_number_2', 'flgs_number_3', 'flgs_number_4', 'flgs_number_5', 'flgs_number_6', 'flgs_number_7', 'flgs_number_8', 'flgs_number_9', 'state_number_1', 'state_number_2', 'state_number_3', 'state_number_4', 'state_number_5', 'state_number_6', 'state_number_7', 'state_number_8', 'state_number_9', 'state_number_10', 'state_number_11', 'proto_number_1', 'proto_number_2', 'proto_number_3', 'proto_number_4', 'proto_number_5']\n",
      "Number of Features: 54\n"
     ]
    }
   ],
   "source": [
    "# # Maintain the order of the rows in the original dataframe\n",
    "feature_cols = COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "print('Feature Columns:', feature_cols)\n",
    "num_features = len(feature_cols)\n",
    "print('Number of Features:', num_features)\n",
    "\n",
    "data['h'] = data[ feature_cols ].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652cb2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pkSeqID         stime                saddr                daddr  \\\n",
      "0  3576925  1.526344e+09     192.168.100.3:80  192.168.100.55:8080   \n",
      "1  3576926  1.526344e+09  192.168.100.46:3456     192.168.100.5:80   \n",
      "2  3576919  1.526344e+09    192.168.100.46:80     192.168.100.5:80   \n",
      "3  3576920  1.526344e+09    192.168.100.46:80     192.168.100.5:80   \n",
      "4  3576922  1.526344e+09    192.168.100.7:365    192.168.100.3:565   \n",
      "\n",
      "         pkts       bytes         ltime        dur      mean    stddev  ...  \\\n",
      "0  514.287519  542.313009  1.526346e+09  77.503750  1.790079 -0.819516  ...   \n",
      "1  514.278867  526.543278  1.526346e+09  77.503750  1.789861 -0.815632  ...   \n",
      "2  257.106013  254.240221  1.526346e+09  77.503750  1.789697 -0.815753  ...   \n",
      "3  260.834786  257.403476  1.526346e+09  77.503750  1.789704 -0.815673  ...   \n",
      "4  141.176650    8.717557  1.526346e+09  77.516146  1.754480 -0.815219  ...   \n",
      "\n",
      "   state_number_8  state_number_9  state_number_10  state_number_11  \\\n",
      "0           False           False            False            False   \n",
      "1           False           False            False            False   \n",
      "2           False           False            False            False   \n",
      "3           False           False            False            False   \n",
      "4           False           False            False            False   \n",
      "\n",
      "   proto_number_1  proto_number_2  proto_number_3  proto_number_4  \\\n",
      "0            True           False           False           False   \n",
      "1           False           False            True           False   \n",
      "2           False           False            True           False   \n",
      "3            True           False           False           False   \n",
      "4           False           False            True           False   \n",
      "\n",
      "   proto_number_5                                                  h  \n",
      "0           False  [514.287518890639, 542.3130091791619, 77.50374...  \n",
      "1           False  [514.2788674456382, 526.5432775870196, 77.5037...  \n",
      "2           False  [257.1060133499324, 254.2402212791131, 77.5037...  \n",
      "3           False  [260.8347861453051, 257.4034757933678, 77.5037...  \n",
      "4           False  [141.17665033834467, 8.717556952576851, 77.516...  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df):\n",
    "\n",
    "    G_nx = nx.from_pandas_edgelist(df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "    \n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    assert num_edges == G_nx.number_of_edges(), \"Number of edges in PyG graph does not match NetworkX graph.\"\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    return G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e650028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class StratifiedGraphDataset:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.total_count = len(self.y)\n",
    "\n",
    "        # Compute class weights\n",
    "        labels = []\n",
    "\n",
    "        for graph in self.X:\n",
    "            labels.append(graph.edge_label.tolist())\n",
    "\n",
    "        labels = np.concatenate(labels)\n",
    "\n",
    "        self.class_counts = Counter(labels)\n",
    "\n",
    "        # Compute the class weights\n",
    "        self.class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "\n",
    "    def k_fold_split(self, k: int = 5, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        cv = MultilabelStratifiedShuffleSplit(test_size=test_ratio, random_state=random_state, n_splits=k)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        y_binary = mlb.fit_transform(self.y)\n",
    "\n",
    "        return cv.split(np.zeros(len(self.X)), y_binary)\n",
    "\n",
    "    def graph_train_test_split(self, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        train_idx, test_idx = next(self.k_fold_split(k = 1, test_ratio = test_ratio, random_state = random_state))\n",
    "        \n",
    "        X_train = [self.X[i] for i in train_idx]\n",
    "        X_test = [self.X[i] for i in test_idx]\n",
    "\n",
    "        y_train = [self.y[i] for i in train_idx]\n",
    "        y_test = [self.y[i] for i in test_idx]\n",
    "\n",
    "        return StratifiedGraphDataset(X_train, y_train), StratifiedGraphDataset(X_test, y_test)\n",
    "    \n",
    "    def print_class_distribution_and_weights(self):\n",
    "        # Use the label encoder to inverse transform the class labels\n",
    "        class_counts_named = {cls: count for cls, count in self.class_counts.items()}\n",
    "        class_weights_named = {cls: weight for cls, weight in enumerate(self.class_weights)}\n",
    "        print(\"Class Counts and Weights:\")\n",
    "        for cls_label in class_counts_named.keys():\n",
    "            count = class_counts_named[cls_label]\n",
    "            weight = class_weights_named[cls_label]\n",
    "            print(f\"{cls_label:<2}  {le.inverse_transform([cls_label])[0]:<15}: Count = {count:<10}, Weight = {weight:<10.4f}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_count\n",
    "\n",
    "    def __iter__(self):\n",
    "        for g in self.X:\n",
    "            yield g\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.X[idx], self.y[idx]\n",
    "        elif isinstance(idx, slice):\n",
    "            return [self.X[i] for i in range(len(self.X))][idx], [self.y[i] for i in range(len(self.y))][idx]\n",
    "        else:\n",
    "            raise TypeError(\"Index must be an integer or a slice.\")\n",
    "\n",
    "def generate_graph_datasets(\n",
    "    df: pd.DataFrame, \n",
    "    window_size: int = WINDOW_SIZE, \n",
    "    feature_cols=feature_cols,\n",
    "    ordering_cols= TIME_COLS, \n",
    "    label_col=label_col,\n",
    "    build_graph_func=create_graph,\n",
    "    ):\n",
    "\n",
    "    print(\"All Columns: \", df.columns)\n",
    "    print(\"Ordering Columns: \", ordering_cols)\n",
    "    assert all(col in df.columns for col in ordering_cols), \"All timestamp columns are required\"\n",
    "    assert label_col in df.columns, \"Edge label column 'label' is required\"\n",
    "    \n",
    "    df = df.sort_values(ordering_cols).reset_index(drop=True)\n",
    "    window_size = int(window_size)\n",
    "    \n",
    "    df.drop(columns=set(df.columns) - set(feature_cols) - set(label_col))\n",
    "\n",
    "    print(\"Final Columns: \", df.columns)\n",
    "    \n",
    "    label_counts_list = []\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    progress_bar = tqdm(range(0, len(df), window_size), desc=f\"Generating graphs\")\n",
    "    for start in progress_bar:\n",
    "        window_df = df[start: min(start + window_size, len(df))]\n",
    "        contains_label = window_df[label_col].unique()\n",
    "\n",
    "        G_pyg = build_graph_func(window_df)\n",
    "\n",
    "        label_counts = window_df[label_col].value_counts()\n",
    "\n",
    "        label_counts_list.append(label_counts)\n",
    "        X.append(G_pyg)\n",
    "        y.append(contains_label.tolist())\n",
    "\n",
    "    return StratifiedGraphDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e7421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Columns:  Index(['pkSeqID', 'stime', 'saddr', 'daddr', 'pkts', 'bytes', 'ltime', 'dur',\n",
      "       'mean', 'stddev', 'sum', 'min', 'max', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'srate', 'drate', 'TnBPSrcIP', 'TnBPDstIP',\n",
      "       'TnP_PSrcIP', 'TnP_PDstIP', 'TnP_PerProto', 'TnP_Per_Dport',\n",
      "       'AR_P_Proto_P_SrcIP', 'AR_P_Proto_P_DstIP', 'N_IN_Conn_P_DstIP',\n",
      "       'N_IN_Conn_P_SrcIP', 'AR_P_Proto_P_Sport', 'AR_P_Proto_P_Dport',\n",
      "       'Pkts_P_State_P_Protocol_P_DestIP', 'Pkts_P_State_P_Protocol_P_SrcIP',\n",
      "       'category', 'flgs_number_1', 'flgs_number_2', 'flgs_number_3',\n",
      "       'flgs_number_4', 'flgs_number_5', 'flgs_number_6', 'flgs_number_7',\n",
      "       'flgs_number_8', 'flgs_number_9', 'state_number_1', 'state_number_2',\n",
      "       'state_number_3', 'state_number_4', 'state_number_5', 'state_number_6',\n",
      "       'state_number_7', 'state_number_8', 'state_number_9', 'state_number_10',\n",
      "       'state_number_11', 'proto_number_1', 'proto_number_2', 'proto_number_3',\n",
      "       'proto_number_4', 'proto_number_5', 'h'],\n",
      "      dtype='object')\n",
      "Ordering Columns:  ['stime', 'ltime']\n",
      "Final Columns:  Index(['pkSeqID', 'stime', 'saddr', 'daddr', 'pkts', 'bytes', 'ltime', 'dur',\n",
      "       'mean', 'stddev', 'sum', 'min', 'max', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'srate', 'drate', 'TnBPSrcIP', 'TnBPDstIP',\n",
      "       'TnP_PSrcIP', 'TnP_PDstIP', 'TnP_PerProto', 'TnP_Per_Dport',\n",
      "       'AR_P_Proto_P_SrcIP', 'AR_P_Proto_P_DstIP', 'N_IN_Conn_P_DstIP',\n",
      "       'N_IN_Conn_P_SrcIP', 'AR_P_Proto_P_Sport', 'AR_P_Proto_P_Dport',\n",
      "       'Pkts_P_State_P_Protocol_P_DestIP', 'Pkts_P_State_P_Protocol_P_SrcIP',\n",
      "       'category', 'flgs_number_1', 'flgs_number_2', 'flgs_number_3',\n",
      "       'flgs_number_4', 'flgs_number_5', 'flgs_number_6', 'flgs_number_7',\n",
      "       'flgs_number_8', 'flgs_number_9', 'state_number_1', 'state_number_2',\n",
      "       'state_number_3', 'state_number_4', 'state_number_5', 'state_number_6',\n",
      "       'state_number_7', 'state_number_8', 'state_number_9', 'state_number_10',\n",
      "       'state_number_11', 'proto_number_1', 'proto_number_2', 'proto_number_3',\n",
      "       'proto_number_4', 'proto_number_5', 'h'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating graphs: 100%|██████████| 2446/2446 [03:03<00:00, 13.32it/s]\n"
     ]
    }
   ],
   "source": [
    "graph_dataset = generate_graph_datasets(data)\n",
    "full_train_graph_dataset, test_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365fd330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distrubution: category\n",
      "0    1926624\n",
      "1    1650260\n",
      "3      91082\n",
      "2        477\n",
      "4         79\n",
      "Name: count, dtype: int64\n",
      "Number of graphs after downsampling: 2446\n",
      "Class Counts and Weights:\n",
      "2   Normal         : Count = 477       , Weight = 1538.1644 \n",
      "3   Reconnaissance : Count = 91082     , Weight = 8.0554    \n",
      "1   DoS            : Count = 1650260   , Weight = 0.4446    \n",
      "0   DDoS           : Count = 1926624   , Weight = 0.3808    \n",
      "4   Theft          : Count = 79        , Weight = 9287.3975 \n",
      "Number of training graphs: 2080\n",
      "Class Counts and Weights:\n",
      "2   Normal         : Count = 449       , Weight = 1389.5421 \n",
      "3   Reconnaissance : Count = 79051     , Weight = 7.8924    \n",
      "1   DoS            : Count = 1402819   , Weight = 0.4448    \n",
      "0   DDoS           : Count = 1637124   , Weight = 0.3811    \n",
      "4   Theft          : Count = 79        , Weight = 7897.5241 \n",
      "Number of testing graphs: 366\n",
      "Class Counts and Weights:\n",
      "3   Reconnaissance : Count = 12031     , Weight = 11.4080   \n",
      "2   Normal         : Count = 28        , Weight = 4901.7857 \n",
      "1   DoS            : Count = 247441    , Weight = 0.5547    \n",
      "0   DDoS           : Count = 289500    , Weight = 0.4741    \n"
     ]
    }
   ],
   "source": [
    "print(\"Class Distrubution:\", data[label_col].value_counts())\n",
    "\n",
    "print(\"Number of graphs after downsampling:\", len(graph_dataset))\n",
    "graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "print(\"Number of training graphs:\", len(full_train_graph_dataset))\n",
    "full_train_graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "print(\"Number of testing graphs:\", len(test_graph_dataset))\n",
    "test_graph_dataset.print_class_distribution_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with learning rate: 0.001, hidden_dim: 128, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([3.8121e-01, 4.4458e-01, 1.9641e+03, 7.8879e+00, 6.7127e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0717, Val Loss: 8.1863, Val F1 (weighted): 0.3623, Micro: 0.5257, Macro: 0.1917 (Best Weighted F1 so far: 0.3623)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.0710, Val Loss: 10.4915, Val F1 (weighted): 0.3673, Micro: 0.5281, Macro: 0.2739 (Best Weighted F1 so far: 0.3673)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.0626, Val Loss: 6.8126, Val F1 (weighted): 0.3679, Micro: 0.5285, Macro: 0.3972 (Best Weighted F1 so far: 0.3679)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 0.0948, Val Loss: 7.2049, Val F1 (weighted): 0.3686, Micro: 0.5289, Macro: 0.3325 (Best Weighted F1 so far: 0.3686)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.0871, Val Loss: 11.7522, Val F1 (weighted): 0.3696, Micro: 0.5291, Macro: 0.3330 (Best Weighted F1 so far: 0.3696)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.0895, Val Loss: 7.3584, Val F1 (weighted): 0.3718, Micro: 0.5306, Macro: 0.3210 (Best Weighted F1 so far: 0.3718)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 0.0655, Val Loss: 7.5776, Val F1 (weighted): 0.3751, Micro: 0.5328, Macro: 0.3232 (Best Weighted F1 so far: 0.3751)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 0.0948, Val Loss: 6.9493, Val F1 (weighted): 0.3770, Micro: 0.5341, Macro: 0.3253 (Best Weighted F1 so far: 0.3770)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 0.1386, Val Loss: 7.1581, Val F1 (weighted): 0.3777, Micro: 0.5345, Macro: 0.3939 (Best Weighted F1 so far: 0.3777)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 0.0819, Val Loss: 4.8119, Val F1 (weighted): 0.3792, Micro: 0.5355, Macro: 0.4000 (Best Weighted F1 so far: 0.3792)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Train Loss: 0.1149, Val Loss: 3.3922, Val F1 (weighted): 0.3848, Micro: 0.5394, Macro: 0.4078 (Best Weighted F1 so far: 0.3848)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Train Loss: 0.0330, Val Loss: 3.0852, Val F1 (weighted): 0.3997, Micro: 0.5484, Macro: 0.4588 (Best Weighted F1 so far: 0.3997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Train Loss: 0.0308, Val Loss: 2.0661, Val F1 (weighted): 0.5078, Micro: 0.6035, Macro: 0.5482 (Best Weighted F1 so far: 0.5078)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 0.0233, Val Loss: 1.4392, Val F1 (weighted): 0.6304, Micro: 0.6771, Macro: 0.5407 (Best Weighted F1 so far: 0.6304)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 0.0174, Val Loss: 1.1901, Val F1 (weighted): 0.7595, Micro: 0.7754, Macro: 0.6412 (Best Weighted F1 so far: 0.7595)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 0.0125, Val Loss: 0.8678, Val F1 (weighted): 0.8301, Micro: 0.8370, Macro: 0.6697 (Best Weighted F1 so far: 0.8301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Train Loss: 0.0194, Val Loss: 0.6534, Val F1 (weighted): 0.8743, Micro: 0.8776, Macro: 0.6942 (Best Weighted F1 so far: 0.8743)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200, Train Loss: 0.0120, Val Loss: 0.7201, Val F1 (weighted): 0.8914, Micro: 0.8937, Macro: 0.7108 (Best Weighted F1 so far: 0.8914)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200, Train Loss: 0.0103, Val Loss: 0.7028, Val F1 (weighted): 0.8961, Micro: 0.8979, Macro: 0.7346 (Best Weighted F1 so far: 0.8961)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 0.0108, Val Loss: 0.7684, Val F1 (weighted): 0.8966, Micro: 0.8985, Macro: 0.7264 (Best Weighted F1 so far: 0.8966)\n",
      "\n",
      "🛑 Early stopping triggered at epoch 46.\n",
      "Fold 2\n",
      "Class weights: tensor([3.8133e-01, 4.4439e-01, 2.0408e+03, 7.8912e+00, 6.7165e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0725, Val Loss: 7.9024, Val F1 (weighted): 0.3635, Micro: 0.5267, Macro: 0.2276 (Best Weighted F1 so far: 0.3635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.0905, Val Loss: 7.2324, Val F1 (weighted): 0.3637, Micro: 0.5269, Macro: 0.3345 (Best Weighted F1 so far: 0.3637)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.1069, Val Loss: 6.4211, Val F1 (weighted): 0.3681, Micro: 0.5290, Macro: 0.3610 (Best Weighted F1 so far: 0.3681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 0.0979, Val Loss: 9.5921, Val F1 (weighted): 0.3683, Micro: 0.5291, Macro: 0.3941 (Best Weighted F1 so far: 0.3683)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 0.0900, Val Loss: 7.9985, Val F1 (weighted): 0.3698, Micro: 0.5299, Macro: 0.4069 (Best Weighted F1 so far: 0.3698)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.0680, Val Loss: 13.3746, Val F1 (weighted): 0.3703, Micro: 0.5301, Macro: 0.4113 (Best Weighted F1 so far: 0.3703)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 0.0708, Val Loss: 8.4185, Val F1 (weighted): 0.3720, Micro: 0.5311, Macro: 0.3413 (Best Weighted F1 so far: 0.3720)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 0.1776, Val Loss: 6.3546, Val F1 (weighted): 0.3746, Micro: 0.5324, Macro: 0.3594 (Best Weighted F1 so far: 0.3746)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 0.0869, Val Loss: 8.0784, Val F1 (weighted): 0.3864, Micro: 0.5417, Macro: 0.3434 (Best Weighted F1 so far: 0.3864)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Train Loss: 0.0821, Val Loss: 3.1740, Val F1 (weighted): 0.4360, Micro: 0.5648, Macro: 0.4842 (Best Weighted F1 so far: 0.4360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Train Loss: 0.0410, Val Loss: 3.2273, Val F1 (weighted): 0.6409, Micro: 0.6858, Macro: 0.5912 (Best Weighted F1 so far: 0.6409)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 0.0159, Val Loss: 2.9334, Val F1 (weighted): 0.7203, Micro: 0.7441, Macro: 0.6381 (Best Weighted F1 so far: 0.7203)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 0.0315, Val Loss: 3.4498, Val F1 (weighted): 0.7298, Micro: 0.7529, Macro: 0.6654 (Best Weighted F1 so far: 0.7298)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 0.0148, Val Loss: 2.9972, Val F1 (weighted): 0.8095, Micro: 0.8185, Macro: 0.6768 (Best Weighted F1 so far: 0.8095)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Train Loss: 0.0103, Val Loss: 2.8099, Val F1 (weighted): 0.8453, Micro: 0.8506, Macro: 0.6939 (Best Weighted F1 so far: 0.8453)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 0.0071, Val Loss: 2.7586, Val F1 (weighted): 0.8872, Micro: 0.8897, Macro: 0.7100 (Best Weighted F1 so far: 0.8872)\n",
      "\n",
      "🛑 Early stopping triggered at epoch 32.\n",
      "Fold 3\n",
      "Class weights: tensor([3.8121e-01, 4.4458e-01, 1.3703e+03, 7.9017e+00, 6.7127e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0793, Val Loss: 6.3731, Val F1 (weighted): 0.3624, Micro: 0.5258, Macro: 0.4105 (Best Weighted F1 so far: 0.3624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.1081, Val Loss: 7.0049, Val F1 (weighted): 0.3628, Micro: 0.5259, Macro: 0.4013 (Best Weighted F1 so far: 0.3628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.0795, Val Loss: 8.0798, Val F1 (weighted): 0.3646, Micro: 0.5268, Macro: 0.4282 (Best Weighted F1 so far: 0.3646)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.0787, Val Loss: 10.6805, Val F1 (weighted): 0.3652, Micro: 0.5271, Macro: 0.4312 (Best Weighted F1 so far: 0.3652)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.0841, Val Loss: 12.3572, Val F1 (weighted): 0.3720, Micro: 0.5308, Macro: 0.4724 (Best Weighted F1 so far: 0.3720)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 0.0849, Val Loss: 3.9290, Val F1 (weighted): 0.4389, Micro: 0.5665, Macro: 0.4325 (Best Weighted F1 so far: 0.4389)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 0.0442, Val Loss: 2.8471, Val F1 (weighted): 0.4581, Micro: 0.5728, Macro: 0.4237 (Best Weighted F1 so far: 0.4581)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200, Train Loss: 0.1148, Val Loss: 4.7209, Val F1 (weighted): 0.4874, Micro: 0.5958, Macro: 0.4086 (Best Weighted F1 so far: 0.4874)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200, Train Loss: 0.0669, Val Loss: 1.8539, Val F1 (weighted): 0.4907, Micro: 0.5962, Macro: 0.5229 (Best Weighted F1 so far: 0.4907)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200, Train Loss: 0.0543, Val Loss: 1.7194, Val F1 (weighted): 0.6094, Micro: 0.6653, Macro: 0.5370 (Best Weighted F1 so far: 0.6094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 0.0402, Val Loss: 1.3168, Val F1 (weighted): 0.7412, Micro: 0.7607, Macro: 0.6120 (Best Weighted F1 so far: 0.7412)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Train Loss: 0.0176, Val Loss: 0.8651, Val F1 (weighted): 0.8265, Micro: 0.8335, Macro: 0.6464 (Best Weighted F1 so far: 0.8265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Train Loss: 0.0128, Val Loss: 0.9468, Val F1 (weighted): 0.8350, Micro: 0.8412, Macro: 0.6731 (Best Weighted F1 so far: 0.8350)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Train Loss: 0.0318, Val Loss: 0.5413, Val F1 (weighted): 0.8951, Micro: 0.8971, Macro: 0.6582 (Best Weighted F1 so far: 0.8951)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 0.0312, Val Loss: 0.4336, Val F1 (weighted): 0.9125, Micro: 0.9137, Macro: 0.6694 (Best Weighted F1 so far: 0.9125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 0.0567, Val Loss: 0.3061, Val F1 (weighted): 0.9194, Micro: 0.9204, Macro: 0.7070 (Best Weighted F1 so far: 0.9194)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Train Loss: 0.0131, Val Loss: 0.2256, Val F1 (weighted): 0.9275, Micro: 0.9283, Macro: 0.7141 (Best Weighted F1 so far: 0.9275)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Train Loss: 0.0102, Val Loss: 0.1827, Val F1 (weighted): 0.9463, Micro: 0.9467, Macro: 0.7114 (Best Weighted F1 so far: 0.9463)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200, Train Loss: 0.0094, Val Loss: 0.1417, Val F1 (weighted): 0.9539, Micro: 0.9542, Macro: 0.7091 (Best Weighted F1 so far: 0.9539)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Train Loss: 0.0078, Val Loss: 0.1122, Val F1 (weighted): 0.9662, Micro: 0.9663, Macro: 0.7231 (Best Weighted F1 so far: 0.9662)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Train Loss: 0.0064, Val Loss: 0.1029, Val F1 (weighted): 0.9713, Micro: 0.9714, Macro: 0.7309 (Best Weighted F1 so far: 0.9713)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200, Train Loss: 0.0050, Val Loss: 0.0716, Val F1 (weighted): 0.9791, Micro: 0.9791, Macro: 0.7246 (Best Weighted F1 so far: 0.9791)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200, Train Loss: 0.0168, Val Loss: 0.0604, Val F1 (weighted): 0.9823, Micro: 0.9822, Macro: 0.7116 (Best Weighted F1 so far: 0.9823)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200, Train Loss: 0.0030, Val Loss: 0.0248, Val F1 (weighted): 0.9890, Micro: 0.9890, Macro: 0.7477 (Best Weighted F1 so far: 0.9890)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Train Loss: 0.0023, Val Loss: 0.0058, Val F1 (weighted): 0.9973, Micro: 0.9973, Macro: 0.7430 (Best Weighted F1 so far: 0.9973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200, Train Loss: 0.0011, Val Loss: 0.0030, Val F1 (weighted): 0.9996, Micro: 0.9996, Macro: 0.7541 (Best Weighted F1 so far: 0.9996)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200, Train Loss: 0.0015, Val Loss: 0.0033, Val F1 (weighted): 0.9997, Micro: 0.9997, Macro: 0.7518 (Best Weighted F1 so far: 0.9997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200, Train Loss: 0.0288, Val Loss: 0.0037, Val F1 (weighted): 0.9998, Micro: 0.9997, Macro: 0.7570 (Best Weighted F1 so far: 0.9998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200, Train Loss: 0.0009, Val Loss: 0.0032, Val F1 (weighted): 0.9998, Micro: 0.9998, Macro: 0.7603 (Best Weighted F1 so far: 0.9998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200, Train Loss: 0.0007, Val Loss: 0.0026, Val F1 (weighted): 0.9998, Micro: 0.9998, Macro: 0.7765 (Best Weighted F1 so far: 0.9998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200, Train Loss: 0.0007, Val Loss: 0.0021, Val F1 (weighted): 0.9999, Micro: 0.9998, Macro: 0.7594 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200, Train Loss: 0.0006, Val Loss: 0.0021, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7780 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200, Train Loss: 0.0006, Val Loss: 0.0019, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7780 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200, Train Loss: 0.0005, Val Loss: 0.0019, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7890 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200, Train Loss: 0.0006, Val Loss: 0.0019, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7781 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200, Train Loss: 0.0006, Val Loss: 0.0018, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7794 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200, Train Loss: 0.0005, Val Loss: 0.0018, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7905 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛑 Early stopping triggered at epoch 116.\n",
      "Average F1 Score for drop_out 0.2, learning rate 0.001, hidden_dim 128: 0.9279\n",
      "Testing with learning rate: 0.001, hidden_dim: 128, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([3.8121e-01, 4.4458e-01, 1.9641e+03, 7.8879e+00, 6.7127e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0805, Val Loss: 6.3809, Val F1 (weighted): 0.3628, Micro: 0.5260, Macro: 0.3491 (Best Weighted F1 so far: 0.3628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.0744, Val Loss: 7.6952, Val F1 (weighted): 0.3674, Micro: 0.5282, Macro: 0.3049 (Best Weighted F1 so far: 0.3674)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.0761, Val Loss: 6.9674, Val F1 (weighted): 0.3678, Micro: 0.5284, Macro: 0.2947 (Best Weighted F1 so far: 0.3678)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.0768, Val Loss: 6.3919, Val F1 (weighted): 0.3743, Micro: 0.5323, Macro: 0.2832 (Best Weighted F1 so far: 0.3743)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 0.0840, Val Loss: 4.4419, Val F1 (weighted): 0.3828, Micro: 0.5375, Macro: 0.3805 (Best Weighted F1 so far: 0.3828)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Train Loss: 0.1004, Val Loss: 3.8870, Val F1 (weighted): 0.3833, Micro: 0.5391, Macro: 0.4316 (Best Weighted F1 so far: 0.3833)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Train Loss: 0.0531, Val Loss: 3.2379, Val F1 (weighted): 0.3842, Micro: 0.5399, Macro: 0.5449 (Best Weighted F1 so far: 0.3842)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Train Loss: 0.0423, Val Loss: 3.2177, Val F1 (weighted): 0.3936, Micro: 0.5460, Macro: 0.4914 (Best Weighted F1 so far: 0.3936)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Train Loss: 0.0294, Val Loss: 4.0476, Val F1 (weighted): 0.4075, Micro: 0.5515, Macro: 0.4677 (Best Weighted F1 so far: 0.4075)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 0.0705, Val Loss: 1.2761, Val F1 (weighted): 0.7031, Micro: 0.7305, Macro: 0.5702 (Best Weighted F1 so far: 0.7031)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Train Loss: 0.0374, Val Loss: 1.5034, Val F1 (weighted): 0.7341, Micro: 0.7552, Macro: 0.5126 (Best Weighted F1 so far: 0.7341)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Train Loss: 0.0449, Val Loss: 0.7879, Val F1 (weighted): 0.8805, Micro: 0.8831, Macro: 0.6405 (Best Weighted F1 so far: 0.8805)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Train Loss: 0.0203, Val Loss: 0.7181, Val F1 (weighted): 0.9073, Micro: 0.9087, Macro: 0.7493 (Best Weighted F1 so far: 0.9073)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Train Loss: 0.0105, Val Loss: 0.4558, Val F1 (weighted): 0.9415, Micro: 0.9419, Macro: 0.7578 (Best Weighted F1 so far: 0.9415)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 0.0645, Val Loss: 0.4102, Val F1 (weighted): 0.9579, Micro: 0.9580, Macro: 0.7660 (Best Weighted F1 so far: 0.9579)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Train Loss: 0.0207, Val Loss: 0.4702, Val F1 (weighted): 0.9619, Micro: 0.9620, Macro: 0.9597 (Best Weighted F1 so far: 0.9619)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Train Loss: 0.2149, Val Loss: 0.3910, Val F1 (weighted): 0.9736, Micro: 0.9737, Macro: 0.9370 (Best Weighted F1 so far: 0.9736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Train Loss: 0.0063, Val Loss: 0.4277, Val F1 (weighted): 0.9969, Micro: 0.9969, Macro: 0.7839 (Best Weighted F1 so far: 0.9969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛑 Early stopping triggered at epoch 61.\n",
      "Fold 2\n",
      "Class weights: tensor([3.8133e-01, 4.4439e-01, 2.0408e+03, 7.8912e+00, 6.7165e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0964, Val Loss: 8.4223, Val F1 (weighted): 0.3635, Micro: 0.5267, Macro: 0.2507 (Best Weighted F1 so far: 0.3635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.0719, Val Loss: 7.4429, Val F1 (weighted): 0.3638, Micro: 0.5269, Macro: 0.3473 (Best Weighted F1 so far: 0.3638)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.0926, Val Loss: 11.6666, Val F1 (weighted): 0.3681, Micro: 0.5290, Macro: 0.3770 (Best Weighted F1 so far: 0.3681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 0.0999, Val Loss: 7.1529, Val F1 (weighted): 0.3681, Micro: 0.5290, Macro: 0.3826 (Best Weighted F1 so far: 0.3681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 0.1028, Val Loss: 7.1365, Val F1 (weighted): 0.3681, Micro: 0.5290, Macro: 0.2993 (Best Weighted F1 so far: 0.3681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.0803, Val Loss: 6.5888, Val F1 (weighted): 0.3692, Micro: 0.5294, Macro: 0.2117 (Best Weighted F1 so far: 0.3692)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 0.0700, Val Loss: 11.3142, Val F1 (weighted): 0.3728, Micro: 0.5316, Macro: 0.3497 (Best Weighted F1 so far: 0.3728)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 0.0815, Val Loss: 11.0003, Val F1 (weighted): 0.3747, Micro: 0.5328, Macro: 0.3591 (Best Weighted F1 so far: 0.3747)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Train Loss: 0.1388, Val Loss: 7.5851, Val F1 (weighted): 0.3784, Micro: 0.5351, Macro: 0.4013 (Best Weighted F1 so far: 0.3784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Train Loss: 0.0586, Val Loss: 4.3429, Val F1 (weighted): 0.4710, Micro: 0.5801, Macro: 0.4467 (Best Weighted F1 so far: 0.4710)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Train Loss: 0.0477, Val Loss: 3.4342, Val F1 (weighted): 0.5094, Micro: 0.6030, Macro: 0.5216 (Best Weighted F1 so far: 0.5094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Train Loss: 0.0320, Val Loss: 3.9861, Val F1 (weighted): 0.6400, Micro: 0.6841, Macro: 0.5783 (Best Weighted F1 so far: 0.6400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 0.0527, Val Loss: 3.0734, Val F1 (weighted): 0.7164, Micro: 0.7403, Macro: 0.5743 (Best Weighted F1 so far: 0.7164)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 0.0315, Val Loss: 1.7236, Val F1 (weighted): 0.7671, Micro: 0.7817, Macro: 0.6340 (Best Weighted F1 so far: 0.7671)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Train Loss: 0.0844, Val Loss: 2.4014, Val F1 (weighted): 0.8125, Micro: 0.8211, Macro: 0.6631 (Best Weighted F1 so far: 0.8125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Train Loss: 0.0133, Val Loss: 1.7574, Val F1 (weighted): 0.8819, Micro: 0.8852, Macro: 0.6841 (Best Weighted F1 so far: 0.8819)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Train Loss: 0.0172, Val Loss: 1.8068, Val F1 (weighted): 0.9079, Micro: 0.9099, Macro: 0.7036 (Best Weighted F1 so far: 0.9079)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 0.0088, Val Loss: 1.7986, Val F1 (weighted): 0.9330, Micro: 0.9341, Macro: 0.7035 (Best Weighted F1 so far: 0.9330)\n",
      "\n",
      "🛑 Early stopping triggered at epoch 39.\n",
      "Fold 3\n",
      "Class weights: tensor([3.8121e-01, 4.4458e-01, 1.3703e+03, 7.9017e+00, 6.7127e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0800, Val Loss: 9.5246, Val F1 (weighted): 0.3624, Micro: 0.5258, Macro: 0.4056 (Best Weighted F1 so far: 0.3624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.1191, Val Loss: 11.1366, Val F1 (weighted): 0.3626, Micro: 0.5259, Macro: 0.4164 (Best Weighted F1 so far: 0.3626)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.1189, Val Loss: 8.8940, Val F1 (weighted): 0.3637, Micro: 0.5264, Macro: 0.3061 (Best Weighted F1 so far: 0.3637)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 0.0835, Val Loss: 11.0944, Val F1 (weighted): 0.3640, Micro: 0.5265, Macro: 0.4175 (Best Weighted F1 so far: 0.3640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 0.0816, Val Loss: 10.4342, Val F1 (weighted): 0.3666, Micro: 0.5278, Macro: 0.3862 (Best Weighted F1 so far: 0.3666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.0698, Val Loss: 6.8510, Val F1 (weighted): 0.3773, Micro: 0.5331, Macro: 0.4130 (Best Weighted F1 so far: 0.3773)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 0.0839, Val Loss: 5.0850, Val F1 (weighted): 0.3841, Micro: 0.5388, Macro: 0.3977 (Best Weighted F1 so far: 0.3841)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 0.0666, Val Loss: 5.0141, Val F1 (weighted): 0.3871, Micro: 0.5418, Macro: 0.4561 (Best Weighted F1 so far: 0.3871)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 0.0603, Val Loss: 4.2244, Val F1 (weighted): 0.3898, Micro: 0.5442, Macro: 0.5249 (Best Weighted F1 so far: 0.3898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Train Loss: 0.0866, Val Loss: 3.6812, Val F1 (weighted): 0.4639, Micro: 0.5801, Macro: 0.4587 (Best Weighted F1 so far: 0.4639)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 0.1024, Val Loss: 0.6954, Val F1 (weighted): 0.8040, Micro: 0.8116, Macro: 0.5131 (Best Weighted F1 so far: 0.8040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 0.0378, Val Loss: 0.8340, Val F1 (weighted): 0.8072, Micro: 0.8154, Macro: 0.5202 (Best Weighted F1 so far: 0.8072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 0.1657, Val Loss: 0.3678, Val F1 (weighted): 0.9491, Micro: 0.9493, Macro: 0.7598 (Best Weighted F1 so far: 0.9491)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Train Loss: 0.0802, Val Loss: 0.2715, Val F1 (weighted): 0.9497, Micro: 0.9500, Macro: 0.7279 (Best Weighted F1 so far: 0.9497)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Train Loss: 0.0155, Val Loss: 0.1656, Val F1 (weighted): 0.9596, Micro: 0.9598, Macro: 0.7362 (Best Weighted F1 so far: 0.9596)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200, Train Loss: 0.0408, Val Loss: 0.2160, Val F1 (weighted): 0.9639, Micro: 0.9643, Macro: 0.7382 (Best Weighted F1 so far: 0.9639)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Train Loss: 0.0159, Val Loss: 0.0559, Val F1 (weighted): 0.9818, Micro: 0.9819, Macro: 0.7577 (Best Weighted F1 so far: 0.9818)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200, Train Loss: 0.0068, Val Loss: 0.0425, Val F1 (weighted): 0.9914, Micro: 0.9914, Macro: 0.7339 (Best Weighted F1 so far: 0.9914)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200, Train Loss: 0.0035, Val Loss: 0.0420, Val F1 (weighted): 0.9930, Micro: 0.9930, Macro: 0.7328 (Best Weighted F1 so far: 0.9930)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200, Train Loss: 0.0029, Val Loss: 0.0198, Val F1 (weighted): 0.9959, Micro: 0.9959, Macro: 0.7500 (Best Weighted F1 so far: 0.9959)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200, Train Loss: 0.0201, Val Loss: 0.0151, Val F1 (weighted): 0.9972, Micro: 0.9972, Macro: 0.7842 (Best Weighted F1 so far: 0.9972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200, Train Loss: 0.0029, Val Loss: 0.0083, Val F1 (weighted): 0.9973, Micro: 0.9973, Macro: 0.7581 (Best Weighted F1 so far: 0.9973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200, Train Loss: 0.0010, Val Loss: 0.0037, Val F1 (weighted): 0.9984, Micro: 0.9983, Macro: 0.7589 (Best Weighted F1 so far: 0.9984)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200, Train Loss: 0.0066, Val Loss: 0.0029, Val F1 (weighted): 0.9998, Micro: 0.9998, Macro: 0.7515 (Best Weighted F1 so far: 0.9998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200, Train Loss: 0.0012, Val Loss: 0.0025, Val F1 (weighted): 0.9999, Micro: 0.9998, Macro: 0.7890 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200, Train Loss: 0.0011, Val Loss: 0.0018, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7892 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛑 Early stopping triggered at epoch 112.\n",
      "Average F1 Score for drop_out 0.3, learning rate 0.001, hidden_dim 128: 0.9766\n",
      "Testing with learning rate: 0.001, hidden_dim: 128, drop_out: 0.4\n",
      "Fold 1\n",
      "Class weights: tensor([3.8121e-01, 4.4458e-01, 1.9641e+03, 7.8879e+00, 6.7127e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0725, Val Loss: 7.8303, Val F1 (weighted): 0.3628, Micro: 0.5260, Macro: 0.3504 (Best Weighted F1 so far: 0.3628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.1021, Val Loss: 9.0508, Val F1 (weighted): 0.3644, Micro: 0.5267, Macro: 0.2950 (Best Weighted F1 so far: 0.3644)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.0895, Val Loss: 7.1913, Val F1 (weighted): 0.3674, Micro: 0.5282, Macro: 0.3493 (Best Weighted F1 so far: 0.3674)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 0.0968, Val Loss: 5.5726, Val F1 (weighted): 0.3688, Micro: 0.5289, Macro: 0.3959 (Best Weighted F1 so far: 0.3688)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.0867, Val Loss: 13.9469, Val F1 (weighted): 0.3690, Micro: 0.5291, Macro: 0.2830 (Best Weighted F1 so far: 0.3690)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.1008, Val Loss: 7.6943, Val F1 (weighted): 0.3797, Micro: 0.5357, Macro: 0.5300 (Best Weighted F1 so far: 0.3797)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 0.0596, Val Loss: 4.8548, Val F1 (weighted): 0.3823, Micro: 0.5382, Macro: 0.4121 (Best Weighted F1 so far: 0.3823)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Train Loss: 0.0640, Val Loss: 3.1411, Val F1 (weighted): 0.3880, Micro: 0.5417, Macro: 0.4674 (Best Weighted F1 so far: 0.3880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Train Loss: 0.0436, Val Loss: 2.3934, Val F1 (weighted): 0.4417, Micro: 0.5682, Macro: 0.4715 (Best Weighted F1 so far: 0.4417)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Train Loss: 0.0540, Val Loss: 5.9991, Val F1 (weighted): 0.5427, Micro: 0.6196, Macro: 0.4302 (Best Weighted F1 so far: 0.5427)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 0.0283, Val Loss: 1.0581, Val F1 (weighted): 0.7071, Micro: 0.7335, Macro: 0.5891 (Best Weighted F1 so far: 0.7071)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 0.0256, Val Loss: 0.7611, Val F1 (weighted): 0.8162, Micro: 0.8242, Macro: 0.6792 (Best Weighted F1 so far: 0.8162)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 0.0153, Val Loss: 0.7217, Val F1 (weighted): 0.8591, Micro: 0.8634, Macro: 0.6564 (Best Weighted F1 so far: 0.8591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 0.0308, Val Loss: 0.6799, Val F1 (weighted): 0.8922, Micro: 0.8943, Macro: 0.7402 (Best Weighted F1 so far: 0.8922)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Train Loss: 0.0166, Val Loss: 0.4141, Val F1 (weighted): 0.9498, Micro: 0.9500, Macro: 0.7648 (Best Weighted F1 so far: 0.9498)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 0.0344, Val Loss: 0.3830, Val F1 (weighted): 0.9526, Micro: 0.9528, Macro: 0.7561 (Best Weighted F1 so far: 0.9526)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Train Loss: 0.0359, Val Loss: 0.3599, Val F1 (weighted): 0.9677, Micro: 0.9677, Macro: 0.7652 (Best Weighted F1 so far: 0.9677)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200, Train Loss: 0.0029, Val Loss: 0.3215, Val F1 (weighted): 0.9911, Micro: 0.9912, Macro: 0.7679 (Best Weighted F1 so far: 0.9911)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200, Train Loss: 0.0048, Val Loss: 0.2836, Val F1 (weighted): 0.9922, Micro: 0.9921, Macro: 0.7765 (Best Weighted F1 so far: 0.9922)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200, Train Loss: 0.0024, Val Loss: 0.2962, Val F1 (weighted): 0.9934, Micro: 0.9934, Macro: 0.7812 (Best Weighted F1 so far: 0.9934)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200, Train Loss: 0.0020, Val Loss: 0.2940, Val F1 (weighted): 0.9936, Micro: 0.9936, Macro: 0.7767 (Best Weighted F1 so far: 0.9936)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200, Train Loss: 0.0027, Val Loss: 0.2582, Val F1 (weighted): 0.9975, Micro: 0.9974, Macro: 0.7836 (Best Weighted F1 so far: 0.9975)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200, Train Loss: 0.0015, Val Loss: 0.2597, Val F1 (weighted): 0.9976, Micro: 0.9975, Macro: 0.7848 (Best Weighted F1 so far: 0.9976)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200, Train Loss: 0.0464, Val Loss: 0.2922, Val F1 (weighted): 0.9977, Micro: 0.9977, Macro: 0.9739 (Best Weighted F1 so far: 0.9977)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200, Train Loss: 0.0022, Val Loss: 0.2717, Val F1 (weighted): 0.9998, Micro: 0.9998, Macro: 0.9760 (Best Weighted F1 so far: 0.9998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200, Train Loss: 0.0012, Val Loss: 0.2724, Val F1 (weighted): 0.9998, Micro: 0.9998, Macro: 0.9830 (Best Weighted F1 so far: 0.9998)\n",
      "\n",
      "🛑 Early stopping triggered at epoch 74.\n",
      "Fold 2\n",
      "Class weights: tensor([3.8133e-01, 4.4439e-01, 2.0408e+03, 7.8912e+00, 6.7165e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0989, Val Loss: 8.5779, Val F1 (weighted): 0.3637, Micro: 0.5269, Macro: 0.3449 (Best Weighted F1 so far: 0.3637)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.0877, Val Loss: 8.1178, Val F1 (weighted): 0.3655, Micro: 0.5277, Macro: 0.2446 (Best Weighted F1 so far: 0.3655)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 0.0984, Val Loss: 9.8003, Val F1 (weighted): 0.3683, Micro: 0.5291, Macro: 0.3872 (Best Weighted F1 so far: 0.3683)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 0.0791, Val Loss: 11.9740, Val F1 (weighted): 0.3717, Micro: 0.5310, Macro: 0.4309 (Best Weighted F1 so far: 0.3717)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 0.0902, Val Loss: 8.3113, Val F1 (weighted): 0.3730, Micro: 0.5318, Macro: 0.3556 (Best Weighted F1 so far: 0.3730)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 0.1236, Val Loss: 3.5983, Val F1 (weighted): 0.5491, Micro: 0.6238, Macro: 0.5295 (Best Weighted F1 so far: 0.5491)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Train Loss: 0.0734, Val Loss: 2.3890, Val F1 (weighted): 0.8116, Micro: 0.8197, Macro: 0.6623 (Best Weighted F1 so far: 0.8116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 0.0266, Val Loss: 3.5343, Val F1 (weighted): 0.8375, Micro: 0.8433, Macro: 0.6905 (Best Weighted F1 so far: 0.8375)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Train Loss: 0.0331, Val Loss: 3.9227, Val F1 (weighted): 0.8541, Micro: 0.8588, Macro: 0.6908 (Best Weighted F1 so far: 0.8541)\n",
      "\n",
      "🛑 Early stopping triggered at epoch 33.\n",
      "Fold 3\n",
      "Class weights: tensor([3.8121e-01, 4.4458e-01, 1.3703e+03, 7.9017e+00, 6.7127e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0740, Val Loss: 7.4259, Val F1 (weighted): 0.3624, Micro: 0.5258, Macro: 0.4079 (Best Weighted F1 so far: 0.3624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.1106, Val Loss: 7.9148, Val F1 (weighted): 0.3627, Micro: 0.5259, Macro: 0.4094 (Best Weighted F1 so far: 0.3627)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.1002, Val Loss: 13.3753, Val F1 (weighted): 0.3644, Micro: 0.5266, Macro: 0.2776 (Best Weighted F1 so far: 0.3644)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.0506, Val Loss: 7.2185, Val F1 (weighted): 0.3709, Micro: 0.5301, Macro: 0.4694 (Best Weighted F1 so far: 0.3709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.0941, Val Loss: 6.5058, Val F1 (weighted): 0.3725, Micro: 0.5311, Macro: 0.4605 (Best Weighted F1 so far: 0.3725)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 0.0672, Val Loss: 9.9955, Val F1 (weighted): 0.3784, Micro: 0.5352, Macro: 0.4049 (Best Weighted F1 so far: 0.3784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 0.1017, Val Loss: 9.6225, Val F1 (weighted): 0.3810, Micro: 0.5371, Macro: 0.2905 (Best Weighted F1 so far: 0.3810)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 0.1147, Val Loss: 4.6009, Val F1 (weighted): 0.5241, Micro: 0.6095, Macro: 0.4546 (Best Weighted F1 so far: 0.5241)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Train Loss: 0.0489, Val Loss: 1.4898, Val F1 (weighted): 0.5495, Micro: 0.6288, Macro: 0.5611 (Best Weighted F1 so far: 0.5495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 0.0436, Val Loss: 2.4289, Val F1 (weighted): 0.6141, Micro: 0.6675, Macro: 0.5728 (Best Weighted F1 so far: 0.6141)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Train Loss: 0.0485, Val Loss: 1.8740, Val F1 (weighted): 0.7661, Micro: 0.7809, Macro: 0.6442 (Best Weighted F1 so far: 0.7661)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 0.0265, Val Loss: 1.6126, Val F1 (weighted): 0.8029, Micro: 0.8118, Macro: 0.5223 (Best Weighted F1 so far: 0.8029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Train Loss: 0.0387, Val Loss: 1.2900, Val F1 (weighted): 0.8440, Micro: 0.8496, Macro: 0.7054 (Best Weighted F1 so far: 0.8440)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 0.0260, Val Loss: 0.2606, Val F1 (weighted): 0.9381, Micro: 0.9387, Macro: 0.7369 (Best Weighted F1 so far: 0.9381)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200, Train Loss: 0.0124, Val Loss: 0.3140, Val F1 (weighted): 0.9424, Micro: 0.9429, Macro: 0.7530 (Best Weighted F1 so far: 0.9424)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Train Loss: 0.0422, Val Loss: 0.1129, Val F1 (weighted): 0.9575, Micro: 0.9577, Macro: 0.6911 (Best Weighted F1 so far: 0.9575)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Train Loss: 0.0064, Val Loss: 0.1201, Val F1 (weighted): 0.9647, Micro: 0.9649, Macro: 0.7129 (Best Weighted F1 so far: 0.9647)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200, Train Loss: 0.0185, Val Loss: 0.0568, Val F1 (weighted): 0.9924, Micro: 0.9924, Macro: 0.7695 (Best Weighted F1 so far: 0.9924)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200, Train Loss: 0.0121, Val Loss: 0.0087, Val F1 (weighted): 0.9951, Micro: 0.9950, Macro: 0.7439 (Best Weighted F1 so far: 0.9951)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Train Loss: 0.0026, Val Loss: 0.0050, Val F1 (weighted): 0.9997, Micro: 0.9996, Macro: 0.7697 (Best Weighted F1 so far: 0.9997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200, Train Loss: 0.0018, Val Loss: 0.0029, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7794 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200, Train Loss: 0.0019, Val Loss: 0.0022, Val F1 (weighted): 0.9999, Micro: 0.9999, Macro: 0.7794 (Best Weighted F1 so far: 0.9999)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200, Train Loss: 0.0013, Val Loss: 0.0016, Val F1 (weighted): 1.0000, Micro: 0.9999, Macro: 0.7796 (Best Weighted F1 so far: 1.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛑 Early stopping triggered at epoch 94.\n",
      "Average F1 Score for drop_out 0.4, learning rate 0.001, hidden_dim 128: 0.9513\n",
      "Testing with learning rate: 0.001, hidden_dim: 256, drop_out: 0.2\n",
      "Fold 1\n",
      "Class weights: tensor([3.8121e-01, 4.4458e-01, 1.9641e+03, 7.8879e+00, 6.7127e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0746, Val Loss: 10.1395, Val F1 (weighted): 0.3628, Micro: 0.5260, Macro: 0.3490 (Best Weighted F1 so far: 0.3628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.1109, Val Loss: 10.3683, Val F1 (weighted): 0.3676, Micro: 0.5283, Macro: 0.3908 (Best Weighted F1 so far: 0.3676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 0.1143, Val Loss: 9.2022, Val F1 (weighted): 0.3678, Micro: 0.5284, Macro: 0.3418 (Best Weighted F1 so far: 0.3678)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.1895, Val Loss: 12.8389, Val F1 (weighted): 0.3682, Micro: 0.5286, Macro: 0.4072 (Best Weighted F1 so far: 0.3682)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 0.1527, Val Loss: 35.6165, Val F1 (weighted): 0.3685, Micro: 0.5285, Macro: 0.2729 (Best Weighted F1 so far: 0.3685)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 0.1773, Val Loss: 11.8581, Val F1 (weighted): 0.3690, Micro: 0.5291, Macro: 0.3379 (Best Weighted F1 so far: 0.3690)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 0.0794, Val Loss: 8.9217, Val F1 (weighted): 0.3732, Micro: 0.5315, Macro: 0.4554 (Best Weighted F1 so far: 0.3732)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Train Loss: 0.1574, Val Loss: 6.3948, Val F1 (weighted): 0.3826, Micro: 0.5385, Macro: 0.4227 (Best Weighted F1 so far: 0.3826)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Train Loss: 0.0668, Val Loss: 5.1803, Val F1 (weighted): 0.3943, Micro: 0.5416, Macro: 0.3483 (Best Weighted F1 so far: 0.3943)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Train Loss: 0.1196, Val Loss: 4.6802, Val F1 (weighted): 0.4229, Micro: 0.5574, Macro: 0.4785 (Best Weighted F1 so far: 0.4229)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 0.1300, Val Loss: 2.2353, Val F1 (weighted): 0.6998, Micro: 0.7270, Macro: 0.5856 (Best Weighted F1 so far: 0.6998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛑 Early stopping triggered at epoch 37.\n",
      "Fold 2\n",
      "Class weights: tensor([3.8133e-01, 4.4439e-01, 2.0408e+03, 7.8912e+00, 6.7165e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0782, Val Loss: 7.8201, Val F1 (weighted): 0.3638, Micro: 0.5269, Macro: 0.3407 (Best Weighted F1 so far: 0.3638)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.1177, Val Loss: 11.6657, Val F1 (weighted): 0.3681, Micro: 0.5290, Macro: 0.3726 (Best Weighted F1 so far: 0.3681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 0.0871, Val Loss: 5.9098, Val F1 (weighted): 0.3697, Micro: 0.5298, Macro: 0.2865 (Best Weighted F1 so far: 0.3697)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 0.1633, Val Loss: 11.7766, Val F1 (weighted): 0.3710, Micro: 0.5306, Macro: 0.4221 (Best Weighted F1 so far: 0.3710)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 0.1001, Val Loss: 12.1059, Val F1 (weighted): 0.3771, Micro: 0.5343, Macro: 0.3693 (Best Weighted F1 so far: 0.3771)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Train Loss: 0.0541, Val Loss: 7.2757, Val F1 (weighted): 0.3832, Micro: 0.5373, Macro: 0.3668 (Best Weighted F1 so far: 0.3832)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛑 Early stopping triggered at epoch 13.\n",
      "Fold 3\n",
      "Class weights: tensor([3.8121e-01, 4.4458e-01, 1.3703e+03, 7.9017e+00, 6.7127e+03],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.0764, Val Loss: 8.2221, Val F1 (weighted): 0.3624, Micro: 0.5258, Macro: 0.4006 (Best Weighted F1 so far: 0.3624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.0939, Val Loss: 7.2798, Val F1 (weighted): 0.3624, Micro: 0.5258, Macro: 0.4010 (Best Weighted F1 so far: 0.3624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 0.1422, Val Loss: 9.6025, Val F1 (weighted): 0.3628, Micro: 0.5260, Macro: 0.4081 (Best Weighted F1 so far: 0.3628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 0.1361, Val Loss: 7.4962, Val F1 (weighted): 0.3634, Micro: 0.5262, Macro: 0.3166 (Best Weighted F1 so far: 0.3634)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 0.1854, Val Loss: 10.9752, Val F1 (weighted): 0.3651, Micro: 0.5271, Macro: 0.3086 (Best Weighted F1 so far: 0.3651)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 0.1115, Val Loss: 14.6118, Val F1 (weighted): 0.3721, Micro: 0.5309, Macro: 0.4882 (Best Weighted F1 so far: 0.3721)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 0.0712, Val Loss: 5.6908, Val F1 (weighted): 0.3754, Micro: 0.5330, Macro: 0.3978 (Best Weighted F1 so far: 0.3754)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 0.1069, Val Loss: 4.9608, Val F1 (weighted): 0.4889, Micro: 0.5899, Macro: 0.4930 (Best Weighted F1 so far: 0.4889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Train Loss: 0.0736, Val Loss: 2.1771, Val F1 (weighted): 0.5572, Micro: 0.6317, Macro: 0.5652 (Best Weighted F1 so far: 0.5572)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Train Loss: 0.0726, Val Loss: 1.5927, Val F1 (weighted): 0.5945, Micro: 0.6564, Macro: 0.5929 (Best Weighted F1 so far: 0.5945)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Train Loss: 0.0265, Val Loss: 1.1032, Val F1 (weighted): 0.6066, Micro: 0.6631, Macro: 0.4390 (Best Weighted F1 so far: 0.6066)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Train Loss: 0.0261, Val Loss: 1.7609, Val F1 (weighted): 0.6124, Micro: 0.6678, Macro: 0.6011 (Best Weighted F1 so far: 0.6124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Train Loss: 0.0270, Val Loss: 1.0511, Val F1 (weighted): 0.7153, Micro: 0.7401, Macro: 0.6143 (Best Weighted F1 so far: 0.7153)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Train Loss: 0.0194, Val Loss: 1.1647, Val F1 (weighted): 0.8193, Micro: 0.8266, Macro: 0.6727 (Best Weighted F1 so far: 0.8193)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 0.0167, Val Loss: 0.5026, Val F1 (weighted): 0.9138, Micro: 0.9150, Macro: 0.6955 (Best Weighted F1 so far: 0.9138)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200, Train Loss: 0.0127, Val Loss: 0.2805, Val F1 (weighted): 0.9233, Micro: 0.9242, Macro: 0.7324 (Best Weighted F1 so far: 0.9233)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 0.0078, Val Loss: 0.1577, Val F1 (weighted): 0.9584, Micro: 0.9586, Macro: 0.7616 (Best Weighted F1 so far: 0.9584)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Train Loss: 0.0086, Val Loss: 0.1222, Val F1 (weighted): 0.9614, Micro: 0.9617, Macro: 0.7341 (Best Weighted F1 so far: 0.9614)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Train Loss: 0.0110, Val Loss: 0.1613, Val F1 (weighted): 0.9657, Micro: 0.9657, Macro: 0.7148 (Best Weighted F1 so far: 0.9657)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 1042/1768 [00:05<00:03, 200.93it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def grid_search(graph_dataset, patience, max_epochs, learning_rates, hidden_dims, drop_outs, folds=3):\n",
    "    global num_features\n",
    "    \n",
    "    best_params = {}\n",
    "    best_f1 = 0\n",
    "    params_results = {}\n",
    "\n",
    "    # Precompute the train and validation graphs for all folds\n",
    "    folds_list = []\n",
    "    for i in range(folds):\n",
    "        train_graph_dataset, val_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=i)\n",
    "        folds_list.append((train_graph_dataset, val_graph_dataset))\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            for drop_out in drop_outs:\n",
    "                print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}, drop_out: {drop_out}\")\n",
    "                fold_f1_scores = []\n",
    "\n",
    "                for fold, (train_graph_dataset, val_graph_dataset) in enumerate(folds_list):\n",
    "                    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                    model = EGraphSAGE(node_in_channels=num_features,\n",
    "                                    edge_in_channels=num_features,\n",
    "                                    hidden_channels=hidden_dim,\n",
    "                                    dropout = drop_out,\n",
    "                                    out_channels=num_classes).to(device)\n",
    "\n",
    "                    model.apply(init_weights)\n",
    "\n",
    "                    # Normalize to stabilize training\n",
    "                    class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "                    print(\"Class weights:\", class_weights)\n",
    "\n",
    "                    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                    optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "                    scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                        optimizer,\n",
    "                        mode='min',\n",
    "                        factor=0.6,\n",
    "                        patience=5,\n",
    "                        min_lr=1e-6,\n",
    "                    )\n",
    "\n",
    "                    best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "                    best_val_loss = float('inf')  # Track the best val_loss for this fold\n",
    "                    patience_counter = 0\n",
    "\n",
    "                    for epoch in range(max_epochs):\n",
    "                        try:\n",
    "                            train_loss = 0\n",
    "                            val_loss = 0\n",
    "                            num_train_graphs = len(train_graph_dataset)\n",
    "                            num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "                            model.train()\n",
    "                            for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "                                optimizer.zero_grad()\n",
    "\n",
    "                                G_pyg_train = G_pyg_train.to(device)\n",
    "                                G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                                G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "                                \n",
    "                                out = model(G_pyg_train)\n",
    "                                loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                                train_loss += loss.item()\n",
    "\n",
    "                                loss.backward()\n",
    "\n",
    "                                optimizer.step()\n",
    "                            \n",
    "\n",
    "                            test_label_list = []\n",
    "                            pred_label_list = []\n",
    "\n",
    "                            model.eval()\n",
    "                            with th.no_grad():\n",
    "                                for G_pyg_val in tqdm(val_graph_dataset, desc=\"Validation\", leave=False):\n",
    "\n",
    "                                    G_pyg_val = G_pyg_val.to(device)\n",
    "                                    G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                                    G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                                    out = model(G_pyg_val)\n",
    "                                    loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                                    val_loss += loss.item()\n",
    "\n",
    "                                    test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                                    pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "                            test_label = th.cat(test_label_list)\n",
    "                            pred_label = th.cat(pred_label_list)\n",
    "\n",
    "                            val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "                            val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "                            val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "                            # Schedule step\n",
    "                            scheduler.step(val_loss)\n",
    "\n",
    "                            if val_f1 > best_epoch_f1:\n",
    "                                best_epoch_f1 = val_f1\n",
    "                                print(f\"Epoch {epoch}/{max_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                                f\"Val F1 (weighted): {val_f1:.4f}, Micro: {val_f1_micro:.4f}, Macro: {val_f1_macro:.4f} \"\n",
    "                                f\"(Best Weighted F1 so far: {best_epoch_f1:.4f})\")\n",
    "\n",
    "                            # Early stopping condition\n",
    "                            if val_loss < best_val_loss:\n",
    "                                best_val_loss = val_loss\n",
    "                                patience_counter = 0\n",
    "                            else:\n",
    "                                patience_counter += 1\n",
    "\n",
    "                            if patience_counter >= patience:\n",
    "                                print(f\"\\n🛑 Early stopping triggered at epoch {epoch}.\")\n",
    "                                break\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                            break\n",
    "\n",
    "                    fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "                \n",
    "                avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "                params_results[(drop_out, lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "                print(f\"Average F1 Score for drop_out {drop_out}, learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "                if avg_f1 > best_f1:\n",
    "                    best_f1 = avg_f1\n",
    "                    best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim, 'drop_out': drop_out}\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "    print(\"All results:\", params_results)\n",
    "\n",
    "# grid_search(\n",
    "#     full_train_graph_dataset, \n",
    "#     patience=10,\n",
    "#     max_epochs=200,\n",
    "#     learning_rates=[0.001, 0.005, 0.01, 0.05], \n",
    "#     hidden_dims=[128, 256, 512], \n",
    "#     drop_outs=[0.2, 0.3, 0.4],\n",
    "#     folds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph_dataset, val_graph_dataset = full_train_graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint():\n",
    "    global epoch, model, optimizer, scheduler, train_loss_history, val_loss_history, val_f1_history, saved_model_epochs, best_f1, patience_counter, best_val_loss, train_ended, max_epochs, patience\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss_history': train_loss_history,\n",
    "        'val_loss_history': val_loss_history,\n",
    "        'val_f1_history': val_f1_history,\n",
    "        'saved_model_epochs': saved_model_epochs,\n",
    "        'best_f1': best_f1,\n",
    "        'patience_counter': patience_counter,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'train_ended': train_ended,\n",
    "        'max_epochs': max_epochs,\n",
    "        'patience': patience\n",
    "    }\n",
    "    \n",
    "    th.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_graph_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m max_epochs = \u001b[32m200\u001b[39m\n\u001b[32m      9\u001b[39m patience = \u001b[32m20\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNumber of train graphs: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_graph_dataset\u001b[49m))\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Initialize the model with the best parameters\u001b[39;00m\n\u001b[32m     14\u001b[39m model = EGraphSAGE(node_in_channels=num_features, \n\u001b[32m     15\u001b[39m                    edge_in_channels=num_features,\n\u001b[32m     16\u001b[39m                    hidden_channels=best_hidden_dim,\n\u001b[32m     17\u001b[39m                    dropout = best_drop_out,\n\u001b[32m     18\u001b[39m                    out_channels=num_classes).to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_graph_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Best parameters from the grid search\n",
    "best_hidden_dim = 256  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.01  # Replace with the best learning_rate found\n",
    "best_drop_out = 0.3  # Replace with the best drop_out found\n",
    "\n",
    "max_epochs = 200\n",
    "patience = 10\n",
    "\n",
    "print(\"Number of train graphs: \", len(train_graph_dataset))\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "model = EGraphSAGE(node_in_channels=num_features, \n",
    "                   edge_in_channels=num_features,\n",
    "                   hidden_channels=best_hidden_dim,\n",
    "                   dropout = best_drop_out,\n",
    "                   out_channels=num_classes).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Normalize class weights\n",
    "class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.6,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "# ===== Load checkpoint if exists =====\n",
    "start_epoch = 0\n",
    "best_f1 = 0\n",
    "\n",
    "patience_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "train_ended = False\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "val_f1_history = []\n",
    "saved_model_epochs = []\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    train_ended = checkpoint['train_ended']\n",
    "    best_f1 = checkpoint['best_f1']\n",
    "\n",
    "    assert max_epochs == checkpoint['max_epochs'], \"Checkpoint max_epochs does not match the current setting.\"\n",
    "    assert patience == checkpoint['patience'], \"Checkpoint patience does not match the current setting.\"\n",
    "\n",
    "    patience_counter = checkpoint['patience_counter']\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    val_loss_history = checkpoint['val_loss_history']\n",
    "    val_f1_history = checkpoint['val_f1_history']\n",
    "    saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "if train_ended:\n",
    "    model.load_state_dict(th.load(best_model_path))\n",
    "    print(\"Training has already ended. Loaded the best model state.\")\n",
    "    print(\"Training history loaded successfully.\")\n",
    "\n",
    "else:\n",
    "    # ===== Start Training =====\n",
    "    num_train_graphs = len(train_graph_dataset)\n",
    "    num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "    for epoch in range(start_epoch, max_epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move the graph data to the device\n",
    "            G_pyg_train = G_pyg_train.to(device)\n",
    "            G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "            G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "            out = model(G_pyg_train)\n",
    "            loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        test_label_list = []\n",
    "        pred_label_list = []\n",
    "\n",
    "        model.eval()\n",
    "        with th.no_grad():\n",
    "            for G_pyg_val in tqdm(val_graph_dataset, desc=\"Evaluation\", leave=False):\n",
    "                G_pyg_val = G_pyg_val.to(device)\n",
    "                G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                out = model(G_pyg_val)\n",
    "                loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "        test_label = th.cat(test_label_list)\n",
    "        pred_label = th.cat(pred_label_list)\n",
    "\n",
    "        val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "        val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "        val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "        \n",
    "        train_loss_history.append(train_loss)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_f1_history.append((val_f1, val_f1_micro, val_f1_macro))\n",
    "\n",
    "        # Schedule step\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1  # Update the best F1 score for this fold\n",
    "            best_model_state = model.state_dict()\n",
    "            saved_model_epochs.append(epoch)\n",
    "\n",
    "            save_checkpoint()\n",
    "            th.save(best_model_state, best_model_path)\n",
    "            print(f\"Epoch {epoch} Saved best model. Best F1:\", best_f1)\n",
    "\n",
    "        print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}, Validation F1 Micro: {val_f1_micro:.4f}, Validation F1 Macro: {val_f1_macro:.4f}')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            save_checkpoint()\n",
    "\n",
    "        # Early stopping condition\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n🛑 Early stopping triggered at epoch {epoch}.\")\n",
    "            train_ended = True\n",
    "            break\n",
    "\n",
    "    # Save the trained model\n",
    "    train_ended = True\n",
    "    save_checkpoint()\n",
    "    print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_process(train_losses, val_losses, val_f1, saved_model_epochs):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Plot Train Loss\n",
    "    axs[0].plot(train_losses, label='Train Loss', color='blue')\n",
    "    axs[0].plot(val_losses, label='Validation Loss', color='red')\n",
    "    axs[0].set_ylabel('Train Loss')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    val_f1_weighted_history = []\n",
    "    val_f1_micro_history = []\n",
    "    val_f1_macro_history = []\n",
    "\n",
    "    for val_f1_weighted, val_f1_micro, val_f1_macro in val_f1:\n",
    "        val_f1_weighted_history.append(val_f1_weighted)\n",
    "        val_f1_micro_history.append(val_f1_micro)\n",
    "        val_f1_macro_history.append(val_f1_macro)\n",
    "    \n",
    "    # Plot Validation F1\n",
    "\n",
    "    axs[1].plot(val_f1_weighted_history, label='Validation F1 Weighted', color='green')\n",
    "    axs[1].plot(val_f1_micro_history, label='Validation F1 Micro', color='blue')\n",
    "    axs[1].plot(val_f1_macro_history, label='Validation F1 Macro', color='red')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Validation F1')\n",
    "    axs[1].set_title('Validation F1 Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    # Add scatter for saved model epochs (e.g., F1 weighted here)\n",
    "    axs[1].scatter(saved_model_epochs, [val_f1_weighted_history[i] for i in saved_model_epochs],\n",
    "                   color='black', marker='o', label='Saved Model')\n",
    "    axs[1].legend()\n",
    "\n",
    "    print(len(train_losses))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_process(train_loss_history, val_loss_history, val_f1_history, saved_model_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or Load test_graph_dataset\n",
    "if os.path.exists(os.path.join(graph_datasets_path, \"test_graph_dataset.pth\")):  \n",
    "    test_graph_dataset = th.load(os.path.join(graph_datasets_path, \"test_graph_dataset.pth\"))\n",
    "else:       \n",
    "    th.save(test_graph_dataset, os.path.join(graph_datasets_path, \"test_graph_dataset.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average, Min, and Max Degrees Across All Graphs:\n",
      "  Attack Class ['DDoS']:\n",
      "    Avg Out-Degree (src): 1.0018 | Min: 1 | Max: 244\n",
      "    Avg In-Degree (dst): 402.3860 | Min: 1 | Max: 1500\n",
      "  Attack Class ['DoS']:\n",
      "    Avg Out-Degree (src): 1.0003 | Min: 1 | Max: 192\n",
      "    Avg In-Degree (dst): 385.4847 | Min: 1 | Max: 1500\n",
      "  Attack Class ['Normal']:\n",
      "    Avg Out-Degree (src): 1.0370 | Min: 1 | Max: 4\n",
      "    Avg In-Degree (dst): 1.7732 | Min: 1 | Max: 20\n",
      "  Attack Class ['Reconnaissance']:\n",
      "    Avg Out-Degree (src): 4.2623 | Min: 1 | Max: 1025\n",
      "    Avg In-Degree (dst): 1.6132 | Min: 1 | Max: 1495\n",
      "  Attack Class ['Theft']:\n",
      "    Avg Out-Degree (src): 1.0128 | Min: 1 | Max: 2\n",
      "    Avg In-Degree (dst): 11.2857 | Min: 1 | Max: 26\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import degree\n",
    "from collections import defaultdict\n",
    "\n",
    "def check_global_avg_degrees_per_class(graph_dataset):\n",
    "    # Dictionaries to hold total degree sums and counts per class\n",
    "    total_out_deg = defaultdict(float)\n",
    "    total_in_deg = defaultdict(float)\n",
    "    count_out_nodes = defaultdict(int)\n",
    "    count_in_nodes = defaultdict(int)\n",
    "    min_out_deg = defaultdict(lambda: float('inf'))\n",
    "    max_out_deg = defaultdict(lambda: float('-inf'))\n",
    "    min_in_deg = defaultdict(lambda: float('inf'))\n",
    "    max_in_deg = defaultdict(lambda: float('-inf'))\n",
    "\n",
    "    for graph in graph_dataset:\n",
    "        edge_index = graph.edge_index\n",
    "        edge_label = graph.edge_label\n",
    "        num_nodes = graph.num_nodes\n",
    "\n",
    "        unique_classes = torch.unique(edge_label)\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            cls = int(cls)\n",
    "            mask = (edge_label == cls)\n",
    "\n",
    "            src_nodes = edge_index[0][mask]\n",
    "            dst_nodes = edge_index[1][mask]\n",
    "\n",
    "            out_deg = degree(src_nodes, num_nodes=num_nodes)\n",
    "            in_deg = degree(dst_nodes, num_nodes=num_nodes)\n",
    "\n",
    "            involved_src = out_deg > 0\n",
    "            involved_dst = in_deg > 0\n",
    "\n",
    "            total_out_deg[cls] += out_deg[involved_src].sum().item()\n",
    "            total_in_deg[cls] += in_deg[involved_dst].sum().item()\n",
    "            count_out_nodes[cls] += involved_src.sum().item()\n",
    "            count_in_nodes[cls] += involved_dst.sum().item()\n",
    "\n",
    "            if involved_src.any():\n",
    "                min_out_deg[cls] = min(min_out_deg[cls], out_deg[involved_src].min().item())\n",
    "                max_out_deg[cls] = max(max_out_deg[cls], out_deg[involved_src].max().item())\n",
    "            if involved_dst.any():\n",
    "                min_in_deg[cls] = min(min_in_deg[cls], in_deg[involved_dst].min().item())\n",
    "                max_in_deg[cls] = max(max_in_deg[cls], in_deg[involved_dst].max().item())\n",
    "\n",
    "    print(\"Average, Min, and Max Degrees Across All Graphs:\")\n",
    "    class_degree_report = {}\n",
    "    for cls in sorted(total_out_deg.keys()):\n",
    "        avg_out = total_out_deg[cls] / count_out_nodes[cls] if count_out_nodes[cls] > 0 else 0.0\n",
    "        avg_in = total_in_deg[cls] / count_in_nodes[cls] if count_in_nodes[cls] > 0 else 0.0\n",
    "        min_out = min_out_deg[cls] if min_out_deg[cls] != float('inf') else 0.0\n",
    "        max_out = max_out_deg[cls] if max_out_deg[cls] != float('-inf') else 0.0\n",
    "        min_in = min_in_deg[cls] if min_in_deg[cls] != float('inf') else 0.0\n",
    "        max_in = max_in_deg[cls] if max_in_deg[cls] != float('-inf') else 0.0\n",
    "\n",
    "        print(f\"  Attack Class {le.inverse_transform([cls])}:\")\n",
    "        print(f\"    Avg Out-Degree (src): {avg_out:.4f} | Min: {min_out:.0f} | Max: {max_out:.0f}\")\n",
    "        print(f\"    Avg In-Degree (dst): {avg_in:.4f} | Min: {min_in:.0f} | Max: {max_in:.0f}\")\n",
    "\n",
    "        class_degree_report[le.inverse_transform([cls])[0]] = {\n",
    "            \"avg_out\": avg_out,\n",
    "            \"min_out\": min_out,\n",
    "            \"max_out\": max_out,\n",
    "            \"avg_in\": avg_in,\n",
    "            \"min_in\": min_in,\n",
    "            \"max_in\": max_in\n",
    "        }\n",
    "\n",
    "    # \n",
    "    return class_degree_report\n",
    "\n",
    "class_degree_report = check_global_avg_degrees_per_class(test_graph_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test graphs:  366\n",
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/BoT_IoT/strat_window_combined_port/best_model_all_raw.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  15%|█▍        | 54/366 [00:00<00:00, 535.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9968\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[287994   1500      3      3      0]\n",
      " [     0 247436      2      3      0]\n",
      " [     0      0     28      0      0]\n",
      " [    79    156     25  11764      7]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9997    0.9948    0.9973    289500\n",
      "           DoS     0.9934    1.0000    0.9967    247441\n",
      "        Normal     0.4828    1.0000    0.6512        28\n",
      "Reconnaissance     0.9995    0.9778    0.9885     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9968    549000\n",
      "     macro avg     0.6951    0.7945    0.7267    549000\n",
      "  weighted avg     0.9968    0.9968    0.9968    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(dataset, adversarial=False):\n",
    "\n",
    "    best_model = EGraphSAGE(node_in_channels=num_features, \n",
    "                       edge_in_channels=num_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=num_classes).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path))\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "        all_pred_logits = []\n",
    "        all_test_labels = []\n",
    "        for G_pyg in tqdm(dataset, desc=\"Evaluation\", leave=False):\n",
    "            try:\n",
    "                # Move the graph data to the device\n",
    "                G_pyg = G_pyg.to(device)\n",
    "                G_pyg.edge_label = G_pyg.edge_label.to(device)\n",
    "                G_pyg.edge_attr = G_pyg.edge_attr.to(device)\n",
    "                out = best_model(G_pyg)\n",
    "                \n",
    "            except Exception as forward_error:\n",
    "                print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "            all_pred_logits.append(out.cpu())\n",
    "            all_test_labels.append(G_pyg.edge_label.cpu())\n",
    "\n",
    "        all_pred_logits = th.cat(all_pred_logits).to(device)\n",
    "        all_test_labels = th.cat(all_test_labels).to(device)\n",
    "        test_accuracy = compute_accuracy(all_pred_logits, all_test_labels)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "        pred_labels = all_pred_logits.argmax(dim=1).cpu()\n",
    "        all_test_labels = all_test_labels.cpu()\n",
    "    \n",
    "    if adversarial:\n",
    "\n",
    "        # Create a boolean mask where the label is NOT equal to the adversarial class\n",
    "        adversarial_mask = all_test_labels == ADVERSARIAL_CLASS_LABEL\n",
    "\n",
    "        # Print the class that the adversarial samples are classified as\n",
    "        cm_adversarial = confusion_matrix(all_test_labels[adversarial_mask], pred_labels[adversarial_mask], labels=range(len(class_map) + 1))\n",
    "        print(\"Adversarial confusion matrix:\", cm_adversarial)\n",
    "\n",
    "        # Apply the mask to both labels and predictions\n",
    "        all_test_labels = all_test_labels[~adversarial_mask]\n",
    "        pred_labels = pred_labels[~adversarial_mask]\n",
    "\n",
    "    print(\"class_map\", class_map)\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map)))\n",
    "    print(cm)\n",
    "\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4)\n",
    "    print(report)\n",
    "    \n",
    "    return classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, output_dict=True)\n",
    "\n",
    "\n",
    "print(\"Number of test graphs: \", len(test_graph_dataset))\n",
    "normal_report = eval(test_graph_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff736d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_traffic_to_node(graph, ratio=0.1, num_injected_nodes=1, to_node_type='both', random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    # Get all src nodes\n",
    "    if to_node_type == 'src':\n",
    "         to_nodes = edge_index[0]\n",
    "\n",
    "    elif to_node_type == 'dst':\n",
    "         to_nodes = edge_index[1]\n",
    "\n",
    "    elif to_node_type == 'both':\n",
    "         to_nodes = th.cat([edge_index[0], edge_index[1]])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"to_node_type must be 'src', 'dst', or 'both'.\")\n",
    "\n",
    "    original_num_nodes = x.size(0)\n",
    "\n",
    "    new_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "    x = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "    # 4. Inject edges from injected nodes to attacker nodes\n",
    "    num_to_inject = max(1, int(ratio * num_edges))\n",
    "    new_edges = []\n",
    "    new_attrs = []\n",
    "    new_labels = []\n",
    "    \n",
    "    for i in range(num_to_inject):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per iteration\n",
    "        src = rng.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "        dst = rng.choice(to_nodes.tolist())  # to existing nodes\n",
    "\n",
    "        new_edges.append([src, dst])\n",
    "        attr = th.rand(feature_dim)  # random feature for the new edge\n",
    "        new_attrs.append(attr)\n",
    "        new_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    # Create a new empty graph to store the injected edges\n",
    "    new_graph = Data()\n",
    "\n",
    "    # 5. Merge into graph\n",
    "    if new_edges:\n",
    "        new_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "        new_attrs = th.stack(new_attrs)\n",
    "        new_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "        new_graph.edge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "        new_graph.edge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "        new_graph.edge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "        new_graph.x = x\n",
    "\n",
    "    return new_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/BoT_IoT/strat_window_combined_port/best_model_all_raw.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6709\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [  361     4    83 54452     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[287837      0      2   1661      0]\n",
      " [126851 111718    146   8726      0]\n",
      " [     0      0     28      0      0]\n",
      " [  6350    117     12   5545      7]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.6836    0.9943    0.8102    289500\n",
      "           DoS     0.9990    0.4515    0.6219    247441\n",
      "        Normal     0.1489    1.0000    0.2593        28\n",
      "Reconnaissance     0.3480    0.4609    0.3966     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.7379    549000\n",
      "     macro avg     0.4359    0.5813    0.4176    549000\n",
      "  weighted avg     0.8184    0.7379    0.7162    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_both_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='both') for g in test_graph_dataset]\n",
    "inject_both_report = eval(inject_both_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b60cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/BoT_IoT/strat_window_combined_port/best_model_all_raw.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8794\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [29480 22970     2  2448     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[289488      0      3      9      0]\n",
      " [  5646 229779     13  12003      0]\n",
      " [     0      0     28      0      0]\n",
      " [    73    140     14  11797      7]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9806    1.0000    0.9902    289500\n",
      "           DoS     0.9994    0.9286    0.9627    247441\n",
      "        Normal     0.4828    1.0000    0.6512        28\n",
      "Reconnaissance     0.4955    0.9806    0.6583     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9674    549000\n",
      "     macro avg     0.5917    0.7818    0.6525    549000\n",
      "  weighted avg     0.9784    0.9674    0.9705    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_src_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='src') for g in test_graph_dataset]\n",
    "inject_src_report = eval(inject_src_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70287333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_dst_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='dst') for g in test_graph_dataset]\n",
    "inject_dst_report = eval(inject_dst_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579e0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Attribute Perturbation\n",
    "def perturb_edge_attributes(graph, affected_edge_ratio=0.1, perturbation_ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = edge_attr.size(1)\n",
    "\n",
    "    # Randomly select edges to perturb\n",
    "    num_to_perturb = max(1, int(affected_edge_ratio * num_edges))\n",
    "    rng = random.Random(random_seed)\n",
    "    indices_to_perturb = rng.sample(range(num_edges), num_to_perturb)\n",
    "\n",
    "    for idx in indices_to_perturb:\n",
    "        # Perturb the edge attributes by adding noise\n",
    "        noise = th.randn(feature_dim) * perturbation_ratio  # Adjust the scale of noise as needed\n",
    "        edge_attr[idx] += noise\n",
    "\n",
    "    # Create a new graph with perturbed attributes\n",
    "    perturbed_graph = Data(edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label, x=graph.x)\n",
    "\n",
    "    return perturbed_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Attribute Perturbation\n",
    "edge_perturb_graph_dataset = [perturb_edge_attributes(g.cpu(), affected_edge_ratio=1, perturbation_ratio=10) for g in test_graph_dataset]\n",
    "edge_perturb_report = eval(edge_perturb_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject Random Edges\n",
    "def inject_random_edges(graph, ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_nodes = x.size(0)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    new_edge_indices = []\n",
    "    new_edge_attrs = []\n",
    "    new_edge_labels = []\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    num_injected_edges = max(1, int(ratio * num_edges))\n",
    "\n",
    "    for i in range(num_injected_edges):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per edge\n",
    "        src = rng.randint(0, num_nodes - 1)  # Random source node\n",
    "        dst = rng.randint(0, num_nodes - 1)  # Random destination node\n",
    "\n",
    "        new_edge_indices.append([src, dst])\n",
    "        new_edge_attrs.append(th.rand(feature_dim))  # Random feature for the new edge\n",
    "        new_edge_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    if new_edge_indices:\n",
    "        new_edge_indices = th.tensor(new_edge_indices, dtype=th.long).t().contiguous()\n",
    "        new_edge_attrs = th.stack(new_edge_attrs)\n",
    "        new_edge_labels = th.tensor(new_edge_labels, dtype=th.long)\n",
    "\n",
    "        edge_index = th.cat([edge_index, new_edge_indices], dim=1)\n",
    "        edge_attr = th.cat([edge_attr, new_edge_attrs], dim=0)\n",
    "        edge_label = th.cat([edge_label, new_edge_labels], dim=0)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25073bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/BoT_IoT/strat_window_combined_port/best_model_all_raw.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6809\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [ 2269    33    96 52501     1     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[288001      0      3   1496      0]\n",
      " [127293 111563    154   8431      0]\n",
      " [     0      0     24      3      1]\n",
      " [   248    128     13  11635      7]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.6931    0.9948    0.8170    289500\n",
      "           DoS     0.9989    0.4509    0.6213    247441\n",
      "        Normal     0.1237    0.8571    0.2162        28\n",
      "Reconnaissance     0.5395    0.9671    0.6926     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.7490    549000\n",
      "     macro avg     0.4710    0.6540    0.4694    549000\n",
      "  weighted avg     0.8275    0.7490    0.7260    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Random Edges\n",
    "random_edge_graph_dataset = [inject_random_edges(g.cpu(), 0.1) for g in test_graph_dataset]\n",
    "random_edge_report = eval(random_edge_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c66190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_overall_metrics(baseline_report, adversarial_reports):\n",
    "    rows = []   \n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "    for label in class_map + ['macro avg', 'weighted avg',]:\n",
    "        row = {\"Class\": label}\n",
    "        row['support'] = baseline_report[label]['support']\n",
    "        for metric in metrics:\n",
    "            baseline_val = baseline_report[label][metric]\n",
    "            row[f\"Normal_{metric}\"] = baseline_val\n",
    "            for name, report in adversarial_reports.items():\n",
    "                adv_val = report[label][metric]\n",
    "                row[f\"{name}_{metric}\"] = adv_val\n",
    "                row[f\"{name}_{metric}_drop(%)\"] = ((baseline_val - adv_val) / baseline_val) * 100\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "adversarial_reports = {\n",
    "    \"Injected Both\": inject_both_report,\n",
    "    \"Injected Src\": inject_src_report,\n",
    "    \"Injected Dst\": inject_dst_report,\n",
    "    \"Edge Perturbation\": edge_perturb_report,\n",
    "    \"Random Edge\": random_edge_report,\n",
    "}\n",
    "\n",
    "comparison_df = compare_overall_metrics(normal_report, adversarial_reports)\n",
    "\n",
    "normal_cols = [col for col in comparison_df.columns if col.startswith('Normal_')] \n",
    "percentage_drop_cols = [col for col in comparison_df.columns if col.endswith('_drop(%)')]\n",
    "\n",
    "percentage_drop_df = pd.concat([comparison_df[normal_cols], comparison_df[percentage_drop_cols]], axis=1)\n",
    "\n",
    "print(\"Comparison of Overall Metrics:\")\n",
    "print(percentage_drop_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
