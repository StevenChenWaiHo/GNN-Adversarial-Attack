{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec16c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====Experiment=====\n",
    "'''\n",
    "DATASET_NAME = \"BoT_IoT\"\n",
    "\n",
    "GRAPH_CONSTRUCTION = 'endpoint'\n",
    "WINDOW_SIZE = 1500\n",
    "\n",
    "MULTICLASS = True\n",
    "\n",
    "LOAD_SAVED = True\n",
    "\n",
    "FIRST_RUN = not LOAD_SAVED\n",
    "\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import joblib\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.BoT_IoT.BoT_IoT_config import BoT_IoT_Config as Dataset_Config\n",
    "\n",
    "EXPERIMENT_NAME = f\"strat_window_{GRAPH_CONSTRUCTION}_{WINDOW_SIZE}\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = Dataset_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = Dataset_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = Dataset_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = Dataset_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = Dataset_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = Dataset_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = Dataset_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = Dataset_Config.TIME_COL_NAMES\n",
    "\n",
    "DROP_COLS = Dataset_Config.DROP_COLS\n",
    "\n",
    "COLS_TO_NORM = Dataset_Config.COLS_TO_NORM\n",
    "CATEGORICAL_COLS = Dataset_Config.CATEGORICAL_COLS\n",
    "\n",
    "if MULTICLASS:\n",
    "    label_col = ATTACK_CLASS_COL_NAME\n",
    "else:\n",
    "    label_col = IS_ATTACK_COL_NAME\n",
    "\n",
    "save_path = os.path.join(project_root, f\"Models/E_GraphSAGE/{DATASET_NAME}/saved\", EXPERIMENT_NAME)\n",
    "\n",
    "checkpoint_path = os.path.join(save_path, f\"checkpoints.pth\")\n",
    "best_model_path = os.path.join(save_path, f\"best_model.pth\")\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    csv_file_name = \"all_raw\"\n",
    "\n",
    "    data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"{DATASET_NAME}/All/{csv_file_name}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ee112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "    print(data[IS_ATTACK_COL_NAME].value_counts())\n",
    "\n",
    "    if MULTICLASS:\n",
    "        data.drop(columns=[IS_ATTACK_COL_NAME], inplace=True)\n",
    "    else:\n",
    "        data.drop(columns=[ATTACK_CLASS_COL_NAME], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    data.drop(columns=DROP_COLS,inplace=True)\n",
    "    print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    if GRAPH_CONSTRUCTION == 'endpoint':\n",
    "        data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "        data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "        # # Combine Port and IP\n",
    "        data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "        data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "        data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "        data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "        data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "        data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "        converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "\n",
    "    elif GRAPH_CONSTRUCTION == 'host':\n",
    "        data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "        converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "        COLS_TO_NORM = COLS_TO_NORM + [SOURCE_PORT_COL_NAME, DESTINATION_PORT_COL_NAME]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GRAPH_CONSTRUCTION value. Use 'host' or 'endpoint'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    # Clean NaN values\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "    data.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SAVED:\n",
    "    # Normalize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    print(data[COLS_TO_NORM].describe()) # Check if there's any too large value\n",
    "\n",
    "    # Check for numeric issues in the columns before normalization\n",
    "    def check_numeric_issues(df, cols_to_norm):\n",
    "        for col in cols_to_norm:\n",
    "            try:\n",
    "                # Try to coerce to numeric\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Column '{col}' failed with error: {e}\")\n",
    "                print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "                print(f\"  - Data type: {df[col].dtype}\")\n",
    "                continue\n",
    "\n",
    "        print(\"\\n‚úÖ All other columns processed successfully.\")\n",
    "\n",
    "    check_numeric_issues(data, COLS_TO_NORM)\n",
    "\n",
    "    data[COLS_TO_NORM] = scaler.fit_transform(data[COLS_TO_NORM])\n",
    "\n",
    "    # Save the scaler for future use\n",
    "    scaler_path = os.path.join(save_path, \"scaler.pkl\")\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(\"Data after normalization:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4382030",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED:\n",
    "    # load scaler\n",
    "    scaler_path = os.path.join(save_path, \"scaler.pkl\")\n",
    "    scaler = joblib.load(scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    num_classes = 2\n",
    "    class_map = [0, 1]\n",
    "    if MULTICLASS:\n",
    "        le = LabelEncoder()\n",
    "        attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "        class_map = le.classes_\n",
    "        print(class_map)\n",
    "        print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "        data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "        num_classes = len(class_map)\n",
    "        class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n",
    "\n",
    "    class_map_path = os.path.join(save_path, \"class_map.pkl\")\n",
    "    labeller_path = os.path.join(save_path, \"labeller.pkl\")\n",
    "\n",
    "    joblib.dump(le, labeller_path)\n",
    "    joblib.dump(class_map, class_map_path)\n",
    "\n",
    "    BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "    ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75c715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED:\n",
    "    # Save the class map BENIGN_CLASS_LABEL, ADVERSARIAL_CLASS_LABEL\n",
    "    class_map_path = os.path.join(save_path, \"class_map.pkl\")\n",
    "    labeller_path = os.path.join(save_path, \"labeller.pkl\")\n",
    "\n",
    "    class_map = joblib.load(class_map_path)\n",
    "    le = joblib.load(labeller_path)\n",
    "\n",
    "    BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "    ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SAVED:\n",
    "    # Maintain the order of the rows in the original dataframe\n",
    "    feature_cols = COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "    print('Feature Columns:', feature_cols)\n",
    "    num_features = len(feature_cols)\n",
    "    print('Number of Features:', num_features)\n",
    "\n",
    "    data['h'] = data[ feature_cols ].values.tolist()\n",
    "    print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df):\n",
    "\n",
    "    G_nx = nx.from_pandas_edgelist(df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "    \n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    assert num_edges == G_nx.number_of_edges(), \"Number of edges in PyG graph does not match NetworkX graph.\"\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    return G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e650028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class StratifiedGraphDataset:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.total_count = len(self.y)\n",
    "\n",
    "        # Compute class weights\n",
    "        labels = []\n",
    "\n",
    "        for graph in self.X:\n",
    "            labels.append(graph.edge_label.tolist())\n",
    "\n",
    "        labels = np.concatenate(labels)\n",
    "\n",
    "        self.class_counts = Counter(labels)\n",
    "\n",
    "        # Compute the class weights\n",
    "        self.class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "\n",
    "    def k_fold_split(self, k: int = 5, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        cv = MultilabelStratifiedShuffleSplit(test_size=test_ratio, random_state=random_state, n_splits=k)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        y_binary = mlb.fit_transform(self.y)\n",
    "\n",
    "        return cv.split(np.zeros(len(self.X)), y_binary)\n",
    "\n",
    "    def graph_train_test_split(self, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        train_idx, test_idx = next(self.k_fold_split(k = 1, test_ratio = test_ratio, random_state = random_state))\n",
    "        \n",
    "        X_train = [self.X[i] for i in train_idx]\n",
    "        X_test = [self.X[i] for i in test_idx]\n",
    "\n",
    "        y_train = [self.y[i] for i in train_idx]\n",
    "        y_test = [self.y[i] for i in test_idx]\n",
    "\n",
    "        return StratifiedGraphDataset(X_train, y_train), StratifiedGraphDataset(X_test, y_test)\n",
    "    \n",
    "    def print_class_distribution_and_weights(self):\n",
    "        # Use the label encoder to inverse transform the class labels\n",
    "        class_counts_named = {cls: count for cls, count in self.class_counts.items()}\n",
    "        class_weights_named = {cls: weight for cls, weight in enumerate(self.class_weights)}\n",
    "        print(\"Class Counts and Weights:\")\n",
    "        for cls_label in class_counts_named.keys():\n",
    "            count = class_counts_named[cls_label]\n",
    "            weight = class_weights_named[cls_label]\n",
    "            print(f\"{cls_label:<2}  {le.inverse_transform([cls_label])[0]:<15}: Count = {count:<10}, Weight = {weight:<10.4f}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_count\n",
    "\n",
    "    def __iter__(self):\n",
    "        for g in self.X:\n",
    "            yield g\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.X[idx], self.y[idx]\n",
    "        elif isinstance(idx, slice):\n",
    "            return [self.X[i] for i in range(len(self.X))][idx], [self.y[i] for i in range(len(self.y))][idx]\n",
    "        else:\n",
    "            raise TypeError(\"Index must be an integer or a slice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8988bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    def generate_graph_datasets(\n",
    "        df: pd.DataFrame, \n",
    "        window_size: int = WINDOW_SIZE, \n",
    "        feature_cols=feature_cols,\n",
    "        ordering_cols= TIME_COLS, \n",
    "        label_col=label_col,\n",
    "        build_graph_func=create_graph,\n",
    "        ):\n",
    "\n",
    "        print(\"All Columns: \", df.columns)\n",
    "        print(\"Ordering Columns: \", ordering_cols)\n",
    "        assert all(col in df.columns for col in ordering_cols), \"All timestamp columns are required\"\n",
    "        assert label_col in df.columns, \"Edge label column 'label' is required\"\n",
    "        \n",
    "        df = df.sort_values(ordering_cols).reset_index(drop=True)\n",
    "        window_size = int(window_size)\n",
    "        \n",
    "        df.drop(columns=set(df.columns) - set(feature_cols) - set(label_col))\n",
    "\n",
    "        print(\"Final Columns: \", df.columns)\n",
    "        \n",
    "        label_counts_list = []\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        progress_bar = tqdm(range(0, len(df), window_size), desc=f\"Generating graphs\")\n",
    "        for start in progress_bar:\n",
    "            window_df = df[start: min(start + window_size, len(df))]\n",
    "            contains_label = window_df[label_col].unique()\n",
    "\n",
    "            G_pyg = build_graph_func(window_df)\n",
    "\n",
    "            label_counts = window_df[label_col].value_counts()\n",
    "\n",
    "            label_counts_list.append(label_counts)\n",
    "            X.append(G_pyg)\n",
    "            y.append(contains_label.tolist())\n",
    "\n",
    "        return StratifiedGraphDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491e7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph_dataset_path = os.path.join(save_path, \"test_graph_dataset.pth\")\n",
    "if FIRST_RUN:\n",
    "    graph_dataset = generate_graph_datasets(data)\n",
    "    full_train_graph_dataset, test_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)\n",
    "    th.save(test_graph_dataset, test_graph_dataset_path)\n",
    "\n",
    "if LOAD_SAVED:\n",
    "    # Save or Load test_graph_dataset\n",
    "    if os.path.exists(test_graph_dataset_path):  \n",
    "        test_graph_dataset = th.load(test_graph_dataset_path, weights_only=False)\n",
    "    else:       \n",
    "        raise FileNotFoundError(f\"File {test_graph_dataset_path} does not exist. Please run the code to generate the dataset first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365fd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    print(\"Class Distrubution:\", data[label_col].value_counts())\n",
    "\n",
    "    print(\"Number of graphs after downsampling:\", len(graph_dataset))\n",
    "    graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "    print(\"Number of training graphs:\", len(full_train_graph_dataset))\n",
    "    full_train_graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "    print(\"Number of testing graphs:\", len(test_graph_dataset))\n",
    "    test_graph_dataset.print_class_distribution_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00a2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    def grid_search(graph_dataset, patience, max_epochs, learning_rates, hidden_dims, drop_outs, folds=3):\n",
    "        global num_features\n",
    "        \n",
    "        best_params = {}\n",
    "        best_f1 = 0\n",
    "        params_results = {}\n",
    "\n",
    "        # Precompute the train and validation graphs for all folds\n",
    "        folds_list = []\n",
    "        for i in range(folds):\n",
    "            train_graph_dataset, val_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=i)\n",
    "            folds_list.append((train_graph_dataset, val_graph_dataset))\n",
    "\n",
    "        for lr in learning_rates:\n",
    "            for hidden_dim in hidden_dims:\n",
    "                for drop_out in drop_outs:\n",
    "                    print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}, drop_out: {drop_out}\")\n",
    "                    fold_f1_scores = []\n",
    "\n",
    "                    for fold, (train_graph_dataset, val_graph_dataset) in enumerate(folds_list):\n",
    "                        print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                        model = EGraphSAGE(node_in_channels=num_features,\n",
    "                                        edge_in_channels=num_features,\n",
    "                                        hidden_channels=hidden_dim,\n",
    "                                        dropout = drop_out,\n",
    "                                        out_channels=num_classes).to(device)\n",
    "\n",
    "                        model.apply(init_weights)\n",
    "\n",
    "                        # Normalize to stabilize training\n",
    "                        class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "                        print(\"Class weights:\", class_weights)\n",
    "\n",
    "                        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                        optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "                        scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                            optimizer,\n",
    "                            mode='min',\n",
    "                            factor=0.6,\n",
    "                            patience=5,\n",
    "                            min_lr=1e-6,\n",
    "                        )\n",
    "\n",
    "                        best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "                        best_val_loss = float('inf')  # Track the best val_loss for this fold\n",
    "                        patience_counter = 0\n",
    "\n",
    "                        for epoch in range(max_epochs):\n",
    "                            try:\n",
    "                                train_loss = 0\n",
    "                                val_loss = 0\n",
    "                                num_train_graphs = len(train_graph_dataset)\n",
    "                                num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "                                model.train()\n",
    "                                optimizer.zero_grad()\n",
    "                                for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "                                    G_pyg_train = G_pyg_train.to(device)\n",
    "                                    G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                                    G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "                                    \n",
    "                                    out = model(G_pyg_train)\n",
    "                                    loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                                    train_loss += loss.item()\n",
    "\n",
    "                                    loss.backward()\n",
    "\n",
    "                                optimizer.step()\n",
    "                                \n",
    "\n",
    "                                test_label_list = []\n",
    "                                pred_label_list = []\n",
    "\n",
    "                                model.eval()\n",
    "                                with th.no_grad():\n",
    "                                    for G_pyg_val in tqdm(val_graph_dataset, desc=\"Validation\", leave=False):\n",
    "\n",
    "                                        G_pyg_val = G_pyg_val.to(device)\n",
    "                                        G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                                        G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                                        out = model(G_pyg_val)\n",
    "                                        loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                                        val_loss += loss.item()\n",
    "\n",
    "                                        test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                                        pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "                                test_label = th.cat(test_label_list)\n",
    "                                pred_label = th.cat(pred_label_list)\n",
    "\n",
    "                                val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "                                val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "                                val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "                                # Schedule step\n",
    "                                scheduler.step(val_loss)\n",
    "\n",
    "                                if val_f1 > best_epoch_f1:\n",
    "                                    best_epoch_f1 = val_f1\n",
    "                                    print(f\"Epoch {epoch}/{max_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                                    f\"Val F1 (weighted): {val_f1:.4f}, Micro: {val_f1_micro:.4f}, Macro: {val_f1_macro:.4f} \"\n",
    "                                    f\"(Best Weighted F1 so far: {best_epoch_f1:.4f})\")\n",
    "\n",
    "                                # Early stopping condition\n",
    "                                if val_loss < best_val_loss:\n",
    "                                    best_val_loss = val_loss\n",
    "                                    patience_counter = 0\n",
    "                                else:\n",
    "                                    patience_counter += 1\n",
    "\n",
    "                                if patience_counter >= patience:\n",
    "                                    print(f\"\\nüõë Early stopping triggered at epoch {epoch}.\")\n",
    "                                    break\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                                break\n",
    "\n",
    "                        fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "                    \n",
    "                    avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "                    params_results[(drop_out, lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "                    print(f\"Average F1 Score for drop_out {drop_out}, learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "                    if avg_f1 > best_f1:\n",
    "                        best_f1 = avg_f1\n",
    "                        best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim, 'drop_out': drop_out}\n",
    "\n",
    "        print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "        print(\"All results:\", params_results)\n",
    "\n",
    "    # grid_search(\n",
    "    #     full_train_graph_dataset, \n",
    "    #     patience=10,\n",
    "    #     max_epochs=200,\n",
    "    #     learning_rates=[0.001, 0.005, 0.01, 0.05], \n",
    "    #     hidden_dims=[128, 256, 512], \n",
    "    #     drop_outs=[0.2, 0.3, 0.4],\n",
    "    #     folds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b158d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    train_graph_dataset, val_graph_dataset = full_train_graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ec4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint():\n",
    "    global epoch, model, optimizer, scheduler, train_loss_history, val_loss_history, val_f1_history, saved_model_epochs, best_f1, patience_counter, best_val_loss, train_ended, max_epochs, patience\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss_history': train_loss_history,\n",
    "        'val_loss_history': val_loss_history,\n",
    "        'val_f1_history': val_f1_history,\n",
    "        'saved_model_epochs': saved_model_epochs,\n",
    "        'best_f1': best_f1,\n",
    "        # 'patience_counter': patience_counter,\n",
    "        # 'best_val_loss': best_val_loss,\n",
    "        'train_ended': train_ended,\n",
    "        'max_epochs': max_epochs,\n",
    "        # 'patience': patience\n",
    "    }\n",
    "    \n",
    "    th.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters from the grid search\n",
    "best_hidden_dim = 256  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.01  # Replace with the best learning_rate found\n",
    "best_drop_out = 0.3  # Replace with the best drop_out found\n",
    "if FIRST_RUN:\n",
    "\n",
    "    max_epochs = 200\n",
    "    # patience = 10\n",
    "\n",
    "    print(\"Number of train graphs: \", len(train_graph_dataset))\n",
    "\n",
    "    # Initialize the model with the best parameters\n",
    "    model = EGraphSAGE(node_in_channels=num_features, \n",
    "                    edge_in_channels=num_features,\n",
    "                    hidden_channels=best_hidden_dim,\n",
    "                    dropout = best_drop_out,\n",
    "                    out_channels=num_classes).to(device)\n",
    "\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # Normalize class weights\n",
    "    class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.6,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "    )\n",
    "\n",
    "    # ===== Load checkpoint if exists =====\n",
    "    start_epoch = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    # patience_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    train_ended = False\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_f1_history = []\n",
    "    saved_model_epochs = []\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = th.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "        train_ended = checkpoint['train_ended']\n",
    "        best_f1 = checkpoint['best_f1']\n",
    "\n",
    "        assert max_epochs == checkpoint['max_epochs'], \"Checkpoint max_epochs does not match the current setting.\"\n",
    "        # assert patience == checkpoint['patience'], \"Checkpoint patience does not match the current setting.\"\n",
    "\n",
    "        # patience_counter = checkpoint['patience_counter']\n",
    "        # best_val_loss = checkpoint['best_val_loss']\n",
    "\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "        train_loss_history = checkpoint['train_loss_history']\n",
    "        val_loss_history = checkpoint['val_loss_history']\n",
    "        val_f1_history = checkpoint['val_f1_history']\n",
    "        saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "        print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "    if train_ended:\n",
    "        model.load_state_dict(th.load(best_model_path))\n",
    "        print(\"Training has already ended. Loaded the best model state.\")\n",
    "        print(\"Training history loaded successfully.\")\n",
    "\n",
    "    else:\n",
    "        # ===== Start Training =====\n",
    "        num_train_graphs = len(train_graph_dataset)\n",
    "        num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "        for epoch in range(start_epoch, max_epochs):\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "                # Move the graph data to the device\n",
    "                G_pyg_train = G_pyg_train.to(device)\n",
    "                G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "                out = model(G_pyg_train)\n",
    "                loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            test_label_list = []\n",
    "            pred_label_list = []\n",
    "\n",
    "            model.eval()\n",
    "            with th.no_grad():\n",
    "                for G_pyg_val in tqdm(val_graph_dataset, desc=\"Evaluation\", leave=False):\n",
    "                    G_pyg_val = G_pyg_val.to(device)\n",
    "                    G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                    G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                    out = model(G_pyg_val)\n",
    "                    loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                    pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "            test_label = th.cat(test_label_list)\n",
    "            pred_label = th.cat(pred_label_list)\n",
    "\n",
    "            val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "            val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "            val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "            train_loss_history.append(train_loss)\n",
    "            val_loss_history.append(val_loss)\n",
    "            val_f1_history.append((val_f1, val_f1_micro, val_f1_macro))\n",
    "\n",
    "            # Schedule step\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1  # Update the best F1 score for this fold\n",
    "                best_model_state = model.state_dict()\n",
    "                saved_model_epochs.append(epoch)\n",
    "\n",
    "                save_checkpoint()\n",
    "                th.save(best_model_state, best_model_path)\n",
    "                print(f\"Epoch {epoch} Saved best model. Best F1:\", best_f1)\n",
    "\n",
    "            print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}, Validation F1 Micro: {val_f1_micro:.4f}, Validation F1 Macro: {val_f1_macro:.4f}')\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                save_checkpoint()\n",
    "\n",
    "            # # Early stopping condition\n",
    "            # if val_loss < best_val_loss:\n",
    "            #     best_val_loss = val_loss\n",
    "            #     patience_counter = 0\n",
    "            # else:\n",
    "            #     patience_counter += 1\n",
    "\n",
    "            # if patience_counter >= patience:\n",
    "            #     print(f\"\\nüõë Early stopping triggered at epoch {epoch}.\")\n",
    "            #     train_ended = True\n",
    "            #     break\n",
    "\n",
    "        # Save the trained model\n",
    "        train_ended = True\n",
    "        save_checkpoint()\n",
    "        print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_process():\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    val_loss_history = checkpoint['val_loss_history']\n",
    "    val_f1_history = checkpoint['val_f1_history']\n",
    "    saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Plot Train Loss\n",
    "    axs[0].plot(train_loss_history, label='Train Loss', color='blue')\n",
    "    axs[0].plot(val_loss_history, label='Validation Loss', color='red')\n",
    "    axs[0].set_ylabel('Train Loss')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    val_f1_weighted_history = []\n",
    "    val_f1_micro_history = []\n",
    "    val_f1_macro_history = []\n",
    "\n",
    "    for val_f1_weighted, val_f1_micro, val_f1_macro in val_f1_history:\n",
    "        val_f1_weighted_history.append(val_f1_weighted)\n",
    "        val_f1_micro_history.append(val_f1_micro)\n",
    "        val_f1_macro_history.append(val_f1_macro)\n",
    "    \n",
    "    # Plot Validation F1\n",
    "\n",
    "    axs[1].plot(val_f1_weighted_history, label='Validation F1 Weighted', color='green')\n",
    "    axs[1].plot(val_f1_micro_history, label='Validation F1 Micro', color='blue')\n",
    "    axs[1].plot(val_f1_macro_history, label='Validation F1 Macro', color='red')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Validation F1')\n",
    "    axs[1].set_title('Validation F1 Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    # Add scatter for saved model epochs (e.g., F1 weighted here)\n",
    "    axs[1].scatter(saved_model_epochs, [val_f1_weighted_history[i] for i in saved_model_epochs],\n",
    "                   color='black', marker='o', label='Saved Model')\n",
    "    axs[1].legend()\n",
    "\n",
    "    print(len(train_loss_history))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2572f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAMWCAYAAADs4eXxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd8U/X+x/H3SZqmLW3Zm7KR7QJR8TJUBAFRBBUFZbgHKqK/60TFxXVecHvV68aFKFdFBBEEBRUHDoay916lO03O74/TpE2b7pGT9vV8PGJz9jf5JNhPP9/z/RqmaZoCAAAAAAAVzhHuBgAAAAAAUF2RdAMAAAAAUElIugEAAAAAqCQk3QAAAAAAVBKSbgAAAAAAKglJNwAAAAAAlYSkGwAAAACASkLSDQAAAABAJSHpBgAAAACgkpB0AwAQIcaPH6/WrVuX6dj7779fhmFUbIMAAECxSLoBACgnwzBK9Fi8eHG4mxoW48ePV3x8fLibAQBAWBimaZrhbgQAAJHs7bffDlp+8803tWDBAr311ltB68866yw1bty4zNfxeDzy+Xxyu92lPjY7O1vZ2dmKiYkp8/XLavz48Zo1a5ZSUlKq/NoAAIRbVLgbAABApLv00kuDlr///nstWLCgwPr80tLSFBcXV+LruFyuMrVPkqKiohQVxf/2AQCoanQvBwCgCvTv31/dunXTzz//rL59+youLk533XWXJGnOnDkaOnSomjVrJrfbrXbt2unBBx+U1+sNOkf+e7o3b94swzD0xBNP6D//+Y/atWsnt9utk046SStWrAg6NtQ93YZhaOLEifrkk0/UrVs3ud1ude3aVfPmzSvQ/sWLF6tnz56KiYlRu3bt9NJLL1X4feIffvihevToodjYWDVo0ECXXnqpduzYEbTP7t27NWHCBLVo0UJut1tNmzbVeeedp82bNwf2+emnnzRo0CA1aNBAsbGxatOmjS6//PIKaycAAKXBn7wBAKgiBw4c0ODBg3XxxRfr0ksvDXQ1f/311xUfH6/JkycrPj5eX3/9te69914lJyfr8ccfL/a8M2fO1NGjR3XNNdfIMAw99thjGjFihDZu3Fhsdfzbb7/V7Nmzdf311yshIUFPP/20Ro4cqa1bt6p+/fqSpF9//VVnn322mjZtqqlTp8rr9eqBBx5Qw4YNy/+m5Hj99dc1YcIEnXTSSZo2bZr27NmjGTNm6LvvvtOvv/6qOnXqSJJGjhypVatW6cYbb1Tr1q21d+9eLViwQFu3bg0sDxw4UA0bNtQdd9yhOnXqaPPmzZo9e3aFtRUAgFIxAQBAhbrhhhvM/P+L7devnynJfPHFFwvsn5aWVmDdNddcY8bFxZkZGRmBdePGjTNbtWoVWN60aZMpyaxfv7558ODBwPo5c+aYksxPP/00sO6+++4r0CZJZnR0tLl+/frAut9++82UZD7zzDOBdcOGDTPj4uLMHTt2BNatW7fOjIqKKnDOUMaNG2fWqlWr0O1ZWVlmo0aNzG7dupnp6emB9Z999pkpybz33ntN0zTNQ4cOmZLMxx9/vNBzffzxx6Ykc8WKFcW2CwCAqkD3cgAAqojb7daECRMKrI+NjQ08P3r0qPbv368+ffooLS1Na9euLfa8o0aNUt26dQPLffr0kSRt3Lix2GMHDBigdu3aBZaPPfZYJSYmBo71er366quvNHz4cDVr1iywX/v27TV48OBiz18SP/30k/bu3avrr78+aKC3oUOHqlOnTvr8888lWe9TdHS0Fi9erEOHDoU8l78i/tlnn8nj8VRI+wAAKA+SbgAAqkjz5s0VHR1dYP2qVat0/vnnq3bt2kpMTFTDhg0Dg7AdOXKk2PO2bNkyaNmfgBeWmBZ1rP94/7F79+5Venq62rdvX2C/UOvKYsuWLZKkjh07FtjWqVOnwHa3261HH31UX3zxhRo3bqy+ffvqscce0+7duwP79+vXTyNHjtTUqVPVoEEDnXfeeXrttdeUmZlZIW0FAKC0SLoBAKgieSvafocPH1a/fv3022+/6YEHHtCnn36qBQsW6NFHH5Uk+Xy+Ys/rdDpDrjdLMCtoeY4Nh0mTJunvv//WtGnTFBMToylTpqhz58769ddfJVmDw82aNUvLly/XxIkTtWPHDl1++eXq0aMHU5YBAMKCpBsAgDBavHixDhw4oNdff10333yzzjnnHA0YMCCou3g4NWrUSDExMVq/fn2BbaHWlUWrVq0kSX/99VeBbX/99Vdgu1+7du106623av78+frzzz+VlZWlJ598MmifU045RQ8//LB++uknvfPOO1q1apXee++9CmkvAAClQdINAEAY+SvNeSvLWVlZev7558PVpCBOp1MDBgzQJ598op07dwbWr1+/Xl988UWFXKNnz55q1KiRXnzxxaBu4F988YXWrFmjoUOHSrLmNc/IyAg6tl27dkpISAgcd+jQoQJV+uOPP16S6GIOAAgLpgwDACCMevfurbp162rcuHG66aabZBiG3nrrLVt1777//vs1f/58nXbaabruuuvk9Xr17LPPqlu3blq5cmWJzuHxePTQQw8VWF+vXj1df/31evTRRzVhwgT169dPl1xySWDKsNatW+uWW26RJP39998688wzddFFF6lLly6KiorSxx9/rD179ujiiy+WJL3xxht6/vnndf7556tdu3Y6evSoXn75ZSUmJmrIkCEV9p4AAFBSJN0AAIRR/fr19dlnn+nWW2/VPffco7p16+rSSy/VmWeeqUGDBoW7eZKkHj166IsvvtBtt92mKVOmKCkpSQ888IDWrFlTotHVJat6P2XKlALr27Vrp+uvv17jx49XXFyc/vWvf+n2229XrVq1dP755+vRRx8NjEielJSkSy65RAsXLtRbb72lqKgoderUSR988IFGjhwpyRpI7ccff9R7772nPXv2qHbt2urVq5feeecdtWnTpsLeEwAASsow7fSndAAAEDGGDx+uVatWad26deFuCgAAtsU93QAAoFjp6elBy+vWrdPcuXPVv3//8DQIAIAIQaUbAAAUq2nTpho/frzatm2rLVu26IUXXlBmZqZ+/fVXdejQIdzNAwDAtrinGwAAFOvss8/Wu+++q927d8vtduvUU0/VI488QsINAEAxqHQDAAAAAFBJuKcbAAAAAIBKQtINAAAAAEAlqXH3dPt8Pu3cuVMJCQkyDCPczQEAAAAARCDTNHX06FE1a9ZMDkfh9ewal3Tv3LlTSUlJ4W4GAAAAAKAa2LZtm1q0aFHo9hqXdCckJEiy3pjExMQwt6ZwHo9H8+fP18CBA+VyucLdHIRAjOyPGNkfMbI/YmR/xMj+iJH9ESN7s2t8kpOTlZSUFMgxC1Pjkm5/l/LExETbJ91xcXFKTEy01QcLuYiR/REj+yNG9keM7I8Y2R8xsj9iZG92j09xty0zkBoAAAAAAJWEpBsAAAAAgEpC0g0AAAAAQCWpcfd0AwAAAKhefD6fsrKyyny8x+NRVFSUMjIy5PV6K7BlqAjhio/L5ZLT6Sz3eUi6AQAAAESsrKwsbdq0ST6fr8znME1TTZo00bZt24odFAtVL5zxqVOnjpo0aVKu65J0AwAAAIhIpmlq165dcjqdSkpKksNRtrtnfT6fUlJSFB8fX+ZzoPKEIz6maSotLU179+6VJDVt2rTM5yLpBgAAABCRsrOzlZaWpmbNmikuLq7M5/F3T4+JiSHptqFwxSc2NlaStHfvXjVq1KjMXc35RAEAAACISP77e6Ojo8PcElRX/j/meDyeMp+DpBsAAABAROM+bFSWivhskXQDAAAAAFBJSLoBAAAAIMK1bt1a06dPD3czEAJJd4Rau1a65RZp9+5wtwQAAABASRmGUeTj/vvvL9N5V6xYoauvvrpcbevfv78mTZpUrnOgIFsl3UuWLNGwYcPUrFkzGYahTz75JGi7aZq699571bRpU8XGxmrAgAFat25deBobZjNmSNOnS++8E+6WAAAAACipXbt2BR7Tp09XYmJi0LrbbrstsK9pmsrOzi7ReRs2bFiuEdxReWyVdKempuq4447Tc889F3L7Y489pqefflovvviifvjhB9WqVUuDBg1SRkZGFbc0/JKTrZ+pqeFtBwAAAICSa9KkSeBRu3ZtGYYRWF67dq0SEhL0xRdfqEePHnK73fr222+1YcMGnXfeeWrcuLHi4+N10kkn6auvvgo6b/7u5YZh6JVXXtH555+vuLg4dejQQf/73//K1faPPvpIXbt2ldvtVuvWrfXkk08GbX/++efVoUMHxcTEqHHjxrrgggsC22bNmqXu3bsrNjZW9evX14ABA5RaQ5IZW83TPXjwYA0ePDjkNtM0NX36dN1zzz0677zzJElvvvmmGjdurE8++UQXX3xxVTa16n34ofS//0n/+Y8UG6vMTGt1Cf/wBQAAAFR7pimlpZX+OJ/PKmY5nVJZp4GOi5MqahD1O+64Q0888YTatm2runXratu2bRoyZIgefvhhud1uvfnmmxo2bJj++usvtWzZstDzTJ06VY899pgef/xxPfPMMxozZoy2bNmievXqlbpNP//8sy666CLdf//9GjVqlJYtW6brr79e9evX1/jx4/XTTz/ppptu0ltvvaXevXvr4MGDWrp0qSSrun/JJZfoscce0/nnn6+jR49q6dKlMk2zzO9RJLFV0l2UTZs2affu3RowYEBgXe3atXXyySdr+fLlhSbdmZmZyvRnqJKSc0rEHo+nXHOtVTZ/2/w/o6ZNk/Hrr8oePVrmgAFKT3dKcigjwyuPxxfGltZc+WME+yFG9keM7I8Y2R8xsj9iVHk8Ho9M05TP55PP51NqqpSYWJas2SGpTrnakpzsU61apTvG5/OF/Hn//ffrzDPPDOxXp04dde/ePbA8depUffzxx5ozZ45uuOGGwHr/e+E3btw4jRo1SpL00EMP6emnn9b333+vs88+u9A25T+H35NPPqkzzjhDd999tySpffv2WrVqlR5//HGNHTtWmzdvVq1atTRkyBAlJCQoKSlJxx13nHw+n3bs2KHs7GwNHz488EeCrl27Br3moviT88LaVpl8Pp9M05TH45HT6QzaVtLvdMQk3btzRgxr3Lhx0PrGjRsHtoUybdo0TZ06tcD6+fPnR8Q9DwsWLJAknbF3rxIk/fTdd9qTlaUdO06V1Ejr1m3U3Lmrw9rGms4fI9gXMbI/YmR/xMj+iJH9EaOKFxUVpSZNmiglJUVZWVk5t17WCUtbkpOT5fWW7piMjAyZphkoDKbllOk7duwYWCdJKSkpevTRRzV//nzt3r1bXq9X6enpWrduXWA/n8+njIyMoOPat28ftJyQkKCtW7cGrcsrOztbWVlZIbevWrVKQ4YMCdp2wgknaMaMGTp06JBOPvlktWjRQu3atdOZZ56pM888U+ecc47i4uLUpk0b9evXT8cdd5zOOOMMnX766TrvvPNUp06dUr1fR48eLdX+FSErK0vp6elasmRJgfvr00rYrSJiku6yuvPOOzV58uTAcnJyspKSkjRw4EAlJiaGsWVF83g8WrBggc466yy5XC5FuVySpJ7HHSdzyBA9+aT1V5akpLYaMqR1GFtac+WPEeyHGNkfMbI/YmR/xMj+iFHlycjI0LZt2xQfH6+YmBglJFgV59IyTVNHjx5VQkKCjDL2EY+LSyx19/KYmBgZhhHIS/xFwSZNmgTlKrfffru++uorPfbYY2rfvr1iY2N10UUXBR3rcDgUExMTdFxiYmLQssPhUHR0dKF5UFRUVKHbnU6n3G530LbY2NjAderWratff/1Vixcv1oIFC/Too4/q8ccf1w8//KC6detq4cKFWrZsmRYsWKBXX31VDz/8sJYvX642bdoU+z5VRHzKKiMjQ7Gxserbt69iYmKCthX2x4v8IibpbtKkiSRpz549atq0aWD9nj17dPzxxxd6nNvtltvtLrDe5XJFxD96gXbmdJGPslYqK8va7vM55XI5Cz0elS9SPks1GTGyP2Jkf8TI/oiR/RGjiuf1emUYhhwOhxw5N2MnJJT+PFb3dCk+3gicpyr4rxXqZ952LFu2TOPHj9fIkSMlWZXvzZs3q3///kH7+d+LvOfP/3pCrcsr/zn8OnfurGXLlgVtW758uY455pjA5zo6OloDBw7UwIEDdf/996tOnTpavHixRowYIUnq06eP+vTpo/vuu0+tWrXSnDlzggqkhfF3KS+sbZXJ4XDIMIyQ39+Sfp8jJulu06aNmjRpooULFwaS7OTkZP3www+67rrrwtu4quC/Lz3nvgEGUgMAAABqhg4dOmj27NkaNmyYDMPQlClTKu3e5n379mnlypVB65o2bapbb71VJ510kh588EGNGjVKy5cv17PPPqvnn39ekvTZZ59p48aN6tu3r+rWrau5c+fK5/OpY8eO+uGHH7Rw4UINHDhQjRo10g8//KB9+/apc+fOlfIa7MZWSXdKSorWr18fWN60aZNWrlypevXqqWXLlpo0aZIeeughdejQQW3atNGUKVPUrFkzDR8+PHyNrir5smz/LGmMxwEAAABUb0899ZQuv/xy9e7dWw0aNNDtt99e4q7NpTVz5kzNnDkzaN2DDz6oe+65Rx988IHuvfdePfjgg2ratKkeeOABjR8/XpI12Nvs2bN1//33KyMjQx06dNC7776rrl27as2aNVqyZImmT5+u5ORktWrVSk8++WShM1dVN7ZKun/66SedfvrpgWV/V4Nx48bp9ddf1z//+U+lpqbq6quv1uHDh/WPf/xD8+bNK9C3vlqi0g0AAABUK+PHjw8krZLUv3//kNNotW7dWl9//XXQuryjlkvS5s2bg5ZDnefw4cNFtmfx4sVFbh85cmSgi3t+//jHPwo9vnPnzpo3b16R567ObJV0F/Yh8zMMQw888IAeeOCBKmyVDfh8udl1zs98OTgAAAAAwIaq9i50lE2eecapdAMAAABA5CDpjgR5k24q3QAAAAAQMUi6IwGVbgAAAACISCTdkSBfpdvny61wU+kGAAAAAPsi6Y4E+SrdWVm5i1S6AQAAAMC+SLojQb5Kd4hbvAEAAAAANkTSHQmKSLrpXg4AAAAA9kXSHQnyZdlUugEAAAAgMpB0RwIq3QAAAADy6N+/vyZNmhRYbt26taZPn17kMYZh6JNPPin3tSvqPDUFSXckoNINAAAAVAvDhg3T2WefHXLb0qVLZRiGfv/991Kfd8WKFbr66qvL27wg999/v44//vgC63ft2qXBgwdX6LXye/3111WnTp1KvUZVIemOBFS6AQAAgGrhiiuu0IIFC7R9+/YC21577TX17NlTxx57bKnP27BhQ8XFxVVEE4vVpEkTud3uKrlWdUDSHQmodAMAAADVwjnnnKOGDRvq9ddfD1qfkpKiDz/8UFdccYUOHDigSy65RM2bN1dcXJy6d++ud999t8jz5u9evm7dOvXt21cxMTHq0qWLFixYUOCY22+/Xcccc4zi4uLUtm1bTZkyRZ6cqt7rr7+uqVOn6rfffpNhGDIMI9Dm/N3L//jjD51xxhmKjY1V/fr1dfXVVyslJSWwffz48Ro+fLieeOIJNW3aVPXr19cNN9wQuFZZbN26Veedd57i4+OVmJioiy66SHv27Als/+2333T66acrISFBiYmJ6tGjh3766SdJ0pYtWzRs2DDVrVtXtWrVUteuXTV37twyt6U4UZV2ZlScjIzc59nZ+RcBAAAASJJpSmlppT/O55NSUyWnU3KUsS4ZFycZRrG7RUVFaezYsXr99dd19913y8g55sMPP5TX69Ull1yilJQU9ejRQ7fffrsSExP1+eef67LLLlO7du3Uq1evErwcn0aMGKHGjRvrhx9+0JEjR4Lu//ZLSEjQ66+/rmbNmumPP/7QVVddpYSEBP3zn//UqFGj9Oeff2revHn66quvJEm1a9cucI7U1FQNGjRIp556qlasWKG9e/fqyiuv1MSJE4P+sLBo0SI1bdpUixYt0vr16zVq1Cgdf/zxuuqqq4p9PaFenz/h/uabb5Sdna0bbrhBo0aN0uLFiyVJY8aM0QknnKAXXnhBTqdTK1eulMvlkiTdcMMNysrK0pIlS1SrVi2tXr1a8fHxpW5HSZF0R4IiKt10LwcAAABypKVJZUieHJLqlPfaKSlSrVol2vXyyy/X448/rm+++Ub9+/eXZHUtHzlypGrXrq3atWvrtttuC+x/44036ssvv9QHH3xQoqT7q6++0tq1a/Xll1+qWbNmkqRHHnmkwH3Y99xzT+B569atddttt+m9997TP//5T8XGxio+Pl5RUVFq0qRJodeaOXOmMjIy9Oabb6pWzut/9tlnNWzYMD366KNq3LixJKlu3bp69tln5XQ61alTJw0dOlQLFy4sU9K9cOFC/fHHH9q0aZOSkpIkSW+++aa6du2qFStW6KSTTtLWrVv1f//3f+rUqZMkqUOHDoHjt27dqpEjR6p79+6SpLZt25a6DaVB9/JIUMQ93VS6AQAAgMjSqVMn9e7dW//9738lSevXr9fSpUt1xRVXSJK8Xq8efPBBde/eXfXq1VN8fLy+/PJLbd26tUTnX7NmjZKSkgIJtySdeuqpBfZ7//33ddppp6lJkyaKj4/XPffcU+Jr5L3WcccdF0i4Jem0006Tz+fTX3/9FVjXtWtXOZ3OwHLTpk21d+/eUl0r7zWTkpICCbckdenSRXXq1NGaNWskSZMnT9aVV16pAQMG6F//+pc2bNgQ2Pemm27SQw89pNNOO0333XdfmQauKw2S7khApRsAAAAoXlycVXEu5cOXnKzD27fLl5xcpuOVkmJduxSuuOIKffTRRzp69Khee+01tWvXTv369ZMkPf7445oxY4Zuv/12LVq0SCtXrtSgQYOUlZVVYW/V8uXLNWbMGA0ZMkSfffaZfv31V919990Veo28/F27/QzDkM/nq5RrSdbI66tWrdLQoUP19ddfq0uXLvr4448lSVdeeaU2btyoyy67TH/88Yd69uypZ555ptLaQtIdCah0AwAAAMUzDKuLdzgeJbifO6+LLrpIDodDM2fO1JtvvqnLL788cH/3d999p/POO0+XXnqpjjvuOLVt21Z///13ic/duXNnbdu2Tbt27Qqs+/7774P2WbZsmVq1aqW7775bPXv2VIcOHbRly5agfaKjo+X1eou91m+//abU1NTAuu+++04Oh0MdO3YscZtLw//6tm3bFli3evVqHT58WF26dAmsO+aYY3TLLbdo/vz5GjFihF577bXAtqSkJF177bWaPXu2br31Vr388suV0laJpDsyUOkGAAAAqpX4+HiNGjVKd955p3bt2qXx48cHtnXo0EELFizQsmXLtGbNGl1zzTVBI3MXZ8CAATrmmGM0btw4/fbbb1q6dKnuvvvuoH06dOigrVu36r333tOGDRv09NNPByrBfq1bt9amTZu0cuVK7d+/X5l5E5EcY8aMUUxMjMaNG6c///xTixYt0o033qjLLrsscD93WXm9Xq1cuVIrV67UH3/8oZUrV2rNmjUaMGCAunfvrjFjxuiXX37Rjz/+qLFjx6pfv37q2bOn0tPTNXHiRC1evFhbtmzRd999pxUrVqhz586SpEmTJunLL7/Upk2b9Msvv2jRokWBbZWBpDsSUOkGAAAAqp0rrrhChw4d0qBBg4Luv77nnnt04oknatCgQerfv7+aNGmi4cOHl/i8DodDH3/8sdLT09WrVy9deeWVevjhh4P2Offcc3XLLbdo4sSJOv7447Vs2TJNmTIlaJ+RI0fq7LPP1umnn66GDRuGnLYsLi5OX375pQ4ePKiTTjpJF1xwgc4880w9++yzpXszQkhJSdEJJ5ygHj16qG/fvurRo4eGDRsmwzA0Z84c1a1bV3379tWAAQPUtm1bvf/++5Ikp9OpAwcOaOzYsTrmmGN00UUXafDgwZo6daokK5m/4YYb1LlzZ5199tk65phj9Pzzz5e7vYVh9PJIUEyl2zRL3ZsFAAAAQJideuqpMk2zwPp69eoFzYMdin9qLL/NmzcHLR9zzDFaunRp0Lr813rsscf02GOPBa3LO7WY2+3WrFmzClw7/3m6d++ur7/+utC25p+TXFLQnOKhjB8/PlD99/l8Sk5OVmJiohw5U7q1bNlSc+bMCXlsdHR0kfOaV+b926FQ6Y4ERVS6JWtaQQAAAACA/ZB0R4IiKt0SXcwBAAAAwK5IuiNBMZVuBlMDAAAAAHsi6Y4EVLoBAAAAICKRdEcCKt0AAAAAEJFIuiNBMUk3lW4AAADUZKFGAAcqgq8CRq1myrBIUEz3cirdAAAAqIlcLpcMw9C+ffvUsGFDGWWcR9fn8ykrK0sZGRmBKalgH+GIj2maysrK0r59++RwOBQdHV3mc5F0R4J8le6MjODNVLoBAABQEzmdTrVo0ULbt28vME91aZimqfT0dMXGxpY5cUflCWd84uLi1LJly3Il+yTdkYBKNwAAABBSfHy8OnToIE85fin2eDxasmSJ+vbtK5fLVYGtQ0UIV3ycTqeioqLKneiTdEcC7ukGAAAACuV0OuV0Ost1fHZ2tmJiYki6bSjS48MNC5GAKcMAAAAAICKRdEcCpgwDAAAAgIhE0h0JqHQDAAAAQEQi6Y4E+SvdGcHzEFLpBgAAAAB7IumOBPlK29mZ3uBlKt0AAAAAYEsk3XZnmgWSbm9mcJZNpRsAAAAA7Imk2+5CZNTeDGtdTIy1TKUbAAAAAOyJpNvu8o+aJsmXZWXZ8fHWMpVuAAAAALAnkm67C5V0Z1pZdq1a1jKVbgAAAACwJ5Juu8vIsH5GRUlOpyTJm6/STdINAAAAAPZE0m13/kq32y25XJIkl4Ir3XQvBwAAAAB7Ium2u7xJd1SUJClKVmmb7uUAAAAAYG9R4W4AipE36TZNSVS6AQAAACBSUOm2OSMry3qSr9IdFWWtkqh0AwAAAIBdkXTbXYh7uqOUnTcHp9INAAAAADZF0m13Ie7pdsmTNwen0g0AAAAANkXSbXdUugEAAAAgYpF0250/6Y6JodINAAAAABEm4pJur9erKVOmqE2bNoqNjVW7du304IMPyswZ2bvaKWTKsLyVbpJuAAAAALCniJsy7NFHH9ULL7ygN954Q127dtVPP/2kCRMmqHbt2rrpppvC3byKl3f08pzStr/STfdyAAAAALC3iEu6ly1bpvPOO09Dhw6VJLVu3VrvvvuufvzxxzC3rHIYhVS6Y2LoXg4AAAAAdhdxSXfv3r31n//8R3///beOOeYY/fbbb/r222/11FNPhdw/MzNTmf7EVVJycrIkyePxyGPjErG/bd60NDkl+VwuKSpKDlmV7uhonwzDlORUZqZXHo8vnM2tkfwxsvPnqKYjRvZHjOyPGNkfMbI/YmR/xMje7BqfkrYn4pLuO+64Q8nJyerUqZOcTqe8Xq8efvhhjRkzJuT+06ZN09SpUwusnz9/vuLi4iq7ueW2btUqdZW0fd8+xSUnq4GsSvfRo/u1deshSR21fv1mzZ37Z5hbWnMtWLAg3E1AMYiR/REj+yNG9keM7I8Y2R8xsje7xSctLa1E+0Vc0v3BBx/onXfe0cyZM9W1a1etXLlSkyZNUrNmzTRu3LgC+995552aPHlyYDk5OVlJSUkaOHCgEhMTq7LppeLxeLRgwQJ1aNlSktS8XTsZpimtXi2XPGrevIE6dqxvbWveWkOGtAxnc2skf4zOOussufx9/WErxMj+iJH9ESP7I0b2R4zsjxjZm13j4+9FXZyIS7r/7//+T3fccYcuvvhiSVL37t21ZcsWTZs2LWTS7Xa75Xa7C6x3uVy2ClhhnDldFpyxsUHzdMfEOBQTY+3j8znlcjnD1cQaL1I+SzUZMbI/YmR/xMj+iJH9ESP7I0b2Zrf4lLQtETdlWFpamhyO4GY7nU75fNX0nuYSjF7OQGoAAAAAYE8RV+keNmyYHn74YbVs2VJdu3bVr7/+qqeeekqXX355uJtWOYqYp9v/hxWbjScAAAAAAMgRcUn3M888oylTpuj666/X3r171axZM11zzTW69957w920ShE0ZVieSreDSjcAAAAA2F7EJd0JCQmaPn26pk+fHu6mVI1CKt1ReZJuKt0AAAAAYE8Rl3TXOEVUuv3dy6l0AwAAAIA9kXTbXSGVbheVbgAAAACwvYgbvbzGKWL0cirdAAAAAGBvJN12V8To5VS6AQAAAMDeSLrtrpB7uql0AwAAAID9kXTbXQkq3STdAAAAAGBPJN02Z2RkWE/ylLajlK2YGLqXAwAAAIDdkXTbXYhKN93LAQAAACAykHTbXd7RyxlIDQAAAAAiCkm33TGQGgAAAABELJJuu2PKMAAAAACIWCTddkelGwAAAAAiFkm33VHpBgAAAICIFRXuBqBwhtcrw+ezFkJUup1OaxOVbgAAAACwJ5JuG3PkLWGHqHT7kXQDAAAAgD2RdNtYUNIdE1Og0u31WpvoXg4AAAAA9sQ93TYWSLodDikqSqYzuNLNQGoAAAAAYG9Uum0skHTn9CX3OlyKUm6l2zStzVS6AQAAAMCeqHTbmNNfws5Juj1m6Eq315ubgAMAAAAA7IOk28byV7o9Cr6nOypPPwW6mAMAAACA/ZB021iBpDtPpTsqKrfSLZF0AwAAAIAdkXTbWP6kO8u0smy3Ya3PW+nmvm4AAAAAsB+SbhsrrNLtMqyyNpVuAAAAALA3km4by590Z/py7unOqXQ78kSPpBsAAAAA7Iek28byj16e5cupdMtabxi5XczpXg4AAAAA9kPSbWOFVbqjjNyytr+LOZVuAAAAALAfkm4bKzCQWqDSnVvWptINAAAAAPZF0m1j+ZPuDG9OpVtUugEAAAAgEpB021iB7uXenHm6TSrdAAAAABAJSLptzJFvILWMbCvDdppUugEAAAAgEpB025izsO7lVLoBAAAAICKQdNtYgXu6Q1S6/Uk3lW4AAAAAsB+SbhtzZGVZT/JVuh0yJa9XEt3LAQAAAMDOSLptLP893emeqNyNOdvoXg4AAAAA9kXSbWP5u5enZ7tyN+Zso9INAAAAAPZF0m1jBQZSy6bSDQAAAACRhKTbxgpUuvN2L6fSDQAAAAC2R9JtYwVGL89yyOsPGZVuAAAAALA9km4byz+QWmam5FFOaZtKNwAAAADYHkm3jeWvdGdmStkKnpibeboBAAAAwL5Ium0sVNKdv9JN93IAAAAAsC+SbhsLjF4eEyNJysgoWOmmezkAAAAA2BdJt41R6QYAAACAyEbSbWOhBlKj0g0AAAAAkYOk28aKrHQzZRgAAAAA2B5Jt40VOXo5U4YBAAAAgO2RdNsYlW4AAAAAiGwk3TbmpNINAAAAABGt3El3enq60tLSAstbtmzR9OnTNX/+/PKeulA7duzQpZdeqvr16ys2Nlbdu3fXTz/9VGnXC5eSDKQWFbwIAAAAALCRqPKe4LzzztOIESN07bXX6vDhwzr55JPlcrm0f/9+PfXUU7ruuusqop0Bhw4d0mmnnabTTz9dX3zxhRo2bKh169apbt26FXqdsPP5QibdTBkGAAAAAJGj3JXuX375RX369JEkzZo1S40bN9aWLVv05ptv6umnny53A/N79NFHlZSUpNdee029evVSmzZtNHDgQLVr167CrxVWWVm5z5kyDAAAAAAiUrmT7rS0NCUkJEiS5s+frxEjRsjhcOiUU07Rli1byt3A/P73v/+pZ8+euvDCC9WoUSOdcMIJevnllyv8OmGXmZn7nEo3AAAAAESkcncvb9++vT755BOdf/75+vLLL3XLLbdIkvbu3avExMRyNzC/jRs36oUXXtDkyZN11113acWKFbrpppsUHR2tcePGFdg/MzNTmXkS2OTkZEmSx+ORx8aZqiclxZ9ey2MYksejzMyoQKU7OyNDpscjh8MhyamsLK88Hl/Y2lsT+T8/dv4c1XTEyP6Ikf0RI/sjRvZHjOyPGNmbXeNT0vYYpmma5bnQrFmzNHr0aHm9Xp155pmBAdSmTZumJUuW6IsvvijP6QuIjo5Wz549tWzZssC6m266SStWrNDy5csL7H///fdr6tSpBdbPnDlTcXFxFdq2ihSzb58GXXWVvFFR+mzWLHm90siR5+kzDdVQzdWvN96orWeeqQ8/7KB33umiAQO2aOLEleFuNgAAAADUCGlpaRo9erSOHDlSZMG53JXuCy64QP/4xz+0a9cuHXfccYH1Z555ps4///zynr6Apk2bqkuXLkHrOnfurI8++ijk/nfeeacmT54cWE5OTlZSUpIGDhxYKZX4ipK9dq0kyREbqyFDhsg/QLy/0t29Sxd1GzJEa9ZYdwg0bZqkIUOahaWtNZXH49GCBQt01llnyeW/uR62QozsjxjZHzGyP2Jkf8TI/oiRvdk1Pv5e1MUpd9ItSU2aNFGTJk0CF/7666/VsWNHderUqSJOH+S0007TX3/9FbTu77//VqtWrULu73a75c65Jzovl8tlq4AV4PVaP91uuVwu+XJ6jvvv6Y7y+SSXy3+7t7xeh1wupl0PB9t/lkCMIgAxsj9iZH/EyP6Ikf0RI3uzW3xK2pZyZ2kXXXSRnn32WUnWnN09e/bURRddpGOPPbbQ6nN53HLLLfr+++/1yCOPaP369Zo5c6b+85//6IYbbqjwa4WVf/TynKw6I8NaZJ5uAAAAAIgc5U66lyxZEpgy7OOPP5Zpmjp8+LCefvppPfTQQ+VuYH4nnXSSPv74Y7377rvq1q2bHnzwQU2fPl1jxoyp8GuFk+Ef/C3PyOWS5HMEj17OlGEAAAAAYF/l7l5+5MgR1atXT5I0b948jRw5UnFxcRo6dKj+7//+r9wNDOWcc87ROeecUynntg1/aTs6WlJu0m06oySfClS6bTaQHwAAAABAFVDpTkpK0vLly5Wamqp58+Zp4MCBkqRDhw4pJiam3A2ssQqrdDupdAMAAABApCh3pXvSpEkaM2aM4uPj1apVK/Xv31+S1e28e/fu5T19zZWTZZtutwzlq3RLVLoBAAAAIAKUO+m+/vrr1atXL23btk1nnXWWHA6reN62bdtKuae7xiik0m1GUekGAAAAgEhRIVOG9ezZUz179pRpmjJNU4ZhaOjQoRVx6pqr0KSbSjcAAAAARIoKmdj5zTffVPfu3RUbG6vY2Fgde+yxeuuttyri1DWXf8qwfAOpKSq4tE2lGwAAAADsq9yV7qeeekpTpkzRxIkTddppp0mSvv32W1177bXav3+/brnllnI3siYqbMowuYJL21S6AQAAAMC+yp10P/PMM3rhhRc0duzYwLpzzz1XXbt21f3330/SXVaFJd35Kt35epsDAAAAAGyk3N3Ld+3apd69exdY37t3b+3atau8p6+5Ckm6jXyVbrqXAwAAAIB9lTvpbt++vT744IMC699//3116NChvKevufJMGZZnMbd7OQOpAQAAAIDtlbt7+dSpUzVq1CgtWbIkcE/3d999p4ULF4ZMxlFC/iw7JiZo0XAxZRgAAAAARIpyV7pHjhypH374QQ0aNNAnn3yiTz75RA0aNNCPP/6o888/vyLaWDMVMnq5QaUbAAAAACJGhczT3aNHD7399ttB6/bu3atHHnlEd911V0VcouYp7J7uaCrdAAAAABApKmSe7lB27dqlKVOmVNbpq738U4ZlZFiLjmgq3QAAAAAQKSot6UY5FVLpdriDK91MGQYAAAAA9kXSbVeFJd35Kt35xlUDAAAAANgISbddFTJlGJVuAAAAAIgcZR5IbfLkyUVu37dvX1lPDanQ0cud7tCVbpJuAAAAALCfMifdv/76a7H79O3bt6ynRynv6fb5rIeDvgsAAAAAYBtlTroXLVpUke1AfoUk3YVVuv2rcgrjAAAAAAAboC5qU/mnDPMvRsWGrnTnWQUAAAAAsAmSbrsqLOmOKbrSDQAAAACwD5Juu/IPpJa/e3kMlW4AAAAAiBQk3XZVwkq3wyEZRtAqAAAAAIBNkHTblX+e7pyR0TIyrNVRccGVbolpwwAAAADArso8enlehw8f1o8//qi9e/fK5/MFbRs7dmxFXKLmyVfpTk21FmNqBVe6JauLeVYW3csBAAAAwG7KnXR/+umnGjNmjFJSUpSYmCjD39dZkmEYJN1lVVjSnVCwrE2lGwAAAADsqdzdy2+99VZdfvnlSklJ0eHDh3Xo0KHA4+DBgxXRxprHNGX4+5PnJN1padZibELO30nylLWjCq4CAAAAANhAuZPuHTt26KabblJcXFxFtAdScMna7ZZp5la6YxOpdAMAAABApCh30j1o0CD99NNPFdEW+Llc8mRm6tMPP5Tq1FFWluT1Wpti4ql0AwAAAECkKPc93UOHDtX//d//afXq1erevbtc/rJrjnPPPbe8l6iZDEM+l0syDKWm5K6OSyw4kBqVbgAAAACwp3In3VdddZUk6YEHHiiwzTAMef0lWpSZv2u5yyW5/FOG+XzWw+Gg0g0AAAAANlXupDv/FGGoeP5B1GrVUm5fcskqbUdHB1ZR6QYAAAAAeyn3Pd2ofP5Kd61ayu1LLgVK23QvBwAAAAB7KlOl++mnn9bVV1+tmJgYPf3000Xue9NNN5WpYcjlT7rj4lSw0i0GUgMAAAAAuypT0v3vf/9bY8aMUUxMjP79738Xup9hGCTdFYBKNwAAAABEpjIl3Zs2bQr5HJUjKOl2OCTDkEyTSjcAAAAA2Bz3dEeAoIHUpNzSNpVuAAAAALC1co9eLknbt2/X//73P23dulVZWVlB25566qmKuESNFlTplqzSdlYWlW4AAAAAsLlyJ90LFy7Uueeeq7Zt22rt2rXq1q2bNm/eLNM0deKJJ1ZEG2u8oIHUpAKVbqYMAwAAAAB7Knf38jvvvFO33Xab/vjjD8XExOijjz7Stm3b1K9fP1144YUV0cYaL2SlWwpk2flycAAAAACATZQ76V6zZo3Gjh0rSYqKilJ6erri4+P1wAMP6NFHHy13AxEi6abSDQAAAAARodxJd61atQL3cTdt2lQbNmwIbNu/f395Tw+VvNJN0g0AAAAA9lLue7pPOeUUffvtt+rcubOGDBmiW2+9VX/88Ydmz56tU045pSLaWOMVN3o5A6kBAAAAgD2VO+l+6qmnlJKSIkmaOnWqUlJS9P7776tDhw6MXF5BqHQDAAAAQGQqV9Lt9Xq1fft2HXvssZKsruYvvvhihTQMuQodvZwpwwAAAADA1sp1T7fT6dTAgQN16NChimoPQii00p2TZVPpBgAAAAB7KvdAat26ddPGjRsroi0oRKGjl1PpBgAAAABbK3fS/dBDD+m2227TZ599pl27dik5OTnogfIrMJBaviybKcMAAAAAwJ7KfE/3Aw88oFtvvVVDhgyRJJ177rkyDCOw3TRNGYYhr9db/lbWcCUdSI1KNwAAAADYS5mT7qlTp+raa6/VokWLKrI9pfKvf/1Ld955p26++WZNnz49bO2obIUOpEalGwAAAABsrcxJt2makqR+/fpVWGNKY8WKFXrppZcCI6dXZ0wZBgAAAACRqVz3dOftTl6VUlJSNGbMGL388suqW7duWNpQVXy+EPd0F1Lppns5AAAAANhLuebpPuaYY4pNvA8ePFieS4R0ww03aOjQoRowYIAeeuihIvfNzMxUZmZmYNk/uJvH45HHxlmqv23JyR5JVpIdHe2RxyM5HQ45JGVnZsr0eORwOCQ5lZXlk8fDPfRVxR8jO3+OajpiZH/EyP6Ikf0RI/sjRvZHjOzNrvEpaXvKlXRPnTpVtWvXLs8pSu29997TL7/8ohUrVpRo/2nTpmnq1KkF1s+fP19xgZuk7euLL76RNFiStHjxXDkc0kkHDqiZpFW//qrNc+dq/fp2krpp8+Ydmjv3l3A2t0ZasGBBuJuAYhAj+yNG9keM7I8Y2R8xsj9iZG92i0+av0tyMcqVdF988cVq1KhReU5RKtu2bdPNN9+sBQsWKCYmpkTH3HnnnZo8eXJgOTk5WUlJSRo4cKASExMrq6nl5vF4tGDBAp10Un9JUkyMqXPOsUaKd779tiSpW6dO6jJkiDZssO4SaNy4uYYMaRKW9tZE/hidddZZcvm7/MNWiJH9ESP7I0b2R4zsjxjZHzGyN7vGp6RTZJc56Q7H/dw///yz9u7dqxNPPDGwzuv1asmSJXr22WeVmZkpp9MZdIzb7Zbb7S5wLpfLZauAFSYz0wpRrVpGbntzXo/T55PT5fIvyut1yOUq99TrKKVI+SzVZMTI/oiR/REj+yNG9keM7I8Y2Zvd4lPStpR79PKqdOaZZ+qPP/4IWjdhwgR16tRJt99+e4GEuzpIS7P+uBEYRE0qMHo5U4YBAAAAgD2VOen2+XwV2Y4SSUhIULdu3YLW1apVS/Xr1y+wvrooMF2YVGD08nyLAAAAAACboC+yzRWYLkyi0g0AAAAAEaJcA6nZweLFi8PdhEpVmko3STcAAAAA2AuVbpvzV7qDZjcrpNJN93IAAAAAsBeSbptLTQ0xkBqVbgAAAACICCTdNheyezmVbgAAAACICCTdNhdyILV8pW0GUgMAAAAAeyLptrkiRy9nyjAAAAAAsDWSbpvzdy8PGkiNSjcAAAAARASSbpsLOZBaIZVukm4AAAAAsBeSbptjIDUAAAAAiFwk3TZX5EBqVLoBAAAAwNZIum2uyIHUqHQDAAAAgK2RdNuc/57ukAOpUekGAAAAAFsj6bY57ukGAAAAgMhF0m1zJbmnmynDAAAAAMCeSLptriSV7nw5OAAAAADAJki6ba60lW7TrLq2AQAAAACKRtJtY16vlJlpDaRWkkq3JPl8VdQ4AAAAAECxSLptLDMzKvC8qNHLo3J3o4s5AAAAANgISbeNZWQ4JUmGIcXE5NlQRKWbwdQAAAAAwD5Ium3MX+muVctKvAOodAMAAABARCDptrHMTKvSHXQ/t1ToPN15VgEAAAAAbICk28b83csLJN35Kt2GITmdQasAAAAAADZA0m1j/u7lQYOoSQUq3YWsAgAAAACEGUm3jRVb6c6TYecrfgMAAAAAbICk28YKTbr9Ze08GTaVbgAAAACwH5JuG8s7enmQIirdJN0AAAAAYB8k3TZW7OjlISrddC8HAAAAAPsg6bYxf/fyAgOpUekGAAAAgIhA0m1jhXYv95e1vV7JNINWUekGAAAAAPsg6baxYgdSkwKlbQZSAwAAAAD7Iem2sULv6fb3JZcCpW2mDAMAAAAA+yHptrFiB1KTqHQDAAAAgI2RdNtYRoaVSRc6kJpEpRsAAAAAbIyk28YKrXQ78oSNSjcAAAAA2BZJt435K90Fkm7DKFDaZsowAAAAALAfkm4bK7TSLRUobTNlGAAAAADYD0m3jRWZdFPpBgAAAADbI+m2sUK7l0tUugEAAAAgApB025i/0l1g9HKpQKWbgdQAAAAAwH5Ium3KNKWMjJLf082UYQAAAABgPyTdNpWVJfl8VnhKck83lW4AAAAAsB+SbptKTc19TqUbAAAAACITSbdNpaVZP10uM5BQB6HSDQAAAAC2R9JtU/5Kd8hB1KRCK90k3QAAAABgHyTdNuWvdIfsWi4VyLKZMgwAAAAA7Iek26ZSUw1JJah0070cAAAAAGyLpNum/N3LS1rpZiA1AAAAALAfkm6byu1ebobegUo3AAAAANgeSbdNlXUgNSrdAAAAAGAfEZd0T5s2TSeddJISEhLUqFEjDR8+XH/99Ve4m1Xh0tKKuaebKcMAAAAAwPYiLun+5ptvdMMNN+j777/XggUL5PF4NHDgQKX6S8PVRLH3dDNlGAAAAADYXlS4G1Ba8+bNC1p+/fXX1ahRI/3888/q27dvmFpV8XKT7kLu6S6k0k33cgAAAACwj4irdOd35MgRSVK9evXC3JKKVew83VS6AQAAAMD2Iq7SnZfP59OkSZN02mmnqVu3biH3yczMVGZmZmA5OTlZkuTxeOSxcVk4JUWSnIqJ8cnj8RXY7nQ65ZDkzciQz+ORYTgkOZWZ6ZPH463i1tZM/s+PnT9HNR0xsj9iZH/EyP6Ikf0RI/sjRvZm1/iUtD0RnXTfcMMN+vPPP/Xtt98Wus+0adM0derUAuvnz5+vuEJHKQu/deuOl9RKO3as09y56wpsP2HPHrWUtPbPP7V+7lxt2NBS0gnasGGf5s79vopbW7MtWLAg3E1AMYiR/REj+yNG9keM7I8Y2R8xsje7xSfN3z25GBGbdE+cOFGfffaZlixZohYtWhS635133qnJkycHlpOTk5WUlKSBAwcqMTGxKppaJm+9ZY1eftxx7TVkSIcC2x2ffy4tWqROLVromCFDFBVl6LnnpKysRhoyZEhVN7dG8ng8WrBggc466yy5/P37YSvEyP6Ikf0RI/sjRvZHjOyPGNmbXePj70VdnIhLuk3T1I033qiPP/5YixcvVps2bYrc3+12y+12F1jvcrlsFbD80tOtLuWJiQ65XCHC1LKlJMm5a5ecLpf8b8P27YatX1d1ZPfPEohRJCBG9keM7I8Y2R8xsj9iZG92i09J2xJxA6ndcMMNevvttzVz5kwlJCRo9+7d2r17t9LT08PdtArlH7280B7wOUm3tm6VJCUlWYuHD/vvBy89j0f6+WfJV/AWcgAAAABAGURc0v3CCy/oyJEj6t+/v5o2bRp4vP/+++FuWoUqdvTyfEl3QoJUu7a1atu20l8vNVU64wypZ09p5szSHw8AAAAAKCgiu5fXBKmp1j3dJap0m6ZkGEpKko4csVZ17lzya6WnS+eeK/nHo/vlF+nSS8vedgAAAACAJeIq3TVFsZXu5s0lw5AyMqT9+yXldjEvcaX755/left9jTjf1Ndf567OKZ4DAAAAAMqJpNumcu/pLqSy73ZLTZpYz/Pd111s0r17tzR+vNSzp1yXXazDX36vuDjp1luDTgcAAAAAKCeSbpvyJ92FVrqlQgdTKzTp9nikp56SOnaU3ngjsPrYqDX69FNp9Oig0wEAAAAAyomk24ZMU0pLs+7pLk3S7V8MmXSbpnTOOVY5OzlZ6tlT30WfLkm68bwtOuOM3OP37JEyMyvghQAAAABADUfSbUMej3TKKT61bn2k4irde/ZI8+db94G//LLSFv2gz7MGSJI6uLZIkurXl2Jjrd23b6+AFwIAAAAANRxJtw1FR0tLlng1ffpixccXsWMRSXeBQd7Xr7d+tmolXXmlNm52aItaSZLcu62k2zAKnBIAAAAAUA4k3ZEsX4bcooW1mJYmHTqUb98NG6yf7dtLsnLwzWptrduypbBTAgAAAADKgaQ7kuXLkGNipIYNrVUFupj7K905SfeGDQpUurVtm+T1hjolAAAAAKAcSLojmT9D3r07MPJZofd1+5Pudu0Ci7vUVF5HlJSdLe3cGXQ8STcAAAAAlB9JdySrX1+Ki7Oe52TZhSbNISrdPjmVVj/ngJwu5lS6AQAAAKDikHRHshAjnxVa6Q5xT7ckeVvkdDEn6QYAAACACkfSHelKknQfPJg7slrbtsrKyh07LbpDa+tJiKS7wAjoAAAAAIBSIemOdCVJuv1l7ebNpbg4bdki+XxWz/TYTjmV7s2bJQWPgH7wYOU2HQAAAACqO5LuSFeapDvPIGr+RaN1cPfy2FipUaOgUwIAAAAAyoikO9IVknRv325VsyWFHEQtsNgqOOkOcUoAAAAAQBmRdEe6fBlys2bW+Goej7R3b84+hQyi1q6dcpPuPDdx+09ZYDA2AAAAAECpkHRHunwjn7lcVuIt5Uma81W6gxaTkqwsPT1d2revwCkBAAAAAGVH0h3p/COfpadLBw5ICnFfd757uv2F73btJEVH52bpOYOpkXQDAAAAQMUg6Y50brfUpIn1PNRgasnJuf3M27WT1ytt3Ggt5hS+C9zXTdINAAAAABWDpLs6KGQwta1blVvWbthQql1bO3ZIWVmSy5W7X/6kO+h4AAAAAECZkXRXB0VNG1bIIGpt2khOZ87xhVS6d+60BmQDAAAAAJQNSXd1UFTSXcj93IGu5VKBpLtRI+tWb9OUduyoxHYDAAAAQDVH0l0dlCTpDjVdmF/r1tbPnKTb4aCLOQAAAABUBJLu6qCQpHvXLslcV8R0YX7+SnfO6OUhTgkAAAAAKAOS7uogX4bcuLE1UJrPJ3n/Ds6yg6YLy398crJ0+HCoUwIAAAAAyoCkuzrwZ8i7dkmZmXI4pObNpRilK2p3zk3Z7drJNAupdNeqJTVoYD1n2jAAAAAAqDAk3dVBgwZSTIz1PGfks6Qkqa1yJuSuXVuqX19790qpqZJh5N7GHcBc3QAAAABQ4Ui6qwPDCHlfd3vlKWsbRqDK3bKl5HbnO0e+wdT8p9u2rfKaDQAAAADVHUl3dZEv6W7ZMl/SrUKmC/PLN5galW4AAAAAKL+ocDcAFSTkCObBo6aFnC7ML1/3cv8I6MnJ0pEjVg91AAAAAEDpUOmuLvxJ99KlUmZmUPfy7TFFTBfmly/prlVLqlfPWkW1GwAAAADKhqS7ujj9dOvn/PnSySerR8wqdchJui+5t70uvFD6+Wdrl5JUuiW6mAMAAABAeZF0Vxd9+0qffGKNZP7bb2o2rIdaG5slSRvUXrNmSX//be0astLtH0ht3z4pLU0SSTcAAAAAlBdJd3Vy3nnSH39IgwdLmZkyTFOKi9P835voggusXRISCkm669SREhOt50wbBgAAAAAVgqS7umnSRPr8c+nZZ6XYWGngQHXrbujDD61K9y+/SHFxhRybr4u5v/j92WdSSkqltxwAAAAAqh2S7urIMKQbbpAOHJA++iiwukOHQqrcfv6k+/vvJUkXXyw1aiT9+ac0erTk9VZimwEAAACgGiLprs5iYyVHKUI8cKD184EHpDfeUPPm0pw5UkyM9Omn0m23VU4zAQAAAKC6IulGrokTpeuvl0xTmjBBevttnXKK9Oab1ubp06Xnnw9rCwEAAAAgopB0I5dhSM88I11zjZV4jxsnvfeeLrxQeuQRa5cbb5T++9/AAOcAAAAAgCKQdCOYw2GVs6+8UvL5pEsvlf7v/3THwF80Ybwpn0+64gprZrLzz5feeEM6eDDcjQYAAAAAeyLpRkEOh/TSS9L48dboaU88IaNnD726pIMW975TZzRbq/R0a1rw8eOlZs2ksWOt8ddMM8xtBwAAAAAbIelGaA6H9Oqr0qxZ0gUXSLGxMjZuUL9l/9LCnZ11uP9wvXLFcnXvLmVmSm+9JZ16qnTiidILL0jbtoX7BQAAAABA+JF0o3AOhzRypPThh9LevdL770vDhkmGodqL5+iKV3vr9zp99fejH+vKyzIVEyOtXGmNxdaypdS1qzR5sjR/vpSVFe4XAwAAAABVj6QbJRMfL110kfS//0mrV1s3drtc0tKl6nD7CL38v8Y6fP4EfXTVPJ3WyyOHw9rt3/+WBg2y5vu+7DJrCrL09HC/GAAAAACoGiTdKL1OnaRXXpE2b5Zuv11q3lw6ckTud1/XiJcH69uNzZRy3W2a+++/dPnlUuPG0pEj0ttvS8OHSw0bWgXzGTOkP//kPnAAAAAA1RdJN8quWTPpX/+Stm6Vliyx+pU3bCjt36/Y557U4Fs66dV1fbXzX29q+WcHNGmSlJQkpaZKn30mTZokde9unWbMGOm116xTAQAAAEB1ERXuBqAacDikPn2sx4wZ0hdfSC+/LH3+ubR0qRxLl+oUw9ApJ5ygp0adqfWtB+izw//QvCVxWrpU2r1bmjnTekhS+/bSgAHSmWdKp58u1a8f3pcHAAAAAGVF0o2KFRVl9R0fNkzascMqX7//vtWP/JdfZPzyizrocd0SHa1bevdW9u0D9FvDAfrfjh6a/3WUVqyQ1q+3Hi++KBmGdMIJVvLds6fUo4fUrp3kyMqQsrOtucR9PuvatWtbBwAAAACATZB0o/I0by7dc4/12L1b+vpr6auvrMe2bdLixYpavFg9dI96xMVpaq9eyrj5VP0ed6oWbWip375P165N6Yr9JV0Hf9mtnfpT9fSn4o0/1dTcVeByWbXqKL1NF5mdush1bGfFnnaiHCefJNWqFYYXDwAAAAARnHQ/99xzevzxx7V7924dd9xxeuaZZ9SrV69wNwuFadJEGj3aepimVcr2J+CLFkmHDkmLFytm8WL1klRkJAsZeC069bCi/1wm/blMmmWty5ZT62OP1fqGp2pn61OV3OVUuTq2VZOmhho2lOrUsQrk/p9REfuNAAAAAGBHEZlivP/++5o8ebJefPFFnXzyyZo+fboGDRqkv/76S40aNQp381Acw5A6dLAe111ndQ9fs0Zavjz3cfCgFBcnxcZaj7p1pa5dld2luzbFddNv6cdo9+EY7Tvg0L79hg7syZZ7+wbV271aTQ+tVvvMP9VLPypJ29Up/Vd12vqrtPV5aYm0Vw31vU7RAp2q5TpVK3SS0mRVw2vVCk7CQ/2sW9f6GR9vaM2aemrc2FCtWpLbbTW1Vi1rhrXo6PC9xQAAAADsISKT7qeeekpXXXWVJkyYIEl68cUX9fnnn+u///2v7rjjjjC3DqXmcEhdu1qPK68sctcoSR1yHsGiJXXPeUhZWdLevdLvv2+XZ+lyuX9erjprl6vJjl/UyLdP5+pTnatPJVnV8N91rH5WDx1NTVBWarSydkYrS8GP/YrWzjzLmXLLI5fma4myFaVsRckjV+C5olyKjnUqrpahmFgj8NMZZchwGHI4rZ/RbkOuaEPuGEMutyG325DL7ZA71iGX2yHD6VCmx6GMLOvh9UqJ7kzrEZ2hWtEeebINZXocSs+09nFEORQVnftwuR1yuSRXtHU9w5A82YY82YayPIZMU4qNs9oYF2c9d0ZZbXQ4JBm5z/3tNhzBy/7nQcs5D8NQyGXDKP5R2H4AAABAJDBMM7JmSc7KylJcXJxmzZql4cOHB9aPGzdOhw8f1pw5c4L2z8zMVGZmZmA5OTlZSUlJ2r9/vxITE6uq2aXm8Xi0YMECnXXWWXK5XOFuTvWRmSnj119lfP+99fjhBxk7doS7VdWaT1aGbMoIPPIuh2ubjNxl/3NDkmnkOc602h84zjRyXk/OspHvnP59jdzrGUH7BR9n+Ntl5NmW93pG8GuQCvlrQ7n/CFHECUp47lC7mSX864jX65XT6Sz8XPlWmIU0qkRXK3KnYs5QggsUtktx70WJQxjivSjpsSX6n33OToH2mtZ/PNnZioqKClytyHOZIZ+GWDYK37HQY0JvzP0u5/xhTqZyvoryf72MfJcsmcr5C19JvxslP6H1e4PL5arYv0oGhaiy/toZIe9xQNnOa8r6HTY6Orpc/16WTWS9x2X5rJXkiOLaa5pSVmaWot3RpfoalaS9ZXmnKus7F+p9qKgrVUab6zz2T3W6+Hjb5kbJyclq0KCBjhw5UmRuGXGV7v3798vr9apx48ZB6xs3bqy1a9cW2H/atGmaOnVqgfXz589XXFxcpbWzoixYsCDcTaiejjnGeowdq5j9+1Xvr7+UsHWrHNnZcng8wT9zHkae5/7thtcrh9crI+fh8Holr09Gdu46mbL+JTclwzQlmTJyfpH1L1u/H5oyTJ8cJfvVWD4Z8jii5TGsfuwO+eQwfXLIK8M05ZCvVOerLLnXt9nf98xCnpf1HAAAAKhQb83rrY2JOwPLdsuN0tLSSrRfxCXdpXXnnXdq8uTJgWV/pXvgwIFUulEuFRGjUHmfV8pJ0s3cKdHyPkxTiomRoqLkMAy5Czm3z38+/5Rq/nPmfZ5/uZK3mT7Tegk+Uz6vaa32WetlBi/7n/uPC9pXwcf5r2Eod5tMU9kej37++Rf1OPEEReVUUk2f5PWa8mVb5/Rm57bFv95hmFa3dhV8nvcahkK3M/BckvK9Pv82f5tNn0r+foaQf3VJ+y4F7VfCc5f0/KHOHfIw06pyb9y4UW3btpXT6Sz4ego5Lv+FitwvVLuKOy7fzgX2K+F7E/L8vmLOXZ7z+8yiKzQl6CyR/3if6dOWzVvUulVLOawvQ6GnK+ra+bcZQecp/INV1HH55f+n03pufc/yfp0qTClOWNpLG6U4t8/n07bt25XUooUVo1DXDzpd5f3FMFS7K+p9L+pzUpQSXb8SO34aMuXz+bRjxw41b968QIzKd+nKj2VlvTVljWd+odtX+nObPp927tylZs2ayijkeySV7rtZ+kZU7uew8i5Zee3uf90QNTm5lW1zo+Tk5BLtF3FJd4MGDeR0OrVnz56g9Xv27FGTJk0K7O92u+V2F0xLXC6XrQJWmEhpZ01GjOzL4/HI8O5Rk7N7EiOb8ng82jZ3rroPGUKMbMrj8Wjv3LnqQYxsy+Px6ODcuTqFGNmWx+PRXGJka8QoMtjt9+6StqXwP+PYVHR0tHr06KGFCxcG1vl8Pi1cuFCnnnpqGFsGAAAAAECwiKt0S9LkyZM1btw49ezZU7169dL06dOVmpoaGM0cAAAAAAA7iMike9SoUdq3b5/uvfde7d69W8cff7zmzZtXYHA1AAAAAADCKSKTbkmaOHGiJk6cGO5mAAAAAABQqIi7pxsAAAAAgEhB0g0AAAAAQCUh6QYAAAAAoJKQdAMAAAAAUElIugEAAAAAqCQk3QAAAAAAVBKSbgAAAAAAKknEztNdVqZpSpKSk5PD3JKieTwepaWlKTk5WS6XK9zNQQjEyP6Ikf0RI/sjRvZHjOyPGNkfMbI3u8bHn1P6c8zC1Lik++jRo5KkpKSkMLcEAAAAABDpjh49qtq1axe63TCLS8urGZ/Pp507dyohIUGGYYS7OYVKTk5WUlKStm3bpsTExHA3ByEQI/sjRvZHjOyPGNkfMbI/YmR/xMje7Bof0zR19OhRNWvWTA5H4Xdu17hKt8PhUIsWLcLdjBJLTEy01QcLBREj+yNG9keM7I8Y2R8xsj9iZH/EyN7sGJ+iKtx+DKQGAAAAAEAlIekGAAAAAKCSkHTblNvt1n333Se32x3upqAQxMj+iJH9ESP7I0b2R4zsjxjZHzGyt0iPT40bSA0AAAAAgKpCpRsAAAAAgEpC0g0AAAAAQCUh6QYAAAAAoJKQdAMAAAAAUElIugEAAAAAqCQk3QAAAAAAVBKSbgAAAAAAKglJNwAAAAAAlYSkGwAAAACASkLSDQAAAABAJSHpBgAAAACgkpB0AwAAAABQSUi6AQAAAACoJCTdAACUwubNm2UYhl5//fXAuvvvv1+GYZToeMMwdP/991dom/r376/+/ftX6DkBAEDFIOkGAFRb5557ruLi4nT06NFC9xkzZoyio6N14MCBKmxZ6a1evVr333+/Nm/eHO6mBCxevFiGYYR8XHzxxYH9fvzxR11//fXq0aOHXC5Xif9A4ZeVlaUZM2bohBNOUGJiourUqaOuXbvq6quv1tq1ayv6ZQEAUKGiwt0AAAAqy5gxY/Tpp5/q448/1tixYwtsT0tL05w5c3T22Werfv36Zb7OPffcozvuuKM8TS3W6tWrNXXqVPXv31+tW7cO2jZ//vxKvXZxbrrpJp100klB6/K2ce7cuXrllVd07LHHqm3btvr7779Ldf6RI0fqiy++0CWXXKKrrrpKHo9Ha9eu1WeffabevXurU6dOFfEyAACoFCTdAIBq69xzz1VCQoJmzpwZMumeM2eOUlNTNWbMmHJdJyoqSlFR4ftfanR0dNiuLUl9+vTRBRdcUOj26667TrfffrtiY2M1ceLEUiXdK1as0GeffaaHH35Yd911V9C2Z599VocPHy5rs0stIyND0dHRcjjoKAgAKDn+rwEAqLZiY2M1YsQILVy4UHv37i2wfebMmUpISNC5556rgwcP6rbbblP37t0VHx+vxMREDR48WL/99lux1wl1T3dmZqZuueUWNWzYMHCN7du3Fzh2y5Ytuv7669WxY0fFxsaqfv36uvDCC4O6kb/++uu68MILJUmnn356oAv34sWLJYW+p3vv3r264oor1LhxY8XExOi4447TG2+8EbSP//70J554Qv/5z3/Url07ud1unXTSSVqxYkWxr7ukGjdurNjY2DIdu2HDBknSaaedVmCb0+ks0ENhx44duuKKK9SsWTO53W61adNG1113nbKysgL7bNy4URdeeKHq1aunuLg4nXLKKfr888+DzuPvOv/ee+/pnnvuUfPmzRUXF6fk5GRJ0g8//KCzzz5btWvXVlxcnPr166fvvvuuTK8RAFC9UekGAFRrY8aM0RtvvKEPPvhAEydODKw/ePCgvvzyS11yySWKjY3VqlWr9Mknn+jCCy9UmzZttGfPHr300kvq16+fVq9erWbNmpXquldeeaXefvttjR49Wr1799bXX3+toUOHFthvxYoVWrZsmS6++GK1aNFCmzdv1gsvvKD+/ftr9erViouLU9++fXXTTTfp6aef1l133aXOnTtLUuBnfunp6erfv7/Wr1+viRMnqk2bNvrwww81fvx4HT58WDfffHPQ/jNnztTRo0d1zTXXyDAMPfbYYxoxYoQ2btwol8tV7Gs9evSo9u/fH7SuXr16FVIRbtWqlSTpnXfe0WmnnVZkj4KdO3eqV69eOnz4sK6++mp16tRJO3bs0KxZs5SWlqbo6Gjt2bNHvXv3Vlpamm666SbVr19fb7zxhs4991zNmjVL559/ftA5H3zwQUVHR+u2225TZmamoqOj9fXXX2vw4MHq0aOH7rvvPjkcDr322ms644wztHTpUvXq1avcrxsAUI2YAABUY9nZ2WbTpk3NU089NWj9iy++aEoyv/zyS9M0TTMjI8P0er1B+2zatMl0u93mAw88ELROkvnaa68F1t13331m3v+lrly50pRkXn/99UHnGz16tCnJvO+++wLr0tLSCrR5+fLlpiTzzTffDKz78MMPTUnmokWLCuzfr18/s1+/foHl6dOnm5LMt99+O7AuKyvLPPXUU834+HgzOTk56LXUr1/fPHjwYGDfOXPmmJLMTz/9tMC18lq0aJEpKeRj06ZNIY+54YYbzNL8+uHz+cx+/fqZkszGjRubl1xyifncc8+ZW7ZsKbDv2LFjTYfDYa5YsSLkeUzTNCdNmmRKMpcuXRrYdvToUbNNmzZm69atA58B/2tr27ZtUIx8Pp/ZoUMHc9CgQYFzmqYVxzZt2phnnXVWiV8bAKBmoHs5AKBaczqduvjii7V8+fKgLtszZ85U48aNdeaZZ0qS3G53oDLr9Xp14MABxcfHq2PHjvrll19Kdc25c+dKsgYYy2vSpEkF9s3b7drj8ejAgQNq37696tSpU+rr5r1+kyZNdMkllwTWuVwu3XTTTUpJSdE333wTtP+oUaNUt27dwHKfPn0kWd2wS+Lee+/VggULgh5NmjQpU9vzMwxDX375pR566CHVrVtX7777rm644Qa1atVKo0aNCtzT7fP59Mknn2jYsGHq2bNnyPNI1nvTq1cv/eMf/whsi4+P19VXX63Nmzdr9erVQceNGzcuKEYrV67UunXrNHr0aB04cED79+/X/v37lZqaqjPPPFNLliyRz+erkNcOAKgeSLoBANWef6C0mTNnSpK2b9+upUuX6uKLL5bT6ZRkJW3//ve/1aFDB7ndbjVo0EANGzbU77//riNHjpTqelu2bJHD4VC7du2C1nfs2LHAvunp6br33nuVlJQUdN3Dhw+X+rp5r9+hQ4cC3bv93dG3bNkStL5ly5ZBy/4E/NChQyW6Xvfu3TVgwICgR0xMTJnaHorb7dbdd9+tNWvWaOfOnXr33Xd1yimnBN0ysG/fPiUnJ6tbt25FnmvLli0h41DYe9OmTZug5XXr1kmykvGGDRsGPV555RVlZmaWOW4AgOqJe7oBANVejx491KlTJ7377ru666679O6778o0zaBRyx955BFNmTJFl19+uR588MHAPcmTJk2q1MrljTfeqNdee02TJk3Sqaeeqtq1awfmua6qiqn/Dw/5maZZJdcvjaZNm+riiy/WyJEj1bVrV33wwQd6/fXXK+16+QeA88fk8ccf1/HHHx/ymPj4+EprDwAg8pB0AwBqhDFjxmjKlCn6/fffNXPmTHXo0CFobulZs2bp9NNP16uvvhp03OHDh9WgQYNSXatVq1by+XzasGFDUFX1r7/+KrDvrFmzNG7cOD355JOBdRkZGQWmwso/Onpx1//999/l8/mCqt1r164NbI90LpdLxx57rNatW6f9+/erUaNGSkxM1J9//lnkca1atQoZh5K+N/7eC4mJiRowYEAZWw8AqEnoXg4AqBH8Ve17771XK1euLDA3t9PpLFDZ/fDDD7Vjx45SX2vw4MGSpKeffjpo/fTp0wvsG+q6zzzzjLxeb9C6WrVqSVKJ5qUeMmSIdu/erffffz+wLjs7W88884zi4+PVr1+/krwMW1i3bp22bt1aYP3hw4e1fPly1a1bVw0bNpTD4dDw4cP16aef6qeffiqwv/89HjJkiH788UctX748sC01NVX/+c9/1Lp1a3Xp0qXI9vTo0UPt2rXTE088oZSUlALb9+3bV9qXCACo5qh0AwBqhDZt2qh3796aM2eOJBVIus855xw98MADmjBhgnr37q0//vhD77zzjtq2bVvqax1//PG65JJL9Pzzz+vIkSPq3bu3Fi5cqPXr1xfY95xzztFbb72l2rVrq0uXLlq+fLm++uqrAvNPH3/88XI6nXr00Ud15MgRud1unXHGGWrUqFGBc1599dV66aWXNH78eP38889q3bq1Zs2ape+++07Tp09XQkJCqV9TeWzZskVvvfWWJAUS4oceekiSVVm+7LLLCj32t99+0+jRozV48GD16dNH9erV044dO/TGG29o586dmj59eqB7/COPPKL58+erX79+uvrqq9W5c2ft2rVLH374ob799lvVqVNHd9xxh959910NHjxYN910k+rVq6c33nhDmzZt0kcffVTsNGcOh0OvvPKKBg8erK5du2rChAlq3ry5duzYoUWLFikxMVGffvppRbxtAIBqgqQbAFBjjBkzRsuWLVOvXr3Uvn37oG133XWXUlNTNXPmTL3//vs68cQT9fnnn+uOO+4o07X++9//qmHDhnrnnXf0ySef6IwzztDnn3+upKSkoP1mzJghp9Opd955RxkZGTrttNP01VdfadCgQUH7NWnSRC+++KKmTZumK664Ql6vV4sWLQqZdMfGxmrx4sW644479MYbbyg5OVkdO3bUa6+9pvHjx5fp9ZTHpk2bNGXKlKB1/uV+/foVmXT37dtXDz74oL744gs99dRT2rdvnxISEnTCCSfo0Ucf1ciRIwP7Nm/eXD/88IOmTJmid955R8nJyWrevLkGDx6suLg4SVLjxo21bNky3X777XrmmWeUkZGhY489Vp9++mnIedRD6d+/v5YvX64HH3xQzz77rFJSUtSkSROdfPLJuuaaa0r79gAAqjnDtOMoKQAAAAAAVAPc0w0AAAAAQCUh6QYAAAAAoJKQdAMAAAAAUElIugEAAAAAqCQk3QAAAAAAVBKSbgAAAAAAKglJNwAAAAAAlSQq3A2oaj6fTzt37lRCQoIMwwh3cwAAAAAAEcg0TR09elTNmjWTw1F4PbvGJd07d+5UUlJSuJsBAAAAAKgGtm3bphYtWhS6vcYl3QkJCZKsNyYxMTHMrSmcx+PR/PnzNXDgQLlcrnA3ByEQI/sjRvZHjOyPGNkfMbI/YmR/xMje7Bqf5ORkJSUlBXLMwtS4pNvfpTwxMdH2SXdcXJwSExNt9cFCLmJkf8TI/oiR/REj+yNG9keM7I8Y2Zvd41PcbcsMpAYAAAAAQCUh6QYAAAAAoJKQdAMAAAAAUElIugEAAAAAqCQk3QAAAAAAVBKSbgAAAAAAKglJNwAAAAAAlSSs83QvWbJEjz/+uH7++Wft2rVLH3/8sYYPH17kMYsXL9bkyZO1atUqJSUl6Z577tH48eOrpL0AKobX69XSpUu1a9cuNW3aVL1799ayZcsCy3369JHT6Qz7NcvbzvzHV8brKotwvP92VZIY2SGOodogKexxjNTPUknaLSnscQdQfdnh/y12Vdj/8yKaGUZz58417777bnP27NmmJPPjjz8ucv+NGzeacXFx5uTJk83Vq1ebzzzzjOl0Os158+aV+JpHjhwxJZlHjhwpZ+srV1ZWlvnJJ5+YWVlZ4W4KClFUjLKzs81FixaZM2fONBctWmRmZ2eHoYVVoySvNe8+U6dONVu0aGFKCjycTmfQcosWLcyPPvqo3G3zx+ijjz4q9TXLckxeoY6vqNdVHuV9XRUtnP/WlSRGdohjqDbUr1/frF+/fpV+j/LHyG6fpZIqSbtDvb92fC1+/M5gf8TI/qoyRnb4f4tdFfXe2PE7VNLcMqxJd14lSbr/+c9/ml27dg1aN2rUKHPQoEElvg5JN8oiVGKZN0bFJZXV9R/SsiYtxT0MwzANwyj3e+aPUVxcXKmu+dFHH5mGYZS5nYUdX1Gvq6zK+7oqQ7j+rStJjOwQx5LGrCq+R3ljZMfPUknY4f2sDPzOYH/EyP6qKkZ2+H+LXRX13sTFxdnyO1TS3NIwTdOUDRiGUWz38r59++rEE0/U9OnTA+tee+01TZo0SUeOHCnRdZKTk1W7dm0dOXJEiYmJ5Wx15fF4PJo7d66GDBkil8sV7ubYWnHdc8rb/XH27Nm6+eabtX379sC6Fi1aaMaMGXI6nfJ6vQW252cYhiRp1qxZGjFiRAW86vCbPXu2LrjgAuX/JyTva5UUch9JkitOioqTDENSziPjkOTLCpynRYsW2rRpU5m7W2VkZOjLL7/UJZdcovT0dCk6XnLX9zfU3+K8jVeDhg1lSjqwb38h++XZX4ZkSA0aNNIrr7wih9Oh7GyvrrryKh04eCB4vzw/6zVooOefe14Oh0O+nPfG9OXuHViX89OX5+3z+fzbQqxTqP2sn9len+6++24dPnQo9zWZwa89qK2Godq16+jee++VYTiC2lWUvK/DlKn8h+RdNmXKm+3T2r/WqmPHjnIYzqBted9r08w9l+l/pTnt97/G/K0zTQV/9kxrH5/p0zNPP6OjR4/mOyL3egkJiZIMHT2anGezEbR3fEKirr3mmsD7U9H/NzVNUy+99JJSCrSzBPI0NT4hQVdfdXWgnaXl9Xm1aeMmtWnbRk6HU6bp03/+87JSUkreLqsNV+W+VwqOS1Xw+Uy98srLSklJKcVRRoE18QkJuuKKKwL/1lW5PB80M+c74PV5tXnzZrVu3VpOR3i7p5pVFdAyCPwbEoYm+nw+bd6yWa1btZbDUfh30R6/lReU/99duwn1/5vS8vl82rpli1q2alVkjMoi8NnzmXr7nbeVlpoaekdDqlUrXmNGj5HhqJr32pRpi7iaPp/emTmz4Htz8Gspdafi4uI0c+ZMDRo0SDExMeFpZAglzS0jKuk+5phjNGHCBN15552BdXPnztXQoUOVlpam2NjYAsdkZmYqMzMzsJycnKykpCTt37/f9kn3ggULdNZZZ5F0F+HTTz/V7bffrh07dgTWNW/eXI8++qiGDRsWcrs/UQ61f6jzX3bZZSETy9jYWL366qu64oorlJaWFrTdNCXTWU9y1ZIjc1vgmObNm+v333+3/T076emmDh7J1KGUDB1OyVRqukcndWmoerXdkqw/ZHTv3j3wvnpjkmTGJEmmRzKzZJjZqlevrnxy62ByhuSIk+msLZ+js8ys7tLRblJy64IXNrKlOn/LiP9TRtQqGb7tGjp0iJo1ayrDkLKzfdp30KsDB0wdPmQoNdWpaLdPtWr5FBcnxcdbSV9WtuTJkg4cTNbB/THavSVeOtpOSmtche8iAAAAyiOq5TC59i1UbGys/vvf/yohIcFW93gnJyerQYMGJN3333+/pk6dWmD9zJkzFRcXVyFtR81w+IiVKCcmeOX/A6jPZ2rzXo9+/ktau66Wdm6vrcN76yvjQDOZmdYXLzbpd501ZK1Gn+lSTLR1YEamtPBXj75fGavEBI9O7uZVr05RirFyWqWkGfr2zyz9tMql/ftrBbXDFZ2t9m1SdGpXh7q0cigqypDPJ63a7NX3q3z6a32CsjKDx0hMrJOhzu3TdVInhzo0d+Yv2Ck729TSVZla9KNbf//WXhk7ukhmvr/yOjyKTVql1p02q+exqTqaKv38W13tXNNF3oOty/8GV5WodMnw/7OX89PI+89gadflLgee5j9/qHVFnit3nWGU5hxG0DqjwH55z6UC6wLXKmJ/oyRVrFCvrcB1Q10//zUL1K7zNcbMWwsv+jqh3pdCr5Nvc6Gvxyh4bDHnqkoF6xb2aVsBNnrfLHnfPbu1LV9sbffeRQbDzu+bndtmc7aOq83Z9b2bcNlGnd4tIdzNKFRaWppGjx5dvZLusnQvp9JdPeWvtIaSv6LtZ33inZJMGYbVFzZUFXrJkm81+KK75Y0bLF/aEOlgD+sERrYUe0CK3Scjo5HM1EaFN9TIlsycBDhul4z6M1U38RQd/PsEyZPvjz7OTNVuvVFej1Mp29pJZvHVcMOdovim25Wyu5nMjJJ9no2YI4pruMeqxvscMn0OZR6pKzO9bsGdHVmSK10yfFJGiO15X2ftTVabfa6ch1OKSpNcqZIzTXKmyIj5W4bjTzmyVsmZvEbKOmx1LDdyui7Xai5vrc7yRXWR6e0m09NICQkJiopyyTQNORw+xSVmKbG2R7Xr+pSYYCgj01RqiqG0VEPpaQ4ZDikqylRUlKmMzBTVik/X36s/ly/1LzlSN8nhKUNX3RL4/PPP9Y9//EPffvuthg4dWuL9q0pJ25VfZbczHP/WlfW9CKUy3x+7tDN/jOz6WSqOXd7PysDvDPZHjOyvKmJk198R7KC49ybSK91hnTKstE499VTNnTs3aN2CBQt06qmnFnqM2+2W2+0usN7lckXEP3qR0s6q9t1332n9+vXWQkxLqe7tkneltH+W5DuUu6ORIDUaL2VcKx1tbyWFeZPZqFQpOlmKOqp1+9NUt+02GWa0fF6nslKOk5m+TDqY7+JmlNVNOa2xVf8wsqV6q6XaP0mu36Ts9VLaRunwJsmZKDW6Wtp7vZTSTGbarYHTGYk71fz41Uo/Gq0D6zpKKY11ZEPn3KbX2arGnTeoTYc05b216PBhhzavaqDULZ1lZsbr6OZO1gZXquJarVWbrvtUv0HujbWmKe3Y6tKOvxsrc8cxMjNqK3Vb7YJvaswhNT3uD51xlkfXjGqj7m0bKj4mVlGO2jJNUwt/Wa+3/rdNS5c4tPX3lvIqRUpcKGV/Je1fIh0uPpn1j4jhk5QdaoeMDdKBDZI+k2EYSmrRQptWlf+e7tGjZykz3y0Aofj/+CJJO3bsCH0veohjWrRoob59+8rpdKpv376qX79+ocfn37+qFNeu/Kq6nVX5b11JYlTc56Aq3p/SxiyUimynP0Z2/ywVxm7vZ2Xgdwb7I0b2V5kxsuvvCHZQkvdGknr37m2r71BJ2xLWpDslJSU3cZK0adMmrVy5UvXq1VPLli115513aseOHXrzzTclSddee62effZZ/fOf/9Tll1+ur7/+Wh988IE+//zzcL0EVLLCBkH76KOPrB3cSZJrsbSrjbXseFZqNE/yzZJcvaT946Q9RXRJya5lPdRUkpSRf3v0Uanpl5LrM+nQF1LaIcnVQIpqpKiYZpp47Ti98Ni1yjxwWDqQ/2BJ2ielPCy5HpPajZRD5+qUfyRq3IUNNHbg8YpxDZAkZWV79OVPq/TJwl2KjjJ00eAk9eveXg6jZaFNP5qRpjnfrtTyXw+qZ7c6GtGvo2rH9Sjy/TyYclT/+3aN1m1JUVSUoSinQ1FOQw3qunXJgC6Kj+kb8jjDMDSgR3sN6NFekhWX1q1ba8eWsictRfH/wzp9+vRy/U8n77GGYRTZDv81Z8yYIckaAK6kx+Rtp9Pp1IwZM0IeX1GvqyyKald+4WxnVShJjIr6HFTV+1OamIVSWe2M1M+SXd9PADWHXX9HsIOSvDf+/SJS+QZJL59Fixb5C19Bj3HjxpmmaZrjxo0z+/XrV+CY448/3oyOjjbbtm1rvvbaa6W6JlOGRY5i51J1NzWVuM6UTFO1N5hq+KvpH6846FF/laljrjXVOMlUwyamGjQwVa+u9bNJG1MtjjPV6h+m2gw0x9zzX3PqG4vMf838xnz646Vm07atC51eJjY2tkzTUVUX/mkd8r8/oaZcKm6Knvxz5CYlJVX5PN35r1mWY/K/P/mPr6jXVR7lfV0VzW7zdJfkc1DVcSzrPN0V/T0qyzzddvjM51fWebrt+Fr8+J3B/oiR/YV7nm47/xtTlYp6b+z4HYq4KcOqClOGRYbCpqMKiG4kxS6WjnSWam+UnP2kw9ul5l2k2Eukw0OluM2S81lp89dSwVu7gxQ2PZW/HZIK/MUtNjZWM2fO1OjRo5Wenl5k1SQpKUnTp0+vNtOF+YWaTi3/ay1syrWrrrpKHTp0KNM0biWV93vkcDhKPXVceaebK246u3Ap7+uqSOH+t64kMbJDHEO1QVKVxLGoGNnps1QaJWm3pLDHvaTC/T1C8YiR/VV1jOzw/xa7CvXe+Hw+W36HIm7KsKpC0m1//q7Loee9biDV6ii5XpAOd5cStkruvtL+LYE9/F1QbrvtNj3xxBOSVKLuj4XNoV1UYlnYPN35k8rq/A+pnZOWmvw9ihTEyP6Ikf0RI/sjRvZHjOzNrvEpaW4ZUQOpoWZYunRpcMJdb6zku15KO0bKqiul5qyP3yHFnCHt2xJ0fIsWLQKV1lNOOaVAQpx/VPO8+4cyYsQInXfeeYX+xW3YsGEht1fXJDs/p9Op/v37l3sfAAAAoDoi6Ybt7Nq1K3chqoGU/KKUnWcO9sStUp3fpIzbpL0bAqsnTpyokSNHBiW8oRLmsnR/DJU0+ny+IrcDAAAAAEk3bKdp06a5C42uk3bGSg1/lRLHSskbpIPpUnLB40aOHBky8Q2VEJMgAwAAAKgKjuJ3AapWnz591KJFC8lwS4cmWisTH5M2/CntSy8wKJphGEpKSgoMfAMAAAAAdkHSDdvxz9OnxpdJ6Y2swdK2zgq5b02f0xAAAACAvZF0w5aGDx+haN8d1kKT6ZInW5IKJNYtWrQodNRxAAAAAAg37ulGWBU2ldS/31qrrL2dJPcRvfmvforKPCmi5oAFAAAAAImkG2EUav7rFi1aaMaMGXr08WMkSV3PXq7LRpwXdByDoAEAAACIFHQvR1jMnj1bF1xwQfB83JJ27NihkeMf0r5V3SSHR9Pva1M1DXrhBalXL+n556XMzKq5JgAAAIBqj0o3qpzX69XNN98s0zStFQnnSO52kmnKlE9yDJeOSk1PXqoBJ5xRuY0xTWnqVOshSStWSI89Jt17rzR2rBTFVwQAAABA2ZFRoEp5vV4988wzuRXuxg9Je+6Wjhbcd9SIHSU/sWlKOSOZl5jPJ02eLM2YYS2PHSt99ZW0ZYt0xRXStGnSe+9JPXqU7rwAAAAAkIPu5agys2fPVuvWrXXLLbdYKxpOtBJuSWrzsdTuXand+1LbD6Uuk3RSsxIMkJaVZVWlExOlUaOkzZtL1pjsbCux9ifczz4rvfGGtH699NRTUsOG1vPnny/16wQAAAAAPyrdqDR5RyZft26d7r///twu5fUvkPblJLyd7pHWPlzg+GbNFhV9gd9/l8aNk1autJY/+ECaM0e65RbpzjutRFyS9u+X/vrLeqxda/384w9p0ybJ6ZRee0267DJr39hY6/iYGOn666XDh8v9PgAAAACouUi6USlCjUweULu/dPhtSQ6pw3PSX8EJt2EYatGihfr06RP65NnZ0uOPS/fdJ3k8Uv361j3ZH38sLVwo/etf0n//K7VvbyXZBw+GPk9MjPTuu9Lw4QW3+RP2I0dK+pIBAAAAoACSblQ4/8jkgaq2n6u7VHe4dPhWyeuWWs+SNt0k5dnNyLkve/r06aHn31671qpu//ijtXzeedJLL0mNG1uV6U8/lW67TVq3Ttq7N/e4pCSpUyepY8fcxwknSA0ahH4R/qQ7OblsbwKAiuH/d6S0YzYAAADYBEk3KlSBkcmdjaX6t0lp50sp7SR/HtxssbT7UinbF3R8ixYtNH36dI0YMSL4xD6fdf/1XXdJGRlS7drSM89Il16a+8u4YUjnniudfbb0ySfWMZ06SR06SLVqle6F1K5t/STpRnVimtb3JyXFeqSnW98T/0OyeoDExVm3Wvh/OkIM/+H1Sqmp0vbt1h/D/I+dO63eKF5v7s8inkdlZ2tQWpqioqIK31+yvt8Oh3VLSIMG0mefWX84AwAAsDmSblSopUuXBncpb/yktHOM9dyZISXNl2I/lra8K2UEz4f973//WzfeeGPBCvemTdL48dKSJdbyoEHSK69ILVqEbkR0tHTRReV7IXQvR3WQliZ98430xRfSl19agwP6fMUfl5/bnZuAezy5CXsFMCTFlGRH08xNwnfulObNI+kGAAARgaQbFWrXrl15lhzSwbOtp50mSvtelzanFjjGfw93yIR7/36pXz9p2zYpPl568knpqqsqv6splW5EMo/H6gUyZ46UmRl6H38S7XRaFWSHI7cSnpYWfFxmpvU4dKjgeRISrB4l/kerVpLLZZ03Ksr6mf95nmWPaerb5cv1j3795IqJCX2MYeRW4++7z/qjG38QAwAAEYKkGxWqadOmuQsJJ0hH60vuI9L6l6zuovkUeQ+3z2fNnb1tm9VF/MsvpTZtKrP5ufyV7rQ0K4FxuarmukBF+PVXazR/yRrPYPBg67aLk06yPtu1alnJbFF8PquanZ5ufQ/8P10u6w9g/ofbXb4/gnk8St61S+ratWTfs+bNrZ8k3QAAIEKQdKNC9enTRy1atNCOHTtkJpwlHZXUeJG0tWDCLRVxD7ckPfqo1S02JkaaNavqEm4pN+mWpKNHpXr1qu7aQHn5K9Ldu0u//Va2pNjhsJLz0o6HUNn8vVBIugEAQIQg6UaFcjqdmjFjhi644ALJM9BaGT1fklXVNk1TU6dOVYcOHdS0aVP16dMn9Cjl33wj3XOP9fzZZ6Vjj62iV5DD5bK63qanW13MSboRSfwJad261W/Ub5JuAAAQYUi6UeFGjBihN978SGPHnWatSLWS7pBV7SNHrJHGHQ6pSxfrntCUFOmSS6zurZddJl1+edW/CMmqdqen88s9Is/hw9bPOnXC2YrKwSCHAAAgwpB0o1IkG8dLvmgZdTbr9cfvU8vmScFV7VWrpOeek95805p2KK+EBKtLd5cu0gsvhK9SV7u2tGcPg6kh8vgTUn9VuDphkEMAABBhSLpRKT7432FJUpduP2hsWob07bfSp59KBw9K69ZJ332Xu3PnzlKjRtLq1dK+fVbCHRcnffhheO8npaKGSOX/zFbHSjfdywEAQIQh6Ual+OW7+pKkpzNfk67+suAODoc0fLg0caLUv39uNXv/fmnNGmuE4rZtq6y9IfmTbipqiDT+7uXVudJN0g0AACIESTcq3Oat2UrZ0VIyvDrp6GZr5dCh1pRA9epJ9etLAwdKLVsWPLhBA6lPnyptb6HoxopIVVO6l/t81h/wAAAAbIykGxXulQ+3SGqn6OYrFL9ps7VyxgypXbtwNqv06F6OSFWdB1LzJ92maQ26mHd6PwAAABsKe4ngueeeU+vWrRUTE6OTTz5ZP/74Y6H7ejwePfDAA2rXrp1iYmJ03HHHad68eVXY2prN6/Vq8eLFevfdd7V48WJ5vd6Q+336Rbok6czO38vIzLTuz67KObYrCt3LEamqc6U7Jsaa0k/iD2IAACAihDXpfv/99zV58mTdd999+uWXX3Tcccdp0KBB2rt3b8j977nnHr300kt65plntHr1al177bU6//zz9euvv1Zxy2ue2bNnq3Xr1jr99NM1evRonX766WrdurVmz54dtJ/PJ635sYUk6aLW262VXbtGZhdQupcjUlXnSrdhcF83AACIKGHNhJ566ildddVVmjBhgrp06aIXX3xRcXFx+u9//xty/7feekt33XWXhgwZorZt2+q6667TkCFD9OSTT1Zxy2uW2bNn64ILLtD27dsl9ZLUVJK0Y8cOXXDBBUGJ9/c/ZchztI4UfVSD462Kt7p3r/I2Vwi6lyNSVedKt0TSDQAAIkrY7unOysrSzz//rDvvvDOwzuFwaMCAAVq+fHnIYzIzMxUTExO0LjY2Vt9++22h18nMzFRmZmZgOTmnaunxeOTxeMrzEiqVv23hbqPX69Xtt9+umJgY+XwnKDNzqQxjg9zuE2UYXhmGoTvuuENDhgyR0+nUqx9ulXSM3B2WqeHGHdY5unSRz8bvdWGM+HhFSfIdPixviPbbJUYoXE2NUdSRIzIkeWrVkmz+2ssSo6jERBmSsg8ckGnz11cd1NTvUSQhRvZHjOyPGNmbXeNT0vaELenev3+/vF6vGjduHLS+cePGWrt2bchjBg0apKeeekp9+/ZVu3bttHDhQs2ePbvQe4sladq0aZo6dWqB9fPnz1dcXFz5XkQVWLBgQbiboCeeeEKS9MabHfXxbIdMs4Ouv36R+vbdEdjnyy+tacHmfHyMJCmp01qlLV+heEk/pKZq39y5Vd7u8mq+YYN6SjqwaZOWFdF+O8QIRatRMfL5dG7OHxcX/vSTMtevD3ODSqY0Meqdna2GklZ+8412mGblNQpBatT3KEIRI/sjRvZHjOzNbvFJS0sr0X4RNXr5jBkzdNVVV6lTp04yDEPt2rXThAkTCu2OLkl33nmnJk+eHFhOTk5WUlKSBg4cqEQbj3rr8Xi0YMECnXXWWXL5Bw0Kg1mzZumKK66QJKWb3wfW/3tGtJ5//pLA9Nqvvvqq6ta9QAc2uCSHR9ddXFe1Zu+SJJ10+eVSvj+uRALDMKQnn1QDl0tDhgwpsN0uMULhamSMjhyRkZOInjlihDXwmI2VJUbOV1+V/vhDJ7Rtq+NCfDdRsWrk9yjCECP7I0b2R4zsza7xSS7h2E9hS7obNGggp9OpPXv2BK3fs2ePmjRpEvKYhg0b6pNPPlFGRoYOHDigZs2a6Y477lDbtm0LvY7b7Zbb7S6w3uVy2SpghQl3O5s2bar09HRJSZKOlQyvFJUu03OsMrz9JFmjxzdu3FRX35gmqbacvV7WhMYdrF/8GzSQq3lzBbLzSFK/viTJOHq0yBiEO0YoXo2KUWqq9dPtlishIbxtKYVSxahuXUmSMzVVzpoSVxuoUd+jCEWM7I8Y2R8xsje7xaekbQnbQGrR0dHq0aOHFi5cGFjn8/m0cOFCnXrqqUUeGxMTo+bNmys7O1sfffSRzjvvvMpubo3Vp08ftWjRQjKGWiuSlkk9X7SeG3fKMAwlJSVp69Y+2rC6tuQ+omtv3au6G3K6nnfvHpkJt8RAaohM1X0QNYmB1AAAQEQJ6+jlkydP1ssvv6w33nhDa9as0XXXXafU1FRNmDBBkjR27NiggdZ++OEHzZ49Wxs3btTSpUt19tlny+fz6Z///Ge4XkK153Q6NWPGDMmdk3S3+Vxq/2/JkSWZfWWavfXoo0/r/+6yBqtz9XtS9w2+QfrjD2v/bt3C1PIKwJRhiETVebowP5JuAAAQQcJ6T/eoUaO0b98+3Xvvvdq9e7eOP/54zZs3LzC42tatW+XIM79zRkaG7rnnHm3cuFHx8fEaMmSI3nrrLdWpzr9c2sDZZ4+Qw5spnyRFfyb9ulM6/g3pl6t0Qo/3tHlzM+3f5ZASt+rmm6WGtRpKf/5pHRyp04VJuZXuzEzrEeI2BcB2qHQDAADYStgHUps4caImTpwYctvixYuDlvv166fVq1dXQauQ19dfSz6PW6q9RXdcfq66+e7U5F9f1N5frtCvP7fQmtXZkhyKGfSQ7ug/zTqoOlS6894Pm5wsNWwYvrYAJeVPRKvzHyNJugEAQAQJe9IN+3v/4xRJ8dIxn+vWcyerQVwDpXVM09VzP5JWX6iM9CipyS+67Zqmqh9XXzpwQNpljVwe0Um30ynFx0spKSTdiBz+7uVUugEAAGwhrPd0w/5MU/r8c+t5p97r1SCugSRp7HFj1WDgq4H9ag29X5N7T7IW/F3LW7cOrhZHIgZTQ6ShezkAAICtUOlGkX7/XTq0J16KStOooblzbbuj3LrrokGavP4ayRelf17WU3VjrWl8qkXXcr/ataWdOxlMDZGDgdQAAABshaQbRZrzqUeSS2r7lYZ3HxS07aoeV+npAd3lM326+eTfczdUh0HU/Kh0I9JQ6QYAALAVkm4Uyuv16tW390pqrvgui9WtwWNB2+Oj47Xq+lUyTVO1omvlbqhOlW5/0k2lG5GiJlW6k5Ote2AMI7ztAQAAKAL3dCOk2bNnKynpRG39q6kkKeXoB2rTpo1mz54dtF+cKy444TbN6lXpZq5uRJqaUOn2/zHM65XS0sLbFgAAgGKQdKOA2bNn64ILLtCuXV0lOaQmv0rbd2jHjh264IILCiTeQbZtsxLUqCipY8cqa3OloXs5Ik1NmDKsVi1rdgGJ7yYAALA9km4E8Xq9uvnmm2WaplSrubWy4e/SRlnrJE2aNElerzf0CfxV7o4dpejoKmhxJaN7OSJNTZgyzDD4gxgAAIgYJN0IsnTpUm3fvt1aSMzpNp6ZKnmsp6Zpatu2bVq6dGnoE1Sn+7klupcj8tSE7uUSg6kBAICIQdKNILt27cpdMHKSbl9q0fvlVZ3u55aopiHy1ISB1CSSbgAAEDFIuhGkadOmeZZykm6jYNIdvF8eVLqB8MnMlDIyrOdUugEAAGyBpBtB+vTpoxYtWsgwDMlXMOk2DENJSUnq06dPwYMzMqRVq6znxx9f+Y2tClS6EUnyfk79n93qiqQbAABECJJuBHE6nZoxY4a1YAYn3UbOXLjTp0+X0z9ycF5//CFlZ0v160stW1ZFcysfA6khkvgT0ISE3NG9qyuSbgAAECFIulHAiBEjNGvWLDkNf6XMSrpbtGihWbNmacSIEaEP/Pln62ePHtbowtUB3csRSWrCdGF+JN0AACBCkHQjpBEjRqh+vVaSpNP+cYIWLVqkTZs2FZ5wS8FJd3VB93JEkpowXZgfSTcAAIgQUeFuAOzLk+6SJHXr2kb9+/cv/oDqmHTnrXSbZvWp4KN6qinThUkk3QAAIGJQ6UahPJnRkqSE+BJ8TDIzc6cLq05Jt7/SnZ0tpaeHty1AcWrKdGES4y0AAICIQdKNQnky3JJKmHT/8Yfk8Uj16kmtWlVyy6pQrVq51W1+uYfdUekGAACwHZJuFMqbaSXdifElGAW5Og6iJkkOBxU1RI6aVOkm6QYAABGCpBuF8mbGSJJqJ5bg1v9ffrF+nnhiJbYoTBhMDZGCSjcAAIDtkHQjpOxsycy27umunVCCpLs6DqLmx7RhiBRMGQYAAGA7JN0IKTU193mdBFfRO2dlWfd0S9Uz6abSjUhRU6cMM83wtgUAAKAIJN0IKZB0G14lxsUUvfOff1qJd926Ups2ld62Ksc93YgUNbF7uccjZWSEty0AAABFIOlGSIGk25WqWFcxSbe/a/mJJ1avQdT86F6OSFGTBlKLj8/994ZeKAAAwMZIuhFSIOmOTlWsK7bonavz/dwS3csROWpSpTvvzAJ8NwEAgI2RdCOkvJXumKhiKt3+kcura9JNpRuRoiZVuiUGUwMAABGBpBshHUnOtp5EF5N0ezzS779bz6tr0s093YgEppn7Ga0JlW6JP4gBAICIEPak+7nnnlPr1q0VExOjk08+WT/++GOR+0+fPl0dO3ZUbGyskpKSdMsttyiDQXQq3OGjHuuJK1WxUUV0L1+1SsrMtH75bdu2ahpX1ejCikiQmip5vdbzmlLp5rsJAAAiQFiT7vfff1+TJ0/Wfffdp19++UXHHXecBg0apL1794bcf+bMmbrjjjt03333ac2aNXr11Vf1/vvv66677qrilld/gaQ7OlXuKHfhO1b3QdQkqmmIDP6u5VFRUmwx4zBUF3QvBwAAESCsSfdTTz2lq666ShMmTFCXLl304osvKi4uTv/9739D7r9s2TKddtppGj16tFq3bq2BAwfqkksuKbY6jtI7ctTqXu6ITpfDKOJjUt0HUZOopiEy5B1Erbr+ASw/km4AABABwpZ0Z2Vl6eeff9aAAQNyG+NwaMCAAVq+fHnIY3r37q2ff/45kGRv3LhRc+fO1ZAhQ6qkzTVJck7S7XQX0XXfNKWffrKe14Skm0o37KymDaImkXQDAICIEBWuC+/fv19er1eNGzcOWt+4cWOtXbs25DGjR4/W/v379Y9//EOmaSo7O1vXXnttkd3LMzMzlZmZGVhOzkmcPB6PPB5PBbySyuFvW7jaeDjZum5UTGZuG0xTxnvvybFggbR2rYy//pJx9KjVzmOPtQZVq4aMWrUUJclMTlZ2ntcY7hiheDUpRsaBA9bnNDEx6HNqd+WJkSM+Xk5J3kOH5Iug1xxpatL3KFIRI/sjRvYXjhgZP/4os0GD6jsuUnn8+accs2bJd999kmHY9jtU0vaELekui8WLF+uRRx7R888/r5NPPlnr16/XzTffrAcffFBTpkwJecy0adM0derUAuvnz5+vuLi4ym5yuS1YsCAs1/3rr8aSmktRaZo7d64kqfnSper55JNB+5kOh3b37Kkf//5bWrcuDC2tfPE7duhMSdn79wfei7zCFSOUXE2IUfNvvlFPSfuzs7UsxOfU7soSow67d6uLpO2rVmllBL7mSFMTvkeRjhjZQ9Nly9R+zhw5/L+MG4ay3W41Hj5cRMj+qup71Oazz3TsK68o2+3W91Om6EC3blVy3UiQsGWLTpsyRa7kZK3ZtUsbzjsvsM1u/86lpaWVaD/DNE2zktsSUlZWluLi4jRr1iwNHz48sH7cuHE6fPiw5syZU+CYPn366JRTTtHjjz8eWPf222/r6quvVkpKihyOgr3lQ1W6k5KStH//fiX6uw3bkMfj0YIFC3TWWWfJ5XJV+fUvumK3PnkrSfUGvaDdn14pZWcr6thjZaxfL99FF8l3/vkyO3WS2reX3EUMtFYd7N4tV8uWMg1D2RkZgftlwx0jFK8mxcjx0kty3nijfOedJ++HH4a7OSVWnhg5XnxRzptukm/4cHk/+KCSWoia9D0KsnGjnHfcIbNhQ5l9+8rs21dq2jTcrQqpxsbIhow335TzqqtkhPj12udwyPPaa3JcckkYWobiVOX3yPHcc3Lecktg2YyLk/d//7P+nanp/vxTUQMHyti/X+YJJyh73jypbl3b/juXnJysBg0a6MiRI0XmlmGrdEdHR6tHjx5auHBhIOn2+XxauHChJk6cGPKYtLS0Aom10+mUJBX2twO32y13iKTQ5XLZKmCFCVc709KtxNIdm21d/803pfXrpQYN5HjlFTkSEqq8TWFTv74kyTBNuTIzpXyvPVI+SzVZjYhRzq0ejnr15IjA11qmGNWrJ0lyHD0aka850tSI75Hf2rXSgAHSjh3W8ssvWz+POcbqBup0Wg+Ho+DPFi2kO+6Q6tat8mbXqBjZ0auvSlddZY15c8UV0siR1nrTlO+dd+SYOVPREybIcLkkEm/bqvTv0TPPSP6E+5//lH7/Xca8eYo691xp7lypX7/Ku7bd/fmnNGiQtH+/dOKJMr76Sq58/5ba7d+5krYlrN3LJ0+erHHjxqlnz57q1auXpk+frtTUVE2YMEGSNHbsWDVv3lzTpk2TJA0bNkxPPfWUTjjhhED38ilTpmjYsGGB5BsVIy3V+umOybbm4fZ30b/rrgJJZ7UXG2v9MuX1WoOp1bTXj8iQd/TymoKB1FAZ/vjDSrj37pU6d7Z+AfzmG2nlSunvv61HcebNk778UmrSpNKbC5v4z3+ka66xnk+cKD39dNBMEt4zztC2PXvUauFC6dJLrd8pLr00TI2tJKZpfW/27rWeVySXy/qDVrh+B8vIkLZvl0rYlbhQX35pJdqSdOed0sMPW79nDx9ubRsyRHr77fDd4x2eDtCW/ful0aOlffusqYi/+iosf7ysLGFNukeNGqV9+/bp3nvv1e7du3X88cdr3rx5gcHVtm7dGlTZvueee2QYhu655x7t2LFDDRs21LBhw/Twww+H6yVUW2lpuZVuvfSStG2b1Ly5dN11YW5ZGBiG9cv9wYNW0t28ebhbBBRE0g2U308/WUn2wYPS8cdL8+dLDRta2w4dkpYts34x9Holn6/gT49HeuIJ6fffpT59rF8aW7UK60uKKCkp1vvr81m//PsfeZeL2uZf3rvX+r1l61brZ05PoCChplYs67rMTOmz/2/vvuObLPf/j7+S7t1CoYtRpuwtHByIgrIcCB4RUYYIDuCL4ERFRP2JE8GJIggejwcFwXFEERAUoYIHLDgAAdmUTSndaXP//rib0NBBCm2Twvv5eORBct0j150rofnkc43/mvfHjoXXXiu6j48PyaNGUbtuXayzZ8PgwfDFF2Yw6Qh0zvy3uLKy7FNZTp06/VoXGtJZISIioE6d07fatU//e55zNVmysohbswbrX3/BgQPmNTluhw+X0wUUcATcFgsEBsLnn58OvPv1K9/nqmratYOlSy+ogBu8YCK10aNHl9idfOXKlS6PfX19mTRpEpMmTaqEml3cMjPMHzui/LPh/71iFk6caP7HcDEKDze/hOnLvXiri3nJMC3nJ+Vh/Xro1s18P3XsaGarC3/pi4qCPn3Ofp6bboJrrzWHZF1+ufnlsWnTiqu3Ow4dgj//NO87gsHS/j3XbWXdx26HP/4wf8xYswY2bjTLqqrx480fXYoL1AGsVvLfftscDvPuu7BgQeXWrzJYLOawvPLugZqdbX4HO3nS7I3y22/le37MoKhjaTsEBZ1eRvZc+fnB/febQ1AKv08cgfe995r/95T0HjofVeGcHTrABx84h49dSDwedIt3ys4yg+7Bm38yf92rXx/uusvDtfIgfbkXb3cxZrodX370Y5icL5sNhg41/4+/8koza3muX64bNoSffjID782b4Yor4B//MLdZLODrC6NGmdsrw7Fj0Lq1GXhXBUFB5th4R2Be+L47jy0WiI52zYBGRroGB2dmgsv6uLiyevWgZ8+zByFWK7z9ttmjYvdus+zMHyWKKzvXfytDYODpzHNCAvj7V8zznDplZtMdvRgc2XXHv7m553V6w2rleGAgUa1aYa1bt2g2vVq1in1dAwNhzpyKO794lIJuKVZ2pg8RpHLHuh/NgsmTzV/nLlb6ci/e7mLOdGdnm1+2KuqLnlz43njDnMCnenVYtOj8s1kJCfDjj9Crl9ll/cwl7VatMidrc3Rdr0iPPmoG3FFREB/v2gX5bF2Xz7bPuW4rvE/dumaPgMsug86dzXG7FzqrFW6+2dO1qHrCwqBZM/NWAfJsNn5avJjevXtrck4pdwq6pVg5Wb78k/mEZWeb/7ld7LNsOr6AlSXTvXat2XXsgQc0Dlwq3sWc6Qbz+isjgJELz7594Bi29uKLzhUrzlt0tDkB29dfQ0bG6WBz6lQzwH/44YrPaq1ebc6oDfDVV2ZwKyIilU5BtxQrJ9uXOFLMB1dcUf5jc6qasnYv/9//zLGBGRnw6afmxBhNmlRc/UQuxky3jw+EhpqTLynolnM1frz5HurcGQpWTyk3wcHwz3+6ljVtamZ15841u7R37Vq+z+lgs52e/HT4cAXcIiIeZD37LnIxys3yJ4oT5oOL6Ut8ScrSvXzbNnPJh4wMMyjYs8f84WLt2pKPyckxJ9C44w7zS9iiRee/LEVJNmww113/4guz++OmTeZssVK1XYyZbtAM5nJ+vvsO5s8/Pc7WWglfi/7xD3OyJDCXmKqo2Z5ff92cbKp6dTODLyIiHqNMtxRht0NeTqGg+wKbsv+cuJvpPnjQnBzlyBFo29bsXn7bbfDLL3DNNebjXr3MyUBSUmDnTli40PzSd+LE6fPMnWtmSHr3hquuMseqOiaIiYyE668v20zyhgHLl8OUKfD990W3Wyxw441md0dlQ6qevDzzRx64OIPu/fsVdEvZ5eSY6ykDjBljLhFWWZ5/3vxx9a+/zID4qafK9/x7957uMv/yy+XXZV5ERM6Jgm4pIivL/FdBdyHujOlOSzMD6p07oUED+OYbiIkxg9xbbjG7mN9wgxksOwKkwuLjzQDdMOCzz8wM+YIFxS8pUru2+YVqyBBzJlwwJ8r54AP45BMziK5d27zFxZlZ7V9+Mffz9TUD6+xsM9BPTTVnqP/iC/PWubO5zmiNGuaPA6dOmfv27HlxTHBTFRUOOC/GoBsUdDvk5ZlrRlutp2+VOYuxt8nKMn/gPHDg9G3/fvPfLVvMnkmxseZkoZUpMtJcy3ngQHOt3ttug8aN3T/ebjdnJU9JgYMHsezfT53167Hu329u/+wz8+/MFVeYfydERMSjFHRLEY54MJJU846C7rN3Lz9xwswUJydDzZpmgB0TY24LDYUvvzTH1H300ekXOCzMDIgvvxwGDTLH9TnGzr/6qtkN/LPPzCVnHLO8GoZZvncv3H03vPQS/N//md3EFy0yx/A5/Pqrax2DgsxjHnzQnC22sC1bzOf88ENISjJvZ2rb1lzH9mL+Au+tHO/L4OCLb5WBqhh022zmkI4jR8xsa+HPt+Nmtxdffua2nBxz/eVNm8zbli1m4F2YY1mlwkF4GT7HvkCf/Hx8qtrcHoZh/mBYGosFpk/3zI9VAwaYE6ktWQLNm5/+ARXOvmRVXp7Leta+QNszz+/rC++8Uzld5kVEpFQKuqUIR0wYxbGCOwq6S+1evns33HST+cU3PNxcGqZBA9d9/P3NgPbJJ80vQHFxZjBeEosF2rc3b2fKzja/SD3/vNk10dE9EqBjRxg50gz49+0zg/N9+8x11u+7z/xBoDhNmsDMmfDss/Dmm2Z23cfH/GEgLAzWrDGD+G+/NbP54l0uxknUHMoadB8/bv7AtGqVmRG224veHIHtmTd3lBbMOrKThYeSVAbDMK81P/+cDrdQxb8sBAaaK0jEx5++OR63amUGvJ5gsZjjyNu3Nz/DZ/5Y4o7q1SE+HntMDIdOniQmLs5c6sjHx/y71KJFuVdbRETKrkr/HZWK4Qy6LSfA4OL8In8mR6Z7wwaYMcPMTAcGEv733/jed5/ZxS8hwQy4W7Uq/hwWC1xyyfnXJTAQxo0zs9bTppkZ7o4dzQl52hbJdZRNbCw895x5K+yhh8xA5fnnFXR7o4t1EjVwf76F9HQzo/nyy96RFbdazSWlAgNPZ54dt8LZ6OJuhbf7+ECjRtC6tfl/T6tW5mvi+KGgpB8WysBms7FixQquvvpq/KpaT4qwMPOHY2/toVO/vvnj6PHjJe9TXN2tVnMIUMHa9Pk2G+u0vrCIiNdS0C1FOINuI7XgjjLdtGljfpE9etTMGD/8MD4338yV8+djyc42swmLF5tjqCtLWBhMnGjeKtr48fDGG/DTT2aG8MorK/45pXh2++mx+Far2YV0505z28X4A5kj6D5wwJy3YPNmsweIY/Z/i8Xszv3JJ+bcBWAGpg88cDoYK9z1uqSbO12yz+wCfCaLBapVM4OlatWqTrdfm42smjXNYSkK6MpfaGjpPZ9ERKTKU9AtRWRkgC82Qin40qqg2/yy+fffZhfxGTNg61as//oXVsDetSvWRYsu7IAnPt5cyuy998wZ0C/WoPvwYVi92syaBgeb4+SDg81gKz399MRzJ064Tth05IgZLBfOVEZGmpnO6GgzCAsONgNoX18ze5mdbR535u3YsZK7CV+MmW5HL5QZM8xbaerXN4dQ3HZb1Ql4RUREpMpT0C1FZGQUmkQNLuxgsiyqVTOzY2PHwooV2N9/n78zMqj78cdYQ0I8XbuK98gj8P775qzsv/56/l3Z9+83l1iz2SA31xzP2KqVGYRWBJsNpk41g2ZHl9v8fDNzl5Bgzsxeq5Y53t4wzDrZbGYwvW4d/PCDmUX1FiEhZj3z8sybj485md/FpkOH0/djY835CZo0Mf/fKjz5WLNm5rAQZWpFRESkkinoliIyMk4vF5YXFoJvVZuxtqJZLHDNNeRfeSV/LF5M3YIxdRe8Bg3MDOHHH8MLL5jddc9Ffr65Ju3zzxfdFh5uLnvWr9/51fVMmzfDsGHmmPzz1bKlGZhnZprLETm6MTsmnQsNNQO+wpM2xcSYQbEjAMzPN7uHO2awPnLEzGw7lnvKyzPHataoYd4c2fDCjwMCXOtlGN47brUi9exp/oATFKReOSIiIuKVFHRLEYWD7vzwML1J5LTHHjOD7vnzzW66ZVlXFsyu0bffDt99Zz6OjzeDS39/8423fz/072+OIX/hhfPPStrt1P/vf/H96CMzqK1WDR5//PR4Wkc37v37zVne9+0zs+8+PuZzO+rWogVcdZXZrb569fOrU0W5GANuh/h4T9dAREREpESKp6SIwkG3PTLcw7URr9KyJdxwA3z1FUyeDP/6l/tjYzdsMAPqXbvMrOSsWTBw4OntNhtMmGDOkj51Kvz8s3n+uDgz8D1bj4u8PHOps7/+MsdeHz6M75YttPztN3N7jx4we7YCNBERERGpVAq6pYjCQbeh8dxypgkTzKD744/NWbNnzCh5mTQwg+E33zSPy842u6kvXFj0GD8/eOUVuOIKc9K2NWtc1zt3rG8+dSrceqvrsSdPwoABsGSJS7EFyPP3x/Lqq/iMGnVxZ4NFRERExCM0fasU4TKRmsZIypk6dzYD7dBQSEqCdu3g4YdPrzVX2Pr10KmTua54djb07m0u61RakN63r5kV79zZtdxuN7uBDxhgLtuWlWWW79wJl11mBtzBwTB8ODzxBLz+Onn/+hfL334b+z33KOAWEREREY9QpluKSE83nJluS7VqHq6NeKV77oE+fczZ3D/7zMxQz5wJrVtD8+bmGOitW80Mt91uTiz24otw993udUevX9/MdGdnn57dPCfHPN8LL5hB/5o18OijZh2OHDG7jX/1lfkjQAHDZiN78eKKehVERERERM5KQbcUkZaeT0JB0G2N8tJJo8TzatUyx1B//TWMHm2O1f7xR/NW2O23m13CY2LK/hyBgebN4fnnoWtXuPNO2LTJXAIKzOXLvvrKXPpLRERERMSLKOiWIk6l5zsz3b7VKmjNZLlw9OkD110Hf/wBv/9++padba7tfd115ft8110HGzfCHXfA8uVw003w0Udmd3cRERERES+joFuKOFWoe7m1mjLd4gY/P2jTxrxVhthYc9mxv/82J1vTeG0RERER8VIKuqWI9HS7cyI1jekWr2W1QsOGnq6FiIiIiEipNHu5FFF4yTDNXi4iIiIiInLuyi3o3rx5M/Xr1y+v04kHZWYWCrq1TreIiIiIiMg5K7egOzc3l927d5fX6cSDMjMtynSLiIiIiIiUA7fHdI8fP77U7UeOHDnvyoh3yM6AcNLMBwq6RUREREREzpnbQff06dNp06YN4eHhxW5PT08vt0qJZ/lnnsKKYT5Q0C0iIiIiInLO3O5e3rBhQ8aNG8eKFSuKvc2cOfOcK/HWW2+RmJhIYGAgnTp1Yt26dSXu27VrVywWS5Fbnz59zvn55TTDgKAsM8ud5e8D/v4erpGIiIiIiEjV5XbQ3aFDB9avX1/idovFgmEYZa7AJ598wvjx45k0aRIbNmygdevW9OjRg8OHDxe7/8KFC0lJSXHefv/9d3x8fPjnP/9Z5ueWonJzIcJ+EoD0YD8P10ZERERERKRqc7t7+auvvkpOTk6J21u3bo3dbi9zBaZOncqIESMYNmwYADNmzODrr79m9uzZPPbYY0X2r3bGutHz5s0jODhYQXc5KbxcWGaogm4REREREZHz4XamOzY2lrp165brk+fm5rJ+/Xq6d+9+ukJWK927dycpKcmtc8yaNYvbbruNkJCQcq3bxSojAyJJBSAzNMCzlREREREREani3M50z549m0GDBhEQUH6B2NGjR8nPzycmJsalPCYmhi1btpz1+HXr1vH7778za9asEvfJyclxydCnpZnjlW02Gzab7RxrXvEcdavsOqamns50Z4UGevVr5GmeaiNxn9rI+6mNvJ/ayPupjbyf2sj7qY28m7e2j7v1sRhuDsT28fEhJSWFmjVrAhAfH8+aNWtITEw850oeOHCAhIQE1qxZQ+fOnZ3ljzzyCD/88ANr164t9fh77rmHpKQkNm3aVOI+Tz/9NJMnTy5S/vHHHxMcHHzOdb9Qbd8ewaGH1vESj7K0YzyZj7/t6SqJiIiIiIh4nczMTG6//XZOnjxZ4ipfUIZM95mx+alTp85pDHdh0dHR+Pj4cOjQIZfyQ4cOERsbW+qxGRkZzJs3j2eeeabU/SZMmOCyxnhaWhq1a9fmuuuuK/WF8TSbzcbSpUu59tpr8fOrvLHVq1ZZWMsSAPziatC7d+9Ke+6qxlNtJO5TG3k/tZH3Uxt5P7WR91MbeT+1kXfz1vZx9KI+G7eD7org7+9P+/btWb58OX379gXAbrezfPlyRo8eXeqx8+fPJycnhzvuuKPU/QICAortEu/n5+dVDVaSyq5nTs7p7uV54aFV4jXytKryXrqYqY28n9rI+6mNvJ/ayPupjbyf2si7eVv7uFsXt4Nux3rYJT0+V+PHj2fIkCF06NCBjh07Mm3aNDIyMpyzmQ8ePJiEhASmTJnictysWbPo27cv1atXP+86yGmFJ1LLCw/zbGVERERERESquDJ1L2/cuLEz0E5PT6dt27ZYra4ToB8/frxMFRgwYABHjhzhqaee4uDBg7Rp04Zvv/3WObnanj17ijzH1q1b+emnn/juu+/K9FxydhkZEOvIdEcq6BYRERERETkfbgfdH3zwQYVVYvTo0SV2J1+5cmWRsksuuaTIGHMpH4XX6TYiIz1bGRERERERkSrO7aB7yJAhFVkP8RKFg257VKRnKyMiIiIiIlLFWc++i1xMCgfd1sgoD9dGRERERESkalPQLS4y0g3nRGpEVfNoXURERERERKo6Bd3iIi81HV/yAfCpppnhRUREREREzoeCbnF1wuxanmPxwT8swsOVERERERERqdoUdIsL60kz6D7h50+gX5CHayMiIiIiIlK1uT17uUN+fj5z5sxh+fLlHD58GLvd7rL9+++/L7fKSeXzOZUKQKq/H0G+CrpFRERERETOR5mD7rFjxzJnzhz69OlDixYtsFgsFVEv8RDfUwWZbn9fwn0DPVwbERERERGRqq3MQfe8efP49NNP6d27d0XURzzMP7Mg6A7woaaCbhERERERkfNS5jHd/v7+NGzYsCLqIl4g0BF0B0GQxnSLiIiIiIiclzIH3Q8++CDTp0/HMIyKqI94WFD2cQBOBEKgMt0iIiIiIiLnpczdy3/66SdWrFjBN998Q/PmzfHz83PZvnDhwnKrnFS+oNxUAFKD7JpITURERERE5DyVOeiOjIzk5ptvroi6iBcItaUCcCI4jwDfAM9WRkREREREpIorc9D9wQcfVEQ9xAvk5UGE3RzTnRZmYLVoGXcREREREZHzUeag2+HIkSNs3boVgEsuuYQaNWqUW6XEMzIyIAoz6M4M11JwIiIiIiIi56vMqcyMjAzuuusu4uLi6NKlC126dCE+Pp7hw4eTmZlZEXWUSuISdEcoyy0iIiIiInK+yhxZjR8/nh9++IGvvvqK1NRUUlNT+eKLL/jhhx948MEHK6KOUkkyMyGSVABywjRzuYiIiIiIyPkqc9D92WefMWvWLHr16kV4eDjh4eH07t2bmTNnsmDBgoqoo7jh+PfJpIbE8797ZnKuq7kVznTnhAeXY+1EREREREQuTmUOujMzM4mJiSlSXrNmTXUv96A/Z/xIZGYKR9/7jJ49Ydu2sp8j63gWgeQAkBOmoFtEREREROR8lTno7ty5M5MmTSI7O9tZlpWVxeTJk+ncuXO5Vk7cl3PKDJbjOcB330GLFjBpEmRluX+O3ENmljsPH+yhIRVRTRERERERkYtKmWcvnz59Oj169KBWrVq0bt0agI0bNxIYGMiSJUvKvYLinryMXAAS/Q/Q42pYsgSeeQb+9z/4+mv3zmE7bAbdqdZQAv2CKqqqIiIiIiIiF40yB90tWrRg27Zt/Pvf/2bLli0ADBw4kEGDBhEUpEDNU/IyzZ4H4bnHeGzcd9x8c3fuvdfK+vXunyP/WCoAJ6whBPpqIjUREREREZHzdU7rdAcHBzNixIjyrouco4ULF7Jr4+/0KXg8tGcPcmL/ASRx8qT757EfK8h0+wYTpEy3iIiIiIjIeXMr6P7yyy/p1asXfn5+fPnll6Xue+ONN5ZLxcQ9Cxcu5JZbbmGq0cdZFgf8fNDshZCdDTk5EBDgxslOmEH3Cd9AZbpFRERERETKgVtBd9++fTl48CA1a9akb9++Je5nsVjIz88vr7rJWeTn5zN27FgMw8C/0Jx48QCkOR8fP55PXJzPWc9nSXUE3QEE+SrTLSIiIiIicr7cmr3cbrdTs2ZN5/2Sbgq4K9eqVavYt28fAIUT2WbQbQfMvuXLlv3PrfP5pBUE3f7+ynSLiIiIiIiUgzIvGfbhhx+Sk5NTpDw3N5cPP/ywXCol7klJSXHeDyjUkvHOe2bQvXt3qlvn80k39zvh76ugW0REREREpByUOegeNmwYJ4uZnevUqVMMGzasXCol7omLi3Pe9zcM5/14i+NeKgBBQbFunc//1HEATgT6qHu5iIiIiIhIOShz0G0YBhaLpUj5vn37iIiIKHMF3nrrLRITEwkMDKRTp06sW7eu1P1TU1MZNWoUcXFxBAQE0LhxYxYvXlzm570QXHnlldSqVQuLxUKAYXeWx/s77pk/jtSu3cKt8wWdOABASni+Mt0iIiIiIiLlwO0lw9q2bYvFYsFisdCtWzd8fU8fmp+fz86dO+nZs2eZnvyTTz5h/PjxzJgxg06dOjFt2jR69OjB1q1bnWPIC8vNzeXaa6+lZs2aLFiwgISEBHbv3k1kZGSZnvdC4ePjw/Tp0+nf/zYCyHOWx/uYk9oZRioAp06dfRI1gLBT+wE4EH2CtloyTERERERE5Ly5HXQ7Zi1PTk6mR48ehIaGOrf5+/uTmJhI//79y/TkU6dOZcSIEc5u6TNmzODrr79m9uzZPPbYY0X2nz17NsePH2fNmjX4+fkBkJiYWKbnvND069ePOXM+w3/oa86y+DyoVasW9eq15scfITX17Oex2aCmzQy698cfUqZbRERERESkHLgddE+aNAkwg9wBAwYQGHh+QVlubi7r169nwoQJzjKr1Ur37t1JSkoq9pgvv/ySzp07M2rUKL744gtq1KjB7bffzqOPPoqPT/HZ3JycHJeJ39LSzKW0bDYbNpvtvK6hIjnq5k4dL7usJ4d5wfk4Khd+/WUNTz4dx48/mkuG2Wz2Us4Af29K55KCZcb2xxzBz+Ln1a+PNyhLG4lnqI28n9rI+6mNvJ/ayPupjbyf2si7eWv7uFsft4NuhyFDhpS5MsU5evQo+fn5xMTEuJTHxMSwZcuWYo/5+++/+f777xk0aBCLFy9m+/bt3H///dhsNuePAmeaMmUKkydPLlL+3XffERwcfP4XUsGWLl161n127QrnclxnlP/oo5c5enQU0JiNG3ezePFvpZ5jz9JMLgHSLCGkB2Ww5fctLN5/cY6VLyt32kg8S23k/dRG3k9t5P3URt5PbeT91EbezdvaJzMz0639yhx05+fn89prr/Hpp5+yZ88ecnNzXbYfP368rKd0m2O98Pfeew8fHx/at2/P/v37efnll0sMuidMmMD48eOdj9PS0qhduzbXXXcd4eHhFVbX82Wz2Vi6dCnXXnutsyt9SVavtuCPazv4cIh27RqwYAFERSXSu3ftUs/x32UrATjoXx3I4B8d/kHvS3qfzyVc8MrSRuIZaiPvpzbyfmoj76c28n5qI++nNvJu3to+jl7UZ1PmoHvy5Mm8//77PPjggzz55JM88cQT7Nq1i88//5ynnnrK7fNER0fj4+PDoUOHXMoPHTpEbGzxS1zFxcXh5+fn0pW8adOmHDx4kNzcXPz9/YscExAQQEBAQJFyPz8/r2qwkrhTz6wsCCjIdOdbLfjYDfZtXUf9DubrlJZmxc+v9Inqs3YcBOBgcBgAoQGhVeL18QZV5b10MVMbeT+1kfdTG3k/tZH3Uxt5P7WRd/O29nG3LmVeMuzf//43M2fO5MEHH8TX15eBAwfy/vvv89RTT/Hzzz+7fR5/f3/at2/P8uXLnWV2u53ly5fTuXPnYo+5/PLL2b59O3b76fHJf/31F3FxccUG3BeLtLTTQXdWbHUAcvbsxCcoHYBillUvIn+3OYnawXDzjROk2ctFRERERETOW5mD7oMHD9KyZUsAQkNDOVkQ0V1//fV8/fXXZTrX+PHjmTlzJnPnzmXz5s3cd999ZGRkOGczHzx4sMtEa/fddx/Hjx9n7Nix/PXXX3z99dc8//zzjBo1qqyXcUFJS8PZvTw/sS4AcadgV3Yy4F7Q7XPIDLpTovIBNHu5iIiIiIhIOShz9/JatWqRkpJCnTp1aNCgAd999x3t2rXjl19+KbYbd2kGDBjAkSNHeOqppzh48CBt2rTh22+/dU6utmfPHqzW078L1K5dmyVLljBu3DhatWpFQkICY8eO5dFHHy3rZVxQCme67XVqw5r1xJ+CRWlJwBVnXTLMMCA0tWCN7hpmdjzIV5luERERERGR81XmoPvmm29m+fLldOrUiTFjxnDHHXcwa9Ys9uzZw7hx48pcgdGjRzN69Ohit61cubJIWefOncvUjf1iUDjopl49AOJPwYYT3wMPnzXTfegQxOSbQfe+GscAZbpFRERERETKQ5mD7hdeOL0e9IABA6hTpw5JSUk0atSIG264oVwrJ+5JSzOcQbdPg4YAxKW7di83DLBYij9+xw6oixl07wrLAhR0i4iIiIiIlIcyB91n6ty5c4kTn0nlOJGaix95APg3aAxA7XQfCEwFwG6H9HQICyv++L+35dMJc/bynSHmAu+aSE1EREREROT8uRV0f/nll26f8MYbbzznysi5OXX89KLsAQ0uASA0O58Qez5ZvnnY83xJTS056D606RC+5JNv8eFQqCZSExERERERKS9uBd19+/Z1eWyxWDAMo0gZQH5+fvnUTNyWmZrlvG+pUQNCQyE9nbh02BmYBunVOHkSatcu/vi0zWbX8oywGOzWA4AmUhMRERERESkPbi0ZZrfbnbfvvvuONm3a8M0335CamkpqairffPMN7dq149tvv63o+koxsk7mnn7g7w/x8YA5mZqji3lpM5jn/G0G3dnRsQBYLVZ8rec98kBEREREROSiV+bI6oEHHmDGjBlcccUVzrIePXoQHBzMyJEj2bx5c7lWUM7OdsoMum1WC35Wqxl0//UX8afACDCnLi91BvMDZnY7P74GYHYtt5Q065qIiIiIiIi4za1Md2E7duwgMjKySHlERAS7du0qhypJWdnSzcnPcn18zIJCmW4j4DhQctB96hSEp5uZbmu96oC6louIiIiIiJSXMgfdl156KePHj+fQoUPOskOHDvHwww/TsWPHcq2cuCc/w5y53OZb0JwuQXcqUHL38h07IKFgubC8WlGAJlETEREREREpL2UOumfPnk1KSgp16tShYcOGNGzYkDp16rB//35mzZpVEXWUUhgG2DPNyevy/QqaMy7O/KfQmO6SMt2Fg+6MGpGAlgsTEREREREpL2Ue092wYUM2bdrE0qVL2bJlCwBNmzale/fuGgfsAZmZ4G+Y3cvz/It2LyfOjLZLy3RfXxB0p0dHQJoy3SIiIiIiIuXlnKaotlgsXHfddVx33XXlXR8po7Q08MecSM1+RtCdkG4pU6b7ZHQo/K2gW0REREREpLy4FXS//vrrjBw5ksDAQF5//fVS9/2///u/cqmYuOfUKQggBwC7X0FzFgTdcacMOMuY7v1b04kgDSgIutFEaiIiIiIiIuXFraD7tddeY9CgQQQGBvLaa6+VuJ/FYlHQXcnS0k4H3Ya/n1lYMKY7NBfCfI9wipIz3VnbCyZRCw4jPcAcHqBMt4iIiIiISPlwK+jeuXNnsffF81y7l/ubhSEhEBEBJ08Sbz/MVooPunNzwXLADLqJTyDLlgUo6BYRERERESkvZZ69XLxL4Uw3jqAbTk+mln8MKL57+e7dEGeYQbdP3QSy87IBzV4uIiIiIiJSXtzKdI8fP97tE06dOvWcKyNl5xJ0BwSc3hAXB5s3E287ARSf6S48iZolIYGsPGW6RUREREREypNbQfevv/7q1sm0ZFjlKzyRmiWwULDsmEwt9xRQfKa7cNBNQqFMtyZSExERERERKRduBd0rVqyo6HrIOSo8ptsSUDTojs/OBMz1vG028PM7vcuOHXCFS9Bt3lemW0REREREpHxoTHcVV7h7uU9xQXdWrrPozC7mZ2a6NZGaiIiIiIhI+XIr032m//3vf3z66afs2bOH3Nxcl20LFy4sl4qJe9LSIKIg6LYGBZ/e4Ai60w38g3LJzfLn5EmIjj69i0vQHR9P9mF1LxcRERERESlPZc50z5s3j8suu4zNmzezaNEibDYbf/zxB99//z0REREVUUcpcMbvG4Br93KfwEJBd8Fa3fGnICDEDKYLj+s2DNj9dz6xHDQLNJGaiIiIiIhIuStz0P3888/z2muv8dVXX+Hv78/06dPZsmULt956K3Xq1KmIOgpw771Qowbs2eNaXngiNb/CQXfNmgDUyICAUHNcd+Hu5YcPQ1jWIXzJx7BaISaG1OxUACIDIyvqMkRERERERC4qZQ66d+zYQZ8+fQDw9/cnIyMDi8XCuHHjeO+998q9gmL68kszq716tWt5WprhDLp9g0JOb6hRA4DwXAgJKLps2N9/F1ouLDYWfH05nnUcgGpB1SroKkRERERERC4uZQ66o6KiOHXKXIYqISGB33//HYDU1FQyMzPLt3YCQEYGpKSY93fvdt2WetLu7F7uFxx6ekNkJPk+ZvPW9N9n7pt6enPhoJuEBAAF3SIiIiIiIuWszEF3ly5dWLp0KQD//Oc/GTt2LCNGjGDgwIF069at3Cso5oRnDmd2Lz9ZONMdWCjTbbGQFWk+ruFjBteFM907dyroFhERERERqWhuz17++++/06JFC958802ys82JuZ544gn8/PxYs2YN/fv358knn6ywil7Mtm8/ff/MoLvwkmHWQNcJ0HKiwgg9dorqFjO4PjPT3fCMoPtEttkNPSooqvwqLyIiIiIichFzO+hu1aoVl156KXfffTe33XYbAFarlccee6zCKiemwkH3md3L009Znd3LCQhw2ZZbLQI4QPWCGcrPHNPdhQPmg4I1urPzzB9TlOkWEREREREpH253L//hhx9o3rw5Dz74IHFxcQwZMoRVq1aVSyXeeustEhMTCQwMpFOnTqxbt67EfefMmYPFYnG5BQZe2EtclZTpzsuD7CyrM9ONv7/LcbZqkQBE2Q8BpY/pdnQt97H4EOYfVp7VFxERERERuWi5HXRfeeWVzJ49m5SUFN544w127drFVVddRePGjXnxxRc5ePDgOVXgk08+Yfz48UyaNIkNGzbQunVrevToweHDh0s8Jjw8nJSUFOdt95np3wtM4aA7Le108Fwwn93poPuMTHd+dHUAovKOAqcz3bm5sG9foaA7Pt5lPLfFYin3axAREREREbkYlXkitZCQEIYNG8YPP/zAX3/9xT//+U/eeust6tSpw4033ljmCkydOpURI0YwbNgwmjVrxowZMwgODmb27NklHmOxWIiNjXXeYmJiyvy8VUnhoBtOZ7vT0sx/A8gquOMadBvVzW7iUbZjwOlgffduMAyIo2BK9DOCbhERERERESkfZQ66C2vYsCGPP/44Tz75JGFhYXz99ddlOj43N5f169fTvXv30xWyWunevTtJSUklHpeenk7dunWpXbs2N910E3/88cc5X4O3y8qCvXvN+3XqmP86EvuOoNvfWnzQ7Viru1puKnA60/333xBANlGY5cTGKugWERERERGpAG5PpHamH3/8kdmzZ/PZZ59htVq59dZbGT58eJnOcfToUfLz84tkqmNiYtiyZUuxx1xyySXMnj2bVq1acfLkSV555RUuu+wy/vjjD2rVqlVk/5ycHHJycpyP0woiVZvNhs1mK1N9K5Ojbn/9lQf4ERFh0LatwZ49VnbuzMdms3P8uAXwJcBiBt15VitGoWuyVy/oXp6TDsDJkwY2Wx7bt1uJLZhczQgIIC80lCM7jpj7BkZ59eviTRyvk14v76U28n5qI++nNvJ+aiPvpzbyfmoj7+at7eNufcoUdB84cIA5c+YwZ84ctm/fzmWXXcbrr7/OrbfeSkhIyNlPUA46d+5M586dnY8vu+wymjZtyrvvvsuzzz5bZP8pU6YwefLkIuXfffcdwcHBFVrX8rBw4SagE9HRJ7HbjwENWLHib+rW/ZMNG2oCnZ1B97qNGzliPd15wThwiIZAtawMAA4fzmXx4m9ZtqwZcZjjvLPCw1n6zTesObwGgMxjmSxevLgSr7Dqc6xbL95LbeT91EbeT23k/dRG3k9t5P3URt7N29onMzPTrf3cDrp79erFsmXLiI6OZvDgwdx1111ccskl51xBgOjoaHx8fDh06JBL+aFDh4iNjXXrHH5+frRt25btZw58LjBhwgTGjx/vfJyWlkbt2rW57rrrCA8PP/fKVzCbzcbSpUsJC2sLQLt24XTsGMZXX4GfXwN6904kI8Oc8My/YCK1jldeidGli/McB6MD4NnpRGebv8BkZfnTq1dv5s71IZbfAQisX5/evXuzesVqOAAtG7ak97W9K/NSqyxHG1177bX4+fl5ujpSDLWR91MbeT+1kfdTG3k/tZH3Uxt5N29tH0cv6rNxO+j28/NjwYIFXH/99fj4+JxzxQrz9/enffv2LF++nL59+wJgt9tZvnw5o0ePdusc+fn5/Pbbb/TuXXygGBAQQMCZY50xr8ebGqwku3aZr3Xjxlbq1TPL9u614udnxfHDSoDFDLp9g4Oh0DUFJ9QFoHq2HR/yyMvzxWbzY9cu+EfBJGrWuDisfn6czDEHfEeHRFeJ18WbVJX30sVMbeT91EbeT23k/dRG3k9t5P3URt7N29rH3bq4HXR/+eWX51yZ0owfP54hQ4bQoUMHOnbsyLRp08jIyGDYsGEADB48mISEBKZMmQLAM888wz/+8Q8aNmxIamoqL7/8Mrt37+buu++ukPp52o4dZja7YUOoa8bQRWcvN3IL7rj+uBAUWws75mx5Na1HSbHHcvIk7NwJNztmLo+LA+B4tiZSExERERERKW/nPJFaeRkwYABHjhzhqaee4uDBg7Rp04Zvv/3WObnanj17sBYap3zixAlGjBjBwYMHiYqKon379qxZs4ZmzZp56hIqVOGg2zF7eUqKuda2c/ZyCgbwnxF0BwaEcDwIorOgXuhhUtJi2bnTXDrMMZGaI+g+kXUCUNAtIiIiIiJSnjwedAOMHj26xO7kK1eudHn82muv8dprr1VCrTzPZrM6s9oNG5orgAUGQnY27NsHp06Z2wKMgqDb39/leKvFytFQC9FZBrWDDkEa/PqruS3RPwVygYKx844lw6ICoyr6skRERERERC4a57VOt1SsQ4eCsdsthIZCTAxYLKez3Xv2FOpebs8ruFN07PrxEHNMeLy/OVmdI+iu7XdG93Kt0y0iIiIiIlLuFHR7sZQUcxm2hg3NgBtOj+vevdsRdBsEGPlmYTFB98kwszNDjN9h4HTQXdPu2r1cQbeIiIiIiEj5U9DtxQoH3Q5nZrr9KLQg+xndywFOhpllNSxmpvv338FKPhHZBcu0xcZiy7dxKtfsq66gW0REREREpPwo6PZiBw8WDbrPzHQHFKzRDRSb6U4LDwQg2jCDbJsNojmKj5Fvps9jYjiRfcK5f2RgZPlehIiIiIiIyEVMQbcXcyfT7U/u6Y3FBN3pEUEAROUfcZY5Zy6vUQN8fZ1dyyMDI/Gxls8a7CIiIiIiIuIls5dL8YoLugtnunNyTme6DR8fLD5FA+bMSPMckbajzrK4M9fo1nhuERERERGRCqGg20vZbHD4cDAAjRqdLi+c6Q4MNIh0dC/39yv2PFlRZtAdkXPMWVbLJwXyKbJcmIJuERERERGR8qXu5V5q1y6w260EBRmOhDQAtWqZQ7GzsyE11XJ6THdAYLHnya0WAUB49nFnWdNIzVwuIiIiIiJSGRR0e6kdO8w1who0OL1cGJgTlBcOwp1juosZzw2QG2UG3WFZJ7FgN88Zou7lIiIiIiIilUFBt5c6HXQbRbY5xnUDBJAFgKWY5cIA8qpFAuBjtxNJKgC1fQuC7oLu5SeyzNnLqwUq6BYRERERESlPCrq91I4d5r/FBd2Ocd0AAX4Fy32VkOn2Dw7jZMGmGpgzmMfYi+9eHhUUdZ61FhERERERkcIUdHspR6a7YcPSM93+vifNOyUE3UF+QRw152NzBt2R2Wd0L89W93IREREREZGKoKDbS23f7gi6i25zzXSnmndK6F4e7BfMkYKgO5qjgEFQqmv3co3pFhERERERqRhaMswL5eWZs5eDG2O6fVML7pSQ6fYN4oi5ahi1/I9QzUjHJzvTLNBEaiIiIiIiIhVKmW4vlJ4OffoYNGx4goSEotsLZ7r9fdPMOyUE3YUz3Q8OPsJ/ZxZkucPCIMSMxhV0i4iIiIiIVAxlur1QZCR8+mk+ixf/iNXau8h210x3QdBdQvfyIL8gDhVkuuuFHqFeomvXclDQLSIiIiIiUlGU6a6CIiIgPNy8H+CTXnDn7JlujhyBg64zl9sN++klwxR0i4iIiIiIlCsF3VWUI9vtf5agu/CYbo4cgRTXmctPZp/EwBw3HhWoJcNERERERETKk4LuKsoxrjvAWhB0uzF7eXFBt6NreYhfCAG+xQfuIiIiIiIicm4UdFdRHTua/wYEFQTRpazT7ZLpdnQvLxjTfSJbXctFREREREQqiiZSq6KeeAJ+rf4o/gs2mgWldS93I9OtoFtERERERKT8Keiuonx8wLfm3wTkFxSUMpHaUUfQnZMD27aZ9xV0i4iIiFwU7HY7ubm5nq6GV7PZbPj6+pKdnU1+fv7ZD5BK5an28fPzw8fH57zPo6C7CkvPTScgr+BBKUuGZfhDli8E5QG7dpkbCrqXO4LuqCBNoiYiIiJyocnNzWXnzp3Y7XZPV8WrGYZBbGwse/fuxWKxeLo6cgZPtk9kZCSxsbHn9bwKuquwjNwMtzLdWOBIMNRJK7ThzEx3oDLdIiIiIhcSwzBISUnBx8eH2rVrY7VqOqeS2O120tPTCQ0N1evkhTzRPoZhkJmZyeHDhwGIK4ifzoWC7iosPTcd/7ME3UG+QQAcCSkUdPv5QTUzyFb3chEREZELU15eHpmZmcTHxxMcHHz2Ay5iji74gYGBCrq9kKfaJyjIjKUOHz5MzZo1z7mrud5RVZi73cuB05OpAcTEQMGbVUG3iIiIyIXJMfbVv4TviSJydo4frGw22zmfQ0F3FZZhO3v3cqvFSoBPwOllw8DZtRwUdIuIiIhc6DRGWeTclcfnR0F3FeZO93Iwx3W7ZLoVdIuIiIjIBaxr16488MADzseJiYlMmzat1GOioqL4/PPPz/u5LRZLuZznQnFmW7ijMl/DlStXYrFYSE1NrbDn8Iqg+6233iIxMZHAwEA6derEunXr3Dpu3rx5WCwW+vbtW7EV9EKGYZgTqZ2lezmYXcxdMt0FM5eDgm4RERER8R433HADPXv2LHbbqlWrsFgsbNq0qczn/eWXXxg5cuT5Vs/F008/TZs2bYqUp6Sk0KtXr3J9rjPNmTMHi8VS5Pb+++8763D77bfTuHFjrFarW0FvXFwcL7zwgkvZY489hsViYeXKlS7lXbt25c4773SrrgsXLuTZZ591a193VUagXJ48HnR/8sknjB8/nkmTJrFhwwZat25Njx49nLPElWTXrl089NBDXHnllZVUU++Sk59DvpF/1u7loEy3iIiIiFQNw4cPZ+nSpezbt6/Itg8++IAOHTrQqlWrMp+3Ro0alTaZXGxsLAGlfDcvL+Hh4aSkpLjcBg0aBEBOTg41atTgySefpHXr1m6dr2vXrkWC6xUrVlC7dm2X8uzsbH7++WeuueYat85brVo1wsLC3Nr3QuXxoHvq1KmMGDGCYcOG0axZM2bMmEFwcDCzZ88u8Zj8/HwGDRrE5MmTqV+/fiXW1oMMAwoN3s/IzQBwq3t5kG9QsWO6DcPgRPYJQEG3iIiIiHje9ddfT40aNZgzZ45LeXp6OvPnz2f48OEcO3aMgQMHkpCQQHBwMC1btuQ///lPqec9s3v5tm3b6NKlC4GBgTRr1oylS5cWOebRRx+lcePGBAcHU79+fSZOnOicTGvOnDlMnjyZjRs3OrPMjjqf2TX6t99+45prriEoKIjq1aszcuRI0tPTnduHDh1K3759eeWVV4iLi6N69eqMGjXqrBN3WSwWYmNjXW6O2bYTExOZPn06gwcPJiIiotTzOFx99dWsXr2avDyzK+2pU6f49ddfefTRR12C7qSkJHJycrj66qsB+P333+nVqxehoaHExMRw5513cvToUef+Z3YvT0lJoU+fPgQFBVGvXj0+/vjjYrv/Hz16lJtvvpng4GAuueQSFi9eDJjJV8dzR0VFYbFYGDp0KGDOcj5lyhTq1atHUFAQrVu3ZsGCBS7nXbx4MY0bNyYoKIirr76aXbt2ufX6nA+PBt25ubmsX7+e7t27O8usVivdu3cnKSmpxOOeeeYZatasyfDhwyujmp6Xlwf9+kGNGlDwq196rvlBDcwvGNhfSvfyYL9gjhaT6c60ZZKbnwso6BYRERERz/P19WXw4MHMmTMHwzCc5fPnzyc/P5+BAweSnZ1N+/bt+frrr/n9998ZOXIkd955p9tDVO12O/369cPf35+1a9cyY8YMJkyYUGS/sLAw5syZw59//sn06dOZOXMmr732GgADBgzgwQcfpHnz5s4s84ABA4qcIyMjgx49ehAVFcUvv/zC/PnzWbZsGaNHj3bZb8WKFezYsYMVK1Ywd+5c5syZU+SHh4p29dVXk56ezi+//AKY3fkbN25M//79Wbt2LdnZ2c66JiYmkpiYSGpqKtdccw1t27blf//7H99++y2HDh3i1ltvLfF5Bg8ezIEDB1i5ciWfffYZ7733XrG9nCdPnsytt97Kpk2b6NWrF/fccw/Hjx+ndu3afPbZZwBs3bqVlJQUpk+fDsCUKVP48MMPmTFjBn/88Qfjxo3jjjvu4IcffgBg79699OvXjxtuuIHk5GTuvvtuHnvssXJ9HYvj0XW6jx49Sn5+PjExMS7lMTExbNmypdhjfvrpJ2bNmkVycrJbz5GTk0NOTo7zcVqauVi1zWY7r2nfK5qjbjabDesjj+BT8GtZ3tq1GDExnMg0M9RBdiuQT56PD0YJ1xPoE8iBQkF3XnQ0hs3GoVOHAPD38ccPP69+PbxR4TYS76Q28n5qI++nNvJ+aiPv56k2stlsGIaB3W7HbrdjGAaZtsxKrYNDsF+w27NADx06lJdffpkVK1bQtWtXwOxa3q9fP8LCwggLC2P8+PHO/UeNGsW3337LJ598QocOHZzljms/8/F3333Hli1b+Oabb4iPjwfg2Wef5frrrwdwHvP44487j61Tpw4PPvggn3zyCQ899BABAQGEhITg6+tLzZo1nfs5jnW85h999BHZ2dnMmTOHkJAQmjVrxuuvv85NN93ElClTiImJwTAMoqKieP311/Hx8aFx48b07t2bZcuWlZhktNvtnDx5ktDQUGdZaGgoBw4cKHb/M1+L4jRo0ICEhARWrFhBp06dWLFiBV26dKFmzZrUqVOH1atXc/XVV7Ny5Uq6du2K3W7njTfeoE2bNjz33HPO87z//vvUrVuXLVu20LhxY5fn37JlC8uWLWPt2rXOtnrvvfe45JJLitRxyJAhzh8ynnvuOd544w3Wrl1Lr169iIyMBCA6Otp5Pysri+eff57vvvuOzp07A2bGf9WqVcyYMYMrr7ySt99+mwYNGvDyyy8D0KhRIzZt2sRLL73kbLPiXmvDMLDZbEXW6Xb3M+3RoLusTp06xZ133snMmTOJjo5265gpU6YwefLkIuXfffddpY3rOB9/Pfwwbd5+2/l4048/stfXl78y/gLAv2AitbXJyRzNzy/uFJw6ccqle/nyP/8k+8gRdmbtBCDYEsw333xTMRdwESiuO5J4F7WR91MbeT+1kfdTG3m/ym4jX19fYmNjSU9PJzc3lwxbBrXerlWpdXDYd/8+QvxCzr4jEB8fT8eOHXnvvfdo164df//9N6tWreKrr74iLS2N/Px8pk6dyqJFi0hJScFms5GTk4O/v78zwZaXl0dubq7zsd1uJzs7m7S0NJKTk0lISCA0NNS5vUWLFoAZuDnKFi5cyLvvvsuuXbvIyMggLy+PsLAw5/acnBzy8/OdjwtznGfTpk00b97cZb+WLVtit9vZsGEDl19+OTabjcaNG5ORkeE8vnr16vz555/FnhvMcdVhYWEu3b6tVmux+5/5WpTmsssuY/ny5dx///18//33jBkzhrS0NDp37sx3331Hs2bNWLt2LbfffjtpaWmsX7+elStXEh4eXuRcv/32G7GxsS7Pn5ycjK+vLw0bNnTWp2bNmkRGRjrbx6HwPmD2PNi7dy9paWlkZpo/Hp06dQqr1ey8vXnzZjIzM+nRo4dLPXJzc2nVqhVpaWn89ttvtG3b1uW8jjHvhc915vFZWVn8+OOPzq73Do56nI1Hg+7o6Gh8fHw4dOiQS/mhQ4eILTTDtsOOHTvYtWsXN9xwg7PM8WuEr68vW7dupUGDBi7HTJgwweWXsLS0NGrXrs11111X7JvDW9hsNjZMm0br994DwAgNxZKeTuvERFr27k3QriDYBsEFme5OXbpgFPyic6a5n81lQ9oG9nRoTC2/6lxz551gtbJy10rYCrERsfTu3bvyLu4CYbPZWLp0Kddeey1+fn6ero4UQ23k/dRG3k9t5P3URt7PU22UnZ3N3r17CQ0NJTAwEJ9cn7MfVEHCw8IJ8Xcv6AYYMWIEY8eO5d1332XBggU0aNCAXr16YbFYePHFF3n33XeZOnUqLVu2JCQkhHHjxmG3253f7319ffH393c+tlqtBAYGEh4eTmBgIFar1SUWcMQUQUFBhIeHk5SUxMiRI3n66ae57rrriIiI4JNPPmHq1KnO4wICAvDx8Sk2pnCcx9/fH19fX5d9HN3mQ0JCCA8Px8/Pz7m/Q0BAQJE6Fua4huJmTz/Tma9Faa699lrGjRuHzWZj06ZN9OzZk/DwcLp168bMmTPp3r07ubm59OnTh/DwcLKzs7n++uuLzHoO5mzojt4Ajud3jDkPDw93CXAtFouzfRzCw8Odjw3DwGKxOM/jSJ6GhYUVua6vvvqKhIQEl7KAgADCw8Px9fXFz8/P5RhHnYo7F5ifo6CgIOccAIW580MGeDjo9vf3p3379ixfvty57Jfdbmf58uVFxjkANGnShN9++82l7Mknn+TUqVNMnz6d2rVrFzkmICCg2NkD/fz8vPsP086dXPrii1jy8uDWW7FERMDMmfikp+Pj50eO3ewyH1Awpts3OBhKuJ6QgBCwwKfT7uahyx7CWtC1J81mvkmqB1f37tfCy3n9e0nURlWA2sj7qY28n9rI+1V2G+Xn52OxWLBarVitVkIDQkmfkH72AytAWbqXA9x2222MGzeOefPm8a9//Yv77rvP2bV3zZo13HTTTQwePBgw44dt27bRrFmzIoFccY+bNWvG3r17OXToEHEFcx2tXbvWuZ/VauXnn3+mbt26PPnkk87yPXv2OLeDGWfk5+cXmx11vObNmjVj7ty5ZGVlERJi/uiQlJSE1WqladOmWK1W50RsZ9a18HMVd/7Stp/pzPOXpFu3bmRkZDBt2jQaNWrkTIR27dqVESNGsGTJEho1auSMu9q3b89nn31G/fr18fUtObR0PH/Tpk3Jy8tj48aNtG/fHoDt27dz4sSJInV0vIaAS7dvxw8oYAbjjn1atGhBQEAA+/btc060dqZmzZrx5ZdfujyPYy6Aws9XmKONivv8uvt59vjs5ePHj2fmzJnMnTuXzZs3c99995GRkcGwYcMAc6C9Y2KDwMBAWrRo4XKLjIwkLCyMFi1a4F/KZGJVyqlT+PbrR0BaGkbbtvDBBxAVZW4rWIvOMZGaf17BBBOlLRnma/4SlJmXBYX+s9NyYSIiIiIXD4vFQoh/iEduZQm4wRyfPGDAACZMmEBKSopzdmowx+EuXbqUNWvWsHnzZu65554iPWdL0717dxo3bsyQIUPYuHEjq1atYuLEiS77NGrUiD179jBv3jx27NjB66+/zqJFi1z2SUxMZOfOnSQnJ3P06FGXeaQcBg0aRGBgIEOGDOH3339nxYoVjBkzhjvvvLPIvFblLTk5meTkZNLT0zly5AjJycn8+eefpR5Tv3596tSpwxtvvMFVV13lLK9duzbx8fG89957LgHtqFGjOH78OAMHDuSXX35hx44dLFmyhGHDhpFfzNDXJk2a0L17d0aOHMm6dev49ddfGTlyJEFBQWV6j9StWxeLxcJ///tfjhw5Qnp6OmFhYTz00EOMGzeOuXPnsmPHDjZs2MAbb7zB3LlzAbj33nvZtm0bDz/8MFu3buXjjz+ulAnrPB50DxgwgFdeeYWnnnqKNm3akJyczLfffut8E+7Zs4eUlBQP17KSHTwIGRlkR0aSt2ABBAeDY6r/kyfJz89nw+8bAPDNK/jVp7Qlw/zMLhNZtiyXcgXdIiIiIuKthg8fzokTJ+jRo4dzwjMwe7q2a9eOHj160LVrV2JjY529Zt1htVpZtGgRWVlZdOzYkbvvvptnn33WZZ8bb7yRcePGMXr0aNq0acOaNWuKBOb9+/enZ8+eXH311dSoUaPYZcuCg4NZsmQJx48f59JLL+WWW26hW7duvPnmm2V7Mc5B27Ztadu2LevXr+fjjz+mbdu2bg0pvfrqqzl16pRzEjuHq666ilOnTrkE3fHx8axevZr8/Hyuu+46WrZsyQMPPEBkZGSJmfUPP/yQmJgYunTpws0338yIESMICwsr0nW7NAkJCUyePJnHHnuMmJgYZy/pZ599lokTJzJlyhSaNm1Kz549+frrr6lXrx5gToj32Wef8fnnn9O6dWtmzJjB888/7/bzniuLUXgu/otAWloaERERnDx50rvHdB84wE+ffMIVo0eb3RbeegtGj2b/P/7BP/btY1+tfdATMp+BIDt8+8479Lz33mLP9fjyx5ny0xTGdhrLtJ7TnOWPLn2Ul9a8xLh/jGNqj6mVdGUXDpvNxuLFi+ndu7e683kptZH3Uxt5P7WR91MbeT9PtVF2djY7d+6kXr16ZQpoLkZ2u520tLQiY42l4u3bt4/atWuzbNkyunXrVuw+nmyf0j5H7saWVWr28otKjRqk1a9/+nHBVPh//vwz+wDqAwYEFCS677rvPt6sWZN+/foVOVWQr5npPnOJCGW6RURERESkMn3//fekp6fTsmVLUlJSeOSRR0hMTKRLly6erlqF0c84VUR+wRp8EY4CP/Cxn27AHOCBBx4oduxEsJ85pjsrz7V7+Ylsc61vBd0iIiIiIlIZbDYbjz/+OM2bN+fmm2+mRo0arFy58oLuqaNMdxWxac8e2gKRjgJ/CCgUX+cAx/fuZdWqVUXGXzjGdCvTLSIiIiIintSjR48ia2lf6JTprgLy8/NZ/fvvQEGmOxJoBgGF1mZ3zJVY3KRzzkz3GROpHcs6BkBUYFT5VlhEREREREQABd1e76uvviIxMZGX3nsPKMh03wGEgX/Bygh2wBF/O9YaLKykMd370vYBkBCeUOQYEREREREROX/qXu7l7rzzTjIzMwkreBwABERATioELDDLcjHXXaxVqxZXXnllkXM4lwwrNKY7IzfD2b28dnjtirsAERERERGRi5gy3V7KMSGaY0W3dIuZ0QaIOAl8BAEZ5mNH1/Jp06bh4+NT5FyO7uWFM9170/YCEB4QTkRgRJFjRERERERE5Pwp6PZSSUlJLo+N7nCyYFm4yAXAUfAv2GazWlmwYEGxy4XB6e7lhcd07zm5B1CWW0REREREpCIp6PZSBw8edC1oBicDzLsRBZsKHlI9Pr7EgBtKyHSfNDPddSLqlEt9RUREREREpCgF3V4qNjb29AMrEFEo011Q7Ai6Lf7+lKa4Md3KdIuIiIjIhapr16488MADzseJiYlMmzat1GOioqL4/PPPz/u5LRZLuZzH261cuRKLxUJqaqqnq+L1FHR7qc6dOwPmh5ZwwAqpjkx3QXmtGjXMgoCAYs/hUNqYbmW6RURERMRb3HDDDfTs2bPYbatWrcJisbBp06Yyn/eXX35h5MiR51s9F08//TRt2rQpUp6SkkKvXr3K9bnONGfOHCwWS5Hb+++/76zD7bffTuPGjbFarS4/QJRk165dWCwWfHx82L9/v8u2lJQUfH19sVgs7Nq1C4DLLruMlJQUIiI0P9TZKOj2Ui4TohUso32yoLUiC4r/7557zDtnCbodY7pz83PJt5sTtDmC7toRynSLiIiIiHcYPnw4S5cuZd++fUW2ffDBB3To0IFWrVqV+bw1atQgODi4PKp4VrGxsQSc5ft5eQgPDyclJcXlNmjQIABycnKoUaMGTz75JK1bty7TeRMSEvjwww9dyubOnUtCgusyw/7+/sTGxppJwnOQm5t7TsdVRQq6vdy//vUvouqZUXdqwfu5bkQECxYs4IpLLzULztK93JHphtNdzB3dy5XpFhERERFvcf3111OjRg3mzJnjUp6ens78+fMZPnw4x44dY+DAgSQkJBAcHEzLli35z3/+U+p5z+xevm3bNrp06UJgYCDNmjVj6dKlRY559NFHady4McHBwdSvX5+JEydis9kAM9M8efJkNm7c6MwyO+p8Zvfy3377jWuuuYagoCCqV6/OyJEjSU9Pd24fOnQoffv25ZVXXiEuLo7q1aszatQo53OVxGKxEBsb63ILCgpyXu/06dMZPHhwmTPRQ4YM4YMPPnAp++CDDxgyZIhLWXHdy1evXk3Xrl0JDg4mKiqKHj16cOLECcDs8j969GgeeOABoqOj6dGjBwA//PADHTt2JCAggLi4OB577DHy8vLKVGdvp6Dby91www3c9/h9AIQn1ALg8VGjzInTcgoWCztbprtgTDeYM5gbhuGcSE1jukVEREQuDoYBGRmeuRWsgntWvr6+DB48mDlz5jiXzgWYP38++fn5DBw4kOzsbNq3b8/XX3/N77//zsiRI7nzzjtZt26dW89ht9vp168f/v7+rF27lhkzZjBhwoQi+4WFhTFnzhz+/PNPpk+fzsyZM3nttdcAGDBgAA8++CDNmzd3ZpkHDBhQ5BwZGRn06NGDqKgofvnlF+bPn8+yZcsYPXq0y34rVqxgx44drFixgrlz5zJnzpwiPzxUlhtvvJETJ07w008/AfDTTz9x4sQJbrjhhlKPS05Oplu3bjRr1oykpCR++uknbrjhBudSyGBmzP39/Vm9ejUzZsxg//799O7dm0svvZSNGzfyzjvvMGvWLJ577rkKvcbK5uvpCsjZ7T65G4Ca9RvBT/uwpqWZGxxdMs4SdFstVgJ8AsjJzyErL4tjWcecGe9a4bUqrN4iIiIi4j0yMyE01DPPnZ4OISHu7XvXXXfx8ssv88MPP9C1a1fAzLT279+fiIgIIiIieOihh5z7jxkzhiVLlvDpp5/SsWPHs55/2bJlbNmyhSVLlhAfHw/Ac889R58+fVz2e/LJJ533ExMTeeihh5g3bx6PPPIIQUFBhIaG4uvr6zoB8hk+/vhjsrOz+fDDDwkpeAHefPNNbrjhBl588UViYmIAcxK3N998Ex8fH5o0aUKfPn1Yvnw5I0aMKPHcJ0+eJLRQg4aGhhZdAekc+Pn5cccddzB79myuuOIKZs+ezR133IGfn1+px7300kt06NCBt99+21nWvHlzl30aNWrESy+95Hz8xBNPULt2bd58800sFgtNmjThwIEDPProozz11FNYrRdGjlhBdxWwM3UnACE1CsZRnDxp/uvIdJ+lezmY2e6c/BwybZkcyzwGQExIDAG+FT/eRERERETEXU2aNOGyyy5j9uzZdO3ale3bt7Nq1SqeeeYZAPLz83n++ef59NNP2b9/P7m5ueTk5Lg9Znvz5s3Url3bGXDD6UmMC/vkk094/fXX2bFjB+np6eTl5REeHl6ma9m8eTOtW7d2BtwAl19+OXa7na1btzqD7ubNm7vM6RQXF8dvv/1W6rnDwsLYsGGD83F5Bqh33XUXl112Gc8//zzz588nKSnprF2+k5OT+ec//1nqPu3bt3d5vHnzZjp37uwyLvzyyy8nPT2dffv2UafOhTEUVkF3FbDzhBl0h9cseNM5xk242b0czMnUUkkly5al8dwiIiIiF6HgYDPj7KnnLovhw4czZswY3nrrLT744AMaNGjAVVddBcDLL7/M9OnTmTZtGi1btiQkJIQHHnigXCfmSkpKYtCgQUyePJkePXoQERHBvHnzePXVV8vtOQo7M4tssViw2+2lHmO1WmnYsGGF1Kdly5Y0adKEgQMH0rRpU1q0aEFycnKpxzjGk5cmxN3uDheYCyNffwHLsmWRkp4CQPX4+mahI9PtZvdycF02TDOXi4iIiFx8LBazi7cnbmWd4PrWW2/FarXy8ccf8+GHH3LXXXc5s6GrV6/mpptu4o477qB169bUr1+fv/76y+1zN23alL1795KSkuIs+/nnn132WbNmDXXr1uWJJ56gQ4cONGrUiN27d7vs4+/v7zJeuaTn2rhxIxkZGc6y1atXY7VaueSSS9yusyfcddddrFy5krvuusut/Vu1asXy5cvL9BxNmzYlKSnJZfz+6tWrCQsLo1atC2cYrIJuL+cYzx3qH0pYjYI33jl2Lwdz9nJnpjtcmW4RERER8T6hoaEMGDCACRMmkJKSwtChQ53bGjVqxNKlS1mzZg2bN2/mnnvu4dChQ26fu3v37jRu3JghQ4awceNGVq1axcSJE132adSoEXv27GHevHns2LGD119/nUWLFrnsk5iYyM6dO0lOTubo0aPkOL6bFzJo0CACAwMZMmQIv//+OytWrGDMmDHceeedzq7lFSU5OZnk5GTS09M5cuQIycnJ/Pnnn24fP2LECI4cOcLdd9/t1v4TJkzgl19+4f7772fTpk1s2bKFd955h6NHj5Z4zP3338/evXsZM2YMW7Zs4YsvvmDSpEmMHz/+ghnPDQq6vd6uk7sAqBdZD0tkpFl4Dt3LlekWERERkapk+PDhnDhxgh49eriMv37yySdp164dPXr0oGvXrsTGxtK3b1+3z2u1Wlm0aBFZWVl07NiRu+++m2effdZlnxtvvJFx48YxevRo2rRpw5o1a4oE5v3796dnz55cffXV1KhRo9hly4KDg1myZAnHjx/n0ksv5ZZbbqFbt268+eabZXsxzkHbtm1p27Yt69ev5+OPP6Zt27b07t3b7eN9fX2Jjo7G19e9EcmNGzfmu+++Y+PGjXTs2JHOnTvzxRdflHp8QkICixcvZt26dbRu3Zp7772X4cOHu0xidyHQmG4vtyt1FwD1ouqBI+g+h+7lQb4Fme5CY7q1XJiIiIiIeKvOnTu7dDt2qFatmss62MVZuXKly+Ndu3a5PG7cuDGrVq1yPrbb7Zw4ccJlorSXXnrJZaZtgAceeMB5PyAggAULFhR57jPr3LJlS77//vsS61rc0mCF1xQvztChQ12y/8Up7rUrTWJiYqnHtGnTxmV7165di+x/1VVXsXr16mKPP7NNCh/j7nJvVZUy3V7OGXRH1gPHwvYnT4Ldfu6Z7oI1ujWRmoiIiIiISMVS0O3lHMuF1YsslOk2DHPqyXMY030q9xT7T+0H1L1cRERERESkoino9nLOMd1R9SAw8HSAffLkOc1evuP4DuyGHT+rH7GhsRVRZRERERERESmgoNvLuXQvh9NdzFNTy7xON8DWY1sBSAhPwGpR84uIiIiIiFQkRV1eLCM/gxPZJ4CCTDe4TqZWhu7ljky3I+jWeG4REREREZGKp6Dbix3KMdcbjA6OJtQ/1CwsnOk+h9nLd6ea635r5nIREREREZGKp6Dbix3OPQwU6loOxWe6yzCm28Cc1l+ZbhERERERkYrnFUH3W2+9RWJiIoGBgXTq1KnUddoWLlxIhw4diIyMJCQkhDZt2vCvf/2rEmtbeQ7lmpluZ9dycF027BxmL3dQpltERERERKTieTzo/uSTTxg/fjyTJk1iw4YNtG7dmh49enD48OFi969WrRpPPPEESUlJbNq0iWHDhjFs2DCWLFlSyTWveM6gO7KYoPscJ1JzUKZbRERERESk4nk86J46dSojRoxg2LBhNGvWjBkzZhAcHMzs2bOL3b9r167cfPPNNG3alAYNGjB27FhatWrFTz/9VMk1r3hn7V5+DkuGOWiNbhERERG5UHXt2pUHHnjA+TgxMZFp06aVekxUVBSff/75eT+3xWIpl/PIhcPXk0+em5vL+vXrmTBhgrPMarXSvXt3kpKSznq8YRh8//33bN26lRdffLHYfXJycshxZISBtLQ0AGw2Gzab7TyvoOLYbDZnprt2WG1nXa2hofgA+cePY83OxgLkWa0YZ7kWP4ufy+O44Divvv6qwPH66XX0Xmoj76c28n5qI++nNvJ+nmojm82GYRjY7XbsdnulPve5uvHGG7HZbHzzzTdFtq1atYquXbvy66+/0qpVq7Oey3HtAGvXriUkJKTE18EwDOd9d1+ryZMn88UXX7BhwwaX8v379xMVFVWhr/mcOXMYPnx4kfJ3332Xu+++m5SUFB566CHWr1/P9u3bGTNmDK+99lqp59y1axcNGjTAarWya9cuEhISnNtSUlKoW7cu+fn57Nixg8TExPK+pFI52qdwm1YWu92OYRjYbDZ8fHxctrn7mfZo0H306FHy8/OJiYlxKY+JiWHLli0lHnfy5EkSEhLIycnBx8eHt99+m2uvvbbYfadMmcLkyZOLlH/33XcEBwcXc4R3MAzDmenevXE3i7csBqD+gQO0BFK2bCH82DHCgbXJyRwt9B9FcTaf3Oy8H2gNZPXy1Vgsloqq/kVl6dKlnq6CnIXayPupjbyf2sj7qY28X2W3ka+vL7GxsaSnp5Pr6CHp5QYOHMjgwYPZvHmzS9AHMHPmTNq2bUtiYqIzkVaSvLw8cnNznfsFBASQl5d31uOysrLOuo9DTk4O+fn5RfYPDg4ukvgrb9nZ2YSFhfHLL7+4lIeHh5OWlsaxY8eIiIhg/PjxvP322y6vRUnS09MBiIuLY+bMmYwfP9657b333iMuLo59+/aRnp7u9mtUVjabDT8/vxK3nzp1qkKetzS5ublkZWXx448/kpeX57ItMzPTrXN4NOg+V2FhYSQnJ5Oens7y5csZP3489evXp2vXrkX2nTBhgssbJi0tjdq1a3PdddcRHh5eibUum32p+8jZmIMFC3fecCcBvmYXcsvRo/D++8QHB2MpmECtU5cuGJdfXur5/Hf6w07zfr1q9ejTp0+F1v9iYLPZWLp0Kddee22p/zmI56iNvJ/ayPupjbyf2sj7eaqNsrOz2bt3L6GhoQQGBlba856Pf/7znzz44IMsXLiQJ554wlmenp7OF198wYsvvojNZmPMmDGsWrWKEydO0KBBAx577DEGDhzo3N/X1xd/f3/n9/369eszduxYxo4dC8C2bdsYMWIE69ato379+kydOhWAoKAg5zGPPfYYn3/+Ofv27SM2Npbbb7+diRMn4ufnx5w5c5w9baOiogCYNWsWQ4cOxcfHh88++4y+ffsC8NtvvzFu3DiSkpIIDg6mX79+vPrqq4SGmksCDxs2jNTUVK644gqmTp1Kbm4uAwYM4LXXXivx/RIYGIjVaqVRo0bFbm/RogVvv/02APPmzXN5LUriqM/QoUOZN28eTz/9tHPbvHnzGDp0KM899xyhoaGEh4eTn5/PPffcw4oVKzh48CB16tThvvvu4//+7/9czjt79mxee+01tm/fTrVq1ejXrx9vvPEGAD4+Prz55pt8++23fP/99zz00ENMmjSJd955h6lTp7J3717q1avH448/zk033URYWFilJw6zs7MJCgqiS5cuRT5H7v744NGgOzo6Gh8fHw4dOuRSfujQIWJjY0s8zmq10rBhQwDatGnD5s2bmTJlSrFBd0BAAAHFjHn28/Pz6j9M+zP2A5AQlkBoUOjpDdWrA2BNS3OO6fYNDoazXEt44OkPWZ2IOl597VWNt7+XRG1UFaiNvJ/ayPupjbxfZbdRfn4+FosFq9WK1WoFwwA3M3PlLjgY3AiW/P39GTx4MHPnzuXJJ590BlifffYZ+fn5DBo0iPT0dDp06MBjjz1GeHg4X3/9NUOGDKFRo0Z07NjReS7HtZ/52G63c8sttxATE8PatWs5efKky/hvxzHh4eHMmTOH+Ph4fvvtN0aMGEF4eDiPPPIIAwcO5M8//+Tbb79l2bJlAERERDiPdbzmGRkZ9OrVi86dO/PLL79w+PBh7r77bv7v//6POXPmOOu1cuVK4uPjWbFiBdu3b2fAgAG0bduWESNGFPs6FX4ed5z5WpR2zptuuol3332XNWvWcMUVV/DTTz9x4sQJbrzxRp577jnnteXn51O7dm3mz59P9erVWbNmDSNHjiQ+Pp5bb70VgHfeeYfx48fzwgsv0KtXL06ePMnq1atd6vLMM8/wwgsvMH36dHx9ffniiy8YN24c06ZNo3v37vz3v/9l+PDhVKtWjT59+rh9zeXFarVisViK/fy6+3n2aNDt7+9P+/btWb58ufOXILvdzvLlyxk9erTb57Hb7RXafcMTdqaaaenEyETXDee4TnfhJcM0c7mIiIjIRSgzE0JDz75fRUhPh5AQt3a96667ePnll/nhhx+cSbUPPviA/v37ExERQUREBA899JBz/zFjxrBkyRI+/fRTl6C7JMuWLWPLli0sWbKE+Ph4AJ577rkiPUGffPJJ5/3ExEQeeugh5s2bxyOPPEJQUBChoaHOLvwl+fjjj8nOzubDDz8kpOD633zzTW644QZefPFF5zDbqKgo3nzzTXx8fGjSpAl9+vRh+fLlJQbdYA65DS3UnqGhoRw8ePCs1382fn5+3HHHHcyePZsrrriC2bNnc8cddxQbcBYexluvXj2SkpL49NNPnUH3c889x4MPPujsYQBw6aWXupzn9ttvZ9iwYc7HAwcOZOjQodx///0AjB8/nqSkJN54440q21vX493Lx48fz5AhQ+jQoQMdO3Zk2rRpZGRkOF/4wYMHk5CQwJQpUwBzjHaHDh1o0KABOTk5LF68mH/961+88847nryMcpWfn88PG38AIDgnmPz8/NOD9gsvGXaOs5drjW4RERER8VZNmjThsssuY/bs2XTt2pXt27ezatUqnnnmGcD8rvz888/z6aefsn//fnJzc8nJyXF7vqbNmzdTu3ZtZ8AN0Llz5yL7ffLJJ7z++uvs2LGD9PR08vLyyjw8dfPmzbRu3doZcANcfvnl2O12tm7d6gy6mzdv7jJJV1xcHL/99lup5w4LC3OZxK08M8B33XUXl112Gc8//zzz588nKSmpyHhmgLfeeovZs2ezZ88esrKyyM3NpU2bNgAcPnyYAwcO0K1bt1Kfq0OHDi6PN2/ezMiRI13KLr/88rPOPu/NPB50DxgwgCNHjvDUU09x8OBB2rRpw7fffut8A+7Zs8flDZSRkcH999/Pvn37CAoKokmTJnz00UcMGDDAU5dQrhYuXMjYsWNJuTQFWsP3C78n8flEpk+fTr9+/Vwz3Q5lXKdbmW4RERGRi1BwsJlx9tRzl8Hw4cMZM2YMb731Fh988AENGjTgqquuAuDll19m+vTpTJs2jZYtWxISEsIDDzxQrpPFJSUlMWjQICZPnkyPHj2IiIhg3rx5vPrqq+X2HIWdmUW2WCxnnaW78JDb8tayZUuaNGnCwIEDadq0KS1atCA5Odlln3nz5vHQQw/x6quv0rlzZ8LCwnj55ZdZu3YtYI6Pd0eImz0gqjKPB90Ao0ePLrE7+cqVK10eP/fcczz33HOVUKvKt3DhQm655RYMw8Da3fyhwXLSwv79+7nllltYsGAB/Rzj1jMzT4+LKZhQrTQumW6t0S0iIiJy8bFY3O7i7Wm33norY8eO5eOPP+bDDz/kvvvuc47vXr16NTfddBN33HEHYA41/euvv2jWrJlb527atCl79+4lJSWFuLg4AH7++WeXfdasWUPdunVdJnPbvXu3yz7+/v7k5+ef9bnmzJlDRkaGM7h0jGm+5JJL3Kqvp9x1113cf//9JfYoXr16NZdddpmzGzjAjh07nPfDwsJITExk+fLlXH311W4/b9OmTVm9ejVDhgxxeS5vf71KU7mj0KVE+fn5jB079vQadBHmv5ZUi7PsgQceIL/wf5SOZcLKOKZb3ctFRERExJuFhoYyYMAAJkyYQEpKCkOHDnVua9SoEUuXLmXNmjVs3ryZe+65p8jEzKXp3r07jRs3ZsiQIWzcuJFVq1YxceJEl30aNWrEnj17mDdvHjt27OD1119n0aJFLvskJiayc+dOkpOTOXr0aLFzTA0aNIjAwECGDBnC77//zooVKxgzZgx33nlnkWWTy1tycrJzxacjR46QnJzMn3/+6fbxI0aM4MiRI9x9993Fbm/UqBH/+9//WLJkCX/99RcTJ04ssoTZ008/zauvvsrrr7/Otm3b2LBhg3Pm8pI8/PDDzJkzh3feeYdt27YxdepUFi1axJgxY9yuu7dR0O0lVq1axb59+8wHFjDCC4Luk+YveoZhsHfvXlYlJRWdAMPNMd2XVL+EOhF1qBtZt1zrLiIiIiJS3oYPH86JEyfo0aOHy/jrJ598knbt2tGjRw+6du1KbGysc1Jmd1itVhYtWkRWVhYdO3bk7rvv5tlnn3XZ58Ybb2TcuHGMHj2aNm3asGbNmiKBef/+/enZsydXX301NWrU4D//+U+R5woODmbJkiUcP36cSy+9lFtuuYVu3brx5ptvlu3FOAdt27albdu2rF+/no8//pi2bdvSu3dvt4/39fUlOjoaX9/iO0ffc8899OvXjwEDBtCpUyeOHTvmkvUGGDJkCNOmTePtt9+mefPmXH/99Wzbtq3U5+3bty/Tp0/nlVdeoXnz5rz77rvMmjWLK664wu26exuL4UijXiTS0tKIiIjg5MmTXrVO93/+8x9uv/1280EAWPtZadC2AXuf3kt2ZrZzv48//piBDz8M+/efPjg7263AO8uWBbhmveXc2Ww2Fi9eTO/evbVEi5dSG3k/tZH3Uxt5P7WR9/NUG2VnZ7Nz507q1atXZdbp9hS73U5aWhrh4eGVviSVnJ0n26e0z5G7saXeUV7CMZ4EgBwI+DyAlxu/jMWwFN3PMZmagxtjusEMthVwi4iIiIiIVB4F3V7iyiuvpFatWs4JIs5ksVioXbs2V1555ellw8AMuEs4RkRERERERDxLQbeX8PHxYfr06QBFAm/H42nTppnr950ZdIuIiIiIiIhXUtDtRfr168eCBQtISEhwKa9Vq5a5XFi/fmZB4e7lbozlFhEREREREc/winW65bR+/fpx00038eOPP5KWlsbXX39Nly5dzAy3Q+FMt4JuERERERERr6VMtxfy8fFxTol/xRVXuAbc4JrpVvdyERERERERr6WguypSpltERERERKRKUNBdFSnoFhERERERqRIUdFdFmkhNRERERESkSlDQXRVpyTARERERkUo3dOhQ+vbt6+lqkJiYyLRp09ze/+mnn6ZNmzYVVh8pnYLuqkiZbhERERG5QB05coT77ruPOnXqEBAQQGxsLD169GD16tWertpZrVy5EovFQlRUFNnZ2S7bfvnlFywWCxaLxUO1E09R0F0VaUy3iIiIiFyg+vfvz6+//srcuXP566+/+PLLL+natSvHjh3zdNXcFhYWxqJFi1zKZs2aRZ06dTxUI/EkBd1VkbqXi4iIiEglyc/PZ+XKlfznP/9h5cqV5OfnV9hzpaamsmrVKl588UWuvvpq6tatS8eOHZkwYQI33nijc7+pU6fSsmVLQkJCqF27Nvfffz/p6ekApKWlERQUxDfffONy7kWLFhEWFkZmZiYAe/fu5dZbbyUyMpLo6Ghuv/12du3a5XLd48ePJzIykurVq/PII49gGIZb1zFkyBBmz57tfJyVlcW8efMYMmRIkX0/++wzmjdvTkBAAImJibz66qsu2w8fPswNN9xAUFAQ9erV49///nexr9vdd99NjRo1CA8P55prrmHjxo1u1VUqnoLuqkjdy0VERESkEixcuJDExESuvvpqbr/9dq6++moSExNZuHBhhTxfaGgooaGhfP755+Tk5JS4n9Vq5fXXX+ePP/5g7ty5fP/99zzyyCMAhIeHc/311/Pxxx+7HPPvf/+bvn37EhwcjM1mo0ePHoSFhbFq1SpWrVpFSEgIvXv3Jjc3F4BXX32VOXPmMHv2bH766SeOHz9eJHtdkjvvvJNVq1axZ88ewAysExMTadeunct+69ev59Zbb+W2227jt99+4+mnn2bixInMmTPHuc/QoUPZu3cvK1asYMGCBbz99tscPnzY5Tz//Oc/OXz4MN988w3r16+nXbt2dOvWjePHj7tVX6lYCrqropAQ8PEx7yvoFhEREZEKsHDhQm655Rb27dvnUr5//35uueWWCgm8fX19mTNnDnPnziUyMpLLL7+cxx9/nE2bNrns98ADDzh/ALjmmmt47rnn+PTTT53bBw0axOeff+7MaqelpfH1118zaNAgAD755BPsdjvvv/8+LVu2pGnTprz11lvs2bOHlStXAjBt2jQmTJhAv379aNq0KTNmzCCicI/TUtSsWZNevXo5g+fZs2dz1113Fdlv6tSpdOvWjYkTJ9K4cWOGDh3K6NGjefnllwH466+/+Oabb5g5cyb/+Mc/aN++PbNmzSIrK8t5jp9++ol169Yxf/58OnToQKNGjXjllVeIjIxkwYIF7r3wUqEUdFdFFsvpLubqXi4iIiIi5Sw/P5+xY8cW253aUfbAAw9USFfz/v37c+DAAb788kt69uzJypUradeunUv2d9myZXTr1o2EhATCwsK48847OXbsmDPI7t27N35+fnz55ZeAmWkODw+ne/fuAGzcuJHt27cTFhZGaGgo4eHh1K9fn+zsbHbs2MHJkydJSUmhU6dOzuf09fWlQ4cObl/HXXfdxZw5c/j7779JSkpyBvyFbd68mcsvv9yl7PLLL2fbtm3k5+ezefNmfH19ad++vXN7kyZNiCzU83Xjxo2kp6dTvXp1Z0+B0NBQdu7cyY4dO9yur1QcBd1VlSPoVqZbRERERMrZqlWrimS4CzMMg71797Jq1aoKef7AwECuvfZaJk6cyJo1axg6dCiTJk0CYNeuXVx//fW0atWKzz77jPXr1/PWW28BOLuG+/v7c8sttzi7mH/88ccMGDAAX19fANLT02nfvj3JyckkJyezYcMGfvzxR7Zs2cLtt99eLtfQq1cvsrKyGD58ODfccAPVq1cvl/OeKT09nbi4OOe1OG5bt27l4YcfrpDnlLJR0F1VKegWERERkQqSkpJSrvudr2bNmpGRkQGY46Dtdjuvvvoq//jHP2jcuDEHDhwocsygQYP49ttv+eOPP/j+++9dMs3t2rVj27Zt1KxZk4YNG9KwYUPq169Pw4YNiYiIICIigri4ONauXes8Ji8vj/Xr17tdZ19fXwYPHszKlSuL7VoO0LRp0yJLoa1evZrGjRvj4+NDkyZNijzv1q1bSU1NdbmWgwcP4uvr67wWxy06Otrt+krFUdBdVTm6lKh7uYiIiIiUs7i4uHLdz13Hjh3jmmuu4aOPPmLTpk3s3LmT+fPn89JLL3HTTTcB0LBhQ2w2G2+88QZ///03//rXv5gxY0aRc3Xp0oXY2FgGDRpEvXr1XLqKDxo0iOjoaG666SZWrVrFzp07+emnnxg7dqwzwz927FheeOEFPv/8c7Zs2cL999/vEuy649lnn+XIkSP06NGj2O0PPvggy5cv59lnn+Wvv/5i7ty5vPnmmzz00EMAXHLJJfTs2ZN77rmHtWvXsn79eu6++26CgoKc5+jevTudO3emb9++fPfdd+zatYs1a9bwxBNP8L///a9M9ZWKoaC7qlKmW0REREQqyJVXXkmtWrWwWCzFbrdYLNSuXZsrr7yyXJ83NDSUTp068dprr9GlSxdatGjBxIkTGTFiBG+++SYArVu3ZurUqbz44ou0aNGCf//730yZMqXYOg4cOJCNGzcWGU8dHBzMjz/+SJ06dejXrx/NmzdnzJgxZGdnEx4eDpgB8Z133smQIUPo3LkzYWFh3HzzzWW6Hn9/f6Kjo0t8Hdu1a8enn37KvHnzaNGiBU899RTPPPMMQ4cOde7zwQcfEB8fz1VXXUW/fv0YOXIkNWvWdLnOxYsX06VLF4YNG0bjxo257bbb2L17NzExMWWqr1QMi+HuYnMXiLS0NCIiIjh58qTzA+WNbDYbixcvdk4CUcTw4TB7Nrz4IhQsjyCV66xtJB6nNvJ+aiPvpzbyfmoj7+epNsrOzmbnzp3Uq1ePwMDAMh/vmL0ccJlQzRFALliwgH79+pVPZT3MbreTlpZGeHg4Vqvykt7Gk+1T2ufI3dhS76iq6v/+D+66CwYO9HRNREREROQC1K9fPxYsWEBCQoJLea1atS6ogFukovl6ugJyjlq3hlmzPF0LEREREbmA9evXzznuOSUlhbi4OK688kp8fHw8XTWRKkNBt4iIiIiIlMjHx4euXbt6uhoiVZZXdC9/6623SExMJDAwkE6dOrFu3boS9505cyZXXnklUVFRREVF0b1791L3FxEREREREfEUjwfdn3zyCePHj2fSpEls2LCB1q1b06NHDw4fPlzs/itXrmTgwIGsWLGCpKQkateuzXXXXcf+/fsrueYiIiIiIiIipfN40D116lRGjBjBsGHDaNasGTNmzCA4OJjZs2cXu/+///1v7r//ftq0aUOTJk14//33sdvtLF++vJJrLiIiIiLi/S6yxYpEylV5fH48GnTn5uayfv16unfv7iyzWq10796dpKQkt86RmZmJzWajWrVqFVVNEREREZEqxzHZWW5urodrIlJ1ZWZmApzXcn8enUjt6NGj5OfnF1m0PSYmhi1btrh1jkcffZT4+HiXwL2wnJwccnJynI/T0tIAc71Em812jjWveI66eXMdL3ZqI++nNvJ+aiPvpzbyfmoj7+epNjIMg8DAQA4fPoyPj4/Wny6FYRjk5uaSlZXlXIdcvIcn2scwDDIzMzly5Ajh4eHY7XbsdrvLPu5+pqv07OUvvPAC8+bNY+XKlUUWKneYMmUKkydPLlL+3XffERwcXNFVPG9Lly71dBXkLNRG3k9t5P3URt5PbeT91EbezxNtZLVaqVGjhjPxJCLus9vtnDp1im3bthW73ZEFPxuPBt3R0dH4+Phw6NAhl/JDhw4RGxtb6rGvvPIKL7zwAsuWLaNVq1Yl7jdhwgTGjx/vfJyWluacfC08PPz8LqAC2Ww2li5dyrXXXnteXRmk4qiNvJ/ayPupjbyf2sj7qY28n6fbyG63Y7PZNLa7FHl5eaxZs4bLLrsMX98qnZe8IHmifSwWC76+vqWuSe/uj1kefUf5+/vTvn17li9fTt++fQGck6KNHj26xONeeukl/t//+38sWbKEDh06lPocAQEBBAQEFCn38/OrEn+Yqko9L2ZqI++nNvJ+aiPvpzbyfmoj7+fJNiru+7CcZrPZyMvLIzQ0VJ8jL+St7eNuXTz+M8748eMZMmQIHTp0oGPHjkybNo2MjAyGDRsGwODBg0lISGDKlCkAvPjiizz11FN8/PHHJCYmcvDgQQBCQ0MJDQ312HWIiIiIiIiInMnjQfeAAQM4cuQITz31FAcPHqRNmzZ8++23zsnV9uzZ4zLpwzvvvENubi633HKLy3kmTZrE008/XZlVFxERERERESmVx4NugNGjR5fYnXzlypUuj3ft2lXxFRIREREREREpB14RdFcmxwQS3j6Do81mIzMzk7S0NK8atyCnqY28n9rI+6mNvJ/ayPupjbyf2sj7qY28m7e2jyOmPNskhRdd0H3q1CkAateu7eGaiIiIiIiISFV36tQpIiIiStxuMS6ytQPsdjsHDhwgLCzMqxe+dyxttnfvXq9e2uxipjbyfmoj76c28n5qI++nNvJ+aiPvpzbybt7aPoZhcOrUKeLj413mITvTRZfptlqt1KpVy9PVcFt4eLhXvbGkKLWR91MbeT+1kfdTG3k/tZH3Uxt5P7WRd/PG9iktw+1QcjguIiIiIiIiIudFQbeIiIiIiIhIBVHQ7aUCAgKYNGkSAQEBnq6KlEBt5P3URt5PbeT91EbeT23k/dRG3k9t5N2qevtcdBOpiYiIiIiIiFQWZbpFREREREREKoiCbhEREREREZEKoqBbREREREREpIIo6PZSb731FomJiQQGBtKpUyfWrVvn6SpdlKZMmcKll15KWFgYNWvWpG/fvmzdutVln65du2KxWFxu9957r4dqfPF5+umni7z+TZo0cW7Pzs5m1KhRVK9endDQUPr378+hQ4c8WOOLT2JiYpE2slgsjBo1CtBnyBN+/PFHbrjhBuLj47FYLHz++ecu2w3D4KmnniIuLo6goCC6d+/Otm3bXPY5fvw4gwYNIjw8nMjISIYPH056enolXsWFrbQ2stlsPProo7Rs2ZKQkBDi4+MZPHgwBw4ccDlHcZ+9F154oZKv5MJ1ts/R0KFDi7z+PXv2dNlHn6OKdbY2Ku5vk8Vi4eWXX3buo89RxXHne7Y73+P27NlDnz59CA4OpmbNmjz88MPk5eVV5qWclYJuL/TJJ58wfvx4Jk2axIYNG2jdujU9evTg8OHDnq7aReeHH35g1KhR/PzzzyxduhSbzcZ1111HRkaGy34jRowgJSXFeXvppZc8VOOLU/PmzV1e/59++sm5bdy4cXz11VfMnz+fH374gQMHDtCvXz8P1vbi88svv7i0z9KlSwH45z//6dxHn6HKlZGRQevWrXnrrbeK3f7SSy/x+uuvM2PGDNauXUtISAg9evQgOzvbuc+gQYP4448/WLp0Kf/973/58ccfGTlyZGVdwgWvtDbKzMxkw4YNTJw4kQ0bNrBw4UK2bt3KjTfeWGTfZ555xuWzNWbMmMqo/kXhbJ8jgJ49e7q8/v/5z39ctutzVLHO1kaF2yYlJYXZs2djsVjo37+/y376HFUMd75nn+17XH5+Pn369CE3N5c1a9Ywd+5c5syZw1NPPeWJSyqZIV6nY8eOxqhRo5yP8/Pzjfj4eGPKlCkerJUYhmEcPnzYAIwffvjBWXbVVVcZY8eO9VylLnKTJk0yWrduXey21NRUw8/Pz5g/f76zbPPmzQZgJCUlVVIN5Uxjx441GjRoYNjtdsMw9BnyNMBYtGiR87HdbjdiY2ONl19+2VmWmppqBAQEGP/5z38MwzCMP//80wCMX375xbnPN998Y1gsFmP//v2VVveLxZltVJx169YZgLF7925nWd26dY3XXnutYisnhmEU30ZDhgwxbrrpphKP0eeocrnzObrpppuMa665xqVMn6PKc+b3bHe+xy1evNiwWq3GwYMHnfu88847Rnh4uJGTk1O5F1AKZbq9TG5uLuvXr6d79+7OMqvVSvfu3UlKSvJgzQTg5MmTAFSrVs2l/N///jfR0dG0aNGCCRMmkJmZ6YnqXbS2bdtGfHw89evXZ9CgQezZsweA9evXY7PZXD5PTZo0oU6dOvo8eUhubi4fffQRd911FxaLxVmuz5D32LlzJwcPHnT53ERERNCpUyfn5yYpKYnIyEg6dOjg3Kd79+5YrVbWrl1b6XUW8++TxWIhMjLSpfyFF16gevXqtG3blpdfftnrulxe6FauXEnNmjW55JJLuO+++zh27Jhzmz5H3uXQoUN8/fXXDB8+vMg2fY4qx5nfs935HpeUlETLli2JiYlx7tOjRw/S0tL4448/KrH2pfP1dAXE1dGjR8nPz3d54wDExMSwZcsWD9VKAOx2Ow888ACXX345LVq0cJbffvvt1K1bl/j4eDZt2sSjjz7K1q1bWbhwoQdre/Ho1KkTc+bM4ZJLLiElJYXJkydz5ZVX8vvvv3Pw4EH8/f2LfAmNiYnh4MGDnqnwRe7zzz8nNTWVoUOHOsv0GfIujs9GcX+HHNsOHjxIzZo1Xbb7+vpSrVo1fbY8IDs7m0cffZSBAwcSHh7uLP+///s/2rVrR7Vq1VizZg0TJkwgJSWFqVOnerC2F4+ePXvSr18/6tWrx44dO3j88cfp1asXSUlJ+Pj46HPkZebOnUtYWFiRIWj6HFWO4r5nu/M97uDBg8X+vXJs8xYKukXcNGrUKH7//XeX8cKAy9irli1bEhcXR7du3dixYwcNGjSo7GpedHr16uW836pVKzp16kTdunX59NNPCQoK8mDNpDizZs2iV69exMfHO8v0GRI5dzabjVtvvRXDMHjnnXdcto0fP955v1WrVvj7+3PPPfcwZcoUAgICKruqF53bbrvNeb9ly5a0atWKBg0asHLlSrp16+bBmklxZs+ezaBBgwgMDHQp1+eocpT0PftCoe7lXiY6OhofH58is/IdOnSI2NhYD9VKRo8ezX//+19WrFhBrVq1St23U6dOAGzfvr0yqiZniIyMpHHjxmzfvp3Y2Fhyc3NJTU112UefJ8/YvXs3y5Yt4+677y51P32GPMvx2Sjt71BsbGyRyT3z8vI4fvy4PluVyBFw7969m6VLl7pkuYvTqVMn8vLy2LVrV+VUUFzUr1+f6Oho5/9t+hx5j1WrVrF169az/n0CfY4qQknfs935HhcbG1vs3yvHNm+hoNvL+Pv70759e5YvX+4ss9vtLF++nM6dO3uwZhcnwzAYPXo0ixYt4vvvv6devXpnPSY5ORmAuLi4Cq6dFCc9PZ0dO3YQFxdH+/bt8fPzc/k8bd26lT179ujz5AEffPABNWvWpE+fPqXup8+QZ9WrV4/Y2FiXz01aWhpr1651fm46d+5Mamoq69evd+7z/fffY7fbnT+aSMVyBNzbtm1j2bJlVK9e/azHJCcnY7Vai3Rplsqxb98+jh075vy/TZ8j7zFr1izat29P69atz7qvPkfl52zfs935Hte5c2d+++03lx+wHD9CNmvWrHIuxB0enshNijFv3jwjICDAmDNnjvHnn38aI0eONCIjI11m5ZPKcd999xkRERHGypUrjZSUFOctMzPTMAzD2L59u/HMM88Y//vf/4ydO3caX3zxhVG/fn2jS5cuHq75xePBBx80Vq5caezcudNYvXq10b17dyM6Oto4fPiwYRiGce+99xp16tQxvv/+e+N///uf0blzZ6Nz584ervXFJz8/38Gf9RwAAAdJSURBVKhTp47x6KOPupTrM+QZp06dMn799Vfj119/NQBj6tSpxq+//uqc+fqFF14wIiMjjS+++MLYtGmTcdNNNxn16tUzsrKynOfo2bOn0bZtW2Pt2rXGTz/9ZDRq1MgYOHCgpy7pglNaG+Xm5ho33nijUatWLSM5Odnl75Njtt41a9YYr732mpGcnGzs2LHD+Oijj4waNWoYgwcP9vCVXThKa6NTp04ZDz30kJGUlGTs3LnTWLZsmdGuXTujUaNGRnZ2tvMc+hxVrLP9X2cYhnHy5EkjODjYeOedd4ocr89RxTrb92zDOPv3uLy8PKNFixbGddddZyQnJxvffvutUaNGDWPChAmeuKQSKej2Um+88YZRp04dw9/f3+jYsaPx888/e7pKFyWg2NsHH3xgGIZh7Nmzx+jSpYtRrVo1IyAgwGjYsKHx8MMPGydPnvRsxS8iAwYMMOLi4gx/f38jISHBGDBggLF9+3bn9qysLOP+++83oqKijODgYOPmm282UlJSPFjji9OSJUsMwNi6datLuT5DnrFixYpi/28bMmSIYRjmsmETJ040YmJijICAAKNbt25F2u7YsWPGwIEDjdDQUCM8PNwYNmyYcerUKQ9czYWptDbauXNniX+fVqxYYRiGYaxfv97o1KmTERERYQQGBhpNmzY1nn/+eZeAT85PaW2UmZlpXHfddUaNGjUMPz8/o27dusaIESOKJFD0OapYZ/u/zjAM49133zWCgoKM1NTUIsfrc1SxzvY92zDc+x63a9cuo1evXkZQUJARHR1tPPjgg4bNZqvkqymdxTAMo4KS6CIiIiIiIiIXNY3pFhEREREREakgCrpFREREREREKoiCbhEREREREZEKoqBbREREREREpIIo6BYRERERERGpIAq6RURERERERCqIgm4RERERERGRCqKgW0RERERERKSCKOgWERGRc2axWPj88889XQ0RERGvpaBbRESkiho6dCgWi6XIrWfPnp6umoiIiBTw9XQFRERE5Nz17NmTDz74wKUsICDAQ7URERGRMynTLSIiUoUFBAQQGxvrcouKigLMrt/vvPMOvXr1IigoiPr167NgwQKX43/77TeuueYagoKCqF69OiNHjiQ9Pd1ln9mzZ9O8eXMCAgKIi4tj9OjRLtuPHj3KzTffTHBwMI0aNeLLL790bjtx4gSDBg2iRo0aBAUF0ahRoyI/EoiIiFzIFHSLiIhcwCZOnEj//v3ZuHEjgwYN4rbbbmPz5s0AZGRk0KNHD6Kiovjll1+YP38+y5Ytcwmq33nnHUaNGsXIkSP57bff+PLLL2nYsKHLc0yePJlbb72VTZs20bt3bwYNGsTx48edz//nn3/yzTffsHnzZt555x2io6Mr7wUQERHxMIthGIanKyEiIiJlN3ToUD766CMCAwNdyh9//HEef/xxLBYL9957L++8845z2z/+8Q/atWvH22+/zcyZM3n00UfZu3cvISEhACxevJgbbriBAwcOEBMTQ0JCAsOGDeO5554rtg4Wi4Unn3ySZ599FjAD+dDQUL755ht69uzJjTfeSHR0NLNnz66gV0FERMS7aUy3iIhIFXb11Ve7BNUA1apVc97v3Lmzy7bOnTuTnJwMwObNm2ndurUz4Aa4/PLLsdvtbN26FYvFwoEDB+jWrVupdWjVqpXzfkhICOHh4Rw+fBiA++67j/79+7Nhwwauu+46+vbty2WXXXZO1yoiIlIVKegWERGpwkJCQop09y4vQUFBbu3n5+fn8thisWC32wHo1asXu3fvZvHixSxdupRu3boxatQoXnnllXKvr4iIiDfSmG4REZEL2M8//1zkcdOmTQFo2rQpGzduJCMjw7l99erVWK1WLrnkEsLCwkhMTGT58uXnVYcaNWowZMgQPvroI6ZNm8Z77713XucTERGpSpTpFhERqcJycnI4ePCgS5mvr69zsrL58+fToUMHrrjiCv7973+zbt06Zs2aBcCgQYOYNGkSQ4YM4emnn+bIkSOMGTOGO++8k5iYGACefvpp7r33XmrWrEmvXr04deoUq1evZsyYMW7V76mnnqJ9+/Y0b96cnJwc/vvf/zqDfhERkYuBgm4REZEq7NtvvyUuLs6l7JJLLmHLli2AObP4vHnzuP/++4mLi+M///kPzZo1AyA4OJglS5YwduxYLr30UoKDg+nfvz9Tp051nmvIkCFkZ2fz2muv8dBDDxEdHc0tt9zidv38/f2ZMGECu3btIigoiCuvvJJ58+aVw5WLiIhUDZq9XERE5AJlsVhYtGgRffv29XRVRERELloa0y0iIiIiIiJSQRR0i4iIiIiIiFQQjekWERG5QGkEmYiIiOcp0y0iIiIiIiJSQRR0i4iIiIiIiFQQBd0iIiIiIiIiFURBt4iIiIiIiEgFUdAtIiIiIiIiUkEUdIuIiIiIiIhUEAXdIiIiIiIiIhVEQbeIiIiIiIhIBVHQLSIiIiIiIlJB/j/VTKHeqAozVQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f060684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average, Min, and Max Degrees Across All Graphs:\n",
      "  Attack Class ['DDoS']:\n",
      "    Avg Out-Degree (src): 1.0020 | Min: 1 | Max: 197\n",
      "    Avg In-Degree (dst): 363.2371 | Min: 1 | Max: 1500\n",
      "    Influence: 0.0000 | Min: 0.0000 | Max: 25.8726\n",
      "  Attack Class ['DoS']:\n",
      "    Avg Out-Degree (src): 1.0000 | Min: 1 | Max: 1\n",
      "    Avg In-Degree (dst): 440.2865 | Min: 1 | Max: 1500\n",
      "    Influence: 0.0000 | Min: 0.0000 | Max: 0.0007\n",
      "  Attack Class ['Normal']:\n",
      "    Avg Out-Degree (src): 1.0370 | Min: 1 | Max: 2\n",
      "    Avg In-Degree (dst): 1.3333 | Min: 1 | Max: 4\n",
      "    Influence: 0.0005 | Min: 0.0002 | Max: 0.0027\n",
      "  Attack Class ['Reconnaissance']:\n",
      "    Avg Out-Degree (src): 2.7792 | Min: 1 | Max: 1023\n",
      "    Avg In-Degree (dst): 1.6003 | Min: 1 | Max: 1476\n",
      "    Influence: 0.0032 | Min: 0.0000 | Max: 697.6853\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import degree\n",
    "from collections import defaultdict\n",
    "\n",
    "def check_global_avg_degrees_per_class(graph_dataset):\n",
    "    # Dictionaries to hold total degree sums and counts per class\n",
    "    total_out_deg = defaultdict(float)\n",
    "    total_in_deg = defaultdict(float)\n",
    "    count_out_nodes = defaultdict(int)\n",
    "    count_in_nodes = defaultdict(int)\n",
    "    min_out_deg = defaultdict(lambda: float('inf'))\n",
    "    max_out_deg = defaultdict(lambda: float('-inf'))\n",
    "    min_in_deg = defaultdict(lambda: float('inf'))\n",
    "    max_in_deg = defaultdict(lambda: float('-inf'))\n",
    "\n",
    "    for graph in graph_dataset:\n",
    "        edge_index = graph.edge_index\n",
    "        edge_label = graph.edge_label\n",
    "        num_nodes = graph.num_nodes\n",
    "\n",
    "        unique_classes = torch.unique(edge_label)\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            cls = int(cls)\n",
    "            mask = (edge_label == cls)\n",
    "\n",
    "            src_nodes = edge_index[0][mask]\n",
    "            dst_nodes = edge_index[1][mask]\n",
    "\n",
    "            out_deg = degree(src_nodes, num_nodes=num_nodes)\n",
    "            in_deg = degree(dst_nodes, num_nodes=num_nodes)\n",
    "\n",
    "            involved_src = out_deg > 0\n",
    "            involved_dst = in_deg > 0\n",
    "\n",
    "            total_out_deg[cls] += out_deg[involved_src].sum().item()\n",
    "            total_in_deg[cls] += in_deg[involved_dst].sum().item()\n",
    "            count_out_nodes[cls] += involved_src.sum().item()\n",
    "            count_in_nodes[cls] += involved_dst.sum().item()\n",
    "\n",
    "            if involved_src.any():\n",
    "                min_out_deg[cls] = min(min_out_deg[cls], out_deg[involved_src].min().item())\n",
    "                max_out_deg[cls] = max(max_out_deg[cls], out_deg[involved_src].max().item())\n",
    "            if involved_dst.any():\n",
    "                min_in_deg[cls] = min(min_in_deg[cls], in_deg[involved_dst].min().item())\n",
    "                max_in_deg[cls] = max(max_in_deg[cls], in_deg[involved_dst].max().item())\n",
    "\n",
    "    print(\"Average, Min, and Max Degrees Across All Graphs:\")\n",
    "    class_degree_report = {}\n",
    "    for cls in sorted(total_out_deg.keys()):\n",
    "        avg_out = total_out_deg[cls] / count_out_nodes[cls] if count_out_nodes[cls] > 0 else 0.0\n",
    "        avg_in = total_in_deg[cls] / count_in_nodes[cls] if count_in_nodes[cls] > 0 else 0.0\n",
    "        min_out = min_out_deg[cls] if min_out_deg[cls] != float('inf') else 0.0\n",
    "        max_out = max_out_deg[cls] if max_out_deg[cls] != float('-inf') else 0.0\n",
    "        min_in = min_in_deg[cls] if min_in_deg[cls] != float('inf') else 0.0\n",
    "        max_in = max_in_deg[cls] if max_in_deg[cls] != float('-inf') else 0.0\n",
    "\n",
    "        epsilon = 1e-6 # to avoid division by zero\n",
    "        avg_influence = (avg_out ** 2) / ((avg_in + epsilon) * WINDOW_SIZE)\n",
    "        max_influence = (max_out ** 2) / ((min_in + epsilon) * WINDOW_SIZE)\n",
    "        min_influence = (min_out ** 2) / ((max_in + epsilon) * WINDOW_SIZE)\n",
    "\n",
    "        print(f\"  Attack Class {le.inverse_transform([cls])}:\")\n",
    "        print(f\"    Avg Out-Degree (src): {avg_out:.4f} | Min: {min_out:.0f} | Max: {max_out:.0f}\")\n",
    "        print(f\"    Avg In-Degree (dst): {avg_in:.4f} | Min: {min_in:.0f} | Max: {max_in:.0f}\")\n",
    "        print(f\"    Influence: {avg_influence:.4f} | Min: {min_influence:.4f} | Max: {max_influence:.4f}\")\n",
    "\n",
    "        class_degree_report[le.inverse_transform([cls])[0]] = {\n",
    "            \"avg_out\": avg_out,\n",
    "            \"min_out\": min_out,\n",
    "            \"max_out\": max_out,\n",
    "            \"avg_in\": avg_in,\n",
    "            \"min_in\": min_in,\n",
    "            \"max_in\": max_in,\n",
    "            \"avg_influence\": avg_influence,\n",
    "            \"min_influence\": min_influence,\n",
    "            \"max_influence\": max_influence\n",
    "        }\n",
    "\n",
    "    return class_degree_report\n",
    "\n",
    "class_degree_report = check_global_avg_degrees_per_class(test_graph_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test graphs:  366\n",
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_1500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  30%|‚ñà‚ñà‚ñà       | 110/366 [00:00<00:01, 146.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9969\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[287995   1500      2      3      0]\n",
      " [     1 247438      0      2      0]\n",
      " [     0      0     26      0      2]\n",
      " [   188      4      5  11824     10]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9993    0.9948    0.9971    289500\n",
      "           DoS     0.9940    1.0000    0.9970    247441\n",
      "        Normal     0.7879    0.9286    0.8525        28\n",
      "Reconnaissance     0.9996    0.9828    0.9911     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9969    549000\n",
      "     macro avg     0.7562    0.7812    0.7675    549000\n",
      "  weighted avg     0.9969    0.9969    0.9969    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(dataset, adversarial=False):\n",
    "\n",
    "    # Check if dataset is a list of (data, label) tuples or just data objects\n",
    "    if isinstance(dataset[0], (list, tuple)):\n",
    "        data_obj = dataset[0][0]\n",
    "    else:\n",
    "        data_obj = dataset[0]\n",
    "\n",
    "    num_features = data_obj.edge_attr.shape[1]\n",
    "    best_model = EGraphSAGE(node_in_channels=num_features, \n",
    "                       edge_in_channels=num_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=len(class_map)).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path))\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "        all_pred_logits = []\n",
    "        all_test_labels = []\n",
    "        for G_pyg in tqdm(dataset, desc=\"Evaluation\", leave=False):\n",
    "            try:\n",
    "                # Move the graph data to the device\n",
    "                G_pyg = G_pyg.to(device)\n",
    "                G_pyg.edge_label = G_pyg.edge_label.to(device)\n",
    "                G_pyg.edge_attr = G_pyg.edge_attr.to(device)\n",
    "                out = best_model(G_pyg)\n",
    "                \n",
    "            except Exception as forward_error:\n",
    "                print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "            all_pred_logits.append(out.cpu())\n",
    "            all_test_labels.append(G_pyg.edge_label.cpu())\n",
    "\n",
    "        all_pred_logits = th.cat(all_pred_logits).to(device)\n",
    "        all_test_labels = th.cat(all_test_labels).to(device)\n",
    "        test_accuracy = compute_accuracy(all_pred_logits, all_test_labels)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "        pred_labels = all_pred_logits.argmax(dim=1).cpu()\n",
    "        all_test_labels = all_test_labels.cpu()\n",
    "    \n",
    "    if adversarial:\n",
    "\n",
    "        # Create a boolean mask where the label is NOT equal to the adversarial class\n",
    "        adversarial_mask = all_test_labels == ADVERSARIAL_CLASS_LABEL\n",
    "\n",
    "        # Print the class that the adversarial samples are classified as\n",
    "        cm_adversarial = confusion_matrix(all_test_labels[adversarial_mask], pred_labels[adversarial_mask], labels=range(len(class_map) + 1))\n",
    "        print(\"Adversarial confusion matrix:\", cm_adversarial)\n",
    "\n",
    "        # Apply the mask to both labels and predictions\n",
    "        all_test_labels = all_test_labels[~adversarial_mask]\n",
    "        pred_labels = pred_labels[~adversarial_mask]\n",
    "\n",
    "    print(\"class_map\", class_map)\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map)))\n",
    "    print(cm)\n",
    "\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, labels=range(len(class_map)))\n",
    "    print(report)\n",
    "    \n",
    "    return classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, output_dict=True, labels=range(len(class_map)))\n",
    "\n",
    "\n",
    "print(\"Number of test graphs: \", len(test_graph_dataset))\n",
    "normal_report = eval(test_graph_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cff736d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_traffic_to_node(graph, ratio=0.1, num_injected_nodes=1, to_node_type='both', random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    # Get all src nodes\n",
    "    if to_node_type == 'src':\n",
    "         to_nodes = edge_index[0]\n",
    "\n",
    "    elif to_node_type == 'dst':\n",
    "         to_nodes = edge_index[1]\n",
    "\n",
    "    elif to_node_type == 'both':\n",
    "         to_nodes = th.cat([edge_index[0], edge_index[1]])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"to_node_type must be 'src', 'dst', or 'both'.\")\n",
    "\n",
    "    original_num_nodes = x.size(0)\n",
    "\n",
    "    new_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "    x = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "    # 4. Inject edges from injected nodes to attacker nodes\n",
    "    num_to_inject = max(1, int(ratio * num_edges))\n",
    "    new_edges = []\n",
    "    new_attrs = []\n",
    "    new_labels = []\n",
    "    \n",
    "    for i in range(num_to_inject):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per iteration\n",
    "        src = rng.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "        dst = rng.choice(to_nodes.tolist())  # to existing nodes\n",
    "\n",
    "        new_edges.append([src, dst])\n",
    "        attr = th.rand(feature_dim)  # random feature for the new edge\n",
    "        new_attrs.append(attr)\n",
    "        new_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    # Create a new empty graph to store the injected edges\n",
    "    new_graph = Data()\n",
    "\n",
    "    # 5. Merge into graph\n",
    "    if new_edges:\n",
    "        new_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "        new_attrs = th.stack(new_attrs)\n",
    "        new_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "        new_graph.edge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "        new_graph.edge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "        new_graph.edge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "        new_graph.x = x\n",
    "\n",
    "    return new_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0a4cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_1500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8760\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [15563 12171  1754 25300   112     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[288864     64     24    548      0]\n",
      " [  7226 228280     16  11919      0]\n",
      " [     0      0     26      0      2]\n",
      " [   147      4      8  11862     10]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9751    0.9978    0.9863    289500\n",
      "           DoS     0.9997    0.9226    0.9596    247441\n",
      "        Normal     0.3514    0.9286    0.5098        28\n",
      "Reconnaissance     0.4876    0.9860    0.6525     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9636    549000\n",
      "     macro avg     0.5627    0.7670    0.6216    549000\n",
      "  weighted avg     0.9755    0.9636    0.9669    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_both_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='both') for g in test_graph_dataset]\n",
    "inject_both_report = eval(inject_both_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90b60cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_1500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8690\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [  789   885  3242 49757   227     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[288425     75     33    967      0]\n",
      " [ 12413 224503     30  10495      0]\n",
      " [     0      0     26      0      2]\n",
      " [   151      4     10  11856     10]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9583    0.9963    0.9769    289500\n",
      "           DoS     0.9996    0.9073    0.9512    247441\n",
      "        Normal     0.2626    0.9286    0.4094        28\n",
      "Reconnaissance     0.5084    0.9855    0.6708     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9559    549000\n",
      "     macro avg     0.5458    0.7635    0.6017    549000\n",
      "  weighted avg     0.9670    0.9559    0.9586    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_src_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='src') for g in test_graph_dataset]\n",
    "inject_src_report = eval(inject_src_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70287333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_1500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9063\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [28748 24896     1  1255     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[287993   1500      2      5      0]\n",
      " [     1 247437      0      3      0]\n",
      " [     0      0     26      0      2]\n",
      " [   169      7      3  11838     14]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9994    0.9948    0.9971    289500\n",
      "           DoS     0.9939    1.0000    0.9970    247441\n",
      "        Normal     0.8387    0.9286    0.8814        28\n",
      "Reconnaissance     0.9993    0.9840    0.9916     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9969    549000\n",
      "     macro avg     0.7663    0.7815    0.7734    549000\n",
      "  weighted avg     0.9969    0.9969    0.9969    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_dst_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='dst') for g in test_graph_dataset]\n",
    "inject_dst_report = eval(inject_dst_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "579e0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Attribute Perturbation\n",
    "def perturb_edge_attributes(graph, affected_edge_ratio=0.1, perturbation_ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = edge_attr.size(1)\n",
    "\n",
    "    # Randomly select edges to perturb\n",
    "    num_to_perturb = max(1, int(affected_edge_ratio * num_edges))\n",
    "    rng = random.Random(random_seed)\n",
    "    indices_to_perturb = rng.sample(range(num_edges), num_to_perturb)\n",
    "\n",
    "    for idx in indices_to_perturb:\n",
    "        # Perturb the edge attributes by adding noise\n",
    "        noise = th.randn(feature_dim) * perturbation_ratio  # Adjust the scale of noise as needed\n",
    "        edge_attr[idx] += noise\n",
    "\n",
    "    # Create a new graph with perturbed attributes\n",
    "    perturbed_graph = Data(edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label, x=graph.x)\n",
    "\n",
    "    return perturbed_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb68c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_1500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 351/366 [00:02<00:00, 155.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1005.21 MiB is allocated by PyTorch, and 40.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 26.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 1010.54 MiB is allocated by PyTorch, and 17.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 26.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 1011.20 MiB is allocated by PyTorch, and 16.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 26.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 1011.85 MiB is allocated by PyTorch, and 16.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 24.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 1012.50 MiB is allocated by PyTorch, and 17.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 24.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 1013.16 MiB is allocated by PyTorch, and 16.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Test Accuracy: 0.9822\n",
      "Adversarial confusion matrix: [[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[287853   1510     50     87      0]\n",
      " [  2354 245071     13      3      0]\n",
      " [     0      2     24      2      0]\n",
      " [  1826   1671   2082   6293    159]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9857    0.9943    0.9900    289500\n",
      "           DoS     0.9872    0.9904    0.9888    247441\n",
      "        Normal     0.0111    0.8571    0.0218        28\n",
      "Reconnaissance     0.9856    0.5231    0.6834     12031\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9822    549000\n",
      "     macro avg     0.5939    0.6730    0.5368    549000\n",
      "  weighted avg     0.9863    0.9822    0.9827    549000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Edge Attribute Perturbation\n",
    "edge_perturb_graph_dataset = [perturb_edge_attributes(g.cpu(), affected_edge_ratio=1, perturbation_ratio=1) for g in test_graph_dataset]\n",
    "edge_perturb_report = eval(edge_perturb_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc04f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject Random Edges\n",
    "def inject_random_edges(graph, ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_nodes = x.size(0)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    new_edge_indices = []\n",
    "    new_edge_attrs = []\n",
    "    new_edge_labels = []\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    num_injected_edges = max(1, int(ratio * num_edges))\n",
    "\n",
    "    for i in range(num_injected_edges):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per edge\n",
    "        src = rng.randint(0, num_nodes - 1)  # Random source node\n",
    "        dst = rng.randint(0, num_nodes - 1)  # Random destination node\n",
    "\n",
    "        new_edge_indices.append([src, dst])\n",
    "        new_edge_attrs.append(th.rand(feature_dim))  # Random feature for the new edge\n",
    "        new_edge_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    if new_edge_indices:\n",
    "        new_edge_indices = th.tensor(new_edge_indices, dtype=th.long).t().contiguous()\n",
    "        new_edge_attrs = th.stack(new_edge_attrs)\n",
    "        new_edge_labels = th.tensor(new_edge_labels, dtype=th.long)\n",
    "\n",
    "        edge_index = th.cat([edge_index, new_edge_indices], dim=1)\n",
    "        edge_attr = th.cat([edge_attr, new_edge_attrs], dim=0)\n",
    "        edge_label = th.cat([edge_label, new_edge_labels], dim=0)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b25073bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_endpoint_1500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   4%|‚ñç         | 15/366 [00:00<00:02, 144.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 20.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.05 GiB memory in use. Of the allocated memory 1014.99 MiB is allocated by PyTorch, and 19.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 18.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1018.56 MiB is allocated by PyTorch, and 17.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 18.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1019.16 MiB is allocated by PyTorch, and 16.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 18.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1021.30 MiB is allocated by PyTorch, and 14.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 16.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1020.53 MiB is allocated by PyTorch, and 17.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 16.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1021.23 MiB is allocated by PyTorch, and 16.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 16.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1021.91 MiB is allocated by PyTorch, and 16.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 14.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1022.60 MiB is allocated by PyTorch, and 17.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 14.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1023.29 MiB is allocated by PyTorch, and 16.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 14.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1023.98 MiB is allocated by PyTorch, and 16.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 12.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1.00 GiB is allocated by PyTorch, and 17.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 12.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1.00 GiB is allocated by PyTorch, and 16.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 12.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1.00 GiB is allocated by PyTorch, and 15.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 10.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1.00 GiB is allocated by PyTorch, and 17.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 10.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.06 GiB memory in use. Of the allocated memory 1.00 GiB is allocated by PyTorch, and 16.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.79 MiB is allocated by PyTorch, and 24.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1022.48 MiB is allocated by PyTorch, and 23.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1020.87 MiB is allocated by PyTorch, and 25.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   8%|‚ñä         | 30/366 [00:00<00:04, 74.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error during forward/backward pass at CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Inject Random Edges\u001b[39;00m\n\u001b[32m      2\u001b[39m random_edge_graph_dataset = [inject_random_edges(g.cpu(), \u001b[32m0.1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m test_graph_dataset]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m random_edge_report = \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrandom_edge_graph_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversarial\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36meval\u001b[39m\u001b[34m(dataset, adversarial)\u001b[39m\n\u001b[32m     43\u001b[39m     all_pred_logits.append(out.cpu())\n\u001b[32m     44\u001b[39m     all_test_labels.append(G_pyg.edge_label.cpu())\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m all_pred_logits = \u001b[43mth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_pred_logits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m all_test_labels = th.cat(all_test_labels).to(device)\n\u001b[32m     48\u001b[39m test_accuracy = compute_accuracy(all_pred_logits, all_test_labels)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 1.94 GiB of which 8.69 MiB is free. Process 2635581 has 808.00 MiB memory in use. Including non-PyTorch memory, this process has 1.07 GiB memory in use. Of the allocated memory 1021.22 MiB is allocated by PyTorch, and 24.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Inject Random Edges\n",
    "random_edge_graph_dataset = [inject_random_edges(g.cpu(), 0.1) for g in test_graph_dataset]\n",
    "random_edge_report = eval(random_edge_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c66190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Overall Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_58b54\">\n",
       "  <caption>Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_58b54_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_58b54_level0_col1\" class=\"col_heading level0 col1\" >Min Influence</th>\n",
       "      <th id=\"T_58b54_level0_col2\" class=\"col_heading level0 col2\" >Avg Influence</th>\n",
       "      <th id=\"T_58b54_level0_col3\" class=\"col_heading level0 col3\" >Max Influence</th>\n",
       "      <th id=\"T_58b54_level0_col4\" class=\"col_heading level0 col4\" >Normal precision</th>\n",
       "      <th id=\"T_58b54_level0_col5\" class=\"col_heading level0 col5\" >To Both precision</th>\n",
       "      <th id=\"T_58b54_level0_col6\" class=\"col_heading level0 col6\" >To Both precision Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col7\" class=\"col_heading level0 col7\" >To Src precision</th>\n",
       "      <th id=\"T_58b54_level0_col8\" class=\"col_heading level0 col8\" >To Src precision Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col9\" class=\"col_heading level0 col9\" >To Dst precision</th>\n",
       "      <th id=\"T_58b54_level0_col10\" class=\"col_heading level0 col10\" >To Dst precision Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col11\" class=\"col_heading level0 col11\" >Edge Perturbation precision</th>\n",
       "      <th id=\"T_58b54_level0_col12\" class=\"col_heading level0 col12\" >Edge Perturbation precision Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col13\" class=\"col_heading level0 col13\" >Random Edge precision</th>\n",
       "      <th id=\"T_58b54_level0_col14\" class=\"col_heading level0 col14\" >Random Edge precision Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col15\" class=\"col_heading level0 col15\" >Normal recall</th>\n",
       "      <th id=\"T_58b54_level0_col16\" class=\"col_heading level0 col16\" >To Both recall</th>\n",
       "      <th id=\"T_58b54_level0_col17\" class=\"col_heading level0 col17\" >To Both recall Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col18\" class=\"col_heading level0 col18\" >To Src recall</th>\n",
       "      <th id=\"T_58b54_level0_col19\" class=\"col_heading level0 col19\" >To Src recall Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col20\" class=\"col_heading level0 col20\" >To Dst recall</th>\n",
       "      <th id=\"T_58b54_level0_col21\" class=\"col_heading level0 col21\" >To Dst recall Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col22\" class=\"col_heading level0 col22\" >Edge Perturbation recall</th>\n",
       "      <th id=\"T_58b54_level0_col23\" class=\"col_heading level0 col23\" >Edge Perturbation recall Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col24\" class=\"col_heading level0 col24\" >Random Edge recall</th>\n",
       "      <th id=\"T_58b54_level0_col25\" class=\"col_heading level0 col25\" >Random Edge recall Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col26\" class=\"col_heading level0 col26\" >Normal f1-score</th>\n",
       "      <th id=\"T_58b54_level0_col27\" class=\"col_heading level0 col27\" >To Both f1-score</th>\n",
       "      <th id=\"T_58b54_level0_col28\" class=\"col_heading level0 col28\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col29\" class=\"col_heading level0 col29\" >To Src f1-score</th>\n",
       "      <th id=\"T_58b54_level0_col30\" class=\"col_heading level0 col30\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col31\" class=\"col_heading level0 col31\" >To Dst f1-score</th>\n",
       "      <th id=\"T_58b54_level0_col32\" class=\"col_heading level0 col32\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col33\" class=\"col_heading level0 col33\" >Edge Perturbation f1-score</th>\n",
       "      <th id=\"T_58b54_level0_col34\" class=\"col_heading level0 col34\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col35\" class=\"col_heading level0 col35\" >Random Edge f1-score</th>\n",
       "      <th id=\"T_58b54_level0_col36\" class=\"col_heading level0 col36\" >Random Edge f1-score Drop (%)</th>\n",
       "      <th id=\"T_58b54_level0_col37\" class=\"col_heading level0 col37\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_58b54_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_58b54_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_58b54_row0_col1\" class=\"data row0 col1\" >0.00</td>\n",
       "      <td id=\"T_58b54_row0_col2\" class=\"data row0 col2\" >0.12</td>\n",
       "      <td id=\"T_58b54_row0_col3\" class=\"data row0 col3\" >500.00</td>\n",
       "      <td id=\"T_58b54_row0_col4\" class=\"data row0 col4\" >0.99</td>\n",
       "      <td id=\"T_58b54_row0_col5\" class=\"data row0 col5\" >0.99</td>\n",
       "      <td id=\"T_58b54_row0_col6\" class=\"data row0 col6\" >0.43</td>\n",
       "      <td id=\"T_58b54_row0_col7\" class=\"data row0 col7\" >0.99</td>\n",
       "      <td id=\"T_58b54_row0_col8\" class=\"data row0 col8\" >0.59</td>\n",
       "      <td id=\"T_58b54_row0_col9\" class=\"data row0 col9\" >0.95</td>\n",
       "      <td id=\"T_58b54_row0_col10\" class=\"data row0 col10\" >4.16</td>\n",
       "      <td id=\"T_58b54_row0_col11\" class=\"data row0 col11\" >0.98</td>\n",
       "      <td id=\"T_58b54_row0_col12\" class=\"data row0 col12\" >1.00</td>\n",
       "      <td id=\"T_58b54_row0_col13\" class=\"data row0 col13\" >0.56</td>\n",
       "      <td id=\"T_58b54_row0_col14\" class=\"data row0 col14\" >43.24</td>\n",
       "      <td id=\"T_58b54_row0_col15\" class=\"data row0 col15\" >0.98</td>\n",
       "      <td id=\"T_58b54_row0_col16\" class=\"data row0 col16\" >0.54</td>\n",
       "      <td id=\"T_58b54_row0_col17\" class=\"data row0 col17\" >45.55</td>\n",
       "      <td id=\"T_58b54_row0_col18\" class=\"data row0 col18\" >0.50</td>\n",
       "      <td id=\"T_58b54_row0_col19\" class=\"data row0 col19\" >49.33</td>\n",
       "      <td id=\"T_58b54_row0_col20\" class=\"data row0 col20\" >1.00</td>\n",
       "      <td id=\"T_58b54_row0_col21\" class=\"data row0 col21\" >-1.42</td>\n",
       "      <td id=\"T_58b54_row0_col22\" class=\"data row0 col22\" >0.99</td>\n",
       "      <td id=\"T_58b54_row0_col23\" class=\"data row0 col23\" >-0.19</td>\n",
       "      <td id=\"T_58b54_row0_col24\" class=\"data row0 col24\" >1.00</td>\n",
       "      <td id=\"T_58b54_row0_col25\" class=\"data row0 col25\" >-1.59</td>\n",
       "      <td id=\"T_58b54_row0_col26\" class=\"data row0 col26\" >0.99</td>\n",
       "      <td id=\"T_58b54_row0_col27\" class=\"data row0 col27\" >0.70</td>\n",
       "      <td id=\"T_58b54_row0_col28\" class=\"data row0 col28\" >29.70</td>\n",
       "      <td id=\"T_58b54_row0_col29\" class=\"data row0 col29\" >0.66</td>\n",
       "      <td id=\"T_58b54_row0_col30\" class=\"data row0 col30\" >32.99</td>\n",
       "      <td id=\"T_58b54_row0_col31\" class=\"data row0 col31\" >0.98</td>\n",
       "      <td id=\"T_58b54_row0_col32\" class=\"data row0 col32\" >1.43</td>\n",
       "      <td id=\"T_58b54_row0_col33\" class=\"data row0 col33\" >0.99</td>\n",
       "      <td id=\"T_58b54_row0_col34\" class=\"data row0 col34\" >0.41</td>\n",
       "      <td id=\"T_58b54_row0_col35\" class=\"data row0 col35\" >0.72</td>\n",
       "      <td id=\"T_58b54_row0_col36\" class=\"data row0 col36\" >27.07</td>\n",
       "      <td id=\"T_58b54_row0_col37\" class=\"data row0 col37\" >289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58b54_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_58b54_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_58b54_row1_col1\" class=\"data row1 col1\" >0.00</td>\n",
       "      <td id=\"T_58b54_row1_col2\" class=\"data row1 col2\" >0.35</td>\n",
       "      <td id=\"T_58b54_row1_col3\" class=\"data row1 col3\" >500.00</td>\n",
       "      <td id=\"T_58b54_row1_col4\" class=\"data row1 col4\" >0.98</td>\n",
       "      <td id=\"T_58b54_row1_col5\" class=\"data row1 col5\" >0.64</td>\n",
       "      <td id=\"T_58b54_row1_col6\" class=\"data row1 col6\" >34.37</td>\n",
       "      <td id=\"T_58b54_row1_col7\" class=\"data row1 col7\" >0.63</td>\n",
       "      <td id=\"T_58b54_row1_col8\" class=\"data row1 col8\" >36.16</td>\n",
       "      <td id=\"T_58b54_row1_col9\" class=\"data row1 col9\" >1.00</td>\n",
       "      <td id=\"T_58b54_row1_col10\" class=\"data row1 col10\" >-1.84</td>\n",
       "      <td id=\"T_58b54_row1_col11\" class=\"data row1 col11\" >0.98</td>\n",
       "      <td id=\"T_58b54_row1_col12\" class=\"data row1 col12\" >-0.19</td>\n",
       "      <td id=\"T_58b54_row1_col13\" class=\"data row1 col13\" >0.99</td>\n",
       "      <td id=\"T_58b54_row1_col14\" class=\"data row1 col14\" >-1.42</td>\n",
       "      <td id=\"T_58b54_row1_col15\" class=\"data row1 col15\" >1.00</td>\n",
       "      <td id=\"T_58b54_row1_col16\" class=\"data row1 col16\" >1.00</td>\n",
       "      <td id=\"T_58b54_row1_col17\" class=\"data row1 col17\" >-0.38</td>\n",
       "      <td id=\"T_58b54_row1_col18\" class=\"data row1 col18\" >1.00</td>\n",
       "      <td id=\"T_58b54_row1_col19\" class=\"data row1 col19\" >-0.38</td>\n",
       "      <td id=\"T_58b54_row1_col20\" class=\"data row1 col20\" >0.95</td>\n",
       "      <td id=\"T_58b54_row1_col21\" class=\"data row1 col21\" >4.91</td>\n",
       "      <td id=\"T_58b54_row1_col22\" class=\"data row1 col22\" >0.98</td>\n",
       "      <td id=\"T_58b54_row1_col23\" class=\"data row1 col23\" >1.18</td>\n",
       "      <td id=\"T_58b54_row1_col24\" class=\"data row1 col24\" >0.13</td>\n",
       "      <td id=\"T_58b54_row1_col25\" class=\"data row1 col25\" >87.21</td>\n",
       "      <td id=\"T_58b54_row1_col26\" class=\"data row1 col26\" >0.99</td>\n",
       "      <td id=\"T_58b54_row1_col27\" class=\"data row1 col27\" >0.78</td>\n",
       "      <td id=\"T_58b54_row1_col28\" class=\"data row1 col28\" >20.77</td>\n",
       "      <td id=\"T_58b54_row1_col29\" class=\"data row1 col29\" >0.77</td>\n",
       "      <td id=\"T_58b54_row1_col30\" class=\"data row1 col30\" >22.10</td>\n",
       "      <td id=\"T_58b54_row1_col31\" class=\"data row1 col31\" >0.97</td>\n",
       "      <td id=\"T_58b54_row1_col32\" class=\"data row1 col32\" >1.62</td>\n",
       "      <td id=\"T_58b54_row1_col33\" class=\"data row1 col33\" >0.98</td>\n",
       "      <td id=\"T_58b54_row1_col34\" class=\"data row1 col34\" >0.49</td>\n",
       "      <td id=\"T_58b54_row1_col35\" class=\"data row1 col35\" >0.23</td>\n",
       "      <td id=\"T_58b54_row1_col36\" class=\"data row1 col36\" >77.14</td>\n",
       "      <td id=\"T_58b54_row1_col37\" class=\"data row1 col37\" >247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58b54_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_58b54_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_58b54_row2_col1\" class=\"data row2 col1\" >0.00</td>\n",
       "      <td id=\"T_58b54_row2_col2\" class=\"data row2 col2\" >0.02</td>\n",
       "      <td id=\"T_58b54_row2_col3\" class=\"data row2 col3\" >16.20</td>\n",
       "      <td id=\"T_58b54_row2_col4\" class=\"data row2 col4\" >0.94</td>\n",
       "      <td id=\"T_58b54_row2_col5\" class=\"data row2 col5\" >0.41</td>\n",
       "      <td id=\"T_58b54_row2_col6\" class=\"data row2 col6\" >56.14</td>\n",
       "      <td id=\"T_58b54_row2_col7\" class=\"data row2 col7\" >0.95</td>\n",
       "      <td id=\"T_58b54_row2_col8\" class=\"data row2 col8\" >-1.05</td>\n",
       "      <td id=\"T_58b54_row2_col9\" class=\"data row2 col9\" >0.93</td>\n",
       "      <td id=\"T_58b54_row2_col10\" class=\"data row2 col10\" >0.82</td>\n",
       "      <td id=\"T_58b54_row2_col11\" class=\"data row2 col11\" >0.94</td>\n",
       "      <td id=\"T_58b54_row2_col12\" class=\"data row2 col12\" >0.00</td>\n",
       "      <td id=\"T_58b54_row2_col13\" class=\"data row2 col13\" >0.21</td>\n",
       "      <td id=\"T_58b54_row2_col14\" class=\"data row2 col14\" >77.53</td>\n",
       "      <td id=\"T_58b54_row2_col15\" class=\"data row2 col15\" >0.65</td>\n",
       "      <td id=\"T_58b54_row2_col16\" class=\"data row2 col16\" >0.68</td>\n",
       "      <td id=\"T_58b54_row2_col17\" class=\"data row2 col17\" >-4.39</td>\n",
       "      <td id=\"T_58b54_row2_col18\" class=\"data row2 col18\" >0.68</td>\n",
       "      <td id=\"T_58b54_row2_col19\" class=\"data row2 col19\" >-4.39</td>\n",
       "      <td id=\"T_58b54_row2_col20\" class=\"data row2 col20\" >0.65</td>\n",
       "      <td id=\"T_58b54_row2_col21\" class=\"data row2 col21\" >0.00</td>\n",
       "      <td id=\"T_58b54_row2_col22\" class=\"data row2 col22\" >0.65</td>\n",
       "      <td id=\"T_58b54_row2_col23\" class=\"data row2 col23\" >0.00</td>\n",
       "      <td id=\"T_58b54_row2_col24\" class=\"data row2 col24\" >0.64</td>\n",
       "      <td id=\"T_58b54_row2_col25\" class=\"data row2 col25\" >1.75</td>\n",
       "      <td id=\"T_58b54_row2_col26\" class=\"data row2 col26\" >0.77</td>\n",
       "      <td id=\"T_58b54_row2_col27\" class=\"data row2 col27\" >0.51</td>\n",
       "      <td id=\"T_58b54_row2_col28\" class=\"data row2 col28\" >33.18</td>\n",
       "      <td id=\"T_58b54_row2_col29\" class=\"data row2 col29\" >0.79</td>\n",
       "      <td id=\"T_58b54_row2_col30\" class=\"data row2 col30\" >-3.00</td>\n",
       "      <td id=\"T_58b54_row2_col31\" class=\"data row2 col31\" >0.77</td>\n",
       "      <td id=\"T_58b54_row2_col32\" class=\"data row2 col32\" >0.34</td>\n",
       "      <td id=\"T_58b54_row2_col33\" class=\"data row2 col33\" >0.77</td>\n",
       "      <td id=\"T_58b54_row2_col34\" class=\"data row2 col34\" >0.00</td>\n",
       "      <td id=\"T_58b54_row2_col35\" class=\"data row2 col35\" >0.32</td>\n",
       "      <td id=\"T_58b54_row2_col36\" class=\"data row2 col36\" >58.61</td>\n",
       "      <td id=\"T_58b54_row2_col37\" class=\"data row2 col37\" >176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58b54_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_58b54_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_58b54_row3_col1\" class=\"data row3 col1\" >0.00</td>\n",
       "      <td id=\"T_58b54_row3_col2\" class=\"data row3 col2\" >0.22</td>\n",
       "      <td id=\"T_58b54_row3_col3\" class=\"data row3 col3\" >500.00</td>\n",
       "      <td id=\"T_58b54_row3_col4\" class=\"data row3 col4\" >1.00</td>\n",
       "      <td id=\"T_58b54_row3_col5\" class=\"data row3 col5\" >0.99</td>\n",
       "      <td id=\"T_58b54_row3_col6\" class=\"data row3 col6\" >0.45</td>\n",
       "      <td id=\"T_58b54_row3_col7\" class=\"data row3 col7\" >0.99</td>\n",
       "      <td id=\"T_58b54_row3_col8\" class=\"data row3 col8\" >0.21</td>\n",
       "      <td id=\"T_58b54_row3_col9\" class=\"data row3 col9\" >1.00</td>\n",
       "      <td id=\"T_58b54_row3_col10\" class=\"data row3 col10\" >-0.00</td>\n",
       "      <td id=\"T_58b54_row3_col11\" class=\"data row3 col11\" >1.00</td>\n",
       "      <td id=\"T_58b54_row3_col12\" class=\"data row3 col12\" >0.01</td>\n",
       "      <td id=\"T_58b54_row3_col13\" class=\"data row3 col13\" >0.99</td>\n",
       "      <td id=\"T_58b54_row3_col14\" class=\"data row3 col14\" >0.55</td>\n",
       "      <td id=\"T_58b54_row3_col15\" class=\"data row3 col15\" >0.91</td>\n",
       "      <td id=\"T_58b54_row3_col16\" class=\"data row3 col16\" >0.64</td>\n",
       "      <td id=\"T_58b54_row3_col17\" class=\"data row3 col17\" >30.06</td>\n",
       "      <td id=\"T_58b54_row3_col18\" class=\"data row3 col18\" >0.64</td>\n",
       "      <td id=\"T_58b54_row3_col19\" class=\"data row3 col19\" >29.94</td>\n",
       "      <td id=\"T_58b54_row3_col20\" class=\"data row3 col20\" >0.92</td>\n",
       "      <td id=\"T_58b54_row3_col21\" class=\"data row3 col21\" >-0.39</td>\n",
       "      <td id=\"T_58b54_row3_col22\" class=\"data row3 col22\" >0.91</td>\n",
       "      <td id=\"T_58b54_row3_col23\" class=\"data row3 col23\" >0.00</td>\n",
       "      <td id=\"T_58b54_row3_col24\" class=\"data row3 col24\" >0.44</td>\n",
       "      <td id=\"T_58b54_row3_col25\" class=\"data row3 col25\" >51.74</td>\n",
       "      <td id=\"T_58b54_row3_col26\" class=\"data row3 col26\" >0.95</td>\n",
       "      <td id=\"T_58b54_row3_col27\" class=\"data row3 col27\" >0.78</td>\n",
       "      <td id=\"T_58b54_row3_col28\" class=\"data row3 col28\" >18.46</td>\n",
       "      <td id=\"T_58b54_row3_col29\" class=\"data row3 col29\" >0.78</td>\n",
       "      <td id=\"T_58b54_row3_col30\" class=\"data row3 col30\" >18.29</td>\n",
       "      <td id=\"T_58b54_row3_col31\" class=\"data row3 col31\" >0.95</td>\n",
       "      <td id=\"T_58b54_row3_col32\" class=\"data row3 col32\" >-0.20</td>\n",
       "      <td id=\"T_58b54_row3_col33\" class=\"data row3 col33\" >0.95</td>\n",
       "      <td id=\"T_58b54_row3_col34\" class=\"data row3 col34\" >0.00</td>\n",
       "      <td id=\"T_58b54_row3_col35\" class=\"data row3 col35\" >0.61</td>\n",
       "      <td id=\"T_58b54_row3_col36\" class=\"data row3 col36\" >35.97</td>\n",
       "      <td id=\"T_58b54_row3_col37\" class=\"data row3 col37\" >13824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58b54_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_58b54_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_58b54_row4_col1\" class=\"data row4 col1\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col10\" class=\"data row4 col10\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col11\" class=\"data row4 col11\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col12\" class=\"data row4 col12\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col13\" class=\"data row4 col13\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col14\" class=\"data row4 col14\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col15\" class=\"data row4 col15\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col16\" class=\"data row4 col16\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col17\" class=\"data row4 col17\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col18\" class=\"data row4 col18\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col19\" class=\"data row4 col19\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col20\" class=\"data row4 col20\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col21\" class=\"data row4 col21\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col22\" class=\"data row4 col22\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col23\" class=\"data row4 col23\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col24\" class=\"data row4 col24\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col25\" class=\"data row4 col25\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col26\" class=\"data row4 col26\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col27\" class=\"data row4 col27\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col28\" class=\"data row4 col28\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col29\" class=\"data row4 col29\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col30\" class=\"data row4 col30\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col31\" class=\"data row4 col31\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col32\" class=\"data row4 col32\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col33\" class=\"data row4 col33\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col34\" class=\"data row4 col34\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col35\" class=\"data row4 col35\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col36\" class=\"data row4 col36\" >0.00</td>\n",
       "      <td id=\"T_58b54_row4_col37\" class=\"data row4 col37\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58b54_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_58b54_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_58b54_row5_col1\" class=\"data row5 col1\" >0.00</td>\n",
       "      <td id=\"T_58b54_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_58b54_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_58b54_row5_col4\" class=\"data row5 col4\" >0.78</td>\n",
       "      <td id=\"T_58b54_row5_col5\" class=\"data row5 col5\" >0.61</td>\n",
       "      <td id=\"T_58b54_row5_col6\" class=\"data row5 col6\" >22.36</td>\n",
       "      <td id=\"T_58b54_row5_col7\" class=\"data row5 col7\" >0.71</td>\n",
       "      <td id=\"T_58b54_row5_col8\" class=\"data row5 col8\" >9.00</td>\n",
       "      <td id=\"T_58b54_row5_col9\" class=\"data row5 col9\" >0.78</td>\n",
       "      <td id=\"T_58b54_row5_col10\" class=\"data row5 col10\" >0.79</td>\n",
       "      <td id=\"T_58b54_row5_col11\" class=\"data row5 col11\" >0.78</td>\n",
       "      <td id=\"T_58b54_row5_col12\" class=\"data row5 col12\" >0.21</td>\n",
       "      <td id=\"T_58b54_row5_col13\" class=\"data row5 col13\" >0.55</td>\n",
       "      <td id=\"T_58b54_row5_col14\" class=\"data row5 col14\" >29.46</td>\n",
       "      <td id=\"T_58b54_row5_col15\" class=\"data row5 col15\" >0.71</td>\n",
       "      <td id=\"T_58b54_row5_col16\" class=\"data row5 col16\" >0.57</td>\n",
       "      <td id=\"T_58b54_row5_col17\" class=\"data row5 col17\" >19.50</td>\n",
       "      <td id=\"T_58b54_row5_col18\" class=\"data row5 col18\" >0.56</td>\n",
       "      <td id=\"T_58b54_row5_col19\" class=\"data row5 col19\" >20.52</td>\n",
       "      <td id=\"T_58b54_row5_col20\" class=\"data row5 col20\" >0.70</td>\n",
       "      <td id=\"T_58b54_row5_col21\" class=\"data row5 col21\" >0.89</td>\n",
       "      <td id=\"T_58b54_row5_col22\" class=\"data row5 col22\" >0.71</td>\n",
       "      <td id=\"T_58b54_row5_col23\" class=\"data row5 col23\" >0.28</td>\n",
       "      <td id=\"T_58b54_row5_col24\" class=\"data row5 col24\" >0.44</td>\n",
       "      <td id=\"T_58b54_row5_col25\" class=\"data row5 col25\" >37.74</td>\n",
       "      <td id=\"T_58b54_row5_col26\" class=\"data row5 col26\" >0.74</td>\n",
       "      <td id=\"T_58b54_row5_col27\" class=\"data row5 col27\" >0.55</td>\n",
       "      <td id=\"T_58b54_row5_col28\" class=\"data row5 col28\" >25.14</td>\n",
       "      <td id=\"T_58b54_row5_col29\" class=\"data row5 col29\" >0.60</td>\n",
       "      <td id=\"T_58b54_row5_col30\" class=\"data row5 col30\" >18.82</td>\n",
       "      <td id=\"T_58b54_row5_col31\" class=\"data row5 col31\" >0.73</td>\n",
       "      <td id=\"T_58b54_row5_col32\" class=\"data row5 col32\" >0.83</td>\n",
       "      <td id=\"T_58b54_row5_col33\" class=\"data row5 col33\" >0.74</td>\n",
       "      <td id=\"T_58b54_row5_col34\" class=\"data row5 col34\" >0.24</td>\n",
       "      <td id=\"T_58b54_row5_col35\" class=\"data row5 col35\" >0.37</td>\n",
       "      <td id=\"T_58b54_row5_col36\" class=\"data row5 col36\" >49.28</td>\n",
       "      <td id=\"T_58b54_row5_col37\" class=\"data row5 col37\" >550500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58b54_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_58b54_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_58b54_row6_col1\" class=\"data row6 col1\" >0.00</td>\n",
       "      <td id=\"T_58b54_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_58b54_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_58b54_row6_col4\" class=\"data row6 col4\" >0.99</td>\n",
       "      <td id=\"T_58b54_row6_col5\" class=\"data row6 col5\" >0.83</td>\n",
       "      <td id=\"T_58b54_row6_col6\" class=\"data row6 col6\" >15.58</td>\n",
       "      <td id=\"T_58b54_row6_col7\" class=\"data row6 col7\" >0.83</td>\n",
       "      <td id=\"T_58b54_row6_col8\" class=\"data row6 col8\" >16.44</td>\n",
       "      <td id=\"T_58b54_row6_col9\" class=\"data row6 col9\" >0.97</td>\n",
       "      <td id=\"T_58b54_row6_col10\" class=\"data row6 col10\" >1.38</td>\n",
       "      <td id=\"T_58b54_row6_col11\" class=\"data row6 col11\" >0.98</td>\n",
       "      <td id=\"T_58b54_row6_col12\" class=\"data row6 col12\" >0.44</td>\n",
       "      <td id=\"T_58b54_row6_col13\" class=\"data row6 col13\" >0.77</td>\n",
       "      <td id=\"T_58b54_row6_col14\" class=\"data row6 col14\" >22.26</td>\n",
       "      <td id=\"T_58b54_row6_col15\" class=\"data row6 col15\" >0.99</td>\n",
       "      <td id=\"T_58b54_row6_col16\" class=\"data row6 col16\" >0.75</td>\n",
       "      <td id=\"T_58b54_row6_col17\" class=\"data row6 col17\" >24.36</td>\n",
       "      <td id=\"T_58b54_row6_col18\" class=\"data row6 col18\" >0.73</td>\n",
       "      <td id=\"T_58b54_row6_col19\" class=\"data row6 col19\" >26.34</td>\n",
       "      <td id=\"T_58b54_row6_col20\" class=\"data row6 col20\" >0.97</td>\n",
       "      <td id=\"T_58b54_row6_col21\" class=\"data row6 col21\" >1.48</td>\n",
       "      <td id=\"T_58b54_row6_col22\" class=\"data row6 col22\" >0.98</td>\n",
       "      <td id=\"T_58b54_row6_col23\" class=\"data row6 col23\" >0.44</td>\n",
       "      <td id=\"T_58b54_row6_col24\" class=\"data row6 col24\" >0.59</td>\n",
       "      <td id=\"T_58b54_row6_col25\" class=\"data row6 col25\" >39.89</td>\n",
       "      <td id=\"T_58b54_row6_col26\" class=\"data row6 col26\" >0.99</td>\n",
       "      <td id=\"T_58b54_row6_col27\" class=\"data row6 col27\" >0.74</td>\n",
       "      <td id=\"T_58b54_row6_col28\" class=\"data row6 col28\" >25.41</td>\n",
       "      <td id=\"T_58b54_row6_col29\" class=\"data row6 col29\" >0.71</td>\n",
       "      <td id=\"T_58b54_row6_col30\" class=\"data row6 col30\" >27.73</td>\n",
       "      <td id=\"T_58b54_row6_col31\" class=\"data row6 col31\" >0.97</td>\n",
       "      <td id=\"T_58b54_row6_col32\" class=\"data row6 col32\" >1.48</td>\n",
       "      <td id=\"T_58b54_row6_col33\" class=\"data row6 col33\" >0.98</td>\n",
       "      <td id=\"T_58b54_row6_col34\" class=\"data row6 col34\" >0.44</td>\n",
       "      <td id=\"T_58b54_row6_col35\" class=\"data row6 col35\" >0.50</td>\n",
       "      <td id=\"T_58b54_row6_col36\" class=\"data row6 col36\" >49.80</td>\n",
       "      <td id=\"T_58b54_row6_col37\" class=\"data row6 col37\" >550500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x72f4d7e43e00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_overall_metrics(baseline_report, adversarial_reports, class_degree_report):\n",
    "    rows = []   \n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    eplison = 1e-10  # To avoid division by zero\n",
    "\n",
    "    for label in list(class_map) + ['macro avg', 'weighted avg']:\n",
    "        row = {\"Class\": label}\n",
    "        row['Class'] = label\n",
    "        row['Min Influence'] = class_degree_report[label]['min_influence'] if label in class_degree_report else 0.0\n",
    "        row['Avg Influence'] = class_degree_report[label]['avg_influence'] if label in class_degree_report else 0.0\n",
    "        row['Max Influence'] = class_degree_report[label]['max_influence'] if label in class_degree_report else 0.0\n",
    "        for metric in metrics:\n",
    "            baseline_val = baseline_report[label][metric]\n",
    "            row[f\"Normal {metric}\"] = baseline_val\n",
    "            for name, report in adversarial_reports.items():\n",
    "                adv_val = report[label][metric]\n",
    "                row[f\"{name} {metric}\"] = adv_val\n",
    "                row[f\"{name} {metric} Drop (%)\"] = ((baseline_val - adv_val) / (baseline_val + eplison)) * 100\n",
    "        row['support'] = int(baseline_report[label]['support'])\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "adversarial_reports = {\n",
    "    \"To Both\": inject_both_report,\n",
    "    \"To Src\": inject_src_report,\n",
    "    \"To Dst\": inject_dst_report,\n",
    "    \"Edge Perturbation\": edge_perturb_report,\n",
    "    \"Random Edge\": random_edge_report,\n",
    "}\n",
    "\n",
    "comparison_df = compare_overall_metrics(normal_report, adversarial_reports, class_degree_report)\n",
    "\n",
    "class_col = comparison_df['Class']\n",
    "support_df = comparison_df['support']\n",
    "normal_cols = [col for col in comparison_df.columns if col.startswith('Normal')] \n",
    "influence_cols = [col for col in comparison_df.columns if col.endswith('Influence')] \n",
    "influence_df = comparison_df[influence_cols]\n",
    "f1_cols = [col for col in comparison_df.columns if col.endswith('f1-score')]\n",
    "f1_drop_cols = [col for col in comparison_df.columns if col.endswith('f1-score Drop (%)')]\n",
    "\n",
    "baselines_df = pd.concat([class_col, support_df, influence_df], axis=1)\n",
    "\n",
    "f1_df = pd.concat([baselines_df, comparison_df[f1_cols]], axis=1)\n",
    "f1_drop_df = pd.concat([baselines_df, comparison_df[f1_drop_cols]], axis=1)\n",
    "\n",
    "print(\"Comparison of Overall Metrics:\")\n",
    "display(comparison_df.style.set_caption(\"Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_94b3b_row0_col5, #T_94b3b_row0_col8, #T_94b3b_row0_col9, #T_94b3b_row0_col10, #T_94b3b_row1_col5, #T_94b3b_row1_col6, #T_94b3b_row1_col9, #T_94b3b_row2_col7, #T_94b3b_row6_col5, #T_94b3b_row6_col8, #T_94b3b_row6_col9 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row0_col6 {\n",
       "  background-color: #00682a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row0_col7 {\n",
       "  background-color: #0a7633;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row1_col7 {\n",
       "  background-color: #004d1f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row1_col8, #T_94b3b_row3_col6 {\n",
       "  background-color: #00451c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row1_col10 {\n",
       "  background-color: #b4e1ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_94b3b_row2_col5 {\n",
       "  background-color: #1c8540;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row2_col6 {\n",
       "  background-color: #3aa357;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row2_col8 {\n",
       "  background-color: #19833e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row2_col9 {\n",
       "  background-color: #1a843f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row2_col10 {\n",
       "  background-color: #8ace88;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_94b3b_row3_col5 {\n",
       "  background-color: #005020;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row3_col7 {\n",
       "  background-color: #00491d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row3_col8 {\n",
       "  background-color: #004a1e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row3_col9 {\n",
       "  background-color: #004e1f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row3_col10 {\n",
       "  background-color: #087432;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row4_col5, #T_94b3b_row4_col6, #T_94b3b_row4_col7, #T_94b3b_row4_col8, #T_94b3b_row4_col9, #T_94b3b_row4_col10 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_94b3b_row5_col5, #T_94b3b_row5_col9 {\n",
       "  background-color: #238b45;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row5_col6 {\n",
       "  background-color: #2d954d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row5_col7 {\n",
       "  background-color: #208843;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row5_col8 {\n",
       "  background-color: #228a44;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row5_col10 {\n",
       "  background-color: #6bc072;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_94b3b_row6_col6 {\n",
       "  background-color: #005622;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row6_col7 {\n",
       "  background-color: #006328;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_94b3b_row6_col10 {\n",
       "  background-color: #329b51;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_94b3b\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_94b3b_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_94b3b_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_94b3b_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_94b3b_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_94b3b_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_94b3b_level0_col5\" class=\"col_heading level0 col5\" >Normal f1-score</th>\n",
       "      <th id=\"T_94b3b_level0_col6\" class=\"col_heading level0 col6\" >To Both f1-score</th>\n",
       "      <th id=\"T_94b3b_level0_col7\" class=\"col_heading level0 col7\" >To Src f1-score</th>\n",
       "      <th id=\"T_94b3b_level0_col8\" class=\"col_heading level0 col8\" >To Dst f1-score</th>\n",
       "      <th id=\"T_94b3b_level0_col9\" class=\"col_heading level0 col9\" >Edge Perturbation f1-score</th>\n",
       "      <th id=\"T_94b3b_level0_col10\" class=\"col_heading level0 col10\" >Random Edge f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_94b3b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_94b3b_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_94b3b_row0_col1\" class=\"data row0 col1\" >289000</td>\n",
       "      <td id=\"T_94b3b_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row0_col3\" class=\"data row0 col3\" >0.12</td>\n",
       "      <td id=\"T_94b3b_row0_col4\" class=\"data row0 col4\" >500.00</td>\n",
       "      <td id=\"T_94b3b_row0_col5\" class=\"data row0 col5\" >0.99</td>\n",
       "      <td id=\"T_94b3b_row0_col6\" class=\"data row0 col6\" >0.70</td>\n",
       "      <td id=\"T_94b3b_row0_col7\" class=\"data row0 col7\" >0.66</td>\n",
       "      <td id=\"T_94b3b_row0_col8\" class=\"data row0 col8\" >0.98</td>\n",
       "      <td id=\"T_94b3b_row0_col9\" class=\"data row0 col9\" >0.99</td>\n",
       "      <td id=\"T_94b3b_row0_col10\" class=\"data row0 col10\" >0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94b3b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_94b3b_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_94b3b_row1_col1\" class=\"data row1 col1\" >247500</td>\n",
       "      <td id=\"T_94b3b_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row1_col3\" class=\"data row1 col3\" >0.35</td>\n",
       "      <td id=\"T_94b3b_row1_col4\" class=\"data row1 col4\" >500.00</td>\n",
       "      <td id=\"T_94b3b_row1_col5\" class=\"data row1 col5\" >0.99</td>\n",
       "      <td id=\"T_94b3b_row1_col6\" class=\"data row1 col6\" >0.78</td>\n",
       "      <td id=\"T_94b3b_row1_col7\" class=\"data row1 col7\" >0.77</td>\n",
       "      <td id=\"T_94b3b_row1_col8\" class=\"data row1 col8\" >0.97</td>\n",
       "      <td id=\"T_94b3b_row1_col9\" class=\"data row1 col9\" >0.98</td>\n",
       "      <td id=\"T_94b3b_row1_col10\" class=\"data row1 col10\" >0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94b3b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_94b3b_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_94b3b_row2_col1\" class=\"data row2 col1\" >176</td>\n",
       "      <td id=\"T_94b3b_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row2_col3\" class=\"data row2 col3\" >0.02</td>\n",
       "      <td id=\"T_94b3b_row2_col4\" class=\"data row2 col4\" >16.20</td>\n",
       "      <td id=\"T_94b3b_row2_col5\" class=\"data row2 col5\" >0.77</td>\n",
       "      <td id=\"T_94b3b_row2_col6\" class=\"data row2 col6\" >0.51</td>\n",
       "      <td id=\"T_94b3b_row2_col7\" class=\"data row2 col7\" >0.79</td>\n",
       "      <td id=\"T_94b3b_row2_col8\" class=\"data row2 col8\" >0.77</td>\n",
       "      <td id=\"T_94b3b_row2_col9\" class=\"data row2 col9\" >0.77</td>\n",
       "      <td id=\"T_94b3b_row2_col10\" class=\"data row2 col10\" >0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94b3b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_94b3b_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_94b3b_row3_col1\" class=\"data row3 col1\" >13824</td>\n",
       "      <td id=\"T_94b3b_row3_col2\" class=\"data row3 col2\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row3_col3\" class=\"data row3 col3\" >0.22</td>\n",
       "      <td id=\"T_94b3b_row3_col4\" class=\"data row3 col4\" >500.00</td>\n",
       "      <td id=\"T_94b3b_row3_col5\" class=\"data row3 col5\" >0.95</td>\n",
       "      <td id=\"T_94b3b_row3_col6\" class=\"data row3 col6\" >0.78</td>\n",
       "      <td id=\"T_94b3b_row3_col7\" class=\"data row3 col7\" >0.78</td>\n",
       "      <td id=\"T_94b3b_row3_col8\" class=\"data row3 col8\" >0.95</td>\n",
       "      <td id=\"T_94b3b_row3_col9\" class=\"data row3 col9\" >0.95</td>\n",
       "      <td id=\"T_94b3b_row3_col10\" class=\"data row3 col10\" >0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94b3b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_94b3b_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_94b3b_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_94b3b_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row4_col10\" class=\"data row4 col10\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94b3b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_94b3b_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_94b3b_row5_col1\" class=\"data row5 col1\" >550500</td>\n",
       "      <td id=\"T_94b3b_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row5_col4\" class=\"data row5 col4\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row5_col5\" class=\"data row5 col5\" >0.74</td>\n",
       "      <td id=\"T_94b3b_row5_col6\" class=\"data row5 col6\" >0.55</td>\n",
       "      <td id=\"T_94b3b_row5_col7\" class=\"data row5 col7\" >0.60</td>\n",
       "      <td id=\"T_94b3b_row5_col8\" class=\"data row5 col8\" >0.73</td>\n",
       "      <td id=\"T_94b3b_row5_col9\" class=\"data row5 col9\" >0.74</td>\n",
       "      <td id=\"T_94b3b_row5_col10\" class=\"data row5 col10\" >0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94b3b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_94b3b_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_94b3b_row6_col1\" class=\"data row6 col1\" >550500</td>\n",
       "      <td id=\"T_94b3b_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row6_col4\" class=\"data row6 col4\" >0.00</td>\n",
       "      <td id=\"T_94b3b_row6_col5\" class=\"data row6 col5\" >0.99</td>\n",
       "      <td id=\"T_94b3b_row6_col6\" class=\"data row6 col6\" >0.74</td>\n",
       "      <td id=\"T_94b3b_row6_col7\" class=\"data row6 col7\" >0.71</td>\n",
       "      <td id=\"T_94b3b_row6_col8\" class=\"data row6 col8\" >0.97</td>\n",
       "      <td id=\"T_94b3b_row6_col9\" class=\"data row6 col9\" >0.98</td>\n",
       "      <td id=\"T_94b3b_row6_col10\" class=\"data row6 col10\" >0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x72f4d7d5a5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check F1 Scores\n",
    "display(f1_df.style.background_gradient(cmap='Greens', subset=f1_cols, axis=0).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c4018_row0_col5 {\n",
       "  background-color: #fa6849;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c4018_row0_col6 {\n",
       "  background-color: #f6563d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c4018_row0_col7 {\n",
       "  background-color: #fff2eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4018_row0_col8 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4018_row0_col9 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c4018\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c4018_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_c4018_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_c4018_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_c4018_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_c4018_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_c4018_level0_col5\" class=\"col_heading level0 col5\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_c4018_level0_col6\" class=\"col_heading level0 col6\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_c4018_level0_col7\" class=\"col_heading level0 col7\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_c4018_level0_col8\" class=\"col_heading level0 col8\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_c4018_level0_col9\" class=\"col_heading level0 col9\" >Random Edge f1-score Drop (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c4018_level0_row0\" class=\"row_heading level0 row0\" >6</th>\n",
       "      <td id=\"T_c4018_row0_col0\" class=\"data row0 col0\" >weighted avg</td>\n",
       "      <td id=\"T_c4018_row0_col1\" class=\"data row0 col1\" >550500</td>\n",
       "      <td id=\"T_c4018_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_c4018_row0_col3\" class=\"data row0 col3\" >0.00</td>\n",
       "      <td id=\"T_c4018_row0_col4\" class=\"data row0 col4\" >0.00</td>\n",
       "      <td id=\"T_c4018_row0_col5\" class=\"data row0 col5\" >25.41</td>\n",
       "      <td id=\"T_c4018_row0_col6\" class=\"data row0 col6\" >27.73</td>\n",
       "      <td id=\"T_c4018_row0_col7\" class=\"data row0 col7\" >1.48</td>\n",
       "      <td id=\"T_c4018_row0_col8\" class=\"data row0 col8\" >0.44</td>\n",
       "      <td id=\"T_c4018_row0_col9\" class=\"data row0 col9\" >49.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x72f4d8243d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Drops per Adversarial Attack\n",
    "display(f1_drop_df[f1_drop_df['Class'] == 'weighted avg'].style.background_gradient(cmap='Reds', subset=f1_drop_cols, axis=None).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8033d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_333f8_row0_col5, #T_333f8_row0_col7 {\n",
       "  background-color: #9a0c14;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row0_col6, #T_333f8_row1_col7, #T_333f8_row1_col8, #T_333f8_row1_col9, #T_333f8_row2_col5 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row0_col8 {\n",
       "  background-color: #b31218;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row0_col9 {\n",
       "  background-color: #fc9b7c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_333f8_row1_col5 {\n",
       "  background-color: #ee3a2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row1_col6 {\n",
       "  background-color: #da2723;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row2_col6, #T_333f8_row2_col8, #T_333f8_row3_col7, #T_333f8_row4_col5, #T_333f8_row4_col8, #T_333f8_row4_col9 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_333f8_row2_col7 {\n",
       "  background-color: #fcad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_333f8_row2_col9 {\n",
       "  background-color: #c8171c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row3_col5 {\n",
       "  background-color: #f6553c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row3_col6 {\n",
       "  background-color: #f24734;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row3_col8 {\n",
       "  background-color: #fff4ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_333f8_row3_col9 {\n",
       "  background-color: #fb7555;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row4_col6 {\n",
       "  background-color: #fee7dc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_333f8_row4_col7 {\n",
       "  background-color: #fee3d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_333f8_row5_col5 {\n",
       "  background-color: #c9181d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row5_col6 {\n",
       "  background-color: #f14130;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row5_col7 {\n",
       "  background-color: #f4503a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row5_col8 {\n",
       "  background-color: #fb6d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row5_col9 {\n",
       "  background-color: #eb372a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row6_col5 {\n",
       "  background-color: #c5171c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row6_col6 {\n",
       "  background-color: #ab1016;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row6_col7 {\n",
       "  background-color: #8e0912;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row6_col8 {\n",
       "  background-color: #9f0e14;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_333f8_row6_col9 {\n",
       "  background-color: #e93529;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_333f8\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_333f8_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_333f8_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_333f8_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_333f8_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_333f8_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_333f8_level0_col5\" class=\"col_heading level0 col5\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_333f8_level0_col6\" class=\"col_heading level0 col6\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_333f8_level0_col7\" class=\"col_heading level0 col7\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_333f8_level0_col8\" class=\"col_heading level0 col8\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_333f8_level0_col9\" class=\"col_heading level0 col9\" >Random Edge f1-score Drop (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_333f8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_333f8_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_333f8_row0_col1\" class=\"data row0 col1\" >289000</td>\n",
       "      <td id=\"T_333f8_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_333f8_row0_col3\" class=\"data row0 col3\" >0.12</td>\n",
       "      <td id=\"T_333f8_row0_col4\" class=\"data row0 col4\" >500.00</td>\n",
       "      <td id=\"T_333f8_row0_col5\" class=\"data row0 col5\" >29.70</td>\n",
       "      <td id=\"T_333f8_row0_col6\" class=\"data row0 col6\" >32.99</td>\n",
       "      <td id=\"T_333f8_row0_col7\" class=\"data row0 col7\" >1.43</td>\n",
       "      <td id=\"T_333f8_row0_col8\" class=\"data row0 col8\" >0.41</td>\n",
       "      <td id=\"T_333f8_row0_col9\" class=\"data row0 col9\" >27.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333f8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_333f8_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_333f8_row1_col1\" class=\"data row1 col1\" >247500</td>\n",
       "      <td id=\"T_333f8_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_333f8_row1_col3\" class=\"data row1 col3\" >0.35</td>\n",
       "      <td id=\"T_333f8_row1_col4\" class=\"data row1 col4\" >500.00</td>\n",
       "      <td id=\"T_333f8_row1_col5\" class=\"data row1 col5\" >20.77</td>\n",
       "      <td id=\"T_333f8_row1_col6\" class=\"data row1 col6\" >22.10</td>\n",
       "      <td id=\"T_333f8_row1_col7\" class=\"data row1 col7\" >1.62</td>\n",
       "      <td id=\"T_333f8_row1_col8\" class=\"data row1 col8\" >0.49</td>\n",
       "      <td id=\"T_333f8_row1_col9\" class=\"data row1 col9\" >77.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333f8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_333f8_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_333f8_row2_col1\" class=\"data row2 col1\" >176</td>\n",
       "      <td id=\"T_333f8_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_333f8_row2_col3\" class=\"data row2 col3\" >0.02</td>\n",
       "      <td id=\"T_333f8_row2_col4\" class=\"data row2 col4\" >16.20</td>\n",
       "      <td id=\"T_333f8_row2_col5\" class=\"data row2 col5\" >33.18</td>\n",
       "      <td id=\"T_333f8_row2_col6\" class=\"data row2 col6\" >-3.00</td>\n",
       "      <td id=\"T_333f8_row2_col7\" class=\"data row2 col7\" >0.34</td>\n",
       "      <td id=\"T_333f8_row2_col8\" class=\"data row2 col8\" >0.00</td>\n",
       "      <td id=\"T_333f8_row2_col9\" class=\"data row2 col9\" >58.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333f8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_333f8_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_333f8_row3_col1\" class=\"data row3 col1\" >13824</td>\n",
       "      <td id=\"T_333f8_row3_col2\" class=\"data row3 col2\" >0.00</td>\n",
       "      <td id=\"T_333f8_row3_col3\" class=\"data row3 col3\" >0.22</td>\n",
       "      <td id=\"T_333f8_row3_col4\" class=\"data row3 col4\" >500.00</td>\n",
       "      <td id=\"T_333f8_row3_col5\" class=\"data row3 col5\" >18.46</td>\n",
       "      <td id=\"T_333f8_row3_col6\" class=\"data row3 col6\" >18.29</td>\n",
       "      <td id=\"T_333f8_row3_col7\" class=\"data row3 col7\" >-0.20</td>\n",
       "      <td id=\"T_333f8_row3_col8\" class=\"data row3 col8\" >0.00</td>\n",
       "      <td id=\"T_333f8_row3_col9\" class=\"data row3 col9\" >35.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333f8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_333f8_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_333f8_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_333f8_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_333f8_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_333f8_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_333f8_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_333f8_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_333f8_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_333f8_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_333f8_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333f8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_333f8_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_333f8_row5_col1\" class=\"data row5 col1\" >550500</td>\n",
       "      <td id=\"T_333f8_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_333f8_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_333f8_row5_col4\" class=\"data row5 col4\" >0.00</td>\n",
       "      <td id=\"T_333f8_row5_col5\" class=\"data row5 col5\" >25.14</td>\n",
       "      <td id=\"T_333f8_row5_col6\" class=\"data row5 col6\" >18.82</td>\n",
       "      <td id=\"T_333f8_row5_col7\" class=\"data row5 col7\" >0.83</td>\n",
       "      <td id=\"T_333f8_row5_col8\" class=\"data row5 col8\" >0.24</td>\n",
       "      <td id=\"T_333f8_row5_col9\" class=\"data row5 col9\" >49.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_333f8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_333f8_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_333f8_row6_col1\" class=\"data row6 col1\" >550500</td>\n",
       "      <td id=\"T_333f8_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_333f8_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_333f8_row6_col4\" class=\"data row6 col4\" >0.00</td>\n",
       "      <td id=\"T_333f8_row6_col5\" class=\"data row6 col5\" >25.41</td>\n",
       "      <td id=\"T_333f8_row6_col6\" class=\"data row6 col6\" >27.73</td>\n",
       "      <td id=\"T_333f8_row6_col7\" class=\"data row6 col7\" >1.48</td>\n",
       "      <td id=\"T_333f8_row6_col8\" class=\"data row6 col8\" >0.44</td>\n",
       "      <td id=\"T_333f8_row6_col9\" class=\"data row6 col9\" >49.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x72f4d7ffff50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Drops per Class\n",
    "display(f1_drop_df.style.background_gradient(cmap='Reds', subset=f1_drop_cols).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b5b4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comparison_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal Report:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(pformat(\u001b[38;5;28mdict\u001b[39m(report_dict), sort_dicts=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m1\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m print_results(class_degree_report, \u001b[43mcomparison_df\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'comparison_df' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pformat\n",
    "\n",
    "def round_tuple(t):\n",
    "    return tuple(round(x, 2) for x in t)\n",
    "\n",
    "def print_results(class_degree_report, comparison_df):\n",
    "    report_dict = defaultdict(dict)\n",
    "\n",
    "    for class_name, metrics in class_degree_report.items():\n",
    "        report_dict[class_name] = {\n",
    "            \"influence\": round_tuple((metrics['min_influence'], metrics['avg_influence'], metrics['max_influence'])),\n",
    "            \"out_degree\": round_tuple((metrics['min_out'], metrics['avg_out'], metrics['max_out'])),\n",
    "            \"in_degree\": round_tuple((metrics['min_in'], metrics['avg_in'], metrics['max_in']))\n",
    "        }\n",
    "\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        class_name = row['Class']\n",
    "        report_dict[class_name].update({\n",
    "            \"normal_f1\": round(row['Normal f1-score'], 2),\n",
    "            \"to_both_f1\": round(row['To Both f1-score'], 2),\n",
    "            \"to_src_f1\": round(row['To Src f1-score'], 2),\n",
    "            \"to_dst_f1\": round(row['To Dst f1-score'], 2),\n",
    "            \"edge_perturb_f1\": round(row['Edge Perturbation f1-score'], 2),\n",
    "            \"random_edge_f1\": round(row['Random Edge f1-score'], 2),\n",
    "        })\n",
    "\n",
    "    print(\"Final Report:\")\n",
    "    print(pformat(dict(report_dict), sort_dicts=False, indent=1))\n",
    "\n",
    "print_results(class_degree_report, comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
