{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec16c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====Experiment=====\n",
    "DONE\n",
    "'''\n",
    "DATASET_NAME = \"BoT_IoT\"\n",
    "\n",
    "GRAPH_CONSTRUCTION = 'host'\n",
    "WINDOW_SIZE = 500\n",
    "\n",
    "MULTICLASS = True\n",
    "\n",
    "LOAD_SAVED = True\n",
    "\n",
    "FIRST_RUN = not LOAD_SAVED\n",
    "\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import joblib\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.BoT_IoT.BoT_IoT_config import BoT_IoT_Config as Dataset_Config\n",
    "\n",
    "EXPERIMENT_NAME = f\"strat_window_{GRAPH_CONSTRUCTION}_{WINDOW_SIZE}\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = Dataset_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = Dataset_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = Dataset_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = Dataset_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = Dataset_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = Dataset_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = Dataset_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = Dataset_Config.TIME_COL_NAMES\n",
    "\n",
    "DROP_COLS = Dataset_Config.DROP_COLS\n",
    "\n",
    "COLS_TO_NORM = Dataset_Config.COLS_TO_NORM\n",
    "CATEGORICAL_COLS = Dataset_Config.CATEGORICAL_COLS\n",
    "\n",
    "if MULTICLASS:\n",
    "    label_col = ATTACK_CLASS_COL_NAME\n",
    "else:\n",
    "    label_col = IS_ATTACK_COL_NAME\n",
    "\n",
    "save_path = os.path.join(project_root, f\"Models/E_GraphSAGE/{DATASET_NAME}/saved\", EXPERIMENT_NAME)\n",
    "\n",
    "checkpoint_path = os.path.join(save_path, f\"checkpoints.pth\")\n",
    "best_model_path = os.path.join(save_path, f\"best_model.pth\")\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    csv_file_name = \"all_raw\"\n",
    "\n",
    "    data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"{DATASET_NAME}/All/{csv_file_name}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ee112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "    print(data[IS_ATTACK_COL_NAME].value_counts())\n",
    "\n",
    "    if MULTICLASS:\n",
    "        data.drop(columns=[IS_ATTACK_COL_NAME], inplace=True)\n",
    "    else:\n",
    "        data.drop(columns=[ATTACK_CLASS_COL_NAME], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    data.drop(columns=DROP_COLS,inplace=True)\n",
    "    print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    if GRAPH_CONSTRUCTION == 'endpoint':\n",
    "        data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "        data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "        # # Combine Port and IP\n",
    "        data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "        data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "        data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "        data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "        data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "        data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "        converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "\n",
    "    elif GRAPH_CONSTRUCTION == 'host':\n",
    "        data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "        converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "        COLS_TO_NORM = COLS_TO_NORM + [SOURCE_PORT_COL_NAME, DESTINATION_PORT_COL_NAME]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GRAPH_CONSTRUCTION value. Use 'host' or 'endpoint'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    # Clean NaN values\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "    data.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SAVED:\n",
    "    # Normalize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    print(data[COLS_TO_NORM].describe()) # Check if there's any too large value\n",
    "\n",
    "    # Check for numeric issues in the columns before normalization\n",
    "    def check_numeric_issues(df, cols_to_norm):\n",
    "        for col in cols_to_norm:\n",
    "            try:\n",
    "                # Try to coerce to numeric\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Column '{col}' failed with error: {e}\")\n",
    "                print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "                print(f\"  - Data type: {df[col].dtype}\")\n",
    "                continue\n",
    "\n",
    "        print(\"\\n‚úÖ All other columns processed successfully.\")\n",
    "\n",
    "    check_numeric_issues(data, COLS_TO_NORM)\n",
    "\n",
    "    data[COLS_TO_NORM] = scaler.fit_transform(data[COLS_TO_NORM])\n",
    "\n",
    "    # Save the scaler for future use\n",
    "    scaler_path = os.path.join(save_path, \"scaler.pkl\")\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(\"Data after normalization:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4382030",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED:\n",
    "    # load scaler\n",
    "    scaler_path = os.path.join(save_path, \"scaler.pkl\")\n",
    "    scaler = joblib.load(scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    num_classes = 2\n",
    "    class_map = [0, 1]\n",
    "    if MULTICLASS:\n",
    "        le = LabelEncoder()\n",
    "        attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "        class_map = le.classes_\n",
    "        print(class_map)\n",
    "        print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "        data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "        num_classes = len(class_map)\n",
    "        class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n",
    "\n",
    "    class_map_path = os.path.join(save_path, \"class_map.pkl\")\n",
    "    labeller_path = os.path.join(save_path, \"labeller.pkl\")\n",
    "\n",
    "    joblib.dump(le, labeller_path)\n",
    "    joblib.dump(class_map, class_map_path)\n",
    "\n",
    "    BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "    ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75c715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED:\n",
    "    # Save the class map BENIGN_CLASS_LABEL, ADVERSARIAL_CLASS_LABEL\n",
    "    class_map_path = os.path.join(save_path, \"class_map.pkl\")\n",
    "    labeller_path = os.path.join(save_path, \"labeller.pkl\")\n",
    "\n",
    "    class_map = joblib.load(class_map_path)\n",
    "    le = joblib.load(labeller_path)\n",
    "\n",
    "    BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "    ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SAVED:\n",
    "    # Maintain the order of the rows in the original dataframe\n",
    "    feature_cols = COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "    print('Feature Columns:', feature_cols)\n",
    "    num_features = len(feature_cols)\n",
    "    print('Number of Features:', num_features)\n",
    "\n",
    "    data['h'] = data[ feature_cols ].values.tolist()\n",
    "    print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df):\n",
    "\n",
    "    G_nx = nx.from_pandas_edgelist(df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "    \n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    assert num_edges == G_nx.number_of_edges(), \"Number of edges in PyG graph does not match NetworkX graph.\"\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    return G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e650028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class StratifiedGraphDataset:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.total_count = len(self.y)\n",
    "\n",
    "        # Compute class weights\n",
    "        labels = []\n",
    "\n",
    "        for graph in self.X:\n",
    "            labels.append(graph.edge_label.tolist())\n",
    "\n",
    "        labels = np.concatenate(labels)\n",
    "\n",
    "        self.class_counts = Counter(labels)\n",
    "\n",
    "        # Compute the class weights\n",
    "        self.class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(labels),\n",
    "            y=labels\n",
    "        )\n",
    "\n",
    "    def k_fold_split(self, k: int = 5, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        cv = MultilabelStratifiedShuffleSplit(test_size=test_ratio, random_state=random_state, n_splits=k)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        y_binary = mlb.fit_transform(self.y)\n",
    "\n",
    "        return cv.split(np.zeros(len(self.X)), y_binary)\n",
    "\n",
    "    def graph_train_test_split(self, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        train_idx, test_idx = next(self.k_fold_split(k = 1, test_ratio = test_ratio, random_state = random_state))\n",
    "        \n",
    "        X_train = [self.X[i] for i in train_idx]\n",
    "        X_test = [self.X[i] for i in test_idx]\n",
    "\n",
    "        y_train = [self.y[i] for i in train_idx]\n",
    "        y_test = [self.y[i] for i in test_idx]\n",
    "\n",
    "        return StratifiedGraphDataset(X_train, y_train), StratifiedGraphDataset(X_test, y_test)\n",
    "    \n",
    "    def print_class_distribution_and_weights(self):\n",
    "        # Use the label encoder to inverse transform the class labels\n",
    "        class_counts_named = {cls: count for cls, count in self.class_counts.items()}\n",
    "        class_weights_named = {cls: weight for cls, weight in enumerate(self.class_weights)}\n",
    "        print(\"Class Counts and Weights:\")\n",
    "        for cls_label in class_counts_named.keys():\n",
    "            count = class_counts_named[cls_label]\n",
    "            weight = class_weights_named[cls_label]\n",
    "            print(f\"{cls_label:<2}  {le.inverse_transform([cls_label])[0]:<15}: Count = {count:<10}, Weight = {weight:<10.4f}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_count\n",
    "\n",
    "    def __iter__(self):\n",
    "        for g in self.X:\n",
    "            yield g\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.X[idx], self.y[idx]\n",
    "        elif isinstance(idx, slice):\n",
    "            return [self.X[i] for i in range(len(self.X))][idx], [self.y[i] for i in range(len(self.y))][idx]\n",
    "        else:\n",
    "            raise TypeError(\"Index must be an integer or a slice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8988bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    def generate_graph_datasets(\n",
    "        df: pd.DataFrame, \n",
    "        window_size: int = WINDOW_SIZE, \n",
    "        feature_cols=feature_cols,\n",
    "        ordering_cols= TIME_COLS, \n",
    "        label_col=label_col,\n",
    "        build_graph_func=create_graph,\n",
    "        ):\n",
    "\n",
    "        print(\"All Columns: \", df.columns)\n",
    "        print(\"Ordering Columns: \", ordering_cols)\n",
    "        assert all(col in df.columns for col in ordering_cols), \"All timestamp columns are required\"\n",
    "        assert label_col in df.columns, \"Edge label column 'label' is required\"\n",
    "        \n",
    "        df = df.sort_values(ordering_cols).reset_index(drop=True)\n",
    "        window_size = int(window_size)\n",
    "        \n",
    "        df.drop(columns=set(df.columns) - set(feature_cols) - set(label_col))\n",
    "\n",
    "        print(\"Final Columns: \", df.columns)\n",
    "        \n",
    "        label_counts_list = []\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        progress_bar = tqdm(range(0, len(df), window_size), desc=f\"Generating graphs\")\n",
    "        for start in progress_bar:\n",
    "            window_df = df[start: min(start + window_size, len(df))]\n",
    "            contains_label = window_df[label_col].unique()\n",
    "\n",
    "            G_pyg = build_graph_func(window_df)\n",
    "\n",
    "            label_counts = window_df[label_col].value_counts()\n",
    "\n",
    "            label_counts_list.append(label_counts)\n",
    "            X.append(G_pyg)\n",
    "            y.append(contains_label.tolist())\n",
    "\n",
    "        return StratifiedGraphDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491e7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph_dataset_path = os.path.join(save_path, \"test_graph_dataset.pth\")\n",
    "if FIRST_RUN:\n",
    "    graph_dataset = generate_graph_datasets(data)\n",
    "    full_train_graph_dataset, test_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)\n",
    "    th.save(test_graph_dataset, test_graph_dataset_path)\n",
    "\n",
    "if LOAD_SAVED:\n",
    "    # Save or Load test_graph_dataset\n",
    "    if os.path.exists(test_graph_dataset_path):  \n",
    "        test_graph_dataset = th.load(test_graph_dataset_path, weights_only=False)\n",
    "    else:       \n",
    "        raise FileNotFoundError(f\"File {test_graph_dataset_path} does not exist. Please run the code to generate the dataset first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365fd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    print(\"Class Distrubution:\", data[label_col].value_counts())\n",
    "\n",
    "    print(\"Number of graphs after downsampling:\", len(graph_dataset))\n",
    "    graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "    print(\"Number of training graphs:\", len(full_train_graph_dataset))\n",
    "    full_train_graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "    print(\"Number of testing graphs:\", len(test_graph_dataset))\n",
    "    test_graph_dataset.print_class_distribution_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00a2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    def grid_search(graph_dataset, patience, max_epochs, learning_rates, hidden_dims, drop_outs, folds=3):\n",
    "        global num_features\n",
    "        \n",
    "        best_params = {}\n",
    "        best_f1 = 0\n",
    "        params_results = {}\n",
    "\n",
    "        # Precompute the train and validation graphs for all folds\n",
    "        folds_list = []\n",
    "        for i in range(folds):\n",
    "            train_graph_dataset, val_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=i)\n",
    "            folds_list.append((train_graph_dataset, val_graph_dataset))\n",
    "\n",
    "        for lr in learning_rates:\n",
    "            for hidden_dim in hidden_dims:\n",
    "                for drop_out in drop_outs:\n",
    "                    print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}, drop_out: {drop_out}\")\n",
    "                    fold_f1_scores = []\n",
    "\n",
    "                    for fold, (train_graph_dataset, val_graph_dataset) in enumerate(folds_list):\n",
    "                        print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                        model = EGraphSAGE(node_in_channels=num_features,\n",
    "                                        edge_in_channels=num_features,\n",
    "                                        hidden_channels=hidden_dim,\n",
    "                                        dropout = drop_out,\n",
    "                                        out_channels=num_classes).to(device)\n",
    "\n",
    "                        model.apply(init_weights)\n",
    "\n",
    "                        # Normalize to stabilize training\n",
    "                        class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "                        print(\"Class weights:\", class_weights)\n",
    "\n",
    "                        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                        optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "                        scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                            optimizer,\n",
    "                            mode='min',\n",
    "                            factor=0.6,\n",
    "                            patience=5,\n",
    "                            min_lr=1e-6,\n",
    "                        )\n",
    "\n",
    "                        best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "                        best_val_loss = float('inf')  # Track the best val_loss for this fold\n",
    "                        patience_counter = 0\n",
    "\n",
    "                        for epoch in range(max_epochs):\n",
    "                            try:\n",
    "                                train_loss = 0\n",
    "                                val_loss = 0\n",
    "                                num_train_graphs = len(train_graph_dataset)\n",
    "                                num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "                                model.train()\n",
    "                                optimizer.zero_grad()\n",
    "                                for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "                                    G_pyg_train = G_pyg_train.to(device)\n",
    "                                    G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                                    G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "                                    \n",
    "                                    out = model(G_pyg_train)\n",
    "                                    loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                                    train_loss += loss.item()\n",
    "\n",
    "                                    loss.backward()\n",
    "\n",
    "                                optimizer.step()\n",
    "                                \n",
    "\n",
    "                                test_label_list = []\n",
    "                                pred_label_list = []\n",
    "\n",
    "                                model.eval()\n",
    "                                with th.no_grad():\n",
    "                                    for G_pyg_val in tqdm(val_graph_dataset, desc=\"Validation\", leave=False):\n",
    "\n",
    "                                        G_pyg_val = G_pyg_val.to(device)\n",
    "                                        G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                                        G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                                        out = model(G_pyg_val)\n",
    "                                        loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                                        val_loss += loss.item()\n",
    "\n",
    "                                        test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                                        pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "                                test_label = th.cat(test_label_list)\n",
    "                                pred_label = th.cat(pred_label_list)\n",
    "\n",
    "                                val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "                                val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "                                val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "                                # Schedule step\n",
    "                                scheduler.step(val_loss)\n",
    "\n",
    "                                if val_f1 > best_epoch_f1:\n",
    "                                    best_epoch_f1 = val_f1\n",
    "                                    print(f\"Epoch {epoch}/{max_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                                    f\"Val F1 (weighted): {val_f1:.4f}, Micro: {val_f1_micro:.4f}, Macro: {val_f1_macro:.4f} \"\n",
    "                                    f\"(Best Weighted F1 so far: {best_epoch_f1:.4f})\")\n",
    "\n",
    "                                # Early stopping condition\n",
    "                                if val_loss < best_val_loss:\n",
    "                                    best_val_loss = val_loss\n",
    "                                    patience_counter = 0\n",
    "                                else:\n",
    "                                    patience_counter += 1\n",
    "\n",
    "                                if patience_counter >= patience:\n",
    "                                    print(f\"\\nüõë Early stopping triggered at epoch {epoch}.\")\n",
    "                                    break\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                                break\n",
    "\n",
    "                        fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "                    \n",
    "                    avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "                    params_results[(drop_out, lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "                    print(f\"Average F1 Score for drop_out {drop_out}, learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "                    if avg_f1 > best_f1:\n",
    "                        best_f1 = avg_f1\n",
    "                        best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim, 'drop_out': drop_out}\n",
    "\n",
    "        print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "        print(\"All results:\", params_results)\n",
    "\n",
    "    # grid_search(\n",
    "    #     full_train_graph_dataset, \n",
    "    #     patience=10,\n",
    "    #     max_epochs=200,\n",
    "    #     learning_rates=[0.001, 0.005, 0.01, 0.05], \n",
    "    #     hidden_dims=[128, 256, 512], \n",
    "    #     drop_outs=[0.2, 0.3, 0.4],\n",
    "    #     folds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b158d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    train_graph_dataset, val_graph_dataset = full_train_graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ec4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint():\n",
    "    global epoch, model, optimizer, scheduler, train_loss_history, val_loss_history, val_f1_history, saved_model_epochs, best_f1, patience_counter, best_val_loss, train_ended, max_epochs, patience\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss_history': train_loss_history,\n",
    "        'val_loss_history': val_loss_history,\n",
    "        'val_f1_history': val_f1_history,\n",
    "        'saved_model_epochs': saved_model_epochs,\n",
    "        'best_f1': best_f1,\n",
    "        # 'patience_counter': patience_counter,\n",
    "        # 'best_val_loss': best_val_loss,\n",
    "        'train_ended': train_ended,\n",
    "        'max_epochs': max_epochs,\n",
    "        # 'patience': patience\n",
    "    }\n",
    "    \n",
    "    th.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters from the grid search\n",
    "best_hidden_dim = 256  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.01  # Replace with the best learning_rate found\n",
    "best_drop_out = 0.3  # Replace with the best drop_out found\n",
    "if FIRST_RUN:\n",
    "\n",
    "    max_epochs = 200\n",
    "    # patience = 10\n",
    "\n",
    "    print(\"Number of train graphs: \", len(train_graph_dataset))\n",
    "\n",
    "    # Initialize the model with the best parameters\n",
    "    model = EGraphSAGE(node_in_channels=num_features, \n",
    "                    edge_in_channels=num_features,\n",
    "                    hidden_channels=best_hidden_dim,\n",
    "                    dropout = best_drop_out,\n",
    "                    out_channels=num_classes).to(device)\n",
    "\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # Normalize class weights\n",
    "    class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.6,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "    )\n",
    "\n",
    "    # ===== Load checkpoint if exists =====\n",
    "    start_epoch = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    # patience_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    train_ended = False\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_f1_history = []\n",
    "    saved_model_epochs = []\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = th.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "        train_ended = checkpoint['train_ended']\n",
    "        best_f1 = checkpoint['best_f1']\n",
    "\n",
    "        assert max_epochs == checkpoint['max_epochs'], \"Checkpoint max_epochs does not match the current setting.\"\n",
    "        # assert patience == checkpoint['patience'], \"Checkpoint patience does not match the current setting.\"\n",
    "\n",
    "        # patience_counter = checkpoint['patience_counter']\n",
    "        # best_val_loss = checkpoint['best_val_loss']\n",
    "\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "        train_loss_history = checkpoint['train_loss_history']\n",
    "        val_loss_history = checkpoint['val_loss_history']\n",
    "        val_f1_history = checkpoint['val_f1_history']\n",
    "        saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "        print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "    if train_ended:\n",
    "        model.load_state_dict(th.load(best_model_path))\n",
    "        print(\"Training has already ended. Loaded the best model state.\")\n",
    "        print(\"Training history loaded successfully.\")\n",
    "\n",
    "    else:\n",
    "        # ===== Start Training =====\n",
    "        num_train_graphs = len(train_graph_dataset)\n",
    "        num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "        for epoch in range(start_epoch, max_epochs):\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "                # Move the graph data to the device\n",
    "                G_pyg_train = G_pyg_train.to(device)\n",
    "                G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "                out = model(G_pyg_train)\n",
    "                loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            test_label_list = []\n",
    "            pred_label_list = []\n",
    "\n",
    "            model.eval()\n",
    "            with th.no_grad():\n",
    "                for G_pyg_val in tqdm(val_graph_dataset, desc=\"Evaluation\", leave=False):\n",
    "                    G_pyg_val = G_pyg_val.to(device)\n",
    "                    G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                    G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                    out = model(G_pyg_val)\n",
    "                    loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                    pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "            test_label = th.cat(test_label_list)\n",
    "            pred_label = th.cat(pred_label_list)\n",
    "\n",
    "            val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "            val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "            val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "            train_loss_history.append(train_loss)\n",
    "            val_loss_history.append(val_loss)\n",
    "            val_f1_history.append((val_f1, val_f1_micro, val_f1_macro))\n",
    "\n",
    "            # Schedule step\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1  # Update the best F1 score for this fold\n",
    "                best_model_state = model.state_dict()\n",
    "                saved_model_epochs.append(epoch)\n",
    "\n",
    "                save_checkpoint()\n",
    "                th.save(best_model_state, best_model_path)\n",
    "                print(f\"Epoch {epoch} Saved best model. Best F1:\", best_f1)\n",
    "\n",
    "            print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}, Validation F1 Micro: {val_f1_micro:.4f}, Validation F1 Macro: {val_f1_macro:.4f}')\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                save_checkpoint()\n",
    "\n",
    "            # # Early stopping condition\n",
    "            # if val_loss < best_val_loss:\n",
    "            #     best_val_loss = val_loss\n",
    "            #     patience_counter = 0\n",
    "            # else:\n",
    "            #     patience_counter += 1\n",
    "\n",
    "            # if patience_counter >= patience:\n",
    "            #     print(f\"\\nüõë Early stopping triggered at epoch {epoch}.\")\n",
    "            #     train_ended = True\n",
    "            #     break\n",
    "\n",
    "        # Save the trained model\n",
    "        train_ended = True\n",
    "        save_checkpoint()\n",
    "        print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_process():\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    val_loss_history = checkpoint['val_loss_history']\n",
    "    val_f1_history = checkpoint['val_f1_history']\n",
    "    saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Plot Train Loss\n",
    "    axs[0].plot(train_loss_history, label='Train Loss', color='blue')\n",
    "    axs[0].plot(val_loss_history, label='Validation Loss', color='red')\n",
    "    axs[0].set_ylabel('Train Loss')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    val_f1_weighted_history = []\n",
    "    val_f1_micro_history = []\n",
    "    val_f1_macro_history = []\n",
    "\n",
    "    for val_f1_weighted, val_f1_micro, val_f1_macro in val_f1_history:\n",
    "        val_f1_weighted_history.append(val_f1_weighted)\n",
    "        val_f1_micro_history.append(val_f1_micro)\n",
    "        val_f1_macro_history.append(val_f1_macro)\n",
    "    \n",
    "    # Plot Validation F1\n",
    "\n",
    "    axs[1].plot(val_f1_weighted_history, label='Validation F1 Weighted', color='green')\n",
    "    axs[1].plot(val_f1_micro_history, label='Validation F1 Micro', color='blue')\n",
    "    axs[1].plot(val_f1_macro_history, label='Validation F1 Macro', color='red')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Validation F1')\n",
    "    axs[1].set_title('Validation F1 Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    # Add scatter for saved model epochs (e.g., F1 weighted here)\n",
    "    axs[1].scatter(saved_model_epochs, [val_f1_weighted_history[i] for i in saved_model_epochs],\n",
    "                   color='black', marker='o', label='Saved Model')\n",
    "    axs[1].legend()\n",
    "\n",
    "    print(len(train_loss_history))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2572f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f060684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average, Min, and Max Degrees Across All Graphs:\n",
      "  Attack Class ['DDoS']:\n",
      "    Avg Out-Degree (src): 168.0233 | Min: 1 | Max: 500\n",
      "    Avg In-Degree (dst): 483.2776 | Min: 1 | Max: 500\n",
      "    Influence: 0.1168 | Min: 0.0000 | Max: 499.9995\n",
      "  Attack Class ['DoS']:\n",
      "    Avg Out-Degree (src): 174.1731 | Min: 1 | Max: 500\n",
      "    Avg In-Degree (dst): 174.1731 | Min: 1 | Max: 500\n",
      "    Influence: 0.3483 | Min: 0.0000 | Max: 499.9995\n",
      "  Attack Class ['Normal']:\n",
      "    Avg Out-Degree (src): 4.6316 | Min: 1 | Max: 90\n",
      "    Avg In-Degree (dst): 2.2564 | Min: 1 | Max: 17\n",
      "    Influence: 0.0190 | Min: 0.0001 | Max: 16.2000\n",
      "  Attack Class ['Reconnaissance']:\n",
      "    Avg Out-Degree (src): 141.0612 | Min: 1 | Max: 500\n",
      "    Avg In-Degree (dst): 181.8947 | Min: 1 | Max: 500\n",
      "    Influence: 0.2188 | Min: 0.0000 | Max: 499.9995\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import degree\n",
    "from collections import defaultdict\n",
    "\n",
    "def check_global_avg_degrees_per_class(graph_dataset):\n",
    "    # Dictionaries to hold total degree sums and counts per class\n",
    "    total_out_deg = defaultdict(float)\n",
    "    total_in_deg = defaultdict(float)\n",
    "    count_out_nodes = defaultdict(int)\n",
    "    count_in_nodes = defaultdict(int)\n",
    "    min_out_deg = defaultdict(lambda: float('inf'))\n",
    "    max_out_deg = defaultdict(lambda: float('-inf'))\n",
    "    min_in_deg = defaultdict(lambda: float('inf'))\n",
    "    max_in_deg = defaultdict(lambda: float('-inf'))\n",
    "\n",
    "    for graph in graph_dataset:\n",
    "        edge_index = graph.edge_index\n",
    "        edge_label = graph.edge_label\n",
    "        num_nodes = graph.num_nodes\n",
    "\n",
    "        unique_classes = torch.unique(edge_label)\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            cls = int(cls)\n",
    "            mask = (edge_label == cls)\n",
    "\n",
    "            src_nodes = edge_index[0][mask]\n",
    "            dst_nodes = edge_index[1][mask]\n",
    "\n",
    "            out_deg = degree(src_nodes, num_nodes=num_nodes)\n",
    "            in_deg = degree(dst_nodes, num_nodes=num_nodes)\n",
    "\n",
    "            involved_src = out_deg > 0\n",
    "            involved_dst = in_deg > 0\n",
    "\n",
    "            total_out_deg[cls] += out_deg[involved_src].sum().item()\n",
    "            total_in_deg[cls] += in_deg[involved_dst].sum().item()\n",
    "            count_out_nodes[cls] += involved_src.sum().item()\n",
    "            count_in_nodes[cls] += involved_dst.sum().item()\n",
    "\n",
    "            if involved_src.any():\n",
    "                min_out_deg[cls] = min(min_out_deg[cls], out_deg[involved_src].min().item())\n",
    "                max_out_deg[cls] = max(max_out_deg[cls], out_deg[involved_src].max().item())\n",
    "            if involved_dst.any():\n",
    "                min_in_deg[cls] = min(min_in_deg[cls], in_deg[involved_dst].min().item())\n",
    "                max_in_deg[cls] = max(max_in_deg[cls], in_deg[involved_dst].max().item())\n",
    "\n",
    "    print(\"Average, Min, and Max Degrees Across All Graphs:\")\n",
    "    class_degree_report = {}\n",
    "    for cls in sorted(total_out_deg.keys()):\n",
    "        avg_out = total_out_deg[cls] / count_out_nodes[cls] if count_out_nodes[cls] > 0 else 0.0\n",
    "        avg_in = total_in_deg[cls] / count_in_nodes[cls] if count_in_nodes[cls] > 0 else 0.0\n",
    "        min_out = min_out_deg[cls] if min_out_deg[cls] != float('inf') else 0.0\n",
    "        max_out = max_out_deg[cls] if max_out_deg[cls] != float('-inf') else 0.0\n",
    "        min_in = min_in_deg[cls] if min_in_deg[cls] != float('inf') else 0.0\n",
    "        max_in = max_in_deg[cls] if max_in_deg[cls] != float('-inf') else 0.0\n",
    "\n",
    "        epsilon = 1e-6 # to avoid division by zero\n",
    "        avg_influence = (avg_out ** 2) / ((avg_in + epsilon) * WINDOW_SIZE)\n",
    "        max_influence = (max_out ** 2) / ((min_in + epsilon) * WINDOW_SIZE)\n",
    "        min_influence = (min_out ** 2) / ((max_in + epsilon) * WINDOW_SIZE)\n",
    "\n",
    "        print(f\"  Attack Class {le.inverse_transform([cls])}:\")\n",
    "        print(f\"    Avg Out-Degree (src): {avg_out:.4f} | Min: {min_out:.0f} | Max: {max_out:.0f}\")\n",
    "        print(f\"    Avg In-Degree (dst): {avg_in:.4f} | Min: {min_in:.0f} | Max: {max_in:.0f}\")\n",
    "        print(f\"    Influence: {avg_influence:.4f} | Min: {min_influence:.4f} | Max: {max_influence:.4f}\")\n",
    "\n",
    "        class_degree_report[le.inverse_transform([cls])[0]] = {\n",
    "            \"avg_out\": avg_out,\n",
    "            \"min_out\": min_out,\n",
    "            \"max_out\": max_out,\n",
    "            \"avg_in\": avg_in,\n",
    "            \"min_in\": min_in,\n",
    "            \"max_in\": max_in,\n",
    "            \"avg_influence\": avg_influence,\n",
    "            \"min_influence\": min_influence,\n",
    "            \"max_influence\": max_influence\n",
    "        }\n",
    "\n",
    "    return class_degree_report\n",
    "\n",
    "class_degree_report = check_global_avg_degrees_per_class(test_graph_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test graphs:  1101\n",
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_host_500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9874\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[284446   4554      0      0      0]\n",
      " [  1138 246361      1      0      0]\n",
      " [     0      1    114     61      0]\n",
      " [   500    702      6  12616      0]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9943    0.9842    0.9892    289000\n",
      "           DoS     0.9791    0.9954    0.9872    247500\n",
      "        Normal     0.9421    0.6477    0.7677       176\n",
      "Reconnaissance     0.9952    0.9126    0.9521     13824\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9874    550500\n",
      "     macro avg     0.7821    0.7080    0.7392    550500\n",
      "  weighted avg     0.9875    0.9874    0.9873    550500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(dataset, adversarial=False):\n",
    "\n",
    "    # Check if dataset is a list of (data, label) tuples or just data objects\n",
    "    if isinstance(dataset[0], (list, tuple)):\n",
    "        data_obj = dataset[0][0]\n",
    "    else:\n",
    "        data_obj = dataset[0]\n",
    "\n",
    "    num_features = data_obj.edge_attr.shape[1]\n",
    "    best_model = EGraphSAGE(node_in_channels=num_features, \n",
    "                       edge_in_channels=num_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=len(class_map)).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path))\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "        all_pred_logits = []\n",
    "        all_test_labels = []\n",
    "        for G_pyg in tqdm(dataset, desc=\"Evaluation\", leave=False):\n",
    "            try:\n",
    "                # Move the graph data to the device\n",
    "                G_pyg = G_pyg.to(device)\n",
    "                G_pyg.edge_label = G_pyg.edge_label.to(device)\n",
    "                G_pyg.edge_attr = G_pyg.edge_attr.to(device)\n",
    "                out = best_model(G_pyg)\n",
    "                \n",
    "            except Exception as forward_error:\n",
    "                print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "            all_pred_logits.append(out.cpu())\n",
    "            all_test_labels.append(G_pyg.edge_label.cpu())\n",
    "\n",
    "        all_pred_logits = th.cat(all_pred_logits).to(device)\n",
    "        all_test_labels = th.cat(all_test_labels).to(device)\n",
    "        test_accuracy = compute_accuracy(all_pred_logits, all_test_labels)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "        pred_labels = all_pred_logits.argmax(dim=1).cpu()\n",
    "        all_test_labels = all_test_labels.cpu()\n",
    "    \n",
    "    if adversarial:\n",
    "\n",
    "        # Create a boolean mask where the label is NOT equal to the adversarial class\n",
    "        adversarial_mask = all_test_labels == ADVERSARIAL_CLASS_LABEL\n",
    "\n",
    "        # Print the class that the adversarial samples are classified as\n",
    "        cm_adversarial = confusion_matrix(all_test_labels[adversarial_mask], pred_labels[adversarial_mask], labels=range(len(class_map) + 1))\n",
    "        print(\"Adversarial confusion matrix:\", cm_adversarial)\n",
    "\n",
    "        # Apply the mask to both labels and predictions\n",
    "        all_test_labels = all_test_labels[~adversarial_mask]\n",
    "        pred_labels = pred_labels[~adversarial_mask]\n",
    "\n",
    "    print(\"class_map\", class_map)\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map)))\n",
    "    print(cm)\n",
    "\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, labels=range(len(class_map)))\n",
    "    print(report)\n",
    "    \n",
    "    return classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, output_dict=True, labels=range(len(class_map)))\n",
    "\n",
    "\n",
    "print(\"Number of test graphs: \", len(test_graph_dataset))\n",
    "normal_report = eval(test_graph_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cff736d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_traffic_to_node(graph, ratio=0.1, num_injected_nodes=1, to_node_type='both', random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    # Get all src nodes\n",
    "    if to_node_type == 'src':\n",
    "         to_nodes = edge_index[0]\n",
    "\n",
    "    elif to_node_type == 'dst':\n",
    "         to_nodes = edge_index[1]\n",
    "\n",
    "    elif to_node_type == 'both':\n",
    "         to_nodes = th.cat([edge_index[0], edge_index[1]])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"to_node_type must be 'src', 'dst', or 'both'.\")\n",
    "\n",
    "    original_num_nodes = x.size(0)\n",
    "\n",
    "    new_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "    x = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "    # 4. Inject edges from injected nodes to attacker nodes\n",
    "    num_to_inject = max(1, int(ratio * num_edges))\n",
    "    new_edges = []\n",
    "    new_attrs = []\n",
    "    new_labels = []\n",
    "    \n",
    "    for i in range(num_to_inject):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per iteration\n",
    "        src = rng.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "        dst = rng.choice(to_nodes.tolist())  # to existing nodes\n",
    "\n",
    "        new_edges.append([src, dst])\n",
    "        attr = th.rand(feature_dim)  # random feature for the new edge\n",
    "        new_attrs.append(attr)\n",
    "        new_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    # Create a new empty graph to store the injected edges\n",
    "    new_graph = Data()\n",
    "\n",
    "    # 5. Merge into graph\n",
    "    if new_edges:\n",
    "        new_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "        new_attrs = th.stack(new_attrs)\n",
    "        new_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "        new_graph.edge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "        new_graph.edge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "        new_graph.edge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "        new_graph.x = x\n",
    "\n",
    "    return new_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0a4cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_host_500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6741\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [15703  4049    33 35265     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[150832 138148      0      1     19]\n",
      " [   205 247292      0      3      0]\n",
      " [     0      1    119     56      0]\n",
      " [  1366   2482      6   9964      6]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9897    0.5219    0.6834    289000\n",
      "           DoS     0.6375    0.9992    0.7784    247500\n",
      "        Normal     0.9520    0.6761    0.7907       176\n",
      "Reconnaissance     0.9940    0.7208    0.8356     13824\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.7415    550500\n",
      "     macro avg     0.7146    0.5836    0.6176    550500\n",
      "  weighted avg     0.8314    0.7415    0.7300    550500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_both_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='both') for g in test_graph_dataset]\n",
    "inject_both_report = eval(inject_both_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90b60cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_host_500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6654\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [  230    25    29 54766     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[146939 142041      0      1     19]\n",
      " [   192 247304      0      4      0]\n",
      " [     0      1    119     56      0]\n",
      " [  1799   3454      6   8554     11]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9866    0.5084    0.6711    289000\n",
      "           DoS     0.6296    0.9992    0.7725    247500\n",
      "        Normal     0.9520    0.6761    0.7907       176\n",
      "Reconnaissance     0.9929    0.6188    0.7624     13824\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.7319    550500\n",
      "     macro avg     0.7122    0.5605    0.5993    550500\n",
      "  weighted avg     0.8263    0.7319    0.7190    550500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_src_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='src') for g in test_graph_dataset]\n",
    "inject_src_report = eval(inject_src_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70287333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_host_500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8840\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [30317 23368    37  1328     0     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[288480    520      0      0      0]\n",
      " [ 13921 233577      2      0      0]\n",
      " [     0      1    114     61      0]\n",
      " [   491    153      6  13165      9]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.9524    0.9982    0.9748    289000\n",
      "           DoS     0.9971    0.9437    0.9697    247500\n",
      "        Normal     0.9344    0.6477    0.7651       176\n",
      "Reconnaissance     0.9954    0.9523    0.9734     13824\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.9725    550500\n",
      "     macro avg     0.7759    0.7084    0.7366    550500\n",
      "  weighted avg     0.9736    0.9725    0.9724    550500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_dst_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='dst') for g in test_graph_dataset]\n",
    "inject_dst_report = eval(inject_dst_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "579e0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Attribute Perturbation\n",
    "def perturb_edge_attributes(graph, affected_edge_ratio=0.1, perturbation_ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = edge_attr.size(1)\n",
    "\n",
    "    # Randomly select edges to perturb\n",
    "    num_to_perturb = max(1, int(affected_edge_ratio * num_edges))\n",
    "    rng = random.Random(random_seed)\n",
    "    indices_to_perturb = rng.sample(range(num_edges), num_to_perturb)\n",
    "\n",
    "    for idx in indices_to_perturb:\n",
    "        # Perturb the edge attributes by adding noise\n",
    "        noise = th.randn(feature_dim) * perturbation_ratio  # Adjust the scale of noise as needed\n",
    "        edge_attr[idx] += noise\n",
    "\n",
    "    # Create a new graph with perturbed attributes\n",
    "    perturbed_graph = Data(edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label, x=graph.x)\n",
    "\n",
    "    return perturbed_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb68c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_host_500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8629\n",
      "Adversarial confusion matrix: [[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[262029  25471      0   1500      0]\n",
      " [ 39604 201338   1256   5301      1]\n",
      " [     5     11    106     53      1]\n",
      " [   522   1625    130  11545      2]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.8672    0.9067    0.8865    289000\n",
      "           DoS     0.8813    0.8135    0.8461    247500\n",
      "        Normal     0.0710    0.6023    0.1271       176\n",
      "Reconnaissance     0.6275    0.8351    0.7166     13824\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.8629    550500\n",
      "     macro avg     0.4894    0.6315    0.5152    550500\n",
      "  weighted avg     0.8673    0.8629    0.8638    550500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Edge Attribute Perturbation\n",
    "edge_perturb_graph_dataset = [perturb_edge_attributes(g.cpu(), affected_edge_ratio=1, perturbation_ratio=5) for g in test_graph_dataset]\n",
    "edge_perturb_report = eval(edge_perturb_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc04f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject Random Edges\n",
    "def inject_random_edges(graph, ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_nodes = x.size(0)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    new_edge_indices = []\n",
    "    new_edge_attrs = []\n",
    "    new_edge_labels = []\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    num_injected_edges = max(1, int(ratio * num_edges))\n",
    "\n",
    "    for i in range(num_injected_edges):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per edge\n",
    "        src = rng.randint(0, num_nodes - 1)  # Random source node\n",
    "        dst = rng.randint(0, num_nodes - 1)  # Random destination node\n",
    "\n",
    "        new_edge_indices.append([src, dst])\n",
    "        new_edge_attrs.append(th.rand(feature_dim))  # Random feature for the new edge\n",
    "        new_edge_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    if new_edge_indices:\n",
    "        new_edge_indices = th.tensor(new_edge_indices, dtype=th.long).t().contiguous()\n",
    "        new_edge_attrs = th.stack(new_edge_attrs)\n",
    "        new_edge_labels = th.tensor(new_edge_labels, dtype=th.long)\n",
    "\n",
    "        edge_index = th.cat([edge_index, new_edge_indices], dim=1)\n",
    "        edge_attr = th.cat([edge_attr, new_edge_attrs], dim=0)\n",
    "        edge_label = th.cat([edge_label, new_edge_labels], dim=0)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b25073bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/BoT_IoT/saved/strat_window_host_500/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5336\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [51978  2217   269   581     5     0]]\n",
      "class_map ['DDoS' 'DoS' 'Normal' 'Reconnaissance' 'Theft']\n",
      "[[288981     19      0      0      0]\n",
      " [219042  28451      7      0      0]\n",
      " [     0      1    112     63      0]\n",
      " [  7618    202    410   5591      3]\n",
      " [     0      0      0      0      0]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          DDoS     0.5604    0.9999    0.7183    289000\n",
      "           DoS     0.9923    0.1150    0.2060    247500\n",
      "        Normal     0.2117    0.6364    0.3177       176\n",
      "Reconnaissance     0.9889    0.4044    0.5741     13824\n",
      "         Theft     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5870    550500\n",
      "     macro avg     0.5507    0.4311    0.3632    550500\n",
      "  weighted avg     0.7652    0.5870    0.4842    550500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inject Random Edges\n",
    "random_edge_graph_dataset = [inject_random_edges(g.cpu(), 0.1) for g in test_graph_dataset]\n",
    "random_edge_report = eval(random_edge_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8c66190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Overall Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_323f5\">\n",
       "  <caption>Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_323f5_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_323f5_level0_col1\" class=\"col_heading level0 col1\" >Min Influence</th>\n",
       "      <th id=\"T_323f5_level0_col2\" class=\"col_heading level0 col2\" >Avg Influence</th>\n",
       "      <th id=\"T_323f5_level0_col3\" class=\"col_heading level0 col3\" >Max Influence</th>\n",
       "      <th id=\"T_323f5_level0_col4\" class=\"col_heading level0 col4\" >Normal precision</th>\n",
       "      <th id=\"T_323f5_level0_col5\" class=\"col_heading level0 col5\" >To Both precision</th>\n",
       "      <th id=\"T_323f5_level0_col6\" class=\"col_heading level0 col6\" >To Both precision Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col7\" class=\"col_heading level0 col7\" >To Src precision</th>\n",
       "      <th id=\"T_323f5_level0_col8\" class=\"col_heading level0 col8\" >To Src precision Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col9\" class=\"col_heading level0 col9\" >To Dst precision</th>\n",
       "      <th id=\"T_323f5_level0_col10\" class=\"col_heading level0 col10\" >To Dst precision Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col11\" class=\"col_heading level0 col11\" >Edge Perturbation precision</th>\n",
       "      <th id=\"T_323f5_level0_col12\" class=\"col_heading level0 col12\" >Edge Perturbation precision Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col13\" class=\"col_heading level0 col13\" >Random Edge precision</th>\n",
       "      <th id=\"T_323f5_level0_col14\" class=\"col_heading level0 col14\" >Random Edge precision Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col15\" class=\"col_heading level0 col15\" >Normal recall</th>\n",
       "      <th id=\"T_323f5_level0_col16\" class=\"col_heading level0 col16\" >To Both recall</th>\n",
       "      <th id=\"T_323f5_level0_col17\" class=\"col_heading level0 col17\" >To Both recall Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col18\" class=\"col_heading level0 col18\" >To Src recall</th>\n",
       "      <th id=\"T_323f5_level0_col19\" class=\"col_heading level0 col19\" >To Src recall Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col20\" class=\"col_heading level0 col20\" >To Dst recall</th>\n",
       "      <th id=\"T_323f5_level0_col21\" class=\"col_heading level0 col21\" >To Dst recall Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col22\" class=\"col_heading level0 col22\" >Edge Perturbation recall</th>\n",
       "      <th id=\"T_323f5_level0_col23\" class=\"col_heading level0 col23\" >Edge Perturbation recall Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col24\" class=\"col_heading level0 col24\" >Random Edge recall</th>\n",
       "      <th id=\"T_323f5_level0_col25\" class=\"col_heading level0 col25\" >Random Edge recall Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col26\" class=\"col_heading level0 col26\" >Normal f1-score</th>\n",
       "      <th id=\"T_323f5_level0_col27\" class=\"col_heading level0 col27\" >To Both f1-score</th>\n",
       "      <th id=\"T_323f5_level0_col28\" class=\"col_heading level0 col28\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col29\" class=\"col_heading level0 col29\" >To Src f1-score</th>\n",
       "      <th id=\"T_323f5_level0_col30\" class=\"col_heading level0 col30\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col31\" class=\"col_heading level0 col31\" >To Dst f1-score</th>\n",
       "      <th id=\"T_323f5_level0_col32\" class=\"col_heading level0 col32\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col33\" class=\"col_heading level0 col33\" >Edge Perturbation f1-score</th>\n",
       "      <th id=\"T_323f5_level0_col34\" class=\"col_heading level0 col34\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col35\" class=\"col_heading level0 col35\" >Random Edge f1-score</th>\n",
       "      <th id=\"T_323f5_level0_col36\" class=\"col_heading level0 col36\" >Random Edge f1-score Drop (%)</th>\n",
       "      <th id=\"T_323f5_level0_col37\" class=\"col_heading level0 col37\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_323f5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_323f5_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_323f5_row0_col1\" class=\"data row0 col1\" >0.00</td>\n",
       "      <td id=\"T_323f5_row0_col2\" class=\"data row0 col2\" >0.12</td>\n",
       "      <td id=\"T_323f5_row0_col3\" class=\"data row0 col3\" >500.00</td>\n",
       "      <td id=\"T_323f5_row0_col4\" class=\"data row0 col4\" >0.99</td>\n",
       "      <td id=\"T_323f5_row0_col5\" class=\"data row0 col5\" >0.99</td>\n",
       "      <td id=\"T_323f5_row0_col6\" class=\"data row0 col6\" >0.46</td>\n",
       "      <td id=\"T_323f5_row0_col7\" class=\"data row0 col7\" >0.99</td>\n",
       "      <td id=\"T_323f5_row0_col8\" class=\"data row0 col8\" >0.77</td>\n",
       "      <td id=\"T_323f5_row0_col9\" class=\"data row0 col9\" >0.95</td>\n",
       "      <td id=\"T_323f5_row0_col10\" class=\"data row0 col10\" >4.21</td>\n",
       "      <td id=\"T_323f5_row0_col11\" class=\"data row0 col11\" >0.87</td>\n",
       "      <td id=\"T_323f5_row0_col12\" class=\"data row0 col12\" >12.78</td>\n",
       "      <td id=\"T_323f5_row0_col13\" class=\"data row0 col13\" >0.56</td>\n",
       "      <td id=\"T_323f5_row0_col14\" class=\"data row0 col14\" >43.63</td>\n",
       "      <td id=\"T_323f5_row0_col15\" class=\"data row0 col15\" >0.98</td>\n",
       "      <td id=\"T_323f5_row0_col16\" class=\"data row0 col16\" >0.52</td>\n",
       "      <td id=\"T_323f5_row0_col17\" class=\"data row0 col17\" >46.97</td>\n",
       "      <td id=\"T_323f5_row0_col18\" class=\"data row0 col18\" >0.51</td>\n",
       "      <td id=\"T_323f5_row0_col19\" class=\"data row0 col19\" >48.34</td>\n",
       "      <td id=\"T_323f5_row0_col20\" class=\"data row0 col20\" >1.00</td>\n",
       "      <td id=\"T_323f5_row0_col21\" class=\"data row0 col21\" >-1.42</td>\n",
       "      <td id=\"T_323f5_row0_col22\" class=\"data row0 col22\" >0.91</td>\n",
       "      <td id=\"T_323f5_row0_col23\" class=\"data row0 col23\" >7.88</td>\n",
       "      <td id=\"T_323f5_row0_col24\" class=\"data row0 col24\" >1.00</td>\n",
       "      <td id=\"T_323f5_row0_col25\" class=\"data row0 col25\" >-1.59</td>\n",
       "      <td id=\"T_323f5_row0_col26\" class=\"data row0 col26\" >0.99</td>\n",
       "      <td id=\"T_323f5_row0_col27\" class=\"data row0 col27\" >0.68</td>\n",
       "      <td id=\"T_323f5_row0_col28\" class=\"data row0 col28\" >30.91</td>\n",
       "      <td id=\"T_323f5_row0_col29\" class=\"data row0 col29\" >0.67</td>\n",
       "      <td id=\"T_323f5_row0_col30\" class=\"data row0 col30\" >32.16</td>\n",
       "      <td id=\"T_323f5_row0_col31\" class=\"data row0 col31\" >0.97</td>\n",
       "      <td id=\"T_323f5_row0_col32\" class=\"data row0 col32\" >1.46</td>\n",
       "      <td id=\"T_323f5_row0_col33\" class=\"data row0 col33\" >0.89</td>\n",
       "      <td id=\"T_323f5_row0_col34\" class=\"data row0 col34\" >10.39</td>\n",
       "      <td id=\"T_323f5_row0_col35\" class=\"data row0 col35\" >0.72</td>\n",
       "      <td id=\"T_323f5_row0_col36\" class=\"data row0 col36\" >27.39</td>\n",
       "      <td id=\"T_323f5_row0_col37\" class=\"data row0 col37\" >289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_323f5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_323f5_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_323f5_row1_col1\" class=\"data row1 col1\" >0.00</td>\n",
       "      <td id=\"T_323f5_row1_col2\" class=\"data row1 col2\" >0.35</td>\n",
       "      <td id=\"T_323f5_row1_col3\" class=\"data row1 col3\" >500.00</td>\n",
       "      <td id=\"T_323f5_row1_col4\" class=\"data row1 col4\" >0.98</td>\n",
       "      <td id=\"T_323f5_row1_col5\" class=\"data row1 col5\" >0.64</td>\n",
       "      <td id=\"T_323f5_row1_col6\" class=\"data row1 col6\" >34.89</td>\n",
       "      <td id=\"T_323f5_row1_col7\" class=\"data row1 col7\" >0.63</td>\n",
       "      <td id=\"T_323f5_row1_col8\" class=\"data row1 col8\" >35.70</td>\n",
       "      <td id=\"T_323f5_row1_col9\" class=\"data row1 col9\" >1.00</td>\n",
       "      <td id=\"T_323f5_row1_col10\" class=\"data row1 col10\" >-1.84</td>\n",
       "      <td id=\"T_323f5_row1_col11\" class=\"data row1 col11\" >0.88</td>\n",
       "      <td id=\"T_323f5_row1_col12\" class=\"data row1 col12\" >9.99</td>\n",
       "      <td id=\"T_323f5_row1_col13\" class=\"data row1 col13\" >0.99</td>\n",
       "      <td id=\"T_323f5_row1_col14\" class=\"data row1 col14\" >-1.34</td>\n",
       "      <td id=\"T_323f5_row1_col15\" class=\"data row1 col15\" >1.00</td>\n",
       "      <td id=\"T_323f5_row1_col16\" class=\"data row1 col16\" >1.00</td>\n",
       "      <td id=\"T_323f5_row1_col17\" class=\"data row1 col17\" >-0.38</td>\n",
       "      <td id=\"T_323f5_row1_col18\" class=\"data row1 col18\" >1.00</td>\n",
       "      <td id=\"T_323f5_row1_col19\" class=\"data row1 col19\" >-0.38</td>\n",
       "      <td id=\"T_323f5_row1_col20\" class=\"data row1 col20\" >0.94</td>\n",
       "      <td id=\"T_323f5_row1_col21\" class=\"data row1 col21\" >5.19</td>\n",
       "      <td id=\"T_323f5_row1_col22\" class=\"data row1 col22\" >0.81</td>\n",
       "      <td id=\"T_323f5_row1_col23\" class=\"data row1 col23\" >18.28</td>\n",
       "      <td id=\"T_323f5_row1_col24\" class=\"data row1 col24\" >0.11</td>\n",
       "      <td id=\"T_323f5_row1_col25\" class=\"data row1 col25\" >88.45</td>\n",
       "      <td id=\"T_323f5_row1_col26\" class=\"data row1 col26\" >0.99</td>\n",
       "      <td id=\"T_323f5_row1_col27\" class=\"data row1 col27\" >0.78</td>\n",
       "      <td id=\"T_323f5_row1_col28\" class=\"data row1 col28\" >21.15</td>\n",
       "      <td id=\"T_323f5_row1_col29\" class=\"data row1 col29\" >0.77</td>\n",
       "      <td id=\"T_323f5_row1_col30\" class=\"data row1 col30\" >21.75</td>\n",
       "      <td id=\"T_323f5_row1_col31\" class=\"data row1 col31\" >0.97</td>\n",
       "      <td id=\"T_323f5_row1_col32\" class=\"data row1 col32\" >1.77</td>\n",
       "      <td id=\"T_323f5_row1_col33\" class=\"data row1 col33\" >0.85</td>\n",
       "      <td id=\"T_323f5_row1_col34\" class=\"data row1 col34\" >14.30</td>\n",
       "      <td id=\"T_323f5_row1_col35\" class=\"data row1 col35\" >0.21</td>\n",
       "      <td id=\"T_323f5_row1_col36\" class=\"data row1 col36\" >79.13</td>\n",
       "      <td id=\"T_323f5_row1_col37\" class=\"data row1 col37\" >247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_323f5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_323f5_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_323f5_row2_col1\" class=\"data row2 col1\" >0.00</td>\n",
       "      <td id=\"T_323f5_row2_col2\" class=\"data row2 col2\" >0.02</td>\n",
       "      <td id=\"T_323f5_row2_col3\" class=\"data row2 col3\" >16.20</td>\n",
       "      <td id=\"T_323f5_row2_col4\" class=\"data row2 col4\" >0.94</td>\n",
       "      <td id=\"T_323f5_row2_col5\" class=\"data row2 col5\" >0.95</td>\n",
       "      <td id=\"T_323f5_row2_col6\" class=\"data row2 col6\" >-1.05</td>\n",
       "      <td id=\"T_323f5_row2_col7\" class=\"data row2 col7\" >0.95</td>\n",
       "      <td id=\"T_323f5_row2_col8\" class=\"data row2 col8\" >-1.05</td>\n",
       "      <td id=\"T_323f5_row2_col9\" class=\"data row2 col9\" >0.93</td>\n",
       "      <td id=\"T_323f5_row2_col10\" class=\"data row2 col10\" >0.82</td>\n",
       "      <td id=\"T_323f5_row2_col11\" class=\"data row2 col11\" >0.07</td>\n",
       "      <td id=\"T_323f5_row2_col12\" class=\"data row2 col12\" >92.46</td>\n",
       "      <td id=\"T_323f5_row2_col13\" class=\"data row2 col13\" >0.21</td>\n",
       "      <td id=\"T_323f5_row2_col14\" class=\"data row2 col14\" >77.53</td>\n",
       "      <td id=\"T_323f5_row2_col15\" class=\"data row2 col15\" >0.65</td>\n",
       "      <td id=\"T_323f5_row2_col16\" class=\"data row2 col16\" >0.68</td>\n",
       "      <td id=\"T_323f5_row2_col17\" class=\"data row2 col17\" >-4.39</td>\n",
       "      <td id=\"T_323f5_row2_col18\" class=\"data row2 col18\" >0.68</td>\n",
       "      <td id=\"T_323f5_row2_col19\" class=\"data row2 col19\" >-4.39</td>\n",
       "      <td id=\"T_323f5_row2_col20\" class=\"data row2 col20\" >0.65</td>\n",
       "      <td id=\"T_323f5_row2_col21\" class=\"data row2 col21\" >0.00</td>\n",
       "      <td id=\"T_323f5_row2_col22\" class=\"data row2 col22\" >0.60</td>\n",
       "      <td id=\"T_323f5_row2_col23\" class=\"data row2 col23\" >7.02</td>\n",
       "      <td id=\"T_323f5_row2_col24\" class=\"data row2 col24\" >0.64</td>\n",
       "      <td id=\"T_323f5_row2_col25\" class=\"data row2 col25\" >1.75</td>\n",
       "      <td id=\"T_323f5_row2_col26\" class=\"data row2 col26\" >0.77</td>\n",
       "      <td id=\"T_323f5_row2_col27\" class=\"data row2 col27\" >0.79</td>\n",
       "      <td id=\"T_323f5_row2_col28\" class=\"data row2 col28\" >-3.00</td>\n",
       "      <td id=\"T_323f5_row2_col29\" class=\"data row2 col29\" >0.79</td>\n",
       "      <td id=\"T_323f5_row2_col30\" class=\"data row2 col30\" >-3.00</td>\n",
       "      <td id=\"T_323f5_row2_col31\" class=\"data row2 col31\" >0.77</td>\n",
       "      <td id=\"T_323f5_row2_col32\" class=\"data row2 col32\" >0.34</td>\n",
       "      <td id=\"T_323f5_row2_col33\" class=\"data row2 col33\" >0.13</td>\n",
       "      <td id=\"T_323f5_row2_col34\" class=\"data row2 col34\" >83.44</td>\n",
       "      <td id=\"T_323f5_row2_col35\" class=\"data row2 col35\" >0.32</td>\n",
       "      <td id=\"T_323f5_row2_col36\" class=\"data row2 col36\" >58.61</td>\n",
       "      <td id=\"T_323f5_row2_col37\" class=\"data row2 col37\" >176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_323f5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_323f5_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_323f5_row3_col1\" class=\"data row3 col1\" >0.00</td>\n",
       "      <td id=\"T_323f5_row3_col2\" class=\"data row3 col2\" >0.22</td>\n",
       "      <td id=\"T_323f5_row3_col3\" class=\"data row3 col3\" >500.00</td>\n",
       "      <td id=\"T_323f5_row3_col4\" class=\"data row3 col4\" >1.00</td>\n",
       "      <td id=\"T_323f5_row3_col5\" class=\"data row3 col5\" >0.99</td>\n",
       "      <td id=\"T_323f5_row3_col6\" class=\"data row3 col6\" >0.12</td>\n",
       "      <td id=\"T_323f5_row3_col7\" class=\"data row3 col7\" >0.99</td>\n",
       "      <td id=\"T_323f5_row3_col8\" class=\"data row3 col8\" >0.23</td>\n",
       "      <td id=\"T_323f5_row3_col9\" class=\"data row3 col9\" >1.00</td>\n",
       "      <td id=\"T_323f5_row3_col10\" class=\"data row3 col10\" >-0.02</td>\n",
       "      <td id=\"T_323f5_row3_col11\" class=\"data row3 col11\" >0.63</td>\n",
       "      <td id=\"T_323f5_row3_col12\" class=\"data row3 col12\" >36.95</td>\n",
       "      <td id=\"T_323f5_row3_col13\" class=\"data row3 col13\" >0.99</td>\n",
       "      <td id=\"T_323f5_row3_col14\" class=\"data row3 col14\" >0.64</td>\n",
       "      <td id=\"T_323f5_row3_col15\" class=\"data row3 col15\" >0.91</td>\n",
       "      <td id=\"T_323f5_row3_col16\" class=\"data row3 col16\" >0.72</td>\n",
       "      <td id=\"T_323f5_row3_col17\" class=\"data row3 col17\" >21.02</td>\n",
       "      <td id=\"T_323f5_row3_col18\" class=\"data row3 col18\" >0.62</td>\n",
       "      <td id=\"T_323f5_row3_col19\" class=\"data row3 col19\" >32.20</td>\n",
       "      <td id=\"T_323f5_row3_col20\" class=\"data row3 col20\" >0.95</td>\n",
       "      <td id=\"T_323f5_row3_col21\" class=\"data row3 col21\" >-4.35</td>\n",
       "      <td id=\"T_323f5_row3_col22\" class=\"data row3 col22\" >0.84</td>\n",
       "      <td id=\"T_323f5_row3_col23\" class=\"data row3 col23\" >8.49</td>\n",
       "      <td id=\"T_323f5_row3_col24\" class=\"data row3 col24\" >0.40</td>\n",
       "      <td id=\"T_323f5_row3_col25\" class=\"data row3 col25\" >55.68</td>\n",
       "      <td id=\"T_323f5_row3_col26\" class=\"data row3 col26\" >0.95</td>\n",
       "      <td id=\"T_323f5_row3_col27\" class=\"data row3 col27\" >0.84</td>\n",
       "      <td id=\"T_323f5_row3_col28\" class=\"data row3 col28\" >12.23</td>\n",
       "      <td id=\"T_323f5_row3_col29\" class=\"data row3 col29\" >0.76</td>\n",
       "      <td id=\"T_323f5_row3_col30\" class=\"data row3 col30\" >19.92</td>\n",
       "      <td id=\"T_323f5_row3_col31\" class=\"data row3 col31\" >0.97</td>\n",
       "      <td id=\"T_323f5_row3_col32\" class=\"data row3 col32\" >-2.23</td>\n",
       "      <td id=\"T_323f5_row3_col33\" class=\"data row3 col33\" >0.72</td>\n",
       "      <td id=\"T_323f5_row3_col34\" class=\"data row3 col34\" >24.74</td>\n",
       "      <td id=\"T_323f5_row3_col35\" class=\"data row3 col35\" >0.57</td>\n",
       "      <td id=\"T_323f5_row3_col36\" class=\"data row3 col36\" >39.70</td>\n",
       "      <td id=\"T_323f5_row3_col37\" class=\"data row3 col37\" >13824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_323f5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_323f5_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_323f5_row4_col1\" class=\"data row4 col1\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col10\" class=\"data row4 col10\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col11\" class=\"data row4 col11\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col12\" class=\"data row4 col12\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col13\" class=\"data row4 col13\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col14\" class=\"data row4 col14\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col15\" class=\"data row4 col15\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col16\" class=\"data row4 col16\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col17\" class=\"data row4 col17\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col18\" class=\"data row4 col18\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col19\" class=\"data row4 col19\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col20\" class=\"data row4 col20\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col21\" class=\"data row4 col21\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col22\" class=\"data row4 col22\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col23\" class=\"data row4 col23\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col24\" class=\"data row4 col24\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col25\" class=\"data row4 col25\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col26\" class=\"data row4 col26\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col27\" class=\"data row4 col27\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col28\" class=\"data row4 col28\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col29\" class=\"data row4 col29\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col30\" class=\"data row4 col30\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col31\" class=\"data row4 col31\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col32\" class=\"data row4 col32\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col33\" class=\"data row4 col33\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col34\" class=\"data row4 col34\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col35\" class=\"data row4 col35\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col36\" class=\"data row4 col36\" >0.00</td>\n",
       "      <td id=\"T_323f5_row4_col37\" class=\"data row4 col37\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_323f5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_323f5_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_323f5_row5_col1\" class=\"data row5 col1\" >0.00</td>\n",
       "      <td id=\"T_323f5_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_323f5_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_323f5_row5_col4\" class=\"data row5 col4\" >0.78</td>\n",
       "      <td id=\"T_323f5_row5_col5\" class=\"data row5 col5\" >0.71</td>\n",
       "      <td id=\"T_323f5_row5_col6\" class=\"data row5 col6\" >8.63</td>\n",
       "      <td id=\"T_323f5_row5_col7\" class=\"data row5 col7\" >0.71</td>\n",
       "      <td id=\"T_323f5_row5_col8\" class=\"data row5 col8\" >8.94</td>\n",
       "      <td id=\"T_323f5_row5_col9\" class=\"data row5 col9\" >0.78</td>\n",
       "      <td id=\"T_323f5_row5_col10\" class=\"data row5 col10\" >0.80</td>\n",
       "      <td id=\"T_323f5_row5_col11\" class=\"data row5 col11\" >0.49</td>\n",
       "      <td id=\"T_323f5_row5_col12\" class=\"data row5 col12\" >37.43</td>\n",
       "      <td id=\"T_323f5_row5_col13\" class=\"data row5 col13\" >0.55</td>\n",
       "      <td id=\"T_323f5_row5_col14\" class=\"data row5 col14\" >29.60</td>\n",
       "      <td id=\"T_323f5_row5_col15\" class=\"data row5 col15\" >0.71</td>\n",
       "      <td id=\"T_323f5_row5_col16\" class=\"data row5 col16\" >0.58</td>\n",
       "      <td id=\"T_323f5_row5_col17\" class=\"data row5 col17\" >17.57</td>\n",
       "      <td id=\"T_323f5_row5_col18\" class=\"data row5 col18\" >0.56</td>\n",
       "      <td id=\"T_323f5_row5_col19\" class=\"data row5 col19\" >20.83</td>\n",
       "      <td id=\"T_323f5_row5_col20\" class=\"data row5 col20\" >0.71</td>\n",
       "      <td id=\"T_323f5_row5_col21\" class=\"data row5 col21\" >-0.06</td>\n",
       "      <td id=\"T_323f5_row5_col22\" class=\"data row5 col22\" >0.63</td>\n",
       "      <td id=\"T_323f5_row5_col23\" class=\"data row5 col23\" >10.80</td>\n",
       "      <td id=\"T_323f5_row5_col24\" class=\"data row5 col24\" >0.43</td>\n",
       "      <td id=\"T_323f5_row5_col25\" class=\"data row5 col25\" >39.10</td>\n",
       "      <td id=\"T_323f5_row5_col26\" class=\"data row5 col26\" >0.74</td>\n",
       "      <td id=\"T_323f5_row5_col27\" class=\"data row5 col27\" >0.62</td>\n",
       "      <td id=\"T_323f5_row5_col28\" class=\"data row5 col28\" >16.45</td>\n",
       "      <td id=\"T_323f5_row5_col29\" class=\"data row5 col29\" >0.60</td>\n",
       "      <td id=\"T_323f5_row5_col30\" class=\"data row5 col30\" >18.93</td>\n",
       "      <td id=\"T_323f5_row5_col31\" class=\"data row5 col31\" >0.74</td>\n",
       "      <td id=\"T_323f5_row5_col32\" class=\"data row5 col32\" >0.36</td>\n",
       "      <td id=\"T_323f5_row5_col33\" class=\"data row5 col33\" >0.52</td>\n",
       "      <td id=\"T_323f5_row5_col34\" class=\"data row5 col34\" >30.30</td>\n",
       "      <td id=\"T_323f5_row5_col35\" class=\"data row5 col35\" >0.36</td>\n",
       "      <td id=\"T_323f5_row5_col36\" class=\"data row5 col36\" >50.86</td>\n",
       "      <td id=\"T_323f5_row5_col37\" class=\"data row5 col37\" >550500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_323f5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_323f5_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_323f5_row6_col1\" class=\"data row6 col1\" >0.00</td>\n",
       "      <td id=\"T_323f5_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_323f5_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_323f5_row6_col4\" class=\"data row6 col4\" >0.99</td>\n",
       "      <td id=\"T_323f5_row6_col5\" class=\"data row6 col5\" >0.83</td>\n",
       "      <td id=\"T_323f5_row6_col6\" class=\"data row6 col6\" >15.80</td>\n",
       "      <td id=\"T_323f5_row6_col7\" class=\"data row6 col7\" >0.83</td>\n",
       "      <td id=\"T_323f5_row6_col8\" class=\"data row6 col8\" >16.33</td>\n",
       "      <td id=\"T_323f5_row6_col9\" class=\"data row6 col9\" >0.97</td>\n",
       "      <td id=\"T_323f5_row6_col10\" class=\"data row6 col10\" >1.40</td>\n",
       "      <td id=\"T_323f5_row6_col11\" class=\"data row6 col11\" >0.87</td>\n",
       "      <td id=\"T_323f5_row6_col12\" class=\"data row6 col12\" >12.17</td>\n",
       "      <td id=\"T_323f5_row6_col13\" class=\"data row6 col13\" >0.77</td>\n",
       "      <td id=\"T_323f5_row6_col14\" class=\"data row6 col14\" >22.51</td>\n",
       "      <td id=\"T_323f5_row6_col15\" class=\"data row6 col15\" >0.99</td>\n",
       "      <td id=\"T_323f5_row6_col16\" class=\"data row6 col16\" >0.74</td>\n",
       "      <td id=\"T_323f5_row6_col17\" class=\"data row6 col17\" >24.90</td>\n",
       "      <td id=\"T_323f5_row6_col18\" class=\"data row6 col18\" >0.73</td>\n",
       "      <td id=\"T_323f5_row6_col19\" class=\"data row6 col19\" >25.87</td>\n",
       "      <td id=\"T_323f5_row6_col20\" class=\"data row6 col20\" >0.97</td>\n",
       "      <td id=\"T_323f5_row6_col21\" class=\"data row6 col21\" >1.51</td>\n",
       "      <td id=\"T_323f5_row6_col22\" class=\"data row6 col22\" >0.86</td>\n",
       "      <td id=\"T_323f5_row6_col23\" class=\"data row6 col23\" >12.61</td>\n",
       "      <td id=\"T_323f5_row6_col24\" class=\"data row6 col24\" >0.59</td>\n",
       "      <td id=\"T_323f5_row6_col25\" class=\"data row6 col25\" >40.55</td>\n",
       "      <td id=\"T_323f5_row6_col26\" class=\"data row6 col26\" >0.99</td>\n",
       "      <td id=\"T_323f5_row6_col27\" class=\"data row6 col27\" >0.73</td>\n",
       "      <td id=\"T_323f5_row6_col28\" class=\"data row6 col28\" >26.07</td>\n",
       "      <td id=\"T_323f5_row6_col29\" class=\"data row6 col29\" >0.72</td>\n",
       "      <td id=\"T_323f5_row6_col30\" class=\"data row6 col30\" >27.18</td>\n",
       "      <td id=\"T_323f5_row6_col31\" class=\"data row6 col31\" >0.97</td>\n",
       "      <td id=\"T_323f5_row6_col32\" class=\"data row6 col32\" >1.51</td>\n",
       "      <td id=\"T_323f5_row6_col33\" class=\"data row6 col33\" >0.86</td>\n",
       "      <td id=\"T_323f5_row6_col34\" class=\"data row6 col34\" >12.51</td>\n",
       "      <td id=\"T_323f5_row6_col35\" class=\"data row6 col35\" >0.48</td>\n",
       "      <td id=\"T_323f5_row6_col36\" class=\"data row6 col36\" >50.95</td>\n",
       "      <td id=\"T_323f5_row6_col37\" class=\"data row6 col37\" >550500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7936bceaf860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_overall_metrics(baseline_report, adversarial_reports, class_degree_report):\n",
    "    rows = []   \n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    eplison = 1e-10  # To avoid division by zero\n",
    "\n",
    "    for label in list(class_map) + ['macro avg', 'weighted avg']:\n",
    "        row = {\"Class\": label}\n",
    "        row['Class'] = label\n",
    "        row['Min Influence'] = class_degree_report[label]['min_influence'] if label in class_degree_report else 0.0\n",
    "        row['Avg Influence'] = class_degree_report[label]['avg_influence'] if label in class_degree_report else 0.0\n",
    "        row['Max Influence'] = class_degree_report[label]['max_influence'] if label in class_degree_report else 0.0\n",
    "        for metric in metrics:\n",
    "            baseline_val = baseline_report[label][metric]\n",
    "            row[f\"Normal {metric}\"] = baseline_val\n",
    "            for name, report in adversarial_reports.items():\n",
    "                adv_val = report[label][metric]\n",
    "                row[f\"{name} {metric}\"] = adv_val\n",
    "                row[f\"{name} {metric} Drop (%)\"] = ((baseline_val - adv_val) / (baseline_val + eplison)) * 100\n",
    "        row['support'] = int(baseline_report[label]['support'])\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "adversarial_reports = {\n",
    "    \"To Both\": inject_both_report,\n",
    "    \"To Src\": inject_src_report,\n",
    "    \"To Dst\": inject_dst_report,\n",
    "    \"Edge Perturbation\": edge_perturb_report,\n",
    "    \"Random Edge\": random_edge_report,\n",
    "}\n",
    "\n",
    "comparison_df = compare_overall_metrics(normal_report, adversarial_reports, class_degree_report)\n",
    "\n",
    "class_col = comparison_df['Class']\n",
    "support_df = comparison_df['support']\n",
    "normal_cols = [col for col in comparison_df.columns if col.startswith('Normal')] \n",
    "influence_cols = [col for col in comparison_df.columns if col.endswith('Influence')] \n",
    "influence_df = comparison_df[influence_cols]\n",
    "f1_cols = [col for col in comparison_df.columns if col.endswith('f1-score')]\n",
    "f1_drop_cols = [col for col in comparison_df.columns if col.endswith('f1-score Drop (%)')]\n",
    "\n",
    "baselines_df = pd.concat([class_col, support_df, influence_df], axis=1)\n",
    "\n",
    "f1_df = pd.concat([baselines_df, comparison_df[f1_cols]], axis=1)\n",
    "f1_drop_df = pd.concat([baselines_df, comparison_df[f1_drop_cols]], axis=1)\n",
    "\n",
    "print(\"Comparison of Overall Metrics:\")\n",
    "display(comparison_df.style.set_caption(\"Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3725caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5bdbe_row0_col5, #T_5bdbe_row0_col8, #T_5bdbe_row0_col9, #T_5bdbe_row0_col10, #T_5bdbe_row1_col5, #T_5bdbe_row2_col7, #T_5bdbe_row3_col6, #T_5bdbe_row3_col8, #T_5bdbe_row6_col5, #T_5bdbe_row6_col8 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row0_col6 {\n",
       "  background-color: #107a37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row0_col7 {\n",
       "  background-color: #077331;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row1_col6 {\n",
       "  background-color: #005a24;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row1_col7 {\n",
       "  background-color: #004a1e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row1_col8 {\n",
       "  background-color: #00451c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row1_col9 {\n",
       "  background-color: #005221;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row1_col10 {\n",
       "  background-color: #bce4b5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5bdbe_row2_col5 {\n",
       "  background-color: #1c8540;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row2_col6 {\n",
       "  background-color: #005522;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row2_col8 {\n",
       "  background-color: #19833e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row2_col9 {\n",
       "  background-color: #e1f3dc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5bdbe_row2_col10 {\n",
       "  background-color: #88ce87;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5bdbe_row3_col5, #T_5bdbe_row3_col7 {\n",
       "  background-color: #005020;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row3_col9 {\n",
       "  background-color: #137d39;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row3_col10 {\n",
       "  background-color: #157f3b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row4_col5, #T_5bdbe_row4_col6, #T_5bdbe_row4_col7, #T_5bdbe_row4_col8, #T_5bdbe_row4_col9, #T_5bdbe_row4_col10 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5bdbe_row5_col5 {\n",
       "  background-color: #238b45;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row5_col6 {\n",
       "  background-color: #258d47;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row5_col7 {\n",
       "  background-color: #208843;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row5_col8 {\n",
       "  background-color: #218944;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row5_col9 {\n",
       "  background-color: #53b466;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row5_col10 {\n",
       "  background-color: #72c375;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5bdbe_row6_col6 {\n",
       "  background-color: #006d2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row6_col7 {\n",
       "  background-color: #006227;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row6_col9 {\n",
       "  background-color: #004c1e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5bdbe_row6_col10 {\n",
       "  background-color: #359e53;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5bdbe\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5bdbe_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_5bdbe_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_5bdbe_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_5bdbe_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_5bdbe_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_5bdbe_level0_col5\" class=\"col_heading level0 col5\" >Normal f1-score</th>\n",
       "      <th id=\"T_5bdbe_level0_col6\" class=\"col_heading level0 col6\" >To Both f1-score</th>\n",
       "      <th id=\"T_5bdbe_level0_col7\" class=\"col_heading level0 col7\" >To Src f1-score</th>\n",
       "      <th id=\"T_5bdbe_level0_col8\" class=\"col_heading level0 col8\" >To Dst f1-score</th>\n",
       "      <th id=\"T_5bdbe_level0_col9\" class=\"col_heading level0 col9\" >Edge Perturbation f1-score</th>\n",
       "      <th id=\"T_5bdbe_level0_col10\" class=\"col_heading level0 col10\" >Random Edge f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdbe_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5bdbe_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_5bdbe_row0_col1\" class=\"data row0 col1\" >289000</td>\n",
       "      <td id=\"T_5bdbe_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row0_col3\" class=\"data row0 col3\" >0.12</td>\n",
       "      <td id=\"T_5bdbe_row0_col4\" class=\"data row0 col4\" >500.00</td>\n",
       "      <td id=\"T_5bdbe_row0_col5\" class=\"data row0 col5\" >0.99</td>\n",
       "      <td id=\"T_5bdbe_row0_col6\" class=\"data row0 col6\" >0.68</td>\n",
       "      <td id=\"T_5bdbe_row0_col7\" class=\"data row0 col7\" >0.67</td>\n",
       "      <td id=\"T_5bdbe_row0_col8\" class=\"data row0 col8\" >0.97</td>\n",
       "      <td id=\"T_5bdbe_row0_col9\" class=\"data row0 col9\" >0.89</td>\n",
       "      <td id=\"T_5bdbe_row0_col10\" class=\"data row0 col10\" >0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdbe_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5bdbe_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_5bdbe_row1_col1\" class=\"data row1 col1\" >247500</td>\n",
       "      <td id=\"T_5bdbe_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row1_col3\" class=\"data row1 col3\" >0.35</td>\n",
       "      <td id=\"T_5bdbe_row1_col4\" class=\"data row1 col4\" >500.00</td>\n",
       "      <td id=\"T_5bdbe_row1_col5\" class=\"data row1 col5\" >0.99</td>\n",
       "      <td id=\"T_5bdbe_row1_col6\" class=\"data row1 col6\" >0.78</td>\n",
       "      <td id=\"T_5bdbe_row1_col7\" class=\"data row1 col7\" >0.77</td>\n",
       "      <td id=\"T_5bdbe_row1_col8\" class=\"data row1 col8\" >0.97</td>\n",
       "      <td id=\"T_5bdbe_row1_col9\" class=\"data row1 col9\" >0.85</td>\n",
       "      <td id=\"T_5bdbe_row1_col10\" class=\"data row1 col10\" >0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdbe_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5bdbe_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_5bdbe_row2_col1\" class=\"data row2 col1\" >176</td>\n",
       "      <td id=\"T_5bdbe_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row2_col3\" class=\"data row2 col3\" >0.02</td>\n",
       "      <td id=\"T_5bdbe_row2_col4\" class=\"data row2 col4\" >16.20</td>\n",
       "      <td id=\"T_5bdbe_row2_col5\" class=\"data row2 col5\" >0.77</td>\n",
       "      <td id=\"T_5bdbe_row2_col6\" class=\"data row2 col6\" >0.79</td>\n",
       "      <td id=\"T_5bdbe_row2_col7\" class=\"data row2 col7\" >0.79</td>\n",
       "      <td id=\"T_5bdbe_row2_col8\" class=\"data row2 col8\" >0.77</td>\n",
       "      <td id=\"T_5bdbe_row2_col9\" class=\"data row2 col9\" >0.13</td>\n",
       "      <td id=\"T_5bdbe_row2_col10\" class=\"data row2 col10\" >0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdbe_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5bdbe_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_5bdbe_row3_col1\" class=\"data row3 col1\" >13824</td>\n",
       "      <td id=\"T_5bdbe_row3_col2\" class=\"data row3 col2\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row3_col3\" class=\"data row3 col3\" >0.22</td>\n",
       "      <td id=\"T_5bdbe_row3_col4\" class=\"data row3 col4\" >500.00</td>\n",
       "      <td id=\"T_5bdbe_row3_col5\" class=\"data row3 col5\" >0.95</td>\n",
       "      <td id=\"T_5bdbe_row3_col6\" class=\"data row3 col6\" >0.84</td>\n",
       "      <td id=\"T_5bdbe_row3_col7\" class=\"data row3 col7\" >0.76</td>\n",
       "      <td id=\"T_5bdbe_row3_col8\" class=\"data row3 col8\" >0.97</td>\n",
       "      <td id=\"T_5bdbe_row3_col9\" class=\"data row3 col9\" >0.72</td>\n",
       "      <td id=\"T_5bdbe_row3_col10\" class=\"data row3 col10\" >0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdbe_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5bdbe_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_5bdbe_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_5bdbe_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row4_col10\" class=\"data row4 col10\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdbe_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5bdbe_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_5bdbe_row5_col1\" class=\"data row5 col1\" >550500</td>\n",
       "      <td id=\"T_5bdbe_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row5_col4\" class=\"data row5 col4\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row5_col5\" class=\"data row5 col5\" >0.74</td>\n",
       "      <td id=\"T_5bdbe_row5_col6\" class=\"data row5 col6\" >0.62</td>\n",
       "      <td id=\"T_5bdbe_row5_col7\" class=\"data row5 col7\" >0.60</td>\n",
       "      <td id=\"T_5bdbe_row5_col8\" class=\"data row5 col8\" >0.74</td>\n",
       "      <td id=\"T_5bdbe_row5_col9\" class=\"data row5 col9\" >0.52</td>\n",
       "      <td id=\"T_5bdbe_row5_col10\" class=\"data row5 col10\" >0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdbe_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5bdbe_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_5bdbe_row6_col1\" class=\"data row6 col1\" >550500</td>\n",
       "      <td id=\"T_5bdbe_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row6_col4\" class=\"data row6 col4\" >0.00</td>\n",
       "      <td id=\"T_5bdbe_row6_col5\" class=\"data row6 col5\" >0.99</td>\n",
       "      <td id=\"T_5bdbe_row6_col6\" class=\"data row6 col6\" >0.73</td>\n",
       "      <td id=\"T_5bdbe_row6_col7\" class=\"data row6 col7\" >0.72</td>\n",
       "      <td id=\"T_5bdbe_row6_col8\" class=\"data row6 col8\" >0.97</td>\n",
       "      <td id=\"T_5bdbe_row6_col9\" class=\"data row6 col9\" >0.86</td>\n",
       "      <td id=\"T_5bdbe_row6_col10\" class=\"data row6 col10\" >0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7936bd1bc980>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check F1 Scores\n",
    "display(f1_df.style.background_gradient(cmap='Greens', subset=f1_cols, axis=0).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e5c86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_295ef_row0_col5 {\n",
       "  background-color: #fb6b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_295ef_row0_col6 {\n",
       "  background-color: #f96346;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_295ef_row0_col7 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_295ef_row0_col8 {\n",
       "  background-color: #fcc4ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_295ef_row0_col9 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_295ef\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_295ef_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_295ef_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_295ef_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_295ef_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_295ef_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_295ef_level0_col5\" class=\"col_heading level0 col5\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_295ef_level0_col6\" class=\"col_heading level0 col6\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_295ef_level0_col7\" class=\"col_heading level0 col7\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_295ef_level0_col8\" class=\"col_heading level0 col8\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_295ef_level0_col9\" class=\"col_heading level0 col9\" >Random Edge f1-score Drop (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_295ef_level0_row0\" class=\"row_heading level0 row0\" >6</th>\n",
       "      <td id=\"T_295ef_row0_col0\" class=\"data row0 col0\" >weighted avg</td>\n",
       "      <td id=\"T_295ef_row0_col1\" class=\"data row0 col1\" >550500</td>\n",
       "      <td id=\"T_295ef_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_295ef_row0_col3\" class=\"data row0 col3\" >0.00</td>\n",
       "      <td id=\"T_295ef_row0_col4\" class=\"data row0 col4\" >0.00</td>\n",
       "      <td id=\"T_295ef_row0_col5\" class=\"data row0 col5\" >26.07</td>\n",
       "      <td id=\"T_295ef_row0_col6\" class=\"data row0 col6\" >27.18</td>\n",
       "      <td id=\"T_295ef_row0_col7\" class=\"data row0 col7\" >1.51</td>\n",
       "      <td id=\"T_295ef_row0_col8\" class=\"data row0 col8\" >12.51</td>\n",
       "      <td id=\"T_295ef_row0_col9\" class=\"data row0 col9\" >50.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7936bce4d730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Drops per Adversarial Attack\n",
    "display(f1_drop_df[f1_drop_df['Class'] == 'weighted avg'].style.background_gradient(cmap='Reds', subset=f1_drop_cols, axis=None).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb8033d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f098b_row0_col5, #T_f098b_row0_col6, #T_f098b_row1_col7, #T_f098b_row1_col9, #T_f098b_row2_col8 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row0_col7 {\n",
       "  background-color: #8c0912;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row0_col8 {\n",
       "  background-color: #fee1d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f098b_row0_col9 {\n",
       "  background-color: #fc9c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f098b_row1_col5 {\n",
       "  background-color: #d52221;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row1_col6 {\n",
       "  background-color: #d82422;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row1_col8 {\n",
       "  background-color: #fdd3c1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f098b_row2_col5, #T_f098b_row2_col6, #T_f098b_row3_col7, #T_f098b_row4_col8, #T_f098b_row4_col9 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f098b_row2_col7, #T_f098b_row5_col9, #T_f098b_row6_col9 {\n",
       "  background-color: #ea362a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row2_col9 {\n",
       "  background-color: #ce1a1e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row3_col5 {\n",
       "  background-color: #fb7b5b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row3_col6 {\n",
       "  background-color: #e83429;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row3_col8 {\n",
       "  background-color: #fcad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f098b_row3_col9 {\n",
       "  background-color: #fb694a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row4_col5 {\n",
       "  background-color: #fee7db;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f098b_row4_col6 {\n",
       "  background-color: #fee7dc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f098b_row4_col7 {\n",
       "  background-color: #f6553c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row5_col5 {\n",
       "  background-color: #f44f39;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row5_col6 {\n",
       "  background-color: #ef3c2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row5_col7 {\n",
       "  background-color: #e93529;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row5_col8 {\n",
       "  background-color: #fc9777;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f098b_row6_col5, #T_f098b_row6_col6 {\n",
       "  background-color: #aa1016;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row6_col7 {\n",
       "  background-color: #860811;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f098b_row6_col8 {\n",
       "  background-color: #fed9c9;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f098b\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f098b_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_f098b_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_f098b_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_f098b_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_f098b_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_f098b_level0_col5\" class=\"col_heading level0 col5\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_f098b_level0_col6\" class=\"col_heading level0 col6\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_f098b_level0_col7\" class=\"col_heading level0 col7\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_f098b_level0_col8\" class=\"col_heading level0 col8\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_f098b_level0_col9\" class=\"col_heading level0 col9\" >Random Edge f1-score Drop (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f098b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f098b_row0_col0\" class=\"data row0 col0\" >DDoS</td>\n",
       "      <td id=\"T_f098b_row0_col1\" class=\"data row0 col1\" >289000</td>\n",
       "      <td id=\"T_f098b_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_f098b_row0_col3\" class=\"data row0 col3\" >0.12</td>\n",
       "      <td id=\"T_f098b_row0_col4\" class=\"data row0 col4\" >500.00</td>\n",
       "      <td id=\"T_f098b_row0_col5\" class=\"data row0 col5\" >30.91</td>\n",
       "      <td id=\"T_f098b_row0_col6\" class=\"data row0 col6\" >32.16</td>\n",
       "      <td id=\"T_f098b_row0_col7\" class=\"data row0 col7\" >1.46</td>\n",
       "      <td id=\"T_f098b_row0_col8\" class=\"data row0 col8\" >10.39</td>\n",
       "      <td id=\"T_f098b_row0_col9\" class=\"data row0 col9\" >27.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f098b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f098b_row1_col0\" class=\"data row1 col0\" >DoS</td>\n",
       "      <td id=\"T_f098b_row1_col1\" class=\"data row1 col1\" >247500</td>\n",
       "      <td id=\"T_f098b_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_f098b_row1_col3\" class=\"data row1 col3\" >0.35</td>\n",
       "      <td id=\"T_f098b_row1_col4\" class=\"data row1 col4\" >500.00</td>\n",
       "      <td id=\"T_f098b_row1_col5\" class=\"data row1 col5\" >21.15</td>\n",
       "      <td id=\"T_f098b_row1_col6\" class=\"data row1 col6\" >21.75</td>\n",
       "      <td id=\"T_f098b_row1_col7\" class=\"data row1 col7\" >1.77</td>\n",
       "      <td id=\"T_f098b_row1_col8\" class=\"data row1 col8\" >14.30</td>\n",
       "      <td id=\"T_f098b_row1_col9\" class=\"data row1 col9\" >79.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f098b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f098b_row2_col0\" class=\"data row2 col0\" >Normal</td>\n",
       "      <td id=\"T_f098b_row2_col1\" class=\"data row2 col1\" >176</td>\n",
       "      <td id=\"T_f098b_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_f098b_row2_col3\" class=\"data row2 col3\" >0.02</td>\n",
       "      <td id=\"T_f098b_row2_col4\" class=\"data row2 col4\" >16.20</td>\n",
       "      <td id=\"T_f098b_row2_col5\" class=\"data row2 col5\" >-3.00</td>\n",
       "      <td id=\"T_f098b_row2_col6\" class=\"data row2 col6\" >-3.00</td>\n",
       "      <td id=\"T_f098b_row2_col7\" class=\"data row2 col7\" >0.34</td>\n",
       "      <td id=\"T_f098b_row2_col8\" class=\"data row2 col8\" >83.44</td>\n",
       "      <td id=\"T_f098b_row2_col9\" class=\"data row2 col9\" >58.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f098b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f098b_row3_col0\" class=\"data row3 col0\" >Reconnaissance</td>\n",
       "      <td id=\"T_f098b_row3_col1\" class=\"data row3 col1\" >13824</td>\n",
       "      <td id=\"T_f098b_row3_col2\" class=\"data row3 col2\" >0.00</td>\n",
       "      <td id=\"T_f098b_row3_col3\" class=\"data row3 col3\" >0.22</td>\n",
       "      <td id=\"T_f098b_row3_col4\" class=\"data row3 col4\" >500.00</td>\n",
       "      <td id=\"T_f098b_row3_col5\" class=\"data row3 col5\" >12.23</td>\n",
       "      <td id=\"T_f098b_row3_col6\" class=\"data row3 col6\" >19.92</td>\n",
       "      <td id=\"T_f098b_row3_col7\" class=\"data row3 col7\" >-2.23</td>\n",
       "      <td id=\"T_f098b_row3_col8\" class=\"data row3 col8\" >24.74</td>\n",
       "      <td id=\"T_f098b_row3_col9\" class=\"data row3 col9\" >39.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f098b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f098b_row4_col0\" class=\"data row4 col0\" >Theft</td>\n",
       "      <td id=\"T_f098b_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_f098b_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_f098b_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
       "      <td id=\"T_f098b_row4_col4\" class=\"data row4 col4\" >0.00</td>\n",
       "      <td id=\"T_f098b_row4_col5\" class=\"data row4 col5\" >0.00</td>\n",
       "      <td id=\"T_f098b_row4_col6\" class=\"data row4 col6\" >0.00</td>\n",
       "      <td id=\"T_f098b_row4_col7\" class=\"data row4 col7\" >0.00</td>\n",
       "      <td id=\"T_f098b_row4_col8\" class=\"data row4 col8\" >0.00</td>\n",
       "      <td id=\"T_f098b_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f098b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f098b_row5_col0\" class=\"data row5 col0\" >macro avg</td>\n",
       "      <td id=\"T_f098b_row5_col1\" class=\"data row5 col1\" >550500</td>\n",
       "      <td id=\"T_f098b_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
       "      <td id=\"T_f098b_row5_col3\" class=\"data row5 col3\" >0.00</td>\n",
       "      <td id=\"T_f098b_row5_col4\" class=\"data row5 col4\" >0.00</td>\n",
       "      <td id=\"T_f098b_row5_col5\" class=\"data row5 col5\" >16.45</td>\n",
       "      <td id=\"T_f098b_row5_col6\" class=\"data row5 col6\" >18.93</td>\n",
       "      <td id=\"T_f098b_row5_col7\" class=\"data row5 col7\" >0.36</td>\n",
       "      <td id=\"T_f098b_row5_col8\" class=\"data row5 col8\" >30.30</td>\n",
       "      <td id=\"T_f098b_row5_col9\" class=\"data row5 col9\" >50.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f098b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f098b_row6_col0\" class=\"data row6 col0\" >weighted avg</td>\n",
       "      <td id=\"T_f098b_row6_col1\" class=\"data row6 col1\" >550500</td>\n",
       "      <td id=\"T_f098b_row6_col2\" class=\"data row6 col2\" >0.00</td>\n",
       "      <td id=\"T_f098b_row6_col3\" class=\"data row6 col3\" >0.00</td>\n",
       "      <td id=\"T_f098b_row6_col4\" class=\"data row6 col4\" >0.00</td>\n",
       "      <td id=\"T_f098b_row6_col5\" class=\"data row6 col5\" >26.07</td>\n",
       "      <td id=\"T_f098b_row6_col6\" class=\"data row6 col6\" >27.18</td>\n",
       "      <td id=\"T_f098b_row6_col7\" class=\"data row6 col7\" >1.51</td>\n",
       "      <td id=\"T_f098b_row6_col8\" class=\"data row6 col8\" >12.51</td>\n",
       "      <td id=\"T_f098b_row6_col9\" class=\"data row6 col9\" >50.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7936bcd486e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Drops per Class\n",
    "display(f1_drop_df.style.background_gradient(cmap='Reds', subset=f1_drop_cols).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "852b5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DDoS': {'influence': (0.0, 0.12, 500.0),\n",
      "          'out_degree': (1.0, 168.02, 500.0),\n",
      "          'in_degree': (1.0, 483.28, 500.0),\n",
      "          'normal_f1': 0.99,\n",
      "          'to_both_f1': 0.68,\n",
      "          'to_src_f1': 0.67,\n",
      "          'to_dst_f1': 0.97,\n",
      "          'edge_perturb_f1': 0.89,\n",
      "          'random_edge_f1': 0.72},\n",
      " 'DoS': {'influence': (0.0, 0.35, 500.0),\n",
      "         'out_degree': (1.0, 174.17, 500.0),\n",
      "         'in_degree': (1.0, 174.17, 500.0),\n",
      "         'normal_f1': 0.99,\n",
      "         'to_both_f1': 0.78,\n",
      "         'to_src_f1': 0.77,\n",
      "         'to_dst_f1': 0.97,\n",
      "         'edge_perturb_f1': 0.85,\n",
      "         'random_edge_f1': 0.21},\n",
      " 'Normal': {'influence': (0.0, 0.02, 16.2),\n",
      "            'out_degree': (1.0, 4.63, 90.0),\n",
      "            'in_degree': (1.0, 2.26, 17.0),\n",
      "            'normal_f1': 0.77,\n",
      "            'to_both_f1': 0.79,\n",
      "            'to_src_f1': 0.79,\n",
      "            'to_dst_f1': 0.77,\n",
      "            'edge_perturb_f1': 0.13,\n",
      "            'random_edge_f1': 0.32},\n",
      " 'Reconnaissance': {'influence': (0.0, 0.22, 500.0),\n",
      "                    'out_degree': (1.0, 141.06, 500.0),\n",
      "                    'in_degree': (1.0, 181.89, 500.0),\n",
      "                    'normal_f1': 0.95,\n",
      "                    'to_both_f1': 0.84,\n",
      "                    'to_src_f1': 0.76,\n",
      "                    'to_dst_f1': 0.97,\n",
      "                    'edge_perturb_f1': 0.72,\n",
      "                    'random_edge_f1': 0.57},\n",
      " 'Theft': {'normal_f1': 0.0,\n",
      "           'to_both_f1': 0.0,\n",
      "           'to_src_f1': 0.0,\n",
      "           'to_dst_f1': 0.0,\n",
      "           'edge_perturb_f1': 0.0,\n",
      "           'random_edge_f1': 0.0},\n",
      " 'macro avg': {'normal_f1': 0.74,\n",
      "               'to_both_f1': 0.62,\n",
      "               'to_src_f1': 0.6,\n",
      "               'to_dst_f1': 0.74,\n",
      "               'edge_perturb_f1': 0.52,\n",
      "               'random_edge_f1': 0.36},\n",
      " 'Weighted Average': {'normal_f1': 0.99,\n",
      "                      'to_both_f1': 0.73,\n",
      "                      'to_src_f1': 0.72,\n",
      "                      'to_dst_f1': 0.97,\n",
      "                      'edge_perturb_f1': 0.86,\n",
      "                      'random_edge_f1': 0.48}}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pformat\n",
    "\n",
    "def round_tuple(t):\n",
    "    return tuple(round(x, 2) for x in t)\n",
    "\n",
    "def print_results(class_degree_report, comparison_df):\n",
    "    report_dict = defaultdict(dict)\n",
    "\n",
    "    for class_name, metrics in class_degree_report.items():\n",
    "        report_dict[class_name] = {\n",
    "            \"influence\": round_tuple((metrics['min_influence'], metrics['avg_influence'], metrics['max_influence'])),\n",
    "            \"out_degree\": round_tuple((metrics['min_out'], metrics['avg_out'], metrics['max_out'])),\n",
    "            \"in_degree\": round_tuple((metrics['min_in'], metrics['avg_in'], metrics['max_in']))\n",
    "        }\n",
    "\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        class_name = row['Class']\n",
    "        if class_name == 'weighted avg':\n",
    "            class_name = 'Weighted Average'\n",
    "        report_dict[class_name].update({\n",
    "            \"normal_f1\": round(row['Normal f1-score'], 2),\n",
    "            \"to_both_f1\": round(row['To Both f1-score'], 2),\n",
    "            \"to_src_f1\": round(row['To Src f1-score'], 2),\n",
    "            \"to_dst_f1\": round(row['To Dst f1-score'], 2),\n",
    "            \"edge_perturb_f1\": round(row['Edge Perturbation f1-score'], 2),\n",
    "            \"random_edge_f1\": round(row['Random Edge f1-score'], 2),\n",
    "        })\n",
    "\n",
    "    print(pformat(dict(report_dict), sort_dicts=False, indent=1))\n",
    "\n",
    "print_results(class_degree_report, comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
