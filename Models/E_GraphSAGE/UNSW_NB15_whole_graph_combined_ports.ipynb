{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb9e1b2-1c5f-49e3-82b4-3bfe52cabad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====Experiment=====\n",
    "Dataset: UNSW-NB15 dataset\n",
    "\n",
    "Training with whole graph\n",
    "Downsampled 90% normal traffic randomly\n",
    "Split train and test randomly\n",
    "\n",
    "Combined IP and Port features\n",
    "'''\n",
    "\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.UNSW_NB15.UNSW_NB15_config import UNSW_NB15_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2428412/3491705315.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"UNSW_NB15/All/{csv_file_name}.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal            221876\n",
      "Generic           215481\n",
      "Exploits           44525\n",
      "Fuzzers            24246\n",
      "DoS                16353\n",
      "Reconnaissance     13987\n",
      "Analysis            2677\n",
      "Backdoor            1795\n",
      "Shellcode           1511\n",
      "Backdoors            534\n",
      "Worms                174\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    321283\n",
      "0    221876\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = \"all_raw_downsampled\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"UNSW_NB15/All/{csv_file_name}.csv\"))\n",
    "\n",
    "DATASET_NAME = \"UNSW_NB15\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = UNSW_NB15_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = UNSW_NB15_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = UNSW_NB15_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = UNSW_NB15_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = UNSW_NB15_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = UNSW_NB15_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = UNSW_NB15_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = UNSW_NB15_Config.TIME_COL_NAMES\n",
    "\n",
    "MULTICLASS = True\n",
    "label_col = ATTACK_CLASS_COL_NAME if MULTICLASS else IS_ATTACK_COL_NAME\n",
    "\n",
    "print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "print(data[IS_ATTACK_COL_NAME].value_counts())\n",
    "\n",
    "if MULTICLASS:\n",
    "    data.drop(columns=[IS_ATTACK_COL_NAME], inplace=True)\n",
    "else:\n",
    "    data.drop(columns=[ATTACK_CLASS_COL_NAME], inplace=True)\n",
    "\n",
    "checkpoint_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, f\"whole_graph_combined_ports/checkpoints_{csv_file_name}.pth\")\n",
    "best_model_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, f\"whole_graph_combined_ports/best_model_{csv_file_name}.pth\")\n",
    "\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>...</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.40.85.1</td>\n",
       "      <td>0</td>\n",
       "      <td>224.0.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>INT</td>\n",
       "      <td>50.004341</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.6</td>\n",
       "      <td>2142</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>53</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>13284</td>\n",
       "      <td>149.171.126.16</td>\n",
       "      <td>80</td>\n",
       "      <td>FIN</td>\n",
       "      <td>2.390390</td>\n",
       "      <td>1362</td>\n",
       "      <td>268</td>\n",
       "      <td>254</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Reconnaissance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>42587</td>\n",
       "      <td>149.171.126.8</td>\n",
       "      <td>25</td>\n",
       "      <td>FIN</td>\n",
       "      <td>34.077175</td>\n",
       "      <td>37358</td>\n",
       "      <td>3380</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.40.170.2</td>\n",
       "      <td>0</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543154</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>47439</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>53</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543155</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>47439</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>53</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543156</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>53521</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>21</td>\n",
       "      <td>CON</td>\n",
       "      <td>1.086072</td>\n",
       "      <td>1940</td>\n",
       "      <td>2404</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543157</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>17293</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>110</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Exploits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543158</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>17293</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>110</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>574</td>\n",
       "      <td>676</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Exploits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543159 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               srcip  sport           dstip dsport state        dur  sbytes  \\\n",
       "0         10.40.85.1      0       224.0.0.5      0   INT  50.004341     384   \n",
       "1         59.166.0.6   2142   149.171.126.4     53   CON   0.001134     132   \n",
       "2       175.45.176.0  13284  149.171.126.16     80   FIN   2.390390    1362   \n",
       "3         59.166.0.3  42587   149.171.126.8     25   FIN  34.077175   37358   \n",
       "4        10.40.170.2      0     10.40.170.2      0   INT   0.000000      46   \n",
       "...              ...    ...             ...    ...   ...        ...     ...   \n",
       "543154  175.45.176.0  47439  149.171.126.10     53   INT   0.000001     114   \n",
       "543155  175.45.176.0  47439  149.171.126.10     53   INT   0.000001     114   \n",
       "543156    59.166.0.5  53521   149.171.126.7     21   CON   1.086072    1940   \n",
       "543157  175.45.176.0  17293  149.171.126.17    110   CON   0.942984     574   \n",
       "543158  175.45.176.0  17293  149.171.126.17    110   CON   0.942984     574   \n",
       "\n",
       "        dbytes  sttl  dttl  ...  is_ftp_login  ct_ftp_cmd  ct_srv_src  \\\n",
       "0            0     1     0  ...           0.0         0.0           2   \n",
       "1          164    31    29  ...           0.0         0.0          12   \n",
       "2          268   254   252  ...           0.0         0.0           5   \n",
       "3         3380    31    29  ...           0.0         0.0           1   \n",
       "4            0     0     0  ...           0.0         0.0           2   \n",
       "...        ...   ...   ...  ...           ...         ...         ...   \n",
       "543154       0   254     0  ...           0.0         NaN          15   \n",
       "543155       0   254     0  ...           0.0         NaN          15   \n",
       "543156    2404    31    29  ...           2.0         2.0           2   \n",
       "543157     676    62   252  ...           0.0         NaN           2   \n",
       "543158     676    62   252  ...           0.0         NaN           1   \n",
       "\n",
       "        ct_srv_dst  ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  \\\n",
       "0                4           4           2                 2   \n",
       "1                7           1           2                 2   \n",
       "2                2           2           1                 1   \n",
       "3                1          12          10                 1   \n",
       "4                2           2           2                 2   \n",
       "...            ...         ...         ...               ...   \n",
       "543154          15          15          15                15   \n",
       "543155          15          15          15                15   \n",
       "543156           2           3           3                 2   \n",
       "543157           1           2           4                 2   \n",
       "543158           1           2           4                 2   \n",
       "\n",
       "        ct_dst_sport_ltm  ct_dst_src_ltm      attack_cat  \n",
       "0                      4               2          Normal  \n",
       "1                      1               1          Normal  \n",
       "2                      1               1  Reconnaissance  \n",
       "3                      1               2          Normal  \n",
       "4                      2               2          Normal  \n",
       "...                  ...             ...             ...  \n",
       "543154                15              15         Generic  \n",
       "543155                15              15         Generic  \n",
       "543156                 2               3          Normal  \n",
       "543157                 2               2        Exploits  \n",
       "543158                 2               2        Exploits  \n",
       "\n",
       "[543159 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=UNSW_NB15_Config.DROP_COLS,inplace=True)\n",
    "data.drop(columns=UNSW_NB15_Config.TIME_COL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "# # Combine Port and IP\n",
    "data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "# data[SOURCE_PORT_COL_NAME] = pd.to_numeric(data[SOURCE_PORT_COL_NAME], errors='coerce').fillna(0).astype(int)\n",
    "# data[DESTINATION_PORT_COL_NAME] = pd.to_numeric(data[DESTINATION_PORT_COL_NAME], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5651ef5b-0a9d-4641-aad7-5738092c46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      srcip               dstip state        dur  sbytes  \\\n",
      "0             10.40.85.1:0         224.0.0.5:0   INT  50.004341     384   \n",
      "1          59.166.0.6:2142    149.171.126.4:53   CON   0.001134     132   \n",
      "2       175.45.176.0:13284   149.171.126.16:80   FIN   2.390390    1362   \n",
      "3         59.166.0.3:42587    149.171.126.8:25   FIN  34.077175   37358   \n",
      "4            10.40.170.2:0       10.40.170.2:0   INT   0.000000      46   \n",
      "...                    ...                 ...   ...        ...     ...   \n",
      "543154  175.45.176.0:47439   149.171.126.10:53   INT   0.000001     114   \n",
      "543155  175.45.176.0:47439   149.171.126.10:53   INT   0.000001     114   \n",
      "543156    59.166.0.5:53521    149.171.126.7:21   CON   1.086072    1940   \n",
      "543157  175.45.176.0:17293  149.171.126.17:110   CON   0.942984     574   \n",
      "543158  175.45.176.0:17293  149.171.126.17:110   CON   0.942984     574   \n",
      "\n",
      "        dbytes  sttl  dttl  sloss  dloss  ...  is_ftp_login  ct_ftp_cmd  \\\n",
      "0            0     1     0      0      0  ...           0.0         0.0   \n",
      "1          164    31    29      0      0  ...           0.0         0.0   \n",
      "2          268   254   252      6      1  ...           0.0         0.0   \n",
      "3         3380    31    29     18      8  ...           0.0         0.0   \n",
      "4            0     0     0      0      0  ...           0.0         0.0   \n",
      "...        ...   ...   ...    ...    ...  ...           ...         ...   \n",
      "543154       0   254     0      0      0  ...           0.0         NaN   \n",
      "543155       0   254     0      0      0  ...           0.0         NaN   \n",
      "543156    2404    31    29      8     10  ...           2.0         2.0   \n",
      "543157     676    62   252      5      6  ...           0.0         NaN   \n",
      "543158     676    62   252      5      6  ...           0.0         NaN   \n",
      "\n",
      "        ct_srv_src  ct_srv_dst  ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  \\\n",
      "0                2           4           4           2                 2   \n",
      "1               12           7           1           2                 2   \n",
      "2                5           2           2           1                 1   \n",
      "3                1           1          12          10                 1   \n",
      "4                2           2           2           2                 2   \n",
      "...            ...         ...         ...         ...               ...   \n",
      "543154          15          15          15          15                15   \n",
      "543155          15          15          15          15                15   \n",
      "543156           2           2           3           3                 2   \n",
      "543157           2           1           2           4                 2   \n",
      "543158           1           1           2           4                 2   \n",
      "\n",
      "        ct_dst_sport_ltm  ct_dst_src_ltm      attack_cat  \n",
      "0                      4               2          Normal  \n",
      "1                      1               1          Normal  \n",
      "2                      1               1  Reconnaissance  \n",
      "3                      1               2          Normal  \n",
      "4                      2               2          Normal  \n",
      "...                  ...             ...             ...  \n",
      "543154                15              15         Generic  \n",
      "543155                15              15         Generic  \n",
      "543156                 2               3          Normal  \n",
      "543157                 2               2        Exploits  \n",
      "543158                 2               2        Exploits  \n",
      "\n",
      "[543159 rows x 44 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7fb458-ca34-42ca-a8af-f8e1609aff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns = UNSW_NB15_Config.CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(UNSW_NB15_Config.CATEGORICAL_COLS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      srcip               dstip        dur  sbytes  dbytes  \\\n",
      "0             10.40.85.1:0         224.0.0.5:0  50.004341     384       0   \n",
      "1          59.166.0.6:2142    149.171.126.4:53   0.001134     132     164   \n",
      "2       175.45.176.0:13284   149.171.126.16:80   2.390390    1362     268   \n",
      "3         59.166.0.3:42587    149.171.126.8:25  34.077175   37358    3380   \n",
      "4            10.40.170.2:0       10.40.170.2:0   0.000000      46       0   \n",
      "...                    ...                 ...        ...     ...     ...   \n",
      "543154  175.45.176.0:47439   149.171.126.10:53   0.000001     114       0   \n",
      "543155  175.45.176.0:47439   149.171.126.10:53   0.000001     114       0   \n",
      "543156    59.166.0.5:53521    149.171.126.7:21   1.086072    1940    2404   \n",
      "543157  175.45.176.0:17293  149.171.126.17:110   0.942984     574     676   \n",
      "543158  175.45.176.0:17293  149.171.126.17:110   0.942984     574     676   \n",
      "\n",
      "        sttl  dttl  sloss  dloss         Sload  ...  state_ECO  state_FIN  \\\n",
      "0          1     0      0      0  5.119556e+01  ...      False      False   \n",
      "1         31    29      0      0  4.656085e+05  ...      False      False   \n",
      "2        254   252      6      1  4.233619e+03  ...      False       True   \n",
      "3         31    29     18      8  8.601652e+03  ...      False       True   \n",
      "4          0     0      0      0  0.000000e+00  ...      False      False   \n",
      "...      ...   ...    ...    ...           ...  ...        ...        ...   \n",
      "543154   254     0      0      0  4.560000e+08  ...      False      False   \n",
      "543155   254     0      0      0  4.560000e+08  ...      False      False   \n",
      "543156    31    29      8     10  1.387017e+04  ...      False      False   \n",
      "543157    62   252      5      6  4.470914e+03  ...      False      False   \n",
      "543158    62   252      5      6  4.470914e+03  ...      False      False   \n",
      "\n",
      "        state_INT  state_MAS  state_PAR  state_REQ  state_RST  state_TST  \\\n",
      "0            True      False      False      False      False      False   \n",
      "1           False      False      False      False      False      False   \n",
      "2           False      False      False      False      False      False   \n",
      "3           False      False      False      False      False      False   \n",
      "4            True      False      False      False      False      False   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "543154       True      False      False      False      False      False   \n",
      "543155       True      False      False      False      False      False   \n",
      "543156      False      False      False      False      False      False   \n",
      "543157      False      False      False      False      False      False   \n",
      "543158      False      False      False      False      False      False   \n",
      "\n",
      "        state_TXD  state_URH  \n",
      "0           False      False  \n",
      "1           False      False  \n",
      "2           False      False  \n",
      "3           False      False  \n",
      "4           False      False  \n",
      "...           ...        ...  \n",
      "543154      False      False  \n",
      "543155      False      False  \n",
      "543156      False      False  \n",
      "543157      False      False  \n",
      "543158      False      False  \n",
      "\n",
      "[543159 rows x 56 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "data.fillna(0,inplace = True)\n",
    "data.drop(columns=['index'],inplace=True)\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1df5c4c-70a2-4566-ae5e-ee3dcc6037a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dur        sbytes        dbytes           sttl  \\\n",
      "count  543159.000000  5.431590e+05  5.431590e+05  543159.000000   \n",
      "mean        0.706760  5.136572e+03  1.936909e+04     157.197364   \n",
      "std        12.637229  1.202311e+05  1.390925e+05     108.452474   \n",
      "min         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
      "25%         0.000007  1.140000e+02  0.000000e+00      31.000000   \n",
      "50%         0.000011  2.000000e+02  0.000000e+00     254.000000   \n",
      "75%         0.072088  1.580000e+03  1.940000e+03     254.000000   \n",
      "max      8760.776367  1.435577e+07  1.465753e+07     255.000000   \n",
      "\n",
      "                dttl          sloss          dloss         Sload  \\\n",
      "count  543159.000000  543159.000000  543159.000000  5.431590e+05   \n",
      "mean       38.850764       3.800661       8.729770  6.877595e+07   \n",
      "std        77.034389      45.616565      50.136204  1.420534e+08   \n",
      "min         0.000000       0.000000       0.000000  0.000000e+00   \n",
      "25%         0.000000       0.000000       0.000000  3.705672e+05   \n",
      "50%         0.000000       0.000000       0.000000  4.560000e+07   \n",
      "75%        29.000000       3.000000       4.000000  8.888889e+07   \n",
      "max       254.000000    5319.000000    5507.000000  5.988000e+09   \n",
      "\n",
      "              Dload          Spkts  ...  ct_flw_http_mthd   is_ftp_login  \\\n",
      "count  5.431590e+05  543159.000000  ...     543159.000000  543159.000000   \n",
      "mean   1.148111e+06      20.369921  ...          0.088724       0.011490   \n",
      "std    3.127653e+06     101.923505  ...          0.566327       0.109623   \n",
      "min    0.000000e+00       0.000000  ...          0.000000       0.000000   \n",
      "25%    0.000000e+00       2.000000  ...          0.000000       0.000000   \n",
      "50%    0.000000e+00       2.000000  ...          0.000000       0.000000   \n",
      "75%    4.087816e+05      14.000000  ...          0.000000       0.000000   \n",
      "max    2.274587e+07   10646.000000  ...         36.000000       4.000000   \n",
      "\n",
      "          ct_ftp_cmd     ct_srv_src     ct_srv_dst     ct_dst_ltm  \\\n",
      "count  543159.000000  543159.000000  543159.000000  543159.000000   \n",
      "mean        0.013029      15.008556      14.833110      10.306825   \n",
      "std         0.141497      14.229735      14.305878      10.989668   \n",
      "min         0.000000       1.000000       1.000000       1.000000   \n",
      "25%         0.000000       3.000000       3.000000       2.000000   \n",
      "50%         0.000000       9.000000       8.000000       5.000000   \n",
      "75%         0.000000      26.000000      26.000000      17.000000   \n",
      "max         8.000000      67.000000      67.000000      67.000000   \n",
      "\n",
      "          ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \n",
      "count  543159.000000     543159.000000     543159.000000   543159.000000  \n",
      "mean       10.837838          9.343288          7.209839       13.766985  \n",
      "std        10.967546         11.391238          8.069018       14.972826  \n",
      "min         1.000000          1.000000          1.000000        1.000000  \n",
      "25%         2.000000          1.000000          1.000000        1.000000  \n",
      "50%         6.000000          2.000000          2.000000        5.000000  \n",
      "75%        17.000000         17.000000         15.000000       26.000000  \n",
      "max        67.000000         67.000000         60.000000       67.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "cols_to_norm = UNSW_NB15_Config.COLS_TO_NORM\n",
    "print(data[cols_to_norm].describe()) # Check if there's any too large value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All other columns processed successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_numeric_issues(df, cols_to_norm):\n",
    "    for col in cols_to_norm:\n",
    "        try:\n",
    "            # Try to coerce to numeric\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Try to clip the column\n",
    "            df[col] = df[col].clip(lower=-1e9, upper=1e9)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "            print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Data type: {df[col].dtype}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "check_numeric_issues(data, UNSW_NB15_Config.COLS_TO_NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37256006-abc1-44aa-8e74-46d05dc6ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cols_to_norm] = scaler.fit_transform(data[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analysis' 'Backdoor' 'Backdoors' 'DoS' 'Exploits' 'Fuzzers' 'Generic'\n",
      " 'Normal' 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Attack label mapping: {'Analysis': 0, 'Backdoor': 1, 'Backdoors': 2, 'DoS': 3, 'Exploits': 4, 'Fuzzers': 5, 'Generic': 6, 'Normal': 7, 'Reconnaissance': 8, 'Shellcode': 9, 'Worms': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "num_classes = 2\n",
    "class_map = [0, 1]\n",
    "if MULTICLASS:\n",
    "    le = LabelEncoder()\n",
    "    attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "    class_map = le.classes_\n",
    "    print(class_map)\n",
    "    print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "    data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "    num_classes = len(class_map)\n",
    "    class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n",
    "\n",
    "BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "ADVERSARIAL_CLASS_LABEL = len(class_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'state_ACC', 'state_CLO', 'state_CON', 'state_ECO', 'state_FIN', 'state_INT', 'state_MAS', 'state_PAR', 'state_REQ', 'state_RST', 'state_TST', 'state_TXD', 'state_URH']\n",
      "Number of training samples: 461685\n",
      "attack_cat\n",
      "7     188595\n",
      "6     183159\n",
      "4      37846\n",
      "5      20609\n",
      "3      13900\n",
      "8      11889\n",
      "0       2275\n",
      "1       1526\n",
      "9       1284\n",
      "2        454\n",
      "10       148\n",
      "Name: count, dtype: int64\n",
      "Number of test samples: 81474\n",
      "attack_cat\n",
      "7     33281\n",
      "6     32322\n",
      "4      6679\n",
      "5      3637\n",
      "3      2453\n",
      "8      2098\n",
      "0       402\n",
      "1       269\n",
      "9       227\n",
      "2        80\n",
      "10       26\n",
      "Name: count, dtype: int64\n",
      "                      srcip                dstip       dur    sbytes  \\\n",
      "35798    175.45.176.0:10819   149.171.126.11:445  0.024183 -0.037815   \n",
      "447994  149.171.126.14:1043      175.45.176.1:53 -0.055926 -0.040527   \n",
      "23187    175.45.176.0:15079    149.171.126.18:80 -0.017630 -0.033324   \n",
      "477690   175.45.176.3:50624  149.171.126.16:5060 -0.055926 -0.030962   \n",
      "134305     59.166.0.1:44316     149.171.126.4:25 -0.005219  0.269111   \n",
      "\n",
      "          dbytes      sttl      dttl     sloss     dloss     Sload     Dload  \\\n",
      "35798  -0.137327  0.892582  2.766939 -0.039474 -0.154176 -0.555127 -0.366518   \n",
      "447994 -0.139253 -0.896222 -0.504331 -0.083318 -0.174121  0.692417 -0.367084   \n",
      "23187  -0.137327  0.892582  2.766939 -0.039474 -0.154176 -0.555023 -0.365900   \n",
      "477690 -0.139253  0.892582 -0.504331 -0.083318 -0.174121  4.122315 -0.367084   \n",
      "134305 -0.114953 -1.163620 -0.127875  0.311276 -0.014556 -0.551365 -0.353912   \n",
      "\n",
      "           Spkts     Dpkts      swin      dwin     stcpb     dtcpb   smeansz  \\\n",
      "35798  -0.101742 -0.159740  1.301681  1.303441  0.949065 -0.462943 -0.329273   \n",
      "447994 -0.180233 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619  0.140425   \n",
      "23187  -0.101742 -0.159740  1.301681  1.303441  1.482943  1.483089  0.018175   \n",
      "477690 -0.180233 -0.216121 -0.768239 -0.767201 -0.721514 -0.721619  3.840098   \n",
      "134305  0.310332  0.178542  1.301681  1.303441  1.482943 -0.716221  3.930177   \n",
      "\n",
      "         dmeansz  trans_depth  res_bdy_len      Sjit      Djit       Stime  \\\n",
      "35798  -0.367140    -0.134353    -0.054182  0.153349 -0.076737  1421933745   \n",
      "447994 -0.526921    -0.134353    -0.054182 -0.080649 -0.189023  1424252930   \n",
      "23187  -0.367140    -0.134353    -0.054182  0.012609 -0.150581  1421931706   \n",
      "477690 -0.526921    -0.134353    -0.054182 -0.080649 -0.189023  1424255007   \n",
      "134305 -0.242867    -0.134353    -0.054182 -0.043228 -0.176821  1424222454   \n",
      "\n",
      "             Ltime   Sintpkt   Dintpkt    tcprtt    synack    ackdat  \\\n",
      "35798   1421933746 -0.008957  0.117394  3.760093  3.793317  3.354919   \n",
      "447994  1424252930 -0.060833 -0.055697 -0.293130 -0.270319 -0.288797   \n",
      "23187   1421931707 -0.037329  0.019030  2.932351  3.123823  2.438738   \n",
      "477690  1424255007 -0.060832 -0.055697 -0.293130 -0.270319 -0.288797   \n",
      "134305  1424222454 -0.054344 -0.040616 -0.280117 -0.250740 -0.284108   \n",
      "\n",
      "        is_sm_ips_ports  ct_state_ttl  ct_flw_http_mthd  is_ftp_login  \\\n",
      "35798         -0.027818     -0.098490         -0.156665     -0.104815   \n",
      "447994        -0.027818     -1.123447         -0.156665     -0.104815   \n",
      "23187         -0.027818     -0.098490         -0.156665     -0.104815   \n",
      "477690        -0.027818      0.926467         -0.156665     -0.104815   \n",
      "134305        -0.027818     -1.123447         -0.156665     -0.104815   \n",
      "\n",
      "        ct_ftp_cmd  ct_srv_src  ct_srv_dst  ct_dst_ltm  ct_src_ltm  \\\n",
      "35798    -0.092082   -0.633080   -0.617447   -0.755877   -0.805818   \n",
      "447994   -0.092082    1.545459    1.549497    2.337941    2.294240   \n",
      "23187    -0.092082   -0.984457   -0.966954   -0.482893   -0.714640   \n",
      "477690   -0.092082   -0.914182   -0.966954   -0.846871   -0.896996   \n",
      "134305   -0.092082   -0.984457   -0.966954   -0.482893   -0.441105   \n",
      "\n",
      "        ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \\\n",
      "35798          -0.732431         -0.769591       -0.785890           5   \n",
      "447994          2.340109          1.709028        1.551680           7   \n",
      "23187          -0.732431         -0.769591       -0.852678           4   \n",
      "477690         -0.732431         -0.769591       -0.852678           6   \n",
      "134305         -0.732431         -0.769591       -0.785890           7   \n",
      "\n",
      "        state_ACC  state_CLO  state_CON  state_ECO  state_FIN  state_INT  \\\n",
      "35798       False      False      False      False       True      False   \n",
      "447994      False      False      False      False      False       True   \n",
      "23187       False      False      False      False       True      False   \n",
      "477690      False      False      False      False      False       True   \n",
      "134305      False      False      False      False       True      False   \n",
      "\n",
      "        state_MAS  state_PAR  state_REQ  state_RST  state_TST  state_TXD  \\\n",
      "35798       False      False      False      False      False      False   \n",
      "447994      False      False      False      False      False      False   \n",
      "23187       False      False      False      False      False      False   \n",
      "477690      False      False      False      False      False      False   \n",
      "134305      False      False      False      False      False      False   \n",
      "\n",
      "        state_URH                                                  h  \n",
      "35798       False  [0.024183325690751246, -0.037815308455400876, ...  \n",
      "447994      False  [-0.05592631735495768, -0.04052675608212099, -...  \n",
      "23187       False  [-0.017629992085505666, -0.03332395349089518, ...  \n",
      "477690      False  [-0.055926079960930894, -0.030961833472525516,...  \n",
      "134305      False  [-0.0052187158398693, 0.26911058210050526, -0....  \n"
     ]
    }
   ],
   "source": [
    "# 70% train, 15% validation, 15% test\n",
    "train_df, test_df = train_test_split(\n",
    "     data, test_size=0.15, random_state=42, stratify=data[label_col])\n",
    "\n",
    "\n",
    "# # Maintain the order of the rows in the original dataframe\n",
    "# train_df = train_df.sort_values(by=UNSW_NB15_Config.TIME_COL_NAMES)\n",
    "# test_df = test_df.sort_values(by=UNSW_NB15_Config.TIME_COL_NAMES)\n",
    "\n",
    "feature_cols = UNSW_NB15_Config.COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "print('Feature Columns:', feature_cols)\n",
    "\n",
    "train_df['h'] = train_df[ feature_cols ].values.tolist()\n",
    "test_df['h'] = test_df[ feature_cols ].values.tolist()\n",
    "\n",
    "# X_train = train_df.drop(columns=[label_col])\n",
    "# X_val = val_df.drop(columns=[label_col])\n",
    "# X_test = test_df.drop(columns=[label_col])\n",
    "\n",
    "y_train = train_df[label_col]\n",
    "y_test = test_df[label_col]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_df))\n",
    "print(y_train.value_counts())\n",
    "print(\"Number of test samples:\", len(test_df))\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f83bd73-531f-42a0-9f73-e1fd98dce1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df, source_ip_col, destination_ip_col, edge_attr, create_using=nx.MultiDiGraph(), **kwargs):\n",
    "    G_nx = nx.from_pandas_edgelist(df, source_ip_col, destination_ip_col, edge_attr, create_using=create_using, **kwargs)\n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    print(\"Number of edges in G_pyg:\", num_edges)\n",
    "    print(\"Number of node in G_pyg:\", num_nodes)\n",
    "    print(\"Shape of node in G_pyg:\", G_pyg.x.shape)\n",
    "    print(\"Shape of edge attr in G_pyg:\", G_pyg.edge_attr.shape)\n",
    "    print(\"Shape of edge label in G_pyg:\", G_pyg.edge_label.shape)\n",
    "\n",
    "    return G_nx, G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c8f9cdb-1316-461a-a927-8d67d90d6144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 461685\n",
      "Number of node in G_pyg: 261376\n",
      "Shape of node in G_pyg: torch.Size([261376, 51])\n",
      "Shape of edge attr in G_pyg: torch.Size([461685, 51])\n",
      "Shape of edge label in G_pyg: torch.Size([461685])\n",
      "Number of edges in G_pyg: 81474\n",
      "Number of node in G_pyg: 52521\n",
      "Shape of node in G_pyg: torch.Size([52521, 51])\n",
      "Shape of edge attr in G_pyg: torch.Size([81474, 51])\n",
      "Shape of edge label in G_pyg: torch.Size([81474])\n"
     ]
    }
   ],
   "source": [
    "G_nx_train, G_pyg_train = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "G_nx_test, G_pyg_test = create_graph(test_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def grid_search(data, epochs, learning_rates, hidden_dims):\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    best_params = {}\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Precompute the train and validation graphs for all folds\n",
    "    folds = []\n",
    "    for train_idx, val_idx in skf.split(data, data[label_col]):\n",
    "        train_df = data.iloc[train_idx]\n",
    "        val_df = data.iloc[val_idx]\n",
    "\n",
    "        G_nx_train, G_pyg_train = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "        G_nx_val, G_pyg_val = create_graph(val_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "\n",
    "        folds.append((G_pyg_train, G_pyg_val))\n",
    "\n",
    "    params_results = {}\n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}\")\n",
    "            fold_f1_scores = []\n",
    "\n",
    "            for fold, (G_pyg_train, G_pyg_val) in enumerate(folds):\n",
    "                print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                model = EGraphSAGE(node_in_channels=G_pyg_train.num_node_features,\n",
    "                                   edge_in_channels=G_pyg_train.num_edge_features,\n",
    "                                   hidden_channels=hidden_dim,\n",
    "                                   out_channels=num_classes).to(device)\n",
    "\n",
    "                model.apply(init_weights)\n",
    "\n",
    "                labels = G_pyg_train.edge_label.cpu().numpy()\n",
    "                class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                                  classes=np.unique(labels),\n",
    "                                                                  y=labels)\n",
    "\n",
    "                # Normalize to stabilize training\n",
    "                class_weights = th.FloatTensor(class_weights).to(device)\n",
    "                print(\"Class weights:\", class_weights)\n",
    "\n",
    "                criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                G_pyg_train = G_pyg_train.to(device)\n",
    "                G_pyg_val = G_pyg_val.to(device)\n",
    "\n",
    "                G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "                G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "\n",
    "                for epoch in range(epochs):\n",
    "                    train_loss = 0\n",
    "                    val_loss = 0\n",
    "\n",
    "                    try:\n",
    "                        model.train()\n",
    "                        out = model(G_pyg_train)\n",
    "                        loss = criterion(out, G_pyg_train.edge_label)\n",
    "                        train_loss = loss.item()\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        model.eval()\n",
    "                        with th.no_grad():\n",
    "                            out = model(G_pyg_val)\n",
    "                            loss = criterion(out, G_pyg_val.edge_label)\n",
    "                            val_loss = loss.item()\n",
    "\n",
    "                        val_f1 = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='weighted')\n",
    "\n",
    "                        if val_f1 > best_epoch_f1:\n",
    "                            best_epoch_f1 = val_f1  # Update the best F1 score for this fold\n",
    "                            print(f\"Best F1 Score at epoch {epoch}: {best_epoch_f1:.4f}, Parameters: lr={lr}, hidden_dim{hidden_dim}\")\n",
    "\n",
    "                        if epoch % 100 == 0:\n",
    "                            print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}')\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                        break\n",
    "\n",
    "                fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "            \n",
    "            avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "            params_results[(lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "            print(f\"Average F1 Score for learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "            if avg_f1 > best_f1:\n",
    "                best_f1 = avg_f1\n",
    "                best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim}\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "    print(\"All results:\", params_results)\n",
    "\n",
    "\n",
    "learning_rates = [0.001, 0.005, 0.01]\n",
    "hidden_dims = [128, 256, 512]\n",
    "\n",
    "# grid_search(train_df, epochs=2000, learning_rates=learning_rates, hidden_dims=hidden_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 461685\n",
      "Number of node in G_pyg: 261376\n",
      "Shape of node in G_pyg: torch.Size([261376, 51])\n",
      "Shape of edge attr in G_pyg: torch.Size([461685, 51])\n",
      "Shape of edge label in G_pyg: torch.Size([461685])\n",
      "Class weights: tensor([1.8449e+01, 2.7504e+01, 9.2448e+01, 3.0195e+00, 1.1090e+00, 2.0366e+00,\n",
      "        2.2915e-01, 2.2255e-01, 3.5303e+00, 3.2688e+01, 2.8359e+02],\n",
      "       device='cuda:0')\n",
      "Saved best model. Lowest Loss: 2.4450581073760986\n",
      "Epoch 0, Loss: 2.4451\n",
      "Saved best model. Lowest Loss: 2.1627137660980225\n",
      "Saved best model. Lowest Loss: 1.8777787685394287\n",
      "Saved best model. Lowest Loss: 1.7127373218536377\n",
      "Saved best model. Lowest Loss: 1.6014554500579834\n",
      "Saved best model. Lowest Loss: 1.5062402486801147\n",
      "Saved best model. Lowest Loss: 1.4739365577697754\n",
      "Saved best model. Lowest Loss: 1.4451699256896973\n",
      "Saved best model. Lowest Loss: 1.3233360052108765\n",
      "Saved best model. Lowest Loss: 1.2668037414550781\n",
      "Saved best model. Lowest Loss: 1.2615469694137573\n",
      "Saved best model. Lowest Loss: 1.230550765991211\n",
      "Saved best model. Lowest Loss: 1.1493059396743774\n",
      "Saved best model. Lowest Loss: 1.1318044662475586\n",
      "Saved best model. Lowest Loss: 1.1120744943618774\n",
      "Saved best model. Lowest Loss: 1.0830320119857788\n",
      "Saved best model. Lowest Loss: 1.0798183679580688\n",
      "Saved best model. Lowest Loss: 1.0663942098617554\n",
      "Saved best model. Lowest Loss: 1.0593944787979126\n",
      "Saved best model. Lowest Loss: 1.0522180795669556\n",
      "Saved best model. Lowest Loss: 1.0448760986328125\n",
      "Saved best model. Lowest Loss: 1.026569128036499\n",
      "Saved best model. Lowest Loss: 1.015600323677063\n",
      "Saved best model. Lowest Loss: 1.0144554376602173\n",
      "Saved best model. Lowest Loss: 1.0020767450332642\n",
      "Saved best model. Lowest Loss: 0.9948459267616272\n",
      "Saved best model. Lowest Loss: 0.9926472306251526\n",
      "Saved best model. Lowest Loss: 0.9733978509902954\n",
      "Saved best model. Lowest Loss: 0.9626091122627258\n",
      "Saved best model. Lowest Loss: 0.9613575339317322\n",
      "Saved best model. Lowest Loss: 0.9554863572120667\n",
      "Saved best model. Lowest Loss: 0.947548508644104\n",
      "Saved best model. Lowest Loss: 0.9431984424591064\n",
      "Saved best model. Lowest Loss: 0.9354260563850403\n",
      "Saved best model. Lowest Loss: 0.9279655814170837\n",
      "Saved best model. Lowest Loss: 0.9275455474853516\n",
      "Saved best model. Lowest Loss: 0.9190737009048462\n",
      "Saved best model. Lowest Loss: 0.9164091944694519\n",
      "Saved best model. Lowest Loss: 0.9146853685379028\n",
      "Saved best model. Lowest Loss: 0.91312175989151\n",
      "Saved best model. Lowest Loss: 0.9096123576164246\n",
      "Saved best model. Lowest Loss: 0.9063491225242615\n",
      "Saved best model. Lowest Loss: 0.9058313965797424\n",
      "Saved best model. Lowest Loss: 0.8934828042984009\n",
      "Epoch 100, Loss: 0.9129\n",
      "Saved best model. Lowest Loss: 0.8881426453590393\n",
      "Saved best model. Lowest Loss: 0.8860594034194946\n",
      "Saved best model. Lowest Loss: 0.8848983645439148\n",
      "Saved best model. Lowest Loss: 0.8812147378921509\n",
      "Saved best model. Lowest Loss: 0.878411054611206\n",
      "Saved best model. Lowest Loss: 0.8751053810119629\n",
      "Saved best model. Lowest Loss: 0.8729395866394043\n",
      "Saved best model. Lowest Loss: 0.8717791438102722\n",
      "Saved best model. Lowest Loss: 0.8695241212844849\n",
      "Saved best model. Lowest Loss: 0.8694065809249878\n",
      "Saved best model. Lowest Loss: 0.8667137026786804\n",
      "Saved best model. Lowest Loss: 0.864726185798645\n",
      "Saved best model. Lowest Loss: 0.8645148873329163\n",
      "Saved best model. Lowest Loss: 0.8643280267715454\n",
      "Saved best model. Lowest Loss: 0.8627321124076843\n",
      "Saved best model. Lowest Loss: 0.8590437769889832\n",
      "Saved best model. Lowest Loss: 0.8568518161773682\n",
      "Saved best model. Lowest Loss: 0.8561448454856873\n",
      "Saved best model. Lowest Loss: 0.8542727828025818\n",
      "Saved best model. Lowest Loss: 0.853537917137146\n",
      "Saved best model. Lowest Loss: 0.8530359864234924\n",
      "Saved best model. Lowest Loss: 0.8526259064674377\n",
      "Saved best model. Lowest Loss: 0.8503965139389038\n",
      "Saved best model. Lowest Loss: 0.8485966920852661\n",
      "Saved best model. Lowest Loss: 0.8477227687835693\n",
      "Saved best model. Lowest Loss: 0.8464240431785583\n",
      "Saved best model. Lowest Loss: 0.8446617722511292\n",
      "Epoch 200, Loss: 0.8447\n",
      "Saved best model. Lowest Loss: 0.8440548181533813\n",
      "Saved best model. Lowest Loss: 0.8432544469833374\n",
      "Saved best model. Lowest Loss: 0.8427404761314392\n",
      "Saved best model. Lowest Loss: 0.840752363204956\n",
      "Saved best model. Lowest Loss: 0.8405704498291016\n",
      "Saved best model. Lowest Loss: 0.8401054739952087\n",
      "Saved best model. Lowest Loss: 0.8395440578460693\n",
      "Saved best model. Lowest Loss: 0.8394433856010437\n",
      "Saved best model. Lowest Loss: 0.8378995060920715\n",
      "Saved best model. Lowest Loss: 0.8378086090087891\n",
      "Saved best model. Lowest Loss: 0.8375651836395264\n",
      "Saved best model. Lowest Loss: 0.8374178409576416\n",
      "Saved best model. Lowest Loss: 0.8356621265411377\n",
      "Saved best model. Lowest Loss: 0.8351568579673767\n",
      "Saved best model. Lowest Loss: 0.8342841863632202\n",
      "Saved best model. Lowest Loss: 0.8342013359069824\n",
      "Saved best model. Lowest Loss: 0.8338636755943298\n",
      "Saved best model. Lowest Loss: 0.8334138989448547\n",
      "Saved best model. Lowest Loss: 0.8328439593315125\n",
      "Saved best model. Lowest Loss: 0.8307287693023682\n",
      "Saved best model. Lowest Loss: 0.8287339210510254\n",
      "Epoch 300, Loss: 0.8361\n",
      "Saved best model. Lowest Loss: 0.8282366394996643\n",
      "Saved best model. Lowest Loss: 0.8279616236686707\n",
      "Saved best model. Lowest Loss: 0.8267010450363159\n",
      "Saved best model. Lowest Loss: 0.8252583742141724\n",
      "Saved best model. Lowest Loss: 0.8246818780899048\n",
      "Saved best model. Lowest Loss: 0.823842465877533\n",
      "Saved best model. Lowest Loss: 0.8221548199653625\n",
      "Saved best model. Lowest Loss: 0.8209193348884583\n",
      "Saved best model. Lowest Loss: 0.8204641938209534\n",
      "Saved best model. Lowest Loss: 0.8202657103538513\n",
      "Saved best model. Lowest Loss: 0.8202365636825562\n",
      "Saved best model. Lowest Loss: 0.8195045590400696\n",
      "Epoch 400, Loss: 0.8195\n",
      "Saved best model. Lowest Loss: 0.8185889720916748\n",
      "Saved best model. Lowest Loss: 0.8185349702835083\n",
      "Saved best model. Lowest Loss: 0.8183334469795227\n",
      "Saved best model. Lowest Loss: 0.8175045847892761\n",
      "Saved best model. Lowest Loss: 0.8154356479644775\n",
      "Saved best model. Lowest Loss: 0.8139262199401855\n",
      "Saved best model. Lowest Loss: 0.8129700422286987\n",
      "Saved best model. Lowest Loss: 0.8122852444648743\n",
      "Saved best model. Lowest Loss: 0.8114627003669739\n",
      "Saved best model. Lowest Loss: 0.8108681440353394\n",
      "Saved best model. Lowest Loss: 0.810613751411438\n",
      "Saved best model. Lowest Loss: 0.8102312684059143\n",
      "Saved best model. Lowest Loss: 0.8090311884880066\n",
      "Saved best model. Lowest Loss: 0.808576226234436\n",
      "Saved best model. Lowest Loss: 0.8084423542022705\n",
      "Epoch 500, Loss: 0.8116\n",
      "Saved best model. Lowest Loss: 0.8083970546722412\n",
      "Saved best model. Lowest Loss: 0.8082075715065002\n",
      "Saved best model. Lowest Loss: 0.8076120615005493\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m loss = criterion(out, G_pyg_train_full.edge_label)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Save the best model based on the lowest loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m < lowest_loss:  \u001b[38;5;66;03m# Here, lowest_loss is used to track the lowest loss\u001b[39;00m\n\u001b[32m     58\u001b[39m     lowest_loss = loss.item()\n\u001b[32m     59\u001b[39m     best_model_state = model.state_dict()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Extract the best parameters from the grid search\n",
    "best_hidden_dim = 256  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.005  # Replace with the best learning_rate found\n",
    "\n",
    "# Create the graph for the entire training dataset\n",
    "G_nx_train_full, G_pyg_train_full = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "model = EGraphSAGE(node_in_channels=G_pyg_train_full.num_node_features,\n",
    "                   edge_in_channels=G_pyg_train_full.num_edge_features,\n",
    "                   hidden_channels=best_hidden_dim,\n",
    "                   out_channels=num_classes).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Compute class weights for the training dataset\n",
    "labels = G_pyg_train_full.edge_label.cpu().numpy()\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(labels),\n",
    "                                                  y=labels)\n",
    "\n",
    "# Normalize class weights\n",
    "class_weights = th.FloatTensor(class_weights).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "\n",
    "# Move the graph data to the device\n",
    "G_pyg_train_full = G_pyg_train_full.to(device)\n",
    "G_pyg_train_full.edge_label = G_pyg_train_full.edge_label.to(device)\n",
    "G_pyg_train_full.edge_attr = G_pyg_train_full.edge_attr.to(device)\n",
    "\n",
    "lowest_loss = float('inf')  # Initialize lowest_loss to a very high value\n",
    "best_model_state = None\n",
    "\n",
    "# Load checkpoint if exists\n",
    "start_epoch = 0\n",
    "epochs = 5000\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    lowest_loss = checkpoint['lowest_loss']\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(G_pyg_train_full)\n",
    "    loss = criterion(out, G_pyg_train_full.edge_label)\n",
    "\n",
    "    # Save the best model based on the lowest loss\n",
    "    if loss.item() < lowest_loss:  # Here, lowest_loss is used to track the lowest loss\n",
    "        lowest_loss = loss.item()\n",
    "        best_model_state = model.state_dict()\n",
    "        th.save(best_model_state, best_model_path)\n",
    "        print(\"Saved best model. Lowest Loss:\", lowest_loss)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Save checkpoint\n",
    "    th.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lowest_loss': lowest_loss\n",
    "    }, checkpoint_path)\n",
    "\n",
    "# Save the trained model\n",
    "print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8368fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 461685\n",
      "Number of node in G_pyg: 261376\n",
      "Shape of node in G_pyg: torch.Size([261376, 51])\n",
      "Shape of edge attr in G_pyg: torch.Size([461685, 51])\n",
      "Shape of edge label in G_pyg: torch.Size([461685])\n"
     ]
    }
   ],
   "source": [
    "G_nx_test, G_pyg_test = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/UNSW_NB15/whole_graph_combined_ports/best_model_all_raw_downsampled.pth\n",
      "inference start\n",
      "inference done\n",
      "Test Accuracy: 0.8770\n",
      "[[   503   1123    413      0      4      0      0      0      0      0\n",
      "     232]\n",
      " [    20   1364     52      1     19      4      0      0      0     20\n",
      "      46]\n",
      " [     3     20    422      0      2      1      0      0      0      2\n",
      "       4]\n",
      " [  1581   8723    601    341    914    129     59      0     15    208\n",
      "    1329]\n",
      " [  3913  10503   1159    283  12020    638    133      1     84    489\n",
      "    8623]\n",
      " [   484   1228    836      0    484  16540      0      0      1     19\n",
      "    1017]\n",
      " [   479   1284     35    499    992    107 178350      1     12    104\n",
      "    1296]\n",
      " [   144     11      1     14    157   2103      2 185862      5     19\n",
      "     277]\n",
      " [   495   1520     50      3     13      5     21      0   8100     72\n",
      "    1610]\n",
      " [     0      5      2      0      5      2      0      0      0   1260\n",
      "      10]\n",
      " [    15      0      0      0      0      1      0      0      0      1\n",
      "     131]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.0659    0.2211    0.1015      2275\n",
      "      Backdoor     0.0529    0.8938    0.0999      1526\n",
      "     Backdoors     0.1182    0.9295    0.2097       454\n",
      "           DoS     0.2989    0.0245    0.0453     13900\n",
      "      Exploits     0.8227    0.3176    0.4583     37846\n",
      "       Fuzzers     0.8469    0.8026    0.8241     20609\n",
      "       Generic     0.9988    0.9737    0.9861    183159\n",
      "        Normal     1.0000    0.9855    0.9927    188595\n",
      "Reconnaissance     0.9858    0.6813    0.8057     11889\n",
      "     Shellcode     0.5743    0.9813    0.7246      1284\n",
      "         Worms     0.0090    0.8851    0.0178       148\n",
      "\n",
      "      accuracy                         0.8770    461685\n",
      "     macro avg     0.5248    0.6997    0.4787    461685\n",
      "  weighted avg     0.9466    0.8770    0.8962    461685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(G_pyg_test, adversarial=False):\n",
    "\n",
    "    G_pyg_test = G_pyg_test.to(device)\n",
    "    G_pyg_test.edge_label = G_pyg_test.edge_label.to(device)\n",
    "    G_pyg_test.edge_attr = G_pyg_test.edge_attr.to(device)\n",
    "\n",
    "    best_model = EGraphSAGE(node_in_channels=G_pyg_test.num_node_features, \n",
    "                       edge_in_channels=G_pyg_test.num_edge_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=num_classes).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path, weights_only=True))\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "            \n",
    "        try:\n",
    "            out = best_model(G_pyg_test)\n",
    "            \n",
    "        except Exception as forward_error:\n",
    "            print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "    print(\"inference done\")\n",
    "\n",
    "    test_accuracy = compute_accuracy(out, G_pyg_test.edge_label)\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "    \n",
    "    pred_labels = out.argmax(dim=1).cpu()\n",
    "    all_test_labels = G_pyg_test.edge_label.cpu()\n",
    "\n",
    "    \n",
    "    global class_map\n",
    "    class_map_2 = class_map\n",
    "    if adversarial:\n",
    "        class_map_2 = np.append(class_map, \"Adversarial\")\n",
    "\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map_2)))\n",
    "    print(cm)\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map_2, digits=4)\n",
    "    print(report)\n",
    "\n",
    "eval(G_pyg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcb5e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_traffic_to_attacker(graph, ratio=0.1, num_injected_nodes=1, is_attack=False):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    # 1. Identify attacker nodes\n",
    "    attacker_edges = (edge_label != BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "    attacker_nodes = th.unique(edge_index[:, attacker_edges])\n",
    "    if attacker_nodes.numel() == 0:\n",
    "        raise ValueError(\"No attacker nodes found.\")\n",
    "\n",
    "    # 2. Sample benign edge feature pool\n",
    "    if is_attack:\n",
    "        attack_edges = (edge_label != BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "        inject_edge_attr_pool = edge_attr[attack_edges]\n",
    "    else:\n",
    "        benign_edges = (edge_label == BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "        inject_edge_attr_pool = edge_attr[benign_edges]\n",
    "\n",
    "    # 3. Inject new nodes\n",
    "    original_num_nodes = x.size(0)\n",
    "\n",
    "    new_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "    x = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "    # 4. Inject edges from injected nodes to attacker nodes\n",
    "    num_to_inject = max(1, int(ratio * num_edges))\n",
    "    new_edges = []\n",
    "    new_attrs = []\n",
    "    new_labels = []\n",
    "\n",
    "    new_nodes = np.array([]) # !!!!!!! REMOVE AFTER VERIFY\n",
    "    for _ in range(num_to_inject):\n",
    "        src = random.randint(original_num_nodes, original_num_nodes + num_injected_nodes)  # from injected nodes\n",
    "\n",
    "        new_nodes = np.append(new_nodes, src)# !!!!!!! REMOVE AFTER VERIFY\n",
    "        dst = attacker_nodes[random.randint(0, len(attacker_nodes) - 1)].item()\n",
    "\n",
    "        new_edges.append([src, dst])\n",
    "        attr = inject_edge_attr_pool[random.randint(0, len(inject_edge_attr_pool) - 1)]\n",
    "        new_attrs.append(attr)\n",
    "        new_labels.append(0)\n",
    "\n",
    "    print(\"New Nodes\", np.unique(new_nodes))  # Fixed to use numpy's unique function\n",
    "\n",
    "    # Create a new empty graph to store the injected edges\n",
    "    new_graph = Data()\n",
    "\n",
    "    # 5. Merge into graph\n",
    "    if new_edges:\n",
    "        new_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "        new_attrs = th.stack(new_attrs)\n",
    "        new_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "        new_graph.edge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "        new_graph.edge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "        new_graph.edge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "        new_graph.x = x\n",
    "\n",
    "        # new_graph.first_injected_node_idx = original_num_nodes # Store injected node indices\n",
    "\n",
    "    return new_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "632c5bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Nodes [261376. 261377.]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m G_pyg_test = G_pyg_test.cpu()\n\u001b[32m      3\u001b[39m injected_graph = inject_traffic_to_attacker(G_pyg_test, \u001b[32m0.1\u001b[39m, num_injected_nodes=\u001b[32m1\u001b[39m, is_attack=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minjected_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversarial\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36meval\u001b[39m\u001b[34m(G_pyg_test, adversarial)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval\u001b[39m(G_pyg_test, adversarial=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mG_pyg_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     G_pyg_test.edge_label = G_pyg_test.edge_label.to(device)\n\u001b[32m     13\u001b[39m     G_pyg_test.edge_attr = G_pyg_test.edge_attr.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/torch_geometric/data/data.py:362\u001b[39m, in \u001b[36mBaseData.to\u001b[39m\u001b[34m(self, device, non_blocking, *args)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], *args: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    358\u001b[39m        non_blocking: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    359\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[33;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[32m    361\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/torch_geometric/data/data.py:342\u001b[39m, in \u001b[36mBaseData.apply\u001b[39m\u001b[34m(self, func, *args)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stores:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/torch_geometric/data/storage.py:201\u001b[39m, in \u001b[36mBaseStorage.apply\u001b[39m\u001b[34m(self, func, *args)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items(*args):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28mself\u001b[39m[key] = \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/torch_geometric/data/storage.py:897\u001b[39m, in \u001b[36mrecursive_apply\u001b[39m\u001b[34m(data, func)\u001b[39m\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrecursive_apply\u001b[39m(data: Any, func: Callable) -> Any:\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    898\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch.nn.utils.rnn.PackedSequence):\n\u001b[32m    899\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/.venv/lib/python3.12/site-packages/torch_geometric/data/data.py:363\u001b[39m, in \u001b[36mBaseData.to.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], *args: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    358\u001b[39m        non_blocking: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    359\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[33;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[32m    361\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply(\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, *args)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "G_pyg_test = G_pyg_test.cpu()\n",
    "injected_graph = inject_traffic_to_attacker(G_pyg_test, 0.1, num_injected_nodes=1, is_attack=True)\n",
    "eval(injected_graph, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c37b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject BENIGN Traffic to Attacker Nodes\n",
    "injected_graph = inject_traffic_to_attacker(G_pyg_test, 0.1, num_injected_nodes=1, is_attack=False)\n",
    "eval(injected_graph, adversarial=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
