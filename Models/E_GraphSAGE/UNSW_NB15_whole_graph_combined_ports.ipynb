{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb9e1b2-1c5f-49e3-82b4-3bfe52cabad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====Experiment=====\n",
    "Dataset: UNSW-NB15 dataset\n",
    "\n",
    "Training with whole graph\n",
    "Downsampled 90% normal traffic randomly\n",
    "Split train and test randomly\n",
    "\n",
    "Combined IP and Port features\n",
    "'''\n",
    "\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.UNSW_NB15.UNSW_NB15_config import UNSW_NB15_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Normal            221876\n",
      "Generic           215481\n",
      "Exploits           44525\n",
      "Fuzzers            24246\n",
      "DoS                16353\n",
      "Reconnaissance     13987\n",
      "Analysis            2677\n",
      "Backdoors           2329\n",
      "Shellcode           1511\n",
      "Worms                174\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    321283\n",
      "0    221876\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = \"all_downsampled\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"UNSW_NB15/All/{csv_file_name}.csv\"))\n",
    "\n",
    "DATASET_NAME = \"UNSW_NB15\"\n",
    "EXPERIMENT_NAME = \"whole_graph_combined_ports\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = UNSW_NB15_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = UNSW_NB15_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = UNSW_NB15_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = UNSW_NB15_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = UNSW_NB15_Config.ATTACK_CLASS_COL_NAME\n",
    "IS_ATTACK_COL_NAME = UNSW_NB15_Config.IS_ATTACK_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = UNSW_NB15_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = UNSW_NB15_Config.TIME_COL_NAMES\n",
    "\n",
    "print(data[ATTACK_CLASS_COL_NAME].value_counts())\n",
    "print(data[IS_ATTACK_COL_NAME].value_counts())\n",
    "\n",
    "MULTICLASS = True\n",
    "\n",
    "if MULTICLASS:\n",
    "    label_col = ATTACK_CLASS_COL_NAME\n",
    "    data.drop(columns=[IS_ATTACK_COL_NAME], inplace=True)\n",
    "else:\n",
    "    label_col = IS_ATTACK_COL_NAME\n",
    "    data.drop(columns=[ATTACK_CLASS_COL_NAME], inplace=True)\n",
    "\n",
    "saves_path = os.path.join(project_root, \"Models/E_GraphSAGE/logs\", DATASET_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "checkpoint_path = os.path.join(saves_path, f\"checkpoints_{csv_file_name}.pth\")\n",
    "best_model_path = os.path.join(saves_path, f\"best_model_{csv_file_name}.pth\")\n",
    "\n",
    "os.makedirs(saves_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srcip', 'sport', 'dstip', 'dsport', 'state', 'dur', 'sbytes', 'dbytes',\n",
      "       'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts',\n",
      "       'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth',\n",
      "       'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt', 'Dintpkt',\n",
      "       'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
      "       'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src',\n",
      "       'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm',\n",
      "       'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat', 'source_file_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data.drop(columns=UNSW_NB15_Config.DROP_COLS,inplace=True)\n",
    "data.drop(columns=UNSW_NB15_Config.TIME_COL_NAMES)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "# # Combine Port and IP\n",
    "data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "data = pd.get_dummies(data, columns = UNSW_NB15_Config.CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(UNSW_NB15_Config.CATEGORICAL_COLS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5651ef5b-0a9d-4641-aad7-5738092c46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                        srcip                  dstip        dur  sbytes  \\\n",
      "0             10.40.85.1_0:0          224.0.0.5_0:0  50.004341     384   \n",
      "1          59.166.0.6_0:2142     149.171.126.4_0:53   0.001134     132   \n",
      "2       175.45.176.0_0:13284    149.171.126.16_0:80   2.390390    1362   \n",
      "3         59.166.0.3_0:42587     149.171.126.8_0:25  34.077175   37358   \n",
      "4            10.40.170.2_0:0        10.40.170.2_0:0   0.000000      46   \n",
      "...                      ...                    ...        ...     ...   \n",
      "543154  175.45.176.1_3:17386  149.171.126.11_3:6071   0.291164     732   \n",
      "543155  175.45.176.3_3:36130  149.171.126.16_3:2140   0.011751      76   \n",
      "543156    59.166.0.2_3:27607     149.171.126.4_3:53   0.002410     146   \n",
      "543157  175.45.176.1_3:24448  149.171.126.11_3:5250   0.176514   10778   \n",
      "543158    59.166.0.2_3:10376   149.171.126.2_3:8406   0.049598    2646   \n",
      "\n",
      "        dbytes  sttl  dttl  sloss  dloss          Sload  ...  state_ECR  \\\n",
      "0            0     1     0      0      0      51.195557  ...      False   \n",
      "1          164    31    29      0      0  465608.468800  ...      False   \n",
      "2          268   254   252      6      1    4233.619141  ...      False   \n",
      "3         3380    31    29     18      8    8601.652344  ...      False   \n",
      "4            0     0     0      0      0       0.000000  ...      False   \n",
      "...        ...   ...   ...    ...    ...            ...  ...        ...   \n",
      "543154     468   254   252      3      2   18436.343750  ...      False   \n",
      "543155     132   254    60      0      0   25870.138670  ...      False   \n",
      "543156     178    31    29      0      0  242323.656300  ...      False   \n",
      "543157     268   254   252      5      1  457980.656300  ...      False   \n",
      "543158   25564    31    29      7     15  416629.687500  ...      False   \n",
      "\n",
      "        state_FIN  state_INT  state_MAS  state_PAR  state_REQ  state_RST  \\\n",
      "0           False       True      False      False      False      False   \n",
      "1           False      False      False      False      False      False   \n",
      "2            True      False      False      False      False      False   \n",
      "3            True      False      False      False      False      False   \n",
      "4           False       True      False      False      False      False   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "543154       True      False      False      False      False      False   \n",
      "543155      False      False      False      False      False      False   \n",
      "543156      False      False      False      False      False      False   \n",
      "543157       True      False      False      False      False      False   \n",
      "543158       True      False      False      False      False      False   \n",
      "\n",
      "        state_TST  state_TXD  state_URH  \n",
      "0           False      False      False  \n",
      "1           False      False      False  \n",
      "2           False      False      False  \n",
      "3           False      False      False  \n",
      "4           False      False      False  \n",
      "...           ...        ...        ...  \n",
      "543154      False      False      False  \n",
      "543155      False      False      False  \n",
      "543156      False      False      False  \n",
      "543157      False      False      False  \n",
      "543158      False      False      False  \n",
      "\n",
      "[543159 rows x 58 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                        srcip                  dstip        dur  sbytes  \\\n",
      "0             10.40.85.1_0:0          224.0.0.5_0:0  50.004341     384   \n",
      "1          59.166.0.6_0:2142     149.171.126.4_0:53   0.001134     132   \n",
      "2       175.45.176.0_0:13284    149.171.126.16_0:80   2.390390    1362   \n",
      "3         59.166.0.3_0:42587     149.171.126.8_0:25  34.077175   37358   \n",
      "4            10.40.170.2_0:0        10.40.170.2_0:0   0.000000      46   \n",
      "...                      ...                    ...        ...     ...   \n",
      "543154  175.45.176.1_3:17386  149.171.126.11_3:6071   0.291164     732   \n",
      "543155  175.45.176.3_3:36130  149.171.126.16_3:2140   0.011751      76   \n",
      "543156    59.166.0.2_3:27607     149.171.126.4_3:53   0.002410     146   \n",
      "543157  175.45.176.1_3:24448  149.171.126.11_3:5250   0.176514   10778   \n",
      "543158    59.166.0.2_3:10376   149.171.126.2_3:8406   0.049598    2646   \n",
      "\n",
      "        dbytes  sttl  dttl  sloss  dloss          Sload  ...  state_ECR  \\\n",
      "0            0     1     0      0      0      51.195557  ...      False   \n",
      "1          164    31    29      0      0  465608.468800  ...      False   \n",
      "2          268   254   252      6      1    4233.619141  ...      False   \n",
      "3         3380    31    29     18      8    8601.652344  ...      False   \n",
      "4            0     0     0      0      0       0.000000  ...      False   \n",
      "...        ...   ...   ...    ...    ...            ...  ...        ...   \n",
      "543154     468   254   252      3      2   18436.343750  ...      False   \n",
      "543155     132   254    60      0      0   25870.138670  ...      False   \n",
      "543156     178    31    29      0      0  242323.656300  ...      False   \n",
      "543157     268   254   252      5      1  457980.656300  ...      False   \n",
      "543158   25564    31    29      7     15  416629.687500  ...      False   \n",
      "\n",
      "        state_FIN  state_INT  state_MAS  state_PAR  state_REQ  state_RST  \\\n",
      "0           False       True      False      False      False      False   \n",
      "1           False      False      False      False      False      False   \n",
      "2            True      False      False      False      False      False   \n",
      "3            True      False      False      False      False      False   \n",
      "4           False       True      False      False      False      False   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "543154       True      False      False      False      False      False   \n",
      "543155      False      False      False      False      False      False   \n",
      "543156      False      False      False      False      False      False   \n",
      "543157       True      False      False      False      False      False   \n",
      "543158       True      False      False      False      False      False   \n",
      "\n",
      "        state_TST  state_TXD  state_URH  \n",
      "0           False      False      False  \n",
      "1           False      False      False  \n",
      "2           False      False      False  \n",
      "3           False      False      False  \n",
      "4           False      False      False  \n",
      "...           ...        ...        ...  \n",
      "543154      False      False      False  \n",
      "543155      False      False      False  \n",
      "543156      False      False      False  \n",
      "543157      False      False      False  \n",
      "543158      False      False      False  \n",
      "\n",
      "[543159 rows x 58 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "data.fillna(0,inplace = True)\n",
    "data.drop(columns=['index'],inplace=True)\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1df5c4c-70a2-4566-ae5e-ee3dcc6037a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 dur        sbytes        dbytes           sttl  \\\n",
      "count  543159.000000  5.431590e+05  5.431590e+05  543159.000000   \n",
      "mean        0.703562  5.129376e+03  1.912066e+04     157.223966   \n",
      "std        12.635598  1.202304e+05  1.382834e+05     108.429349   \n",
      "min         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
      "25%         0.000007  1.140000e+02  0.000000e+00      31.000000   \n",
      "50%         0.000010  2.000000e+02  0.000000e+00     254.000000   \n",
      "75%         0.070875  1.580000e+03  1.936000e+03     254.000000   \n",
      "max      8760.776367  1.435577e+07  1.465753e+07     255.000000   \n",
      "\n",
      "                dttl          sloss          dloss         Sload  \\\n",
      "count  543159.000000  543159.000000  543159.000000  5.431590e+05   \n",
      "mean       38.847354       3.789714       8.637535  6.901181e+07   \n",
      "std        77.059190      45.614073      49.869719  1.425974e+08   \n",
      "min         0.000000       0.000000       0.000000  0.000000e+00   \n",
      "25%         0.000000       0.000000       0.000000  3.760815e+05   \n",
      "50%         0.000000       0.000000       0.000000  4.560000e+07   \n",
      "75%        29.000000       3.000000       4.000000  8.888889e+07   \n",
      "max       254.000000    5319.000000    5507.000000  5.988000e+09   \n",
      "\n",
      "              Dload          Spkts  ...  ct_flw_http_mthd   is_ftp_login  \\\n",
      "count  5.431590e+05  543159.000000  ...     543159.000000  543159.000000   \n",
      "mean   1.145602e+06      20.260456  ...          0.089263       0.011459   \n",
      "std    3.125320e+06     101.785929  ...          0.568852       0.109870   \n",
      "min    0.000000e+00       0.000000  ...          0.000000       0.000000   \n",
      "25%    0.000000e+00       2.000000  ...          0.000000       0.000000   \n",
      "50%    0.000000e+00       2.000000  ...          0.000000       0.000000   \n",
      "75%    4.080209e+05      14.000000  ...          0.000000       0.000000   \n",
      "max    2.248756e+07   10646.000000  ...         36.000000       4.000000   \n",
      "\n",
      "          ct_ftp_cmd     ct_srv_src     ct_srv_dst     ct_dst_ltm  \\\n",
      "count  543159.000000  543159.000000  543159.000000  543159.000000   \n",
      "mean        0.007661      15.025361      14.853214      10.321932   \n",
      "std         0.091356      14.239878      14.314732      10.996982   \n",
      "min         0.000000       1.000000       1.000000       1.000000   \n",
      "25%         0.000000       3.000000       3.000000       2.000000   \n",
      "50%         0.000000       9.000000       8.000000       5.000000   \n",
      "75%         0.000000      26.000000      26.000000      17.000000   \n",
      "max         4.000000      67.000000      67.000000      67.000000   \n",
      "\n",
      "          ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \n",
      "count  543159.000000     543159.000000     543159.000000   543159.000000  \n",
      "mean       10.848566          9.357573          7.219855       13.786578  \n",
      "std        10.976383         11.399195          8.074346       14.983005  \n",
      "min         1.000000          1.000000          1.000000        1.000000  \n",
      "25%         2.000000          1.000000          1.000000        1.000000  \n",
      "50%         6.000000          2.000000          2.000000        5.000000  \n",
      "75%        17.000000         17.000000         15.000000       26.000000  \n",
      "max        67.000000         67.000000         60.000000       67.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "cols_to_norm = UNSW_NB15_Config.COLS_TO_NORM\n",
    "print(data[cols_to_norm].describe()) # Check if there's any too large value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All other columns processed successfully.\n"
     ]
    }
   ],
   "source": [
    "def check_numeric_issues(df, cols_to_norm):\n",
    "    for col in cols_to_norm:\n",
    "        try:\n",
    "            # Try to coerce to numeric\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Try to clip the column\n",
    "            df[col] = df[col].clip(lower=-1e9, upper=1e9)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "            print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "            print(f\"  - Data type: {df[col].dtype}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "check_numeric_issues(data, UNSW_NB15_Config.COLS_TO_NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37256006-abc1-44aa-8e74-46d05dc6ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cols_to_norm] = scaler.fit_transform(data[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analysis' 'Backdoors' 'DoS' 'Exploits' 'Fuzzers' 'Generic' 'Normal'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "Attack label mapping: {'Analysis': 0, 'Backdoors': 1, 'DoS': 2, 'Exploits': 3, 'Fuzzers': 4, 'Generic': 5, 'Normal': 6, 'Reconnaissance': 7, 'Shellcode': 8, 'Worms': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "num_classes = 2\n",
    "class_map = [0, 1]\n",
    "if MULTICLASS:\n",
    "    le = LabelEncoder()\n",
    "    attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "    class_map = le.classes_\n",
    "    print(class_map)\n",
    "    print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "    data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "    num_classes = len(class_map)\n",
    "    class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n",
    "\n",
    "BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "ADVERSARIAL_CLASS_LABEL = len(class_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'state_ACC', 'state_CLO', 'state_CON', 'state_ECO', 'state_ECR', 'state_FIN', 'state_INT', 'state_MAS', 'state_PAR', 'state_REQ', 'state_RST', 'state_TST', 'state_TXD', 'state_URH']\n",
      "Number of training samples: 461685\n",
      "attack_cat\n",
      "6    188595\n",
      "5    183159\n",
      "3     37846\n",
      "4     20609\n",
      "2     13900\n",
      "7     11889\n",
      "0      2275\n",
      "1      1980\n",
      "8      1284\n",
      "9       148\n",
      "Name: count, dtype: int64\n",
      "Number of test samples: 81474\n",
      "attack_cat\n",
      "6    33281\n",
      "5    32322\n",
      "3     6679\n",
      "4     3637\n",
      "2     2453\n",
      "7     2098\n",
      "0      402\n",
      "1      349\n",
      "8      227\n",
      "9       26\n",
      "Name: count, dtype: int64\n",
      "                       srcip                  dstip       dur    sbytes  \\\n",
      "35798   175.45.176.0_0:10819   149.171.126.11_0:445  0.024440 -0.037756   \n",
      "454500    59.166.0.2_3:13452  149.171.126.1_3:39482 -0.052447 -0.010009   \n",
      "23187   175.45.176.0_0:15079    149.171.126.18_0:80 -0.017379 -0.033264   \n",
      "489755   175.45.176.3_3:1043    149.171.126.15_3:53 -0.055680 -0.041715   \n",
      "134305    59.166.0.1_1:44316     149.171.126.4_1:25 -0.004966  0.269172   \n",
      "\n",
      "          dbytes      sttl      dttl     sloss     dloss     Sload     Dload  \\\n",
      "35798  -0.136334  0.892527  2.766092 -0.039236 -0.153150 -0.554662 -0.365989   \n",
      "454500  0.271236 -1.164114 -0.127790  0.070379  0.368209 -0.548462  3.128362   \n",
      "23187  -0.136334  0.892527  2.766092 -0.039236 -0.153150 -0.554559 -0.365371   \n",
      "489755 -0.138272  0.892527 -0.504124 -0.083082 -0.173202 -0.018194 -0.366555   \n",
      "134305 -0.113829 -1.164114 -0.127790  0.311533 -0.012784 -0.550916 -0.353373   \n",
      "\n",
      "           Spkts     Dpkts      swin      dwin     stcpb     dtcpb   smeansz  \\\n",
      "35798  -0.100804 -0.158623  1.303104  1.304850  0.950180 -0.462170 -0.329716   \n",
      "454500  0.449370  0.427016  1.303104  1.304850  0.274400  0.303777 -0.329716   \n",
      "23187  -0.100804 -0.158623  1.303104  1.304850  1.484216  1.484299  0.017606   \n",
      "489755 -0.179401 -0.215298 -0.767401 -0.766374 -0.720896 -0.720905 -0.342580   \n",
      "134305  0.311827  0.181426  1.303104  1.304850  1.484216 -0.715505  3.928197   \n",
      "\n",
      "         dmeansz  trans_depth  res_bdy_len      Sjit      Djit       Stime  \\\n",
      "35798  -0.366711    -0.134792     -0.05343  0.153264 -0.076895  1421933745   \n",
      "454500  2.437416    -0.134792     -0.05343 -0.080902 -0.175606  1424240533   \n",
      "23187  -0.366711    -0.134792     -0.05343  0.012423 -0.150894  1421931706   \n",
      "489755 -0.526845    -0.134792     -0.05343 -0.080902 -0.189417  1424245264   \n",
      "134305 -0.242162    -0.134792     -0.05343 -0.043454 -0.177189  1424222454   \n",
      "\n",
      "             Ltime   Sintpkt   Dintpkt    tcprtt    synack    ackdat  \\\n",
      "35798   1421933746 -0.008638  0.119318  3.717742  3.612803  3.416380   \n",
      "454500  1424240533 -0.060137 -0.054933 -0.278494 -0.242636 -0.288018   \n",
      "23187   1421931707 -0.036975  0.019956  2.899294  2.974987  2.483664   \n",
      "489755  1424245264 -0.060450 -0.055530 -0.289971 -0.258558 -0.293097   \n",
      "134305  1424222454 -0.053968 -0.040295 -0.277104 -0.239905 -0.288324   \n",
      "\n",
      "        is_sm_ips_ports  ct_state_ttl  ct_flw_http_mthd  is_ftp_login  \\\n",
      "35798         -0.028049     -0.098678         -0.156918     -0.104295   \n",
      "454500        -0.028049     -1.123769         -0.156918     -0.104295   \n",
      "23187         -0.028049     -0.098678         -0.156918     -0.104295   \n",
      "489755        -0.028049      0.926413         -0.156918     -0.104295   \n",
      "134305        -0.028049     -1.123769         -0.156918     -0.104295   \n",
      "\n",
      "        ct_ftp_cmd  ct_srv_src  ct_srv_dst  ct_dst_ltm  ct_src_ltm  \\\n",
      "35798    -0.083856   -0.633809   -0.618469   -0.756748   -0.806147   \n",
      "454500   -0.083856   -0.774260   -0.688327   -0.574879   -0.715042   \n",
      "23187    -0.083856   -0.984936   -0.967760   -0.483945   -0.715042   \n",
      "489755   -0.083856    0.489797    0.499261    1.061935    1.015949   \n",
      "134305   -0.083856   -0.984936   -0.967760   -0.483945   -0.441727   \n",
      "\n",
      "        ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \\\n",
      "35798          -0.733173         -0.770324       -0.786664           4   \n",
      "454500         -0.733173         -0.770324       -0.786664           6   \n",
      "23187          -0.733173         -0.770324       -0.853406           3   \n",
      "489755          1.109064          1.830509        0.548183           5   \n",
      "134305         -0.733173         -0.770324       -0.786664           6   \n",
      "\n",
      "        source_file_id  state_ACC  state_CLO  state_CON  state_ECO  state_ECR  \\\n",
      "35798                0      False      False      False      False      False   \n",
      "454500               3      False      False      False      False      False   \n",
      "23187                0      False      False      False      False      False   \n",
      "489755               3      False      False      False      False      False   \n",
      "134305               1      False      False      False      False      False   \n",
      "\n",
      "        state_FIN  state_INT  state_MAS  state_PAR  state_REQ  state_RST  \\\n",
      "35798        True      False      False      False      False      False   \n",
      "454500       True      False      False      False      False      False   \n",
      "23187        True      False      False      False      False      False   \n",
      "489755      False       True      False      False      False      False   \n",
      "134305       True      False      False      False      False      False   \n",
      "\n",
      "        state_TST  state_TXD  state_URH  \\\n",
      "35798       False      False      False   \n",
      "454500      False      False      False   \n",
      "23187       False      False      False   \n",
      "489755      False      False      False   \n",
      "134305      False      False      False   \n",
      "\n",
      "                                                        h  \n",
      "35798   [0.024439518249307186, -0.03775569116632746, -...  \n",
      "454500  [-0.05244682114681552, -0.01000892950063232, 0...  \n",
      "23187   [-0.01737919714689172, -0.03326430888231206, -...  \n",
      "489755  [-0.05568046603287485, -0.04171476147594104, -...  \n",
      "134305  [-0.004966318747785316, 0.269172066323925, -0....  \n"
     ]
    }
   ],
   "source": [
    "# 70% train, 15% validation, 15% test\n",
    "train_full_df, test_df = train_test_split(\n",
    "     data, test_size=0.15, random_state=42, stratify=data[label_col])\n",
    "\n",
    "\n",
    "feature_cols = UNSW_NB15_Config.COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "print('Feature Columns:', feature_cols)\n",
    "\n",
    "train_full_df['h'] = train_full_df[ feature_cols ].values.tolist()\n",
    "test_df['h'] = test_df[ feature_cols ].values.tolist()\n",
    "\n",
    "y_train = train_full_df[label_col]\n",
    "y_test = test_df[label_col]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_full_df))\n",
    "print(y_train.value_counts())\n",
    "print(\"Number of test samples:\", len(test_df))\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print(train_full_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f83bd73-531f-42a0-9f73-e1fd98dce1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df, source_ip_col, destination_ip_col, edge_attr, create_using=nx.MultiDiGraph(), **kwargs):\n",
    "    G_nx = nx.from_pandas_edgelist(df, source_ip_col, destination_ip_col, edge_attr, create_using=create_using, **kwargs)\n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    print(\"Number of edges in G_pyg:\", num_edges)\n",
    "    print(\"Number of node in G_pyg:\", num_nodes)\n",
    "    print(\"Shape of node in G_pyg:\", G_pyg.x.shape)\n",
    "    print(\"Shape of edge attr in G_pyg:\", G_pyg.edge_attr.shape)\n",
    "    print(\"Shape of edge label in G_pyg:\", G_pyg.edge_label.shape)\n",
    "\n",
    "    return G_nx, G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8f9cdb-1316-461a-a927-8d67d90d6144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 81474\n",
      "Number of node in G_pyg: 54154\n",
      "Shape of node in G_pyg: torch.Size([54154, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([81474, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([81474])\n"
     ]
    }
   ],
   "source": [
    "G_nx_test, G_pyg_test = create_graph(test_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 307790\n",
      "Number of node in G_pyg: 195382\n",
      "Shape of node in G_pyg: torch.Size([195382, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([307790, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([307790])\n",
      "Number of edges in G_pyg: 153895\n",
      "Number of node in G_pyg: 100146\n",
      "Shape of node in G_pyg: torch.Size([100146, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([153895, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([153895])\n",
      "Number of edges in G_pyg: 307790\n",
      "Number of node in G_pyg: 194910\n",
      "Shape of node in G_pyg: torch.Size([194910, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([307790, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([307790])\n",
      "Number of edges in G_pyg: 153895\n",
      "Number of node in G_pyg: 100550\n",
      "Shape of node in G_pyg: torch.Size([100550, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([153895, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([153895])\n",
      "Number of edges in G_pyg: 307790\n",
      "Number of node in G_pyg: 195087\n",
      "Shape of node in G_pyg: torch.Size([195087, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([307790, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([307790])\n",
      "Number of edges in G_pyg: 153895\n",
      "Number of node in G_pyg: 100420\n",
      "Shape of node in G_pyg: torch.Size([100420, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([153895, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([153895])\n",
      "Testing with learning rate: 0.001, hidden_dim: 256, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.0289e+01, 2.3317e+01, 3.3217e+00, 1.2199e+00, 2.2403e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1090e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.4212, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.3550, Validation Loss: 2.1382, Validation F1: 0.4212\n",
      "Best F1 Score at epoch 1: 0.7672, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.7812, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.8095, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.8207, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.8245, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8307, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.8322, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.8421, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8452, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.8559, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 17: 0.8743, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 18: 0.8805, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 24: 0.8820, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.8862, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 31: 0.8883, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 32: 0.8888, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 39: 0.8904, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 54: 0.8927, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.9362, Validation Loss: 0.9931, Validation F1: 0.8907\n",
      "Best F1 Score at epoch 102: 0.8947, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 158: 0.8948, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 164: 0.8948, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 195: 0.8960, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8820, Validation Loss: 0.9392, Validation F1: 0.8919\n",
      "Best F1 Score at epoch 247: 0.8965, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 260: 0.8996, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 263: 0.8999, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 274: 0.9025, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 288: 0.9026, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 296: 0.9029, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 300, Train Loss: 0.8553, Validation Loss: 0.9203, Validation F1: 0.8934\n",
      "Best F1 Score at epoch 317: 0.9032, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 319: 0.9035, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 326: 0.9038, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 389: 0.9039, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 400, Train Loss: 0.8438, Validation Loss: 0.9149, Validation F1: 0.9030\n",
      "Best F1 Score at epoch 419: 0.9044, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Fold 2\n",
      "Class weights: tensor([2.0303e+01, 2.3317e+01, 3.3214e+00, 1.2199e+00, 2.2403e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1090e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.5335, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.3323, Validation Loss: 2.1087, Validation F1: 0.5335\n",
      "Best F1 Score at epoch 1: 0.6924, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.7813, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.8010, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.8108, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.8209, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.8259, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8262, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.8375, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.8402, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.8442, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8733, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.8811, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 22: 0.8825, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.8850, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 26: 0.8863, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 29: 0.8865, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 32: 0.8866, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 36: 0.8897, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 41: 0.8923, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 98: 0.8929, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.9437, Validation Loss: 0.9840, Validation F1: 0.8916\n",
      "Best F1 Score at epoch 106: 0.8936, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 120: 0.8939, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 123: 0.8941, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 125: 0.8948, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 159: 0.8949, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 182: 0.8949, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 188: 0.8957, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8783, Validation Loss: 0.9316, Validation F1: 0.8935\n",
      "Best F1 Score at epoch 206: 0.8965, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 260: 0.8967, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 269: 0.9005, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 291: 0.9017, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 300, Train Loss: 0.8522, Validation Loss: 0.9202, Validation F1: 0.8956\n",
      "Best F1 Score at epoch 339: 0.9027, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 340: 0.9029, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 349: 0.9029, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 359: 0.9045, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 400, Train Loss: 0.8425, Validation Loss: 0.9140, Validation F1: 0.8954\n",
      "Fold 3\n",
      "Class weights: tensor([2.0289e+01, 2.3317e+01, 3.3214e+00, 1.2199e+00, 2.2401e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1407e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.4060, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.4229, Validation Loss: 2.1559, Validation F1: 0.4060\n",
      "Best F1 Score at epoch 1: 0.5637, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.7266, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.8205, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.8219, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.8240, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.8242, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.8278, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.8388, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8424, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 13: 0.8426, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 14: 0.8547, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.8725, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 17: 0.8754, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 18: 0.8820, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 25: 0.8832, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 26: 0.8847, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 34: 0.8891, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 57: 0.8903, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 64: 0.8903, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 70: 0.8919, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 90: 0.8921, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.9405, Validation Loss: 0.9579, Validation F1: 0.8906\n",
      "Best F1 Score at epoch 124: 0.8928, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 131: 0.8931, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 139: 0.8936, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 155: 0.8944, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 177: 0.8948, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8806, Validation Loss: 0.9062, Validation F1: 0.8926\n",
      "Best F1 Score at epoch 254: 0.8951, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 268: 0.8953, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 269: 0.9015, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 296: 0.9016, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 300, Train Loss: 0.8617, Validation Loss: 0.8884, Validation F1: 0.8942\n",
      "Best F1 Score at epoch 305: 0.9026, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 334: 0.9029, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 371: 0.9036, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 381: 0.9044, Parameters: lr=0.001, hidden_dim256, drop_out=0.3\n",
      "Epoch 400, Train Loss: 0.8498, Validation Loss: 0.8787, Validation F1: 0.9006\n",
      "Current Results:  {(0.3, 0.001, 256): {'folds': [0.9044126315908197, 0.9045356304078723, 0.904360080455408], 'avg_f1': 0.9044361141513667}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.001, hidden_dim 256: 0.9044\n",
      "Best Parameters: {'learning_rate': 0.001, 'hidden_dim': 256, 'drop_out': 0.3}, Best F1 Score: 0.9044\n",
      "All results: {(0.3, 0.001, 256): {'folds': [0.9044126315908197, 0.9045356304078723, 0.904360080455408], 'avg_f1': 0.9044361141513667}}\n",
      "Testing with learning rate: 0.005, hidden_dim: 256, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.0289e+01, 2.3317e+01, 3.3217e+00, 1.2199e+00, 2.2403e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1090e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0506, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.3808, Validation Loss: 2.7688, Validation F1: 0.0506\n",
      "Best F1 Score at epoch 1: 0.7017, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.7917, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.8198, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.8290, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8432, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.8445, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.8508, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.8854, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 14: 0.8869, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 22: 0.8885, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 23: 0.8885, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 27: 0.8890, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 31: 0.8916, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 52: 0.8918, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 56: 0.8934, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 57: 0.8934, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 61: 0.8947, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 79: 0.8952, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 89: 0.9015, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 92: 0.9016, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.8656, Validation Loss: 0.9251, Validation F1: 0.8963\n",
      "Best F1 Score at epoch 102: 0.9025, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 116: 0.9028, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 121: 0.9039, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 128: 0.9040, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 133: 0.9046, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 154: 0.9051, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 169: 0.9052, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 173: 0.9059, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 192: 0.9066, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8174, Validation Loss: 0.9014, Validation F1: 0.9053\n",
      "Epoch 300, Train Loss: 0.7980, Validation Loss: 0.9000, Validation F1: 0.9048\n",
      "Best F1 Score at epoch 343: 0.9070, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 400, Train Loss: 0.7884, Validation Loss: 0.9144, Validation F1: 0.9050\n",
      "Fold 2\n",
      "Class weights: tensor([2.0303e+01, 2.3317e+01, 3.3214e+00, 1.2199e+00, 2.2403e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1090e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.0070, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.4243, Validation Loss: 3.2716, Validation F1: 0.0070\n",
      "Best F1 Score at epoch 1: 0.6113, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 2: 0.7372, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.7551, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.7808, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.8025, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.8217, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8568, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.8709, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.8846, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 17: 0.8847, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 18: 0.8903, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 22: 0.8905, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 23: 0.8909, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 27: 0.8918, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 39: 0.8935, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 51: 0.8937, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 52: 0.8943, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 74: 0.8948, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 84: 0.8996, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 94: 0.8997, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 95: 0.9000, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.8647, Validation Loss: 0.9190, Validation F1: 0.8996\n",
      "Best F1 Score at epoch 102: 0.9012, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 106: 0.9013, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 111: 0.9025, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 155: 0.9026, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 172: 0.9035, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 176: 0.9038, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8150, Validation Loss: 0.9073, Validation F1: 0.9032\n",
      "Best F1 Score at epoch 201: 0.9040, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 214: 0.9060, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 282: 0.9061, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 300, Train Loss: 0.7949, Validation Loss: 0.9262, Validation F1: 0.8986\n",
      "Best F1 Score at epoch 395: 0.9066, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 400, Train Loss: 0.7873, Validation Loss: 0.9345, Validation F1: 0.9005\n",
      "Fold 3\n",
      "Class weights: tensor([2.0289e+01, 2.3317e+01, 3.3214e+00, 1.2199e+00, 2.2401e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1407e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.3570, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.4068, Validation Loss: 2.9573, Validation F1: 0.3570\n",
      "Best F1 Score at epoch 1: 0.7811, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 3: 0.7861, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.8389, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8720, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.8728, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 10: 0.8812, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 13: 0.8831, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 16: 0.8843, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 17: 0.8922, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 62: 0.8925, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 70: 0.8926, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 75: 0.8930, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 79: 0.8931, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 80: 0.8936, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 90: 0.8942, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 91: 0.8944, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.8721, Validation Loss: 0.8997, Validation F1: 0.8928\n",
      "Best F1 Score at epoch 102: 0.8946, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 103: 0.8954, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 110: 0.8956, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 120: 0.8956, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 123: 0.9001, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 124: 0.9025, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 136: 0.9047, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 169: 0.9050, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 186: 0.9052, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 197: 0.9055, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8247, Validation Loss: 0.8609, Validation F1: 0.9053\n",
      "Best F1 Score at epoch 233: 0.9055, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 248: 0.9059, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 269: 0.9061, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 283: 0.9067, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 284: 0.9069, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 300, Train Loss: 0.8005, Validation Loss: 0.8498, Validation F1: 0.9039\n",
      "Best F1 Score at epoch 316: 0.9076, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 386: 0.9076, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 395: 0.9087, Parameters: lr=0.005, hidden_dim256, drop_out=0.3\n",
      "Epoch 400, Train Loss: 0.7897, Validation Loss: 0.8482, Validation F1: 0.9063\n",
      "Current Results:  {(0.3, 0.001, 256): {'folds': [0.9044126315908197, 0.9045356304078723, 0.904360080455408], 'avg_f1': 0.9044361141513667}, (0.3, 0.005, 256): {'folds': [0.9070103860882799, 0.906556209099025, 0.9087090746726099], 'avg_f1': 0.9074252232866383}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.005, hidden_dim 256: 0.9074\n",
      "Best Parameters: {'learning_rate': 0.005, 'hidden_dim': 256, 'drop_out': 0.3}, Best F1 Score: 0.9074\n",
      "All results: {(0.3, 0.001, 256): {'folds': [0.9044126315908197, 0.9045356304078723, 0.904360080455408], 'avg_f1': 0.9044361141513667}, (0.3, 0.005, 256): {'folds': [0.9070103860882799, 0.906556209099025, 0.9087090746726099], 'avg_f1': 0.9074252232866383}}\n",
      "Testing with learning rate: 0.01, hidden_dim: 256, drop_out: 0.3\n",
      "Fold 1\n",
      "Class weights: tensor([2.0289e+01, 2.3317e+01, 3.3217e+00, 1.2199e+00, 2.2403e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1090e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.7122, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.4566, Validation Loss: 5.4280, Validation F1: 0.7122\n",
      "Best F1 Score at epoch 3: 0.7133, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.8006, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 6: 0.8029, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8184, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.8425, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 11: 0.8470, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8684, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 14: 0.8854, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 15: 0.8898, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 28: 0.8905, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 32: 0.8907, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 38: 0.8913, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 43: 0.8918, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 47: 0.8934, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 56: 0.8934, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 60: 0.8943, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 65: 0.8949, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 74: 0.8951, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 84: 0.8952, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 86: 0.9016, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 87: 0.9017, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 88: 0.9019, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 89: 0.9021, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 93: 0.9022, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 99: 0.9022, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 100: 0.9031, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.8569, Validation Loss: 0.9387, Validation F1: 0.9031\n",
      "Best F1 Score at epoch 104: 0.9033, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 133: 0.9038, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 145: 0.9038, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 148: 0.9043, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 151: 0.9047, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 178: 0.9059, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 197: 0.9065, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8133, Validation Loss: 0.9303, Validation F1: 0.9051\n",
      "Best F1 Score at epoch 245: 0.9069, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 264: 0.9069, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 271: 0.9074, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 274: 0.9076, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 300, Train Loss: 0.7920, Validation Loss: 0.9327, Validation F1: 0.9070\n",
      "Epoch 400, Train Loss: 0.7840, Validation Loss: 0.9410, Validation F1: 0.9056\n",
      "Fold 2\n",
      "Class weights: tensor([2.0303e+01, 2.3317e+01, 3.3214e+00, 1.2199e+00, 2.2403e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1090e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.3466, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.3746, Validation Loss: 4.4557, Validation F1: 0.3466\n",
      "Best F1 Score at epoch 1: 0.6270, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.7399, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 5: 0.7553, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8311, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.8317, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 9: 0.8532, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8691, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 13: 0.8839, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 17: 0.8875, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 28: 0.8902, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 39: 0.8910, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 45: 0.8926, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 51: 0.8931, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 60: 0.8986, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 61: 0.9009, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 69: 0.9015, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.8540, Validation Loss: 0.9360, Validation F1: 0.8993\n",
      "Best F1 Score at epoch 105: 0.9017, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 107: 0.9020, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 108: 0.9024, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 111: 0.9025, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 117: 0.9026, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 126: 0.9028, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 129: 0.9035, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 132: 0.9035, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 164: 0.9043, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 168: 0.9044, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8205, Validation Loss: 0.9290, Validation F1: 0.9012\n",
      "Best F1 Score at epoch 208: 0.9053, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 300, Train Loss: 0.7996, Validation Loss: 0.9364, Validation F1: 0.9049\n",
      "Best F1 Score at epoch 328: 0.9059, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 400, Train Loss: 0.7917, Validation Loss: 0.9231, Validation F1: 0.9013\n",
      "Fold 3\n",
      "Class weights: tensor([2.0289e+01, 2.3317e+01, 3.3214e+00, 1.2199e+00, 2.2401e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8833e+00, 3.5957e+01, 3.1407e+02], device='cuda:0')\n",
      "Best F1 Score at epoch 0: 0.3141, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 0, Train Loss: 2.4149, Validation Loss: 5.5765, Validation F1: 0.3141\n",
      "Best F1 Score at epoch 1: 0.7750, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 4: 0.7930, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 7: 0.8414, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 8: 0.8611, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 12: 0.8878, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 13: 0.8960, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 86: 0.8999, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 88: 0.9015, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 96: 0.9017, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 100: 0.9017, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 100, Train Loss: 0.8546, Validation Loss: 0.8795, Validation F1: 0.9017\n",
      "Best F1 Score at epoch 103: 0.9020, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 109: 0.9021, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 111: 0.9028, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 113: 0.9030, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 116: 0.9031, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 120: 0.9031, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 132: 0.9034, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 144: 0.9043, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 173: 0.9046, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 192: 0.9051, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 195: 0.9057, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 200, Train Loss: 0.8141, Validation Loss: 0.8590, Validation F1: 0.9026\n",
      "Best F1 Score at epoch 248: 0.9060, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 263: 0.9062, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 290: 0.9066, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 300, Train Loss: 0.7948, Validation Loss: 0.8536, Validation F1: 0.9057\n",
      "Best F1 Score at epoch 313: 0.9068, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 325: 0.9069, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 329: 0.9072, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 390: 0.9075, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 391: 0.9076, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Epoch 400, Train Loss: 0.7877, Validation Loss: 0.8504, Validation F1: 0.9068\n",
      "Best F1 Score at epoch 411: 0.9080, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Best F1 Score at epoch 441: 0.9081, Parameters: lr=0.01, hidden_dim256, drop_out=0.3\n",
      "Current Results:  {(0.3, 0.001, 256): {'folds': [0.9044126315908197, 0.9045356304078723, 0.904360080455408], 'avg_f1': 0.9044361141513667}, (0.3, 0.005, 256): {'folds': [0.9070103860882799, 0.906556209099025, 0.9087090746726099], 'avg_f1': 0.9074252232866383}, (0.3, 0.01, 256): {'folds': [0.9076471030278986, 0.9058809263412559, 0.908120268064801], 'avg_f1': 0.907216099144652}}\n",
      "Average F1 Score for dropout 0.3, learning rate 0.01, hidden_dim 256: 0.9072\n",
      "Best Parameters: {'learning_rate': 0.005, 'hidden_dim': 256, 'drop_out': 0.3}, Best F1 Score: 0.9074\n",
      "All results: {(0.3, 0.001, 256): {'folds': [0.9044126315908197, 0.9045356304078723, 0.904360080455408], 'avg_f1': 0.9044361141513667}, (0.3, 0.005, 256): {'folds': [0.9070103860882799, 0.906556209099025, 0.9087090746726099], 'avg_f1': 0.9074252232866383}, (0.3, 0.01, 256): {'folds': [0.9076471030278986, 0.9058809263412559, 0.908120268064801], 'avg_f1': 0.907216099144652}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def grid_search(data, epochs, learning_rates, hidden_dims, drop_outs):\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    best_params = {}\n",
    "    best_f1 = 0\n",
    "\n",
    "    # Precompute the train and validation graphs for all folds\n",
    "    folds = []\n",
    "    for train_idx, val_idx in skf.split(data, data[label_col]):\n",
    "        train_df = data.iloc[train_idx]\n",
    "        val_df = data.iloc[val_idx]\n",
    "\n",
    "        G_nx_train, G_pyg_train = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "        G_nx_val, G_pyg_val = create_graph(val_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "\n",
    "        G_pyg_train = G_pyg_train.to(device)\n",
    "        G_pyg_val = G_pyg_val.to(device)\n",
    "\n",
    "        G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "        G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "        G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "        G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "        folds.append((G_pyg_train, G_pyg_val))\n",
    "\n",
    "    params_results = {}\n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            for drop_out in drop_outs:\n",
    "                print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}, drop_out: {drop_out}\")\n",
    "                fold_f1_scores = []\n",
    "\n",
    "                for fold, (G_pyg_train, G_pyg_val) in enumerate(folds):\n",
    "                    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                    model = EGraphSAGE(node_in_channels=G_pyg_train.num_node_features,\n",
    "                                    edge_in_channels=G_pyg_train.num_edge_features,\n",
    "                                    hidden_channels=hidden_dim,\n",
    "                                    dropout=drop_out,\n",
    "                                    out_channels=num_classes).to(device)\n",
    "\n",
    "                    model.apply(init_weights)\n",
    "\n",
    "                    labels = G_pyg_train.edge_label.cpu().numpy()\n",
    "                    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                                    classes=np.unique(labels),\n",
    "                                                                    y=labels)\n",
    "\n",
    "                    # Normalize to stabilize training\n",
    "                    class_weights = th.FloatTensor(class_weights).to(device)\n",
    "                    print(\"Class weights:\", class_weights)\n",
    "\n",
    "                    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                    optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "                    scheduler = th.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "\n",
    "                    best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "\n",
    "                    for epoch in range(epochs):\n",
    "                        train_loss = 0\n",
    "                        val_loss = 0\n",
    "\n",
    "                        try:\n",
    "                            model.train()\n",
    "                            out = model(G_pyg_train)\n",
    "                            \n",
    "                            optimizer.zero_grad()\n",
    "                            loss = criterion(out, G_pyg_train.edge_label)\n",
    "                            train_loss = loss.item()\n",
    "\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            scheduler.step()\n",
    "\n",
    "                            model.eval()\n",
    "                            with th.no_grad():\n",
    "                                out = model(G_pyg_val)\n",
    "                                loss = criterion(out, G_pyg_val.edge_label)\n",
    "                                val_loss = loss.item()\n",
    "\n",
    "                            val_f1 = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='weighted')\n",
    "\n",
    "                            if val_f1 > best_epoch_f1:\n",
    "                                best_epoch_f1 = val_f1  # Update the best F1 score for this fold\n",
    "                                print(f\"Best F1 Score at epoch {epoch}: {best_epoch_f1:.4f}, Parameters: lr={lr}, hidden_dim{hidden_dim}, drop_out={drop_out}\")\n",
    "\n",
    "                            if epoch % 100 == 0:\n",
    "                                print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}')\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                            break\n",
    "\n",
    "                    fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "                \n",
    "                avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "                params_results[(drop_out, lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "                print(\"Current Results: \", params_results)\n",
    "                print(f\"Average F1 Score for dropout {drop_out}, learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "                if avg_f1 > best_f1:\n",
    "                    best_f1 = avg_f1\n",
    "                    best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim, 'drop_out': drop_out}\n",
    "\n",
    "        print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "        print(\"All results:\", params_results)\n",
    "\n",
    "\n",
    "learning_rates = [0.001, 0.005, 0.01]\n",
    "hidden_dims = [128, 256, 512]\n",
    "drop_outs = [0.2, 0.3, 0.4]\n",
    "\n",
    "grid_search(train_full_df, epochs=500, learning_rates=learning_rates, hidden_dims=hidden_dims, drop_outs=drop_outs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 392432\n",
      "Number of node in G_pyg: 245578\n",
      "Shape of node in G_pyg: torch.Size([245578, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([392432, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([392432])\n",
      "Number of edges in G_pyg: 69253\n",
      "Number of node in G_pyg: 46463\n",
      "Shape of node in G_pyg: torch.Size([46463, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([69253, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([69253])\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "     train_full_df, test_size=0.15, random_state=42, stratify=train_full_df[label_col])\n",
    "\n",
    "G_nx_train, G_pyg_train = create_graph(train_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "G_nx_val, G_pyg_val = create_graph(val_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88bdffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([2.0291e+01, 2.3317e+01, 3.3215e+00, 1.2199e+00, 2.2403e+00, 2.5207e-01,\n",
      "        2.4480e-01, 3.8832e+00, 3.5970e+01, 3.1145e+02], device='cuda:0')\n",
      "Epoch 0 Saved best model. Best F1: 0.35675963158778856\n",
      "Epoch 0, Train Loss: 2.4535, Validation Loss: 2.7107, Validation F1: 0.3568\n",
      "Epoch 1 Saved best model. Best F1: 0.357916233483906\n",
      "Epoch 2 Saved best model. Best F1: 0.41191112312759487\n",
      "Epoch 3 Saved best model. Best F1: 0.766470940552873\n",
      "Epoch 4 Saved best model. Best F1: 0.7838183514215967\n",
      "Epoch 5 Saved best model. Best F1: 0.7928635232639838\n",
      "Epoch 6 Saved best model. Best F1: 0.8451443101188193\n",
      "Epoch 7 Saved best model. Best F1: 0.8803274807243063\n",
      "Epoch 10, Train Loss: 1.2421, Validation Loss: 1.2835, Validation F1: 0.8654\n",
      "Epoch 12 Saved best model. Best F1: 0.8817022162949003\n",
      "Epoch 16 Saved best model. Best F1: 0.8844544200852004\n",
      "Epoch 17 Saved best model. Best F1: 0.8855596008578333\n",
      "Epoch 20 Saved best model. Best F1: 0.8873373456823959\n",
      "Epoch 20, Train Loss: 1.0673, Validation Loss: 1.1434, Validation F1: 0.8873\n",
      "Epoch 21 Saved best model. Best F1: 0.8887987924140185\n",
      "Epoch 25 Saved best model. Best F1: 0.891598478409702\n",
      "Epoch 30, Train Loss: 1.0118, Validation Loss: 1.0785, Validation F1: 0.8887\n",
      "Epoch 37 Saved best model. Best F1: 0.8920339381927463\n",
      "Epoch 40, Train Loss: 0.9687, Validation Loss: 1.0432, Validation F1: 0.8899\n",
      "Epoch 47 Saved best model. Best F1: 0.8921611352886636\n",
      "Epoch 50, Train Loss: 0.9351, Validation Loss: 1.0151, Validation F1: 0.8853\n",
      "Epoch 51 Saved best model. Best F1: 0.8926946745067066\n",
      "Epoch 59 Saved best model. Best F1: 0.8933023278747981\n",
      "Epoch 60, Train Loss: 0.9109, Validation Loss: 1.0088, Validation F1: 0.8892\n",
      "Epoch 70, Train Loss: 0.8961, Validation Loss: 0.9946, Validation F1: 0.8921\n",
      "Epoch 71 Saved best model. Best F1: 0.8938424631850164\n",
      "Epoch 76 Saved best model. Best F1: 0.8938613605491394\n",
      "Epoch 80, Train Loss: 0.8823, Validation Loss: 0.9806, Validation F1: 0.8927\n",
      "Epoch 83 Saved best model. Best F1: 0.8940397583148867\n",
      "Epoch 86 Saved best model. Best F1: 0.8948063307755801\n",
      "Epoch 90, Train Loss: 0.8800, Validation Loss: 0.9709, Validation F1: 0.8923\n",
      "Epoch 100, Train Loss: 0.8630, Validation Loss: 0.9719, Validation F1: 0.8936\n",
      "Epoch 103 Saved best model. Best F1: 0.8955896020599172\n",
      "Epoch 110, Train Loss: 0.8638, Validation Loss: 0.9587, Validation F1: 0.8935\n",
      "Epoch 114 Saved best model. Best F1: 0.8989030851426987\n",
      "Epoch 120, Train Loss: 0.8515, Validation Loss: 0.9576, Validation F1: 0.8868\n",
      "Epoch 124 Saved best model. Best F1: 0.900258884649662\n",
      "Epoch 130, Train Loss: 0.8454, Validation Loss: 0.9623, Validation F1: 0.8986\n",
      "Epoch 132 Saved best model. Best F1: 0.9019313956355838\n",
      "Epoch 140, Train Loss: 0.8484, Validation Loss: 0.9628, Validation F1: 0.9007\n",
      "Epoch 142 Saved best model. Best F1: 0.9025567742544834\n",
      "Epoch 147 Saved best model. Best F1: 0.9031255419507185\n",
      "Epoch 150, Train Loss: 0.8371, Validation Loss: 0.9718, Validation F1: 0.8964\n",
      "Epoch 158 Saved best model. Best F1: 0.9031898357599994\n",
      "Epoch 160, Train Loss: 0.8353, Validation Loss: 0.9499, Validation F1: 0.8996\n",
      "Epoch 165 Saved best model. Best F1: 0.9032629983840713\n",
      "Epoch 170, Train Loss: 0.8261, Validation Loss: 0.9479, Validation F1: 0.8954\n",
      "Epoch 175 Saved best model. Best F1: 0.9038971988189175\n",
      "Epoch 180, Train Loss: 0.8213, Validation Loss: 0.9607, Validation F1: 0.9019\n",
      "Epoch 190, Train Loss: 0.8243, Validation Loss: 0.9601, Validation F1: 0.9028\n",
      "Epoch 200, Train Loss: 0.8337, Validation Loss: 0.9896, Validation F1: 0.8927\n",
      "Epoch 210, Train Loss: 0.8262, Validation Loss: 0.9513, Validation F1: 0.9012\n",
      "Epoch 220 Saved best model. Best F1: 0.9041276161654414\n",
      "Epoch 220, Train Loss: 0.8166, Validation Loss: 0.9451, Validation F1: 0.9041\n",
      "Epoch 221 Saved best model. Best F1: 0.9044478423601039\n",
      "Epoch 230, Train Loss: 0.8155, Validation Loss: 0.9610, Validation F1: 0.9010\n",
      "Epoch 240, Train Loss: 0.8127, Validation Loss: 0.9634, Validation F1: 0.9029\n",
      "Epoch 247 Saved best model. Best F1: 0.9050967822267119\n",
      "Epoch 250 Saved best model. Best F1: 0.9054379773067358\n",
      "Epoch 250, Train Loss: 0.8158, Validation Loss: 0.9820, Validation F1: 0.9054\n",
      "Epoch 260, Train Loss: 0.8141, Validation Loss: 0.9772, Validation F1: 0.8962\n",
      "Epoch 270, Train Loss: 0.8055, Validation Loss: 0.9652, Validation F1: 0.9047\n",
      "Epoch 280 Saved best model. Best F1: 0.9054467766993336\n",
      "Epoch 280, Train Loss: 0.7990, Validation Loss: 0.9650, Validation F1: 0.9054\n",
      "Epoch 290, Train Loss: 0.7978, Validation Loss: 0.9702, Validation F1: 0.8979\n",
      "Epoch 300, Train Loss: 0.7989, Validation Loss: 0.9746, Validation F1: 0.9005\n",
      "Epoch 301 Saved best model. Best F1: 0.905720384623836\n",
      "Epoch 307 Saved best model. Best F1: 0.9058578932606894\n",
      "Epoch 310, Train Loss: 0.7948, Validation Loss: 0.9843, Validation F1: 0.9034\n",
      "Epoch 320, Train Loss: 0.8075, Validation Loss: 0.9971, Validation F1: 0.9044\n",
      "Epoch 330, Train Loss: 0.7933, Validation Loss: 0.9892, Validation F1: 0.9050\n",
      "Epoch 336 Saved best model. Best F1: 0.9065506525170585\n",
      "Epoch 340, Train Loss: 0.7942, Validation Loss: 0.9888, Validation F1: 0.9037\n",
      "Epoch 350, Train Loss: 0.7929, Validation Loss: 0.9877, Validation F1: 0.9048\n",
      "Epoch 360, Train Loss: 0.7900, Validation Loss: 0.9712, Validation F1: 0.9048\n",
      "Epoch 370, Train Loss: 0.7911, Validation Loss: 0.9884, Validation F1: 0.9024\n",
      "Epoch 380, Train Loss: 0.8018, Validation Loss: 0.9809, Validation F1: 0.9048\n",
      "Epoch 390, Train Loss: 0.7972, Validation Loss: 1.0023, Validation F1: 0.9041\n",
      "Epoch 400, Train Loss: 0.7900, Validation Loss: 0.9836, Validation F1: 0.9065\n",
      "Epoch 410, Train Loss: 0.7864, Validation Loss: 0.9965, Validation F1: 0.9031\n",
      "Epoch 420, Train Loss: 0.7838, Validation Loss: 1.0017, Validation F1: 0.9001\n",
      "Epoch 430, Train Loss: 0.7888, Validation Loss: 1.0007, Validation F1: 0.9064\n",
      "Epoch 440, Train Loss: 0.7907, Validation Loss: 1.0188, Validation F1: 0.9050\n",
      "Epoch 450, Train Loss: 0.7866, Validation Loss: 1.0076, Validation F1: 0.9012\n",
      "Epoch 460, Train Loss: 0.7827, Validation Loss: 1.0176, Validation F1: 0.9029\n",
      "Epoch 470, Train Loss: 0.7806, Validation Loss: 1.0106, Validation F1: 0.9057\n",
      "Epoch 480, Train Loss: 0.7770, Validation Loss: 1.0420, Validation F1: 0.9059\n",
      "Epoch 490, Train Loss: 0.7760, Validation Loss: 1.0162, Validation F1: 0.9039\n",
      "Epoch 500, Train Loss: 0.7741, Validation Loss: 1.0384, Validation F1: 0.9026\n",
      "Epoch 510, Train Loss: 0.7826, Validation Loss: 1.0435, Validation F1: 0.9060\n",
      "Epoch 520, Train Loss: 0.9112, Validation Loss: 1.0837, Validation F1: 0.8964\n",
      "Epoch 530, Train Loss: 0.8647, Validation Loss: 1.0269, Validation F1: 0.8983\n",
      "Epoch 540, Train Loss: 0.8174, Validation Loss: 0.9973, Validation F1: 0.9017\n",
      "Epoch 550, Train Loss: 0.8097, Validation Loss: 0.9953, Validation F1: 0.9006\n",
      "Epoch 560, Train Loss: 0.7976, Validation Loss: 0.9972, Validation F1: 0.9034\n",
      "Epoch 570, Train Loss: 0.7914, Validation Loss: 0.9948, Validation F1: 0.9039\n",
      "Epoch 580, Train Loss: 0.7890, Validation Loss: 1.0002, Validation F1: 0.9011\n",
      "Epoch 590, Train Loss: 0.7856, Validation Loss: 1.0228, Validation F1: 0.9013\n",
      "Epoch 600, Train Loss: 0.7846, Validation Loss: 1.0174, Validation F1: 0.8992\n",
      "Epoch 610, Train Loss: 0.7822, Validation Loss: 1.0367, Validation F1: 0.9025\n",
      "Epoch 620, Train Loss: 0.7811, Validation Loss: 1.0413, Validation F1: 0.9020\n",
      "Epoch 630, Train Loss: 0.7793, Validation Loss: 1.0401, Validation F1: 0.8979\n",
      "Epoch 640, Train Loss: 0.7813, Validation Loss: 1.0461, Validation F1: 0.9031\n",
      "Epoch 650, Train Loss: 0.7773, Validation Loss: 1.0546, Validation F1: 0.9005\n",
      "Epoch 660, Train Loss: 0.7767, Validation Loss: 1.0712, Validation F1: 0.9013\n",
      "Epoch 670, Train Loss: 0.7770, Validation Loss: 1.0562, Validation F1: 0.9013\n",
      "Epoch 680, Train Loss: 0.7754, Validation Loss: 1.0585, Validation F1: 0.9008\n",
      "Epoch 690, Train Loss: 0.7745, Validation Loss: 1.0770, Validation F1: 0.9021\n",
      "Epoch 700, Train Loss: 0.7732, Validation Loss: 1.0887, Validation F1: 0.9040\n",
      "Epoch 710, Train Loss: 0.7731, Validation Loss: 1.0823, Validation F1: 0.9036\n",
      "Epoch 720, Train Loss: 0.7780, Validation Loss: 1.0822, Validation F1: 0.9018\n",
      "Epoch 730, Train Loss: 0.7729, Validation Loss: 1.0862, Validation F1: 0.9004\n",
      "Epoch 740, Train Loss: 0.7728, Validation Loss: 1.0886, Validation F1: 0.9021\n",
      "Epoch 750, Train Loss: 0.7726, Validation Loss: 1.1034, Validation F1: 0.9020\n",
      "Epoch 759 Saved best model. Best F1: 0.9077886395509044\n",
      "Epoch 760, Train Loss: 0.7698, Validation Loss: 1.0971, Validation F1: 0.9015\n",
      "Epoch 770, Train Loss: 0.7687, Validation Loss: 1.0977, Validation F1: 0.9047\n",
      "Epoch 780, Train Loss: 0.7683, Validation Loss: 1.1096, Validation F1: 0.9018\n",
      "Epoch 790, Train Loss: 0.7681, Validation Loss: 1.1155, Validation F1: 0.9035\n",
      "Epoch 800, Train Loss: 0.7681, Validation Loss: 1.1213, Validation F1: 0.9048\n",
      "Epoch 810, Train Loss: 0.7672, Validation Loss: 1.1077, Validation F1: 0.9069\n",
      "Epoch 813 Saved best model. Best F1: 0.9081851047198674\n",
      "Epoch 820, Train Loss: 0.7688, Validation Loss: 1.1349, Validation F1: 0.9016\n",
      "Epoch 830, Train Loss: 0.7672, Validation Loss: 1.1340, Validation F1: 0.9007\n",
      "Epoch 840, Train Loss: 0.7660, Validation Loss: 1.1368, Validation F1: 0.9023\n",
      "Epoch 844 Saved best model. Best F1: 0.9089557249964341\n",
      "Epoch 850, Train Loss: 0.7671, Validation Loss: 1.1416, Validation F1: 0.9063\n",
      "Epoch 856 Saved best model. Best F1: 0.9089691449573755\n",
      "Epoch 860, Train Loss: 0.7735, Validation Loss: 1.1145, Validation F1: 0.9041\n",
      "Epoch 870, Train Loss: 0.7719, Validation Loss: 1.1163, Validation F1: 0.9062\n",
      "Epoch 880, Train Loss: 0.7666, Validation Loss: 1.1390, Validation F1: 0.9049\n",
      "Epoch 890, Train Loss: 0.7656, Validation Loss: 1.1487, Validation F1: 0.9063\n",
      "Epoch 900, Train Loss: 0.7697, Validation Loss: 1.1298, Validation F1: 0.9060\n",
      "Epoch 910, Train Loss: 0.7629, Validation Loss: 1.1443, Validation F1: 0.9056\n",
      "Epoch 920, Train Loss: 0.7634, Validation Loss: 1.1479, Validation F1: 0.9038\n",
      "Epoch 930, Train Loss: 0.7623, Validation Loss: 1.1420, Validation F1: 0.9047\n",
      "Epoch 934 Saved best model. Best F1: 0.9090161681049591\n",
      "Epoch 940, Train Loss: 0.7637, Validation Loss: 1.1396, Validation F1: 0.9051\n",
      "Epoch 950, Train Loss: 0.7624, Validation Loss: 1.1360, Validation F1: 0.9035\n",
      "Epoch 960, Train Loss: 0.7604, Validation Loss: 1.1527, Validation F1: 0.9016\n",
      "Epoch 970, Train Loss: 0.7628, Validation Loss: 1.1638, Validation F1: 0.9065\n",
      "Epoch 980 Saved best model. Best F1: 0.9091801335387385\n",
      "Epoch 980, Train Loss: 0.7620, Validation Loss: 1.1548, Validation F1: 0.9092\n",
      "Epoch 990, Train Loss: 0.7619, Validation Loss: 1.1617, Validation F1: 0.9038\n",
      "Epoch 1000, Train Loss: 0.7630, Validation Loss: 1.1573, Validation F1: 0.9060\n",
      "Epoch 1010, Train Loss: 0.7607, Validation Loss: 1.1552, Validation F1: 0.9075\n",
      "Epoch 1020, Train Loss: 0.7623, Validation Loss: 1.1595, Validation F1: 0.9001\n",
      "Epoch 1030, Train Loss: 0.7605, Validation Loss: 1.1708, Validation F1: 0.9053\n",
      "Epoch 1040, Train Loss: 0.7610, Validation Loss: 1.1852, Validation F1: 0.9044\n",
      "Epoch 1050, Train Loss: 0.7596, Validation Loss: 1.1989, Validation F1: 0.9015\n",
      "Epoch 1054 Saved best model. Best F1: 0.9094183213363977\n",
      "Epoch 1060, Train Loss: 0.7592, Validation Loss: 1.1980, Validation F1: 0.9081\n",
      "Epoch 1070, Train Loss: 0.7604, Validation Loss: 1.2118, Validation F1: 0.9037\n",
      "Epoch 1080, Train Loss: 0.7576, Validation Loss: 1.2068, Validation F1: 0.9048\n",
      "Epoch 1090, Train Loss: 0.7579, Validation Loss: 1.2125, Validation F1: 0.9068\n",
      "Epoch 1100, Train Loss: 0.7564, Validation Loss: 1.1994, Validation F1: 0.9065\n",
      "Epoch 1110, Train Loss: 0.7576, Validation Loss: 1.2183, Validation F1: 0.9067\n",
      "Epoch 1120, Train Loss: 0.7578, Validation Loss: 1.2029, Validation F1: 0.9063\n",
      "Epoch 1121 Saved best model. Best F1: 0.9094730402196346\n",
      "Epoch 1130, Train Loss: 0.7616, Validation Loss: 1.2125, Validation F1: 0.9067\n",
      "Epoch 1140, Train Loss: 0.7587, Validation Loss: 1.1983, Validation F1: 0.9066\n",
      "Epoch 1143 Saved best model. Best F1: 0.9095710866598\n",
      "Epoch 1150, Train Loss: 0.7585, Validation Loss: 1.2214, Validation F1: 0.9053\n",
      "Epoch 1160, Train Loss: 0.7554, Validation Loss: 1.1979, Validation F1: 0.9070\n",
      "Epoch 1170, Train Loss: 0.7559, Validation Loss: 1.2243, Validation F1: 0.9053\n",
      "Epoch 1178 Saved best model. Best F1: 0.9096217972897359\n",
      "Epoch 1180, Train Loss: 0.7542, Validation Loss: 1.2141, Validation F1: 0.9019\n",
      "Epoch 1190, Train Loss: 0.7555, Validation Loss: 1.2345, Validation F1: 0.9088\n",
      "Epoch 1200, Train Loss: 0.7564, Validation Loss: 1.2319, Validation F1: 0.9076\n",
      "Epoch 1210, Train Loss: 0.7568, Validation Loss: 1.2560, Validation F1: 0.9040\n",
      "Epoch 1220, Train Loss: 0.7583, Validation Loss: 1.2531, Validation F1: 0.9064\n",
      "Epoch 1230, Train Loss: 0.7555, Validation Loss: 1.2542, Validation F1: 0.9094\n",
      "Epoch 1240, Train Loss: 0.7534, Validation Loss: 1.2327, Validation F1: 0.9068\n",
      "Epoch 1250, Train Loss: 0.7542, Validation Loss: 1.2531, Validation F1: 0.9053\n",
      "Epoch 1260, Train Loss: 0.7582, Validation Loss: 1.2605, Validation F1: 0.9025\n",
      "Epoch 1270, Train Loss: 0.7559, Validation Loss: 1.2513, Validation F1: 0.9004\n",
      "Epoch 1280, Train Loss: 0.7547, Validation Loss: 1.2736, Validation F1: 0.9036\n",
      "Epoch 1290, Train Loss: 0.7530, Validation Loss: 1.2701, Validation F1: 0.9057\n",
      "Epoch 1300, Train Loss: 0.7533, Validation Loss: 1.2756, Validation F1: 0.9045\n",
      "Epoch 1310, Train Loss: 0.7536, Validation Loss: 1.2514, Validation F1: 0.9037\n",
      "Epoch 1320, Train Loss: 0.7527, Validation Loss: 1.2844, Validation F1: 0.9064\n",
      "Epoch 1330, Train Loss: 0.7521, Validation Loss: 1.2771, Validation F1: 0.9068\n",
      "Epoch 1340, Train Loss: 0.7525, Validation Loss: 1.2989, Validation F1: 0.9044\n",
      "Epoch 1350, Train Loss: 0.7532, Validation Loss: 1.3099, Validation F1: 0.9046\n",
      "Epoch 1360, Train Loss: 1.0314, Validation Loss: 1.4739, Validation F1: 0.8990\n",
      "Epoch 1370, Train Loss: 0.8409, Validation Loss: 1.2902, Validation F1: 0.8981\n",
      "Epoch 1380, Train Loss: 0.8053, Validation Loss: 1.2439, Validation F1: 0.9009\n",
      "Epoch 1390, Train Loss: 0.7949, Validation Loss: 1.2299, Validation F1: 0.9029\n",
      "Epoch 1400, Train Loss: 0.7833, Validation Loss: 1.2120, Validation F1: 0.9035\n",
      "Epoch 1410, Train Loss: 0.7796, Validation Loss: 1.2223, Validation F1: 0.9007\n",
      "Epoch 1420, Train Loss: 0.7738, Validation Loss: 1.2307, Validation F1: 0.9029\n",
      "Epoch 1430, Train Loss: 0.7757, Validation Loss: 1.2333, Validation F1: 0.9026\n",
      "Epoch 1440, Train Loss: 0.7710, Validation Loss: 1.2379, Validation F1: 0.9021\n",
      "Epoch 1450, Train Loss: 0.7698, Validation Loss: 1.2380, Validation F1: 0.9022\n",
      "Epoch 1460, Train Loss: 0.7683, Validation Loss: 1.2424, Validation F1: 0.8984\n",
      "Epoch 1470, Train Loss: 0.7658, Validation Loss: 1.2461, Validation F1: 0.9026\n",
      "Epoch 1480, Train Loss: 0.7659, Validation Loss: 1.2540, Validation F1: 0.9044\n",
      "Epoch 1490, Train Loss: 0.7645, Validation Loss: 1.2549, Validation F1: 0.9052\n",
      "Epoch 1500, Train Loss: 0.7636, Validation Loss: 1.2639, Validation F1: 0.9044\n",
      "Epoch 1510, Train Loss: 0.7622, Validation Loss: 1.2697, Validation F1: 0.9034\n",
      "Epoch 1520, Train Loss: 0.7620, Validation Loss: 1.2668, Validation F1: 0.9047\n",
      "Epoch 1530, Train Loss: 0.7611, Validation Loss: 1.2678, Validation F1: 0.9040\n",
      "Epoch 1540, Train Loss: 0.7622, Validation Loss: 1.2769, Validation F1: 0.9046\n",
      "Epoch 1550, Train Loss: 0.7627, Validation Loss: 1.2896, Validation F1: 0.9035\n",
      "Epoch 1560, Train Loss: 0.7607, Validation Loss: 1.2878, Validation F1: 0.9037\n",
      "Epoch 1570, Train Loss: 0.7616, Validation Loss: 1.2893, Validation F1: 0.9032\n",
      "Epoch 1580, Train Loss: 0.7599, Validation Loss: 1.2938, Validation F1: 0.9047\n",
      "Epoch 1590, Train Loss: 0.7600, Validation Loss: 1.3023, Validation F1: 0.9031\n",
      "Epoch 1600, Train Loss: 0.7593, Validation Loss: 1.2997, Validation F1: 0.9027\n",
      "Epoch 1610, Train Loss: 0.7590, Validation Loss: 1.3052, Validation F1: 0.9027\n",
      "Epoch 1620, Train Loss: 0.7585, Validation Loss: 1.3054, Validation F1: 0.9012\n",
      "Epoch 1630, Train Loss: 0.7582, Validation Loss: 1.3146, Validation F1: 0.9052\n",
      "Epoch 1640, Train Loss: 0.7604, Validation Loss: 1.3216, Validation F1: 0.9025\n",
      "Epoch 1650, Train Loss: 0.7602, Validation Loss: 1.3214, Validation F1: 0.8993\n",
      "Epoch 1660, Train Loss: 0.7585, Validation Loss: 1.3208, Validation F1: 0.9013\n",
      "Epoch 1670, Train Loss: 0.7576, Validation Loss: 1.3183, Validation F1: 0.9032\n",
      "Epoch 1680, Train Loss: 0.7595, Validation Loss: 1.3234, Validation F1: 0.8992\n",
      "Epoch 1690, Train Loss: 0.7561, Validation Loss: 1.3315, Validation F1: 0.9041\n",
      "Epoch 1700, Train Loss: 0.7564, Validation Loss: 1.3310, Validation F1: 0.9038\n",
      "Epoch 1710, Train Loss: 0.7563, Validation Loss: 1.3407, Validation F1: 0.9028\n",
      "Epoch 1720, Train Loss: 0.7576, Validation Loss: 1.3453, Validation F1: 0.8993\n",
      "Epoch 1730, Train Loss: 0.7583, Validation Loss: 1.3491, Validation F1: 0.9040\n",
      "Epoch 1740, Train Loss: 0.7566, Validation Loss: 1.3426, Validation F1: 0.9009\n",
      "Epoch 1750, Train Loss: 0.7563, Validation Loss: 1.3469, Validation F1: 0.9002\n",
      "Epoch 1760, Train Loss: 0.7561, Validation Loss: 1.3471, Validation F1: 0.9046\n",
      "Epoch 1770, Train Loss: 0.7571, Validation Loss: 1.3554, Validation F1: 0.9036\n",
      "Epoch 1780, Train Loss: 0.7569, Validation Loss: 1.3597, Validation F1: 0.9047\n",
      "Epoch 1790, Train Loss: 0.7567, Validation Loss: 1.3629, Validation F1: 0.9052\n",
      "Epoch 1800, Train Loss: 0.7565, Validation Loss: 1.3736, Validation F1: 0.9047\n",
      "Epoch 1810, Train Loss: 0.7547, Validation Loss: 1.3698, Validation F1: 0.9048\n",
      "Epoch 1820, Train Loss: 0.7550, Validation Loss: 1.3815, Validation F1: 0.9049\n",
      "Epoch 1830, Train Loss: 0.7545, Validation Loss: 1.3818, Validation F1: 0.9026\n",
      "Epoch 1840, Train Loss: 0.7558, Validation Loss: 1.3835, Validation F1: 0.9028\n",
      "Epoch 1850, Train Loss: 0.7560, Validation Loss: 1.3939, Validation F1: 0.8991\n",
      "Epoch 1860, Train Loss: 0.7555, Validation Loss: 1.3952, Validation F1: 0.9005\n",
      "Epoch 1870, Train Loss: 0.7536, Validation Loss: 1.3992, Validation F1: 0.9006\n",
      "Epoch 1880, Train Loss: 0.7545, Validation Loss: 1.4035, Validation F1: 0.9038\n",
      "Epoch 1890, Train Loss: 0.7551, Validation Loss: 1.4029, Validation F1: 0.9062\n",
      "Epoch 1900, Train Loss: 0.7534, Validation Loss: 1.4150, Validation F1: 0.9054\n",
      "Epoch 1910, Train Loss: 0.7522, Validation Loss: 1.4187, Validation F1: 0.9055\n",
      "Epoch 1920, Train Loss: 0.7532, Validation Loss: 1.4207, Validation F1: 0.9058\n",
      "Epoch 1930, Train Loss: 0.7526, Validation Loss: 1.4289, Validation F1: 0.9047\n",
      "Epoch 1940, Train Loss: 0.7521, Validation Loss: 1.4335, Validation F1: 0.9049\n",
      "Epoch 1950, Train Loss: 0.7518, Validation Loss: 1.4360, Validation F1: 0.9044\n",
      "Epoch 1960, Train Loss: 0.7519, Validation Loss: 1.4318, Validation F1: 0.9053\n",
      "Epoch 1970, Train Loss: 0.7529, Validation Loss: 1.4501, Validation F1: 0.9002\n",
      "Epoch 1980, Train Loss: 0.7532, Validation Loss: 1.4409, Validation F1: 0.9059\n",
      "Epoch 1990, Train Loss: 0.7523, Validation Loss: 1.4502, Validation F1: 0.9050\n",
      "Epoch 2000, Train Loss: 0.7561, Validation Loss: 1.4485, Validation F1: 0.9036\n",
      "Epoch 2010, Train Loss: 0.7540, Validation Loss: 1.4500, Validation F1: 0.9034\n",
      "Epoch 2020, Train Loss: 0.7525, Validation Loss: 1.4461, Validation F1: 0.9008\n",
      "Epoch 2030, Train Loss: 0.7509, Validation Loss: 1.4527, Validation F1: 0.9055\n",
      "Epoch 2040, Train Loss: 0.7514, Validation Loss: 1.4680, Validation F1: 0.9037\n",
      "Epoch 2050, Train Loss: 0.7509, Validation Loss: 1.4550, Validation F1: 0.9018\n",
      "Epoch 2060, Train Loss: 0.7509, Validation Loss: 1.4677, Validation F1: 0.9021\n",
      "Epoch 2070, Train Loss: 0.7503, Validation Loss: 1.4696, Validation F1: 0.9032\n",
      "Epoch 2080, Train Loss: 0.7498, Validation Loss: 1.4732, Validation F1: 0.9042\n",
      "Epoch 2090, Train Loss: 0.7510, Validation Loss: 1.4807, Validation F1: 0.9020\n",
      "Epoch 2100, Train Loss: 0.7531, Validation Loss: 1.4770, Validation F1: 0.9050\n",
      "Epoch 2110, Train Loss: 0.7513, Validation Loss: 1.4801, Validation F1: 0.9050\n",
      "Epoch 2120, Train Loss: 0.7510, Validation Loss: 1.4771, Validation F1: 0.9035\n",
      "Epoch 2130, Train Loss: 0.7502, Validation Loss: 1.4906, Validation F1: 0.9049\n",
      "Epoch 2140, Train Loss: 0.7493, Validation Loss: 1.4983, Validation F1: 0.9039\n",
      "Epoch 2150, Train Loss: 0.7493, Validation Loss: 1.4847, Validation F1: 0.9017\n",
      "Epoch 2160, Train Loss: 0.7497, Validation Loss: 1.4887, Validation F1: 0.9012\n",
      "Epoch 2170, Train Loss: 0.7485, Validation Loss: 1.4989, Validation F1: 0.9004\n",
      "Epoch 2180, Train Loss: 0.7487, Validation Loss: 1.5072, Validation F1: 0.9034\n",
      "Epoch 2190, Train Loss: 0.7483, Validation Loss: 1.5013, Validation F1: 0.9043\n",
      "Epoch 2200, Train Loss: 0.7485, Validation Loss: 1.5120, Validation F1: 0.9043\n",
      "Epoch 2210, Train Loss: 0.7483, Validation Loss: 1.5224, Validation F1: 0.9041\n",
      "Epoch 2220, Train Loss: 0.7483, Validation Loss: 1.5122, Validation F1: 0.9042\n",
      "Epoch 2230, Train Loss: 0.7480, Validation Loss: 1.5219, Validation F1: 0.9051\n",
      "Epoch 2240, Train Loss: 0.7476, Validation Loss: 1.5285, Validation F1: 0.9044\n",
      "Epoch 2250, Train Loss: 0.7477, Validation Loss: 1.5259, Validation F1: 0.9050\n",
      "Epoch 2260, Train Loss: 0.7482, Validation Loss: 1.5364, Validation F1: 0.9049\n",
      "Epoch 2270, Train Loss: 0.7480, Validation Loss: 1.5382, Validation F1: 0.9020\n",
      "Epoch 2280, Train Loss: 0.7479, Validation Loss: 1.5362, Validation F1: 0.8995\n",
      "Epoch 2290, Train Loss: 0.7475, Validation Loss: 1.5430, Validation F1: 0.9048\n",
      "Epoch 2300, Train Loss: 0.7477, Validation Loss: 1.5430, Validation F1: 0.9049\n",
      "Epoch 2310, Train Loss: 0.7483, Validation Loss: 1.5468, Validation F1: 0.8993\n",
      "Epoch 2320, Train Loss: 0.7478, Validation Loss: 1.5519, Validation F1: 0.8997\n",
      "Epoch 2330, Train Loss: 0.7483, Validation Loss: 1.5435, Validation F1: 0.9045\n",
      "Epoch 2340, Train Loss: 0.7475, Validation Loss: 1.5560, Validation F1: 0.9050\n",
      "Epoch 2350, Train Loss: 0.7486, Validation Loss: 1.5545, Validation F1: 0.9042\n",
      "Epoch 2360, Train Loss: 0.7469, Validation Loss: 1.5566, Validation F1: 0.9040\n",
      "Epoch 2370, Train Loss: 0.7468, Validation Loss: 1.5601, Validation F1: 0.9035\n",
      "Epoch 2380, Train Loss: 0.7467, Validation Loss: 1.5642, Validation F1: 0.9041\n",
      "Epoch 2390, Train Loss: 0.7466, Validation Loss: 1.5683, Validation F1: 0.9019\n",
      "Epoch 2400, Train Loss: 0.7466, Validation Loss: 1.5810, Validation F1: 0.9045\n",
      "Epoch 2410, Train Loss: 0.7465, Validation Loss: 1.5806, Validation F1: 0.9021\n",
      "Epoch 2420, Train Loss: 0.7464, Validation Loss: 1.5801, Validation F1: 0.9039\n",
      "Epoch 2430, Train Loss: 0.7464, Validation Loss: 1.5835, Validation F1: 0.9046\n",
      "Epoch 2440, Train Loss: 0.7461, Validation Loss: 1.5784, Validation F1: 0.9018\n",
      "Epoch 2450, Train Loss: 0.7478, Validation Loss: 1.5908, Validation F1: 0.9016\n",
      "Epoch 2460, Train Loss: 0.7467, Validation Loss: 1.5912, Validation F1: 0.9049\n",
      "Epoch 2470, Train Loss: 0.7473, Validation Loss: 1.5962, Validation F1: 0.9049\n",
      "Epoch 2480, Train Loss: 0.7472, Validation Loss: 1.5937, Validation F1: 0.9048\n",
      "Epoch 2490, Train Loss: 0.7465, Validation Loss: 1.5948, Validation F1: 0.9042\n",
      "Epoch 2500, Train Loss: 0.7463, Validation Loss: 1.6023, Validation F1: 0.9029\n",
      "Epoch 2510, Train Loss: 0.7465, Validation Loss: 1.6077, Validation F1: 0.9051\n",
      "Epoch 2520, Train Loss: 0.7459, Validation Loss: 1.6124, Validation F1: 0.9037\n",
      "Epoch 2530, Train Loss: 0.7464, Validation Loss: 1.6027, Validation F1: 0.9036\n",
      "Epoch 2540, Train Loss: 0.7453, Validation Loss: 1.6136, Validation F1: 0.9048\n",
      "Epoch 2550, Train Loss: 0.7457, Validation Loss: 1.6190, Validation F1: 0.9019\n",
      "Epoch 2560, Train Loss: 0.7463, Validation Loss: 1.6208, Validation F1: 0.9045\n",
      "Epoch 2570, Train Loss: 0.7454, Validation Loss: 1.6237, Validation F1: 0.9050\n",
      "Epoch 2580, Train Loss: 0.7451, Validation Loss: 1.6257, Validation F1: 0.9016\n",
      "Epoch 2590, Train Loss: 0.7448, Validation Loss: 1.6234, Validation F1: 0.9047\n",
      "Epoch 2600, Train Loss: 0.7450, Validation Loss: 1.6269, Validation F1: 0.9050\n",
      "Epoch 2610, Train Loss: 0.7453, Validation Loss: 1.6261, Validation F1: 0.9050\n",
      "Epoch 2620, Train Loss: 0.7454, Validation Loss: 1.6292, Validation F1: 0.9042\n",
      "Epoch 2630, Train Loss: 0.7449, Validation Loss: 1.6337, Validation F1: 0.9019\n",
      "Epoch 2640, Train Loss: 0.7451, Validation Loss: 1.6299, Validation F1: 0.9048\n",
      "Epoch 2650, Train Loss: 0.7467, Validation Loss: 1.6363, Validation F1: 0.9020\n",
      "Epoch 2660, Train Loss: 0.7454, Validation Loss: 1.6325, Validation F1: 0.9029\n",
      "Epoch 2670, Train Loss: 0.7453, Validation Loss: 1.6277, Validation F1: 0.9049\n",
      "Epoch 2680, Train Loss: 0.7454, Validation Loss: 1.6449, Validation F1: 0.9053\n",
      "Epoch 2690, Train Loss: 0.7443, Validation Loss: 1.6333, Validation F1: 0.9051\n",
      "Epoch 2700, Train Loss: 0.7449, Validation Loss: 1.6468, Validation F1: 0.9049\n",
      "Epoch 2710, Train Loss: 0.7447, Validation Loss: 1.6448, Validation F1: 0.9046\n",
      "Epoch 2720, Train Loss: 0.7442, Validation Loss: 1.6440, Validation F1: 0.9032\n",
      "Epoch 2730, Train Loss: 0.7441, Validation Loss: 1.6389, Validation F1: 0.9020\n",
      "Epoch 2740, Train Loss: 0.7444, Validation Loss: 1.6465, Validation F1: 0.8996\n",
      "Epoch 2750, Train Loss: 0.7437, Validation Loss: 1.6569, Validation F1: 0.8998\n",
      "Epoch 2760, Train Loss: 0.7436, Validation Loss: 1.6595, Validation F1: 0.9037\n",
      "Epoch 2770, Train Loss: 0.7436, Validation Loss: 1.6596, Validation F1: 0.9041\n",
      "Epoch 2780, Train Loss: 0.7438, Validation Loss: 1.6673, Validation F1: 0.8999\n",
      "Epoch 2790, Train Loss: 0.7441, Validation Loss: 1.6653, Validation F1: 0.9047\n",
      "Epoch 2800, Train Loss: 0.7442, Validation Loss: 1.6638, Validation F1: 0.9005\n",
      "Epoch 2810, Train Loss: 0.7438, Validation Loss: 1.6586, Validation F1: 0.9038\n",
      "Epoch 2820, Train Loss: 0.7435, Validation Loss: 1.6709, Validation F1: 0.9042\n",
      "Epoch 2830, Train Loss: 0.7432, Validation Loss: 1.6756, Validation F1: 0.9034\n",
      "Epoch 2840, Train Loss: 0.7432, Validation Loss: 1.6804, Validation F1: 0.9019\n",
      "Epoch 2850, Train Loss: 0.7430, Validation Loss: 1.6773, Validation F1: 0.9052\n",
      "Epoch 2860, Train Loss: 0.7433, Validation Loss: 1.6839, Validation F1: 0.9052\n",
      "Epoch 2870, Train Loss: 0.7431, Validation Loss: 1.6747, Validation F1: 0.9052\n",
      "Epoch 2880, Train Loss: 0.7432, Validation Loss: 1.6911, Validation F1: 0.9020\n",
      "Epoch 2890, Train Loss: 0.7431, Validation Loss: 1.6830, Validation F1: 0.9033\n",
      "Epoch 2900, Train Loss: 0.7432, Validation Loss: 1.6910, Validation F1: 0.9051\n",
      "Epoch 2910, Train Loss: 0.7425, Validation Loss: 1.6801, Validation F1: 0.9049\n",
      "Epoch 2920, Train Loss: 0.7431, Validation Loss: 1.6936, Validation F1: 0.9004\n",
      "Epoch 2930, Train Loss: 0.7438, Validation Loss: 1.6932, Validation F1: 0.9021\n",
      "Epoch 2940, Train Loss: 0.7479, Validation Loss: 1.6901, Validation F1: 0.9034\n",
      "Epoch 2950, Train Loss: 0.7432, Validation Loss: 1.6947, Validation F1: 0.9033\n",
      "Epoch 2960, Train Loss: 0.7436, Validation Loss: 1.6960, Validation F1: 0.9052\n",
      "Epoch 2970, Train Loss: 0.7439, Validation Loss: 1.6920, Validation F1: 0.9047\n",
      "Epoch 2980, Train Loss: 0.7432, Validation Loss: 1.6978, Validation F1: 0.9019\n",
      "Epoch 2990, Train Loss: 0.7427, Validation Loss: 1.6928, Validation F1: 0.8999\n",
      "Epoch 3000, Train Loss: 0.7421, Validation Loss: 1.6982, Validation F1: 0.8999\n",
      "Epoch 3010, Train Loss: 0.7426, Validation Loss: 1.7045, Validation F1: 0.9005\n",
      "Epoch 3020, Train Loss: 0.7425, Validation Loss: 1.7040, Validation F1: 0.9047\n",
      "Epoch 3030, Train Loss: 0.7427, Validation Loss: 1.7103, Validation F1: 0.9029\n",
      "Epoch 3040, Train Loss: 0.7428, Validation Loss: 1.7179, Validation F1: 0.9047\n",
      "Epoch 3050, Train Loss: 0.7422, Validation Loss: 1.7136, Validation F1: 0.9052\n",
      "Epoch 3060, Train Loss: 0.7420, Validation Loss: 1.7216, Validation F1: 0.9052\n",
      "Epoch 3070, Train Loss: 0.7423, Validation Loss: 1.7105, Validation F1: 0.9035\n",
      "Epoch 3080, Train Loss: 0.7419, Validation Loss: 1.7207, Validation F1: 0.9020\n",
      "Epoch 3090, Train Loss: 0.7426, Validation Loss: 1.7146, Validation F1: 0.9036\n",
      "Epoch 3100, Train Loss: 0.7418, Validation Loss: 1.7287, Validation F1: 0.9044\n",
      "Epoch 3110, Train Loss: 0.7420, Validation Loss: 1.7243, Validation F1: 0.9051\n",
      "Epoch 3120, Train Loss: 0.7419, Validation Loss: 1.7229, Validation F1: 0.9051\n",
      "Epoch 3130, Train Loss: 0.7421, Validation Loss: 1.7181, Validation F1: 0.9048\n",
      "Epoch 3140, Train Loss: 0.7417, Validation Loss: 1.7188, Validation F1: 0.9034\n",
      "Epoch 3150, Train Loss: 0.7418, Validation Loss: 1.7321, Validation F1: 0.9033\n",
      "Epoch 3160, Train Loss: 0.7422, Validation Loss: 1.7321, Validation F1: 0.9028\n",
      "Epoch 3170, Train Loss: 0.7418, Validation Loss: 1.7282, Validation F1: 0.9050\n",
      "Epoch 3180, Train Loss: 0.7422, Validation Loss: 1.7291, Validation F1: 0.9054\n",
      "Epoch 3190, Train Loss: 0.7425, Validation Loss: 1.7304, Validation F1: 0.9034\n",
      "Epoch 3200, Train Loss: 0.7440, Validation Loss: 1.7322, Validation F1: 0.9017\n",
      "Epoch 3210, Train Loss: 0.7422, Validation Loss: 1.7281, Validation F1: 0.9031\n",
      "Epoch 3220, Train Loss: 0.7417, Validation Loss: 1.7246, Validation F1: 0.9022\n",
      "Epoch 3230, Train Loss: 0.7419, Validation Loss: 1.7324, Validation F1: 0.8997\n",
      "Epoch 3240, Train Loss: 0.7418, Validation Loss: 1.7373, Validation F1: 0.8998\n",
      "Epoch 3250, Train Loss: 0.7412, Validation Loss: 1.7419, Validation F1: 0.9020\n",
      "Epoch 3260, Train Loss: 0.7411, Validation Loss: 1.7422, Validation F1: 0.9034\n",
      "Epoch 3270, Train Loss: 0.7417, Validation Loss: 1.7434, Validation F1: 0.9021\n",
      "Epoch 3280, Train Loss: 0.7415, Validation Loss: 1.7458, Validation F1: 0.8998\n",
      "Epoch 3290, Train Loss: 0.7411, Validation Loss: 1.7377, Validation F1: 0.9056\n",
      "Epoch 3300, Train Loss: 0.7411, Validation Loss: 1.7452, Validation F1: 0.9051\n",
      "Epoch 3310, Train Loss: 0.7410, Validation Loss: 1.7507, Validation F1: 0.9031\n",
      "Epoch 3320, Train Loss: 0.7412, Validation Loss: 1.7597, Validation F1: 0.9037\n",
      "Epoch 3330, Train Loss: 0.7417, Validation Loss: 1.7571, Validation F1: 0.9020\n",
      "Epoch 3340, Train Loss: 0.7409, Validation Loss: 1.7531, Validation F1: 0.9051\n",
      "Epoch 3350, Train Loss: 0.7408, Validation Loss: 1.7575, Validation F1: 0.9051\n",
      "Epoch 3360, Train Loss: 0.7411, Validation Loss: 1.7542, Validation F1: 0.9022\n",
      "Epoch 3370, Train Loss: 0.7410, Validation Loss: 1.7634, Validation F1: 0.9021\n",
      "Epoch 3380, Train Loss: 0.7408, Validation Loss: 1.7542, Validation F1: 0.9001\n",
      "Epoch 3390, Train Loss: 0.7406, Validation Loss: 1.7630, Validation F1: 0.9047\n",
      "Epoch 3400, Train Loss: 0.7407, Validation Loss: 1.7627, Validation F1: 0.9002\n",
      "Epoch 3410, Train Loss: 0.7411, Validation Loss: 1.7541, Validation F1: 0.9042\n",
      "Epoch 3420, Train Loss: 0.7410, Validation Loss: 1.7634, Validation F1: 0.9049\n",
      "Epoch 3430, Train Loss: 0.7407, Validation Loss: 1.7568, Validation F1: 0.9021\n",
      "Epoch 3440, Train Loss: 0.7408, Validation Loss: 1.7676, Validation F1: 0.9039\n",
      "Epoch 3450, Train Loss: 0.7410, Validation Loss: 1.7702, Validation F1: 0.9053\n",
      "Epoch 3460, Train Loss: 0.7412, Validation Loss: 1.7628, Validation F1: 0.9020\n",
      "Epoch 3470, Train Loss: 0.7404, Validation Loss: 1.7645, Validation F1: 0.9050\n",
      "Epoch 3480, Train Loss: 0.7404, Validation Loss: 1.7762, Validation F1: 0.9051\n",
      "Epoch 3490, Train Loss: 0.7404, Validation Loss: 1.7731, Validation F1: 0.9051\n",
      "Epoch 3500, Train Loss: 0.7404, Validation Loss: 1.7775, Validation F1: 0.9030\n",
      "Epoch 3510, Train Loss: 0.7403, Validation Loss: 1.7766, Validation F1: 0.9036\n",
      "Epoch 3520, Train Loss: 0.7401, Validation Loss: 1.7821, Validation F1: 0.9032\n",
      "Epoch 3530, Train Loss: 0.7405, Validation Loss: 1.7817, Validation F1: 0.9053\n",
      "Epoch 3540, Train Loss: 0.7403, Validation Loss: 1.7837, Validation F1: 0.9046\n",
      "Epoch 3550, Train Loss: 0.7402, Validation Loss: 1.7815, Validation F1: 0.9017\n",
      "Epoch 3560, Train Loss: 0.7402, Validation Loss: 1.7809, Validation F1: 0.9050\n",
      "Epoch 3570, Train Loss: 0.7404, Validation Loss: 1.7851, Validation F1: 0.9003\n",
      "Epoch 3580, Train Loss: 0.7400, Validation Loss: 1.7908, Validation F1: 0.9033\n",
      "Epoch 3590, Train Loss: 0.7400, Validation Loss: 1.7905, Validation F1: 0.9016\n",
      "Epoch 3600, Train Loss: 0.7400, Validation Loss: 1.7805, Validation F1: 0.9034\n",
      "Epoch 3610, Train Loss: 0.7401, Validation Loss: 1.7933, Validation F1: 0.9031\n",
      "Epoch 3620, Train Loss: 0.7398, Validation Loss: 1.7905, Validation F1: 0.9050\n",
      "Epoch 3630, Train Loss: 0.7399, Validation Loss: 1.7915, Validation F1: 0.9014\n",
      "Epoch 3640, Train Loss: 0.7397, Validation Loss: 1.7943, Validation F1: 0.9028\n",
      "Epoch 3650, Train Loss: 0.7398, Validation Loss: 1.7961, Validation F1: 0.9047\n",
      "Epoch 3660, Train Loss: 0.7408, Validation Loss: 1.7870, Validation F1: 0.9017\n",
      "Epoch 3670, Train Loss: 0.7396, Validation Loss: 1.7914, Validation F1: 0.9031\n",
      "Epoch 3680, Train Loss: 0.7398, Validation Loss: 1.8006, Validation F1: 0.9050\n",
      "Epoch 3690, Train Loss: 0.7398, Validation Loss: 1.7974, Validation F1: 0.9018\n",
      "Epoch 3700, Train Loss: 0.7401, Validation Loss: 1.7890, Validation F1: 0.9028\n",
      "Epoch 3710, Train Loss: 0.7396, Validation Loss: 1.8053, Validation F1: 0.9014\n",
      "Epoch 3720, Train Loss: 0.7398, Validation Loss: 1.7955, Validation F1: 0.9011\n",
      "Epoch 3730, Train Loss: 0.7397, Validation Loss: 1.7981, Validation F1: 0.9046\n",
      "Epoch 3740, Train Loss: 0.7398, Validation Loss: 1.8064, Validation F1: 0.9014\n",
      "Epoch 3750, Train Loss: 0.7395, Validation Loss: 1.7936, Validation F1: 0.9036\n",
      "Epoch 3760, Train Loss: 0.7396, Validation Loss: 1.8048, Validation F1: 0.9048\n",
      "Epoch 3770, Train Loss: 0.7396, Validation Loss: 1.8064, Validation F1: 0.9018\n",
      "Epoch 3780, Train Loss: 0.7396, Validation Loss: 1.8013, Validation F1: 0.9031\n",
      "Epoch 3790, Train Loss: 0.7394, Validation Loss: 1.8133, Validation F1: 0.9042\n",
      "Epoch 3800, Train Loss: 0.7394, Validation Loss: 1.8071, Validation F1: 0.9045\n",
      "Epoch 3810, Train Loss: 0.7394, Validation Loss: 1.8110, Validation F1: 0.9049\n",
      "Epoch 3820, Train Loss: 0.7395, Validation Loss: 1.7999, Validation F1: 0.9012\n",
      "Epoch 3830, Train Loss: 0.7392, Validation Loss: 1.8040, Validation F1: 0.9025\n",
      "Epoch 3840, Train Loss: 0.7393, Validation Loss: 1.8153, Validation F1: 0.9046\n",
      "Epoch 3850, Train Loss: 0.7397, Validation Loss: 1.8024, Validation F1: 0.9016\n",
      "Epoch 3860, Train Loss: 0.7395, Validation Loss: 1.8160, Validation F1: 0.9026\n",
      "Epoch 3870, Train Loss: 0.7392, Validation Loss: 1.8110, Validation F1: 0.9038\n",
      "Epoch 3880, Train Loss: 0.7396, Validation Loss: 1.8116, Validation F1: 0.9043\n",
      "Epoch 3890, Train Loss: 0.7392, Validation Loss: 1.8173, Validation F1: 0.9024\n",
      "Epoch 3900, Train Loss: 0.7392, Validation Loss: 1.8149, Validation F1: 0.9009\n",
      "Epoch 3910, Train Loss: 0.7392, Validation Loss: 1.8062, Validation F1: 0.9046\n",
      "Epoch 3920, Train Loss: 0.7395, Validation Loss: 1.8103, Validation F1: 0.9040\n",
      "Epoch 3930, Train Loss: 0.7391, Validation Loss: 1.8222, Validation F1: 0.9027\n",
      "Epoch 3940, Train Loss: 0.7391, Validation Loss: 1.8210, Validation F1: 0.9026\n",
      "Epoch 3950, Train Loss: 0.7393, Validation Loss: 1.8263, Validation F1: 0.9025\n",
      "Epoch 3960, Train Loss: 0.7390, Validation Loss: 1.8232, Validation F1: 0.9030\n",
      "Epoch 3970, Train Loss: 0.7392, Validation Loss: 1.8117, Validation F1: 0.9045\n",
      "Epoch 3980, Train Loss: 0.7392, Validation Loss: 1.8281, Validation F1: 0.9010\n",
      "Epoch 3990, Train Loss: 0.7391, Validation Loss: 1.8177, Validation F1: 0.9028\n",
      "Epoch 4000, Train Loss: 0.7392, Validation Loss: 1.8263, Validation F1: 0.9029\n",
      "Epoch 4010, Train Loss: 0.7391, Validation Loss: 1.8132, Validation F1: 0.9029\n",
      "Epoch 4020, Train Loss: 0.7390, Validation Loss: 1.8289, Validation F1: 0.9031\n",
      "Epoch 4030, Train Loss: 0.7390, Validation Loss: 1.8195, Validation F1: 0.9015\n",
      "Epoch 4040, Train Loss: 0.7403, Validation Loss: 1.8173, Validation F1: 0.9032\n",
      "Epoch 4050, Train Loss: 0.7389, Validation Loss: 1.8320, Validation F1: 0.9028\n",
      "Epoch 4060, Train Loss: 0.7388, Validation Loss: 1.8153, Validation F1: 0.9032\n",
      "Epoch 4070, Train Loss: 0.7388, Validation Loss: 1.8237, Validation F1: 0.9015\n",
      "Epoch 4080, Train Loss: 0.7390, Validation Loss: 1.8286, Validation F1: 0.9031\n",
      "Epoch 4090, Train Loss: 0.7389, Validation Loss: 1.8294, Validation F1: 0.9017\n",
      "Epoch 4100, Train Loss: 0.7387, Validation Loss: 1.8302, Validation F1: 0.9031\n",
      "Epoch 4110, Train Loss: 0.7388, Validation Loss: 1.8229, Validation F1: 0.9029\n",
      "Epoch 4120, Train Loss: 0.7389, Validation Loss: 1.8355, Validation F1: 0.9032\n",
      "Epoch 4130, Train Loss: 0.7387, Validation Loss: 1.8395, Validation F1: 0.9030\n",
      "Epoch 4140, Train Loss: 0.7391, Validation Loss: 1.8378, Validation F1: 0.9028\n",
      "Epoch 4150, Train Loss: 0.7394, Validation Loss: 1.8349, Validation F1: 0.9031\n",
      "Epoch 4160, Train Loss: 0.7387, Validation Loss: 1.8364, Validation F1: 0.9031\n",
      "Epoch 4170, Train Loss: 0.7389, Validation Loss: 1.8293, Validation F1: 0.9031\n",
      "Epoch 4180, Train Loss: 0.7386, Validation Loss: 1.8301, Validation F1: 0.9029\n",
      "Epoch 4190, Train Loss: 0.7388, Validation Loss: 1.8257, Validation F1: 0.9031\n",
      "Epoch 4200, Train Loss: 0.7391, Validation Loss: 1.8385, Validation F1: 0.9027\n",
      "Epoch 4210, Train Loss: 0.7387, Validation Loss: 1.8279, Validation F1: 0.9029\n",
      "Epoch 4220, Train Loss: 0.7388, Validation Loss: 1.8432, Validation F1: 0.9030\n",
      "Epoch 4230, Train Loss: 0.7391, Validation Loss: 1.8286, Validation F1: 0.9028\n",
      "Epoch 4240, Train Loss: 0.7387, Validation Loss: 1.8328, Validation F1: 0.9031\n",
      "Epoch 4250, Train Loss: 0.7386, Validation Loss: 1.8399, Validation F1: 0.9030\n",
      "Epoch 4260, Train Loss: 0.7386, Validation Loss: 1.8467, Validation F1: 0.9030\n",
      "Epoch 4270, Train Loss: 0.7388, Validation Loss: 1.8434, Validation F1: 0.9030\n",
      "Epoch 4280, Train Loss: 0.7386, Validation Loss: 1.8390, Validation F1: 0.9046\n",
      "Epoch 4290, Train Loss: 0.7392, Validation Loss: 1.8462, Validation F1: 0.9031\n",
      "Epoch 4300, Train Loss: 0.7388, Validation Loss: 1.8412, Validation F1: 0.9029\n",
      "Epoch 4310, Train Loss: 0.7388, Validation Loss: 1.8470, Validation F1: 0.9031\n",
      "Epoch 4320, Train Loss: 0.7388, Validation Loss: 1.8347, Validation F1: 0.9032\n",
      "Epoch 4330, Train Loss: 0.7388, Validation Loss: 1.8434, Validation F1: 0.9029\n",
      "Epoch 4340, Train Loss: 0.7391, Validation Loss: 1.8287, Validation F1: 0.9031\n",
      "Epoch 4350, Train Loss: 0.7387, Validation Loss: 1.8427, Validation F1: 0.9033\n",
      "Epoch 4360, Train Loss: 0.7386, Validation Loss: 1.8433, Validation F1: 0.9026\n",
      "Epoch 4370, Train Loss: 0.7385, Validation Loss: 1.8333, Validation F1: 0.9032\n",
      "Epoch 4380, Train Loss: 0.7385, Validation Loss: 1.8441, Validation F1: 0.9031\n",
      "Epoch 4390, Train Loss: 0.7384, Validation Loss: 1.8358, Validation F1: 0.9028\n",
      "Epoch 4400, Train Loss: 0.7384, Validation Loss: 1.8364, Validation F1: 0.9031\n",
      "Epoch 4410, Train Loss: 0.7385, Validation Loss: 1.8508, Validation F1: 0.9030\n",
      "Epoch 4420, Train Loss: 0.7385, Validation Loss: 1.8490, Validation F1: 0.9029\n",
      "Epoch 4430, Train Loss: 0.7386, Validation Loss: 1.8501, Validation F1: 0.9029\n",
      "Epoch 4440, Train Loss: 0.7385, Validation Loss: 1.8578, Validation F1: 0.9031\n",
      "Epoch 4450, Train Loss: 0.7385, Validation Loss: 1.8458, Validation F1: 0.9033\n",
      "Epoch 4460, Train Loss: 0.7384, Validation Loss: 1.8486, Validation F1: 0.9034\n",
      "Epoch 4470, Train Loss: 0.7384, Validation Loss: 1.8510, Validation F1: 0.9029\n",
      "Epoch 4480, Train Loss: 0.7386, Validation Loss: 1.8478, Validation F1: 0.9030\n",
      "Epoch 4490, Train Loss: 0.7390, Validation Loss: 1.8473, Validation F1: 0.9029\n",
      "Epoch 4500, Train Loss: 0.7387, Validation Loss: 1.8490, Validation F1: 0.9032\n",
      "Epoch 4510, Train Loss: 0.7386, Validation Loss: 1.8562, Validation F1: 0.9029\n",
      "Epoch 4520, Train Loss: 0.7402, Validation Loss: 1.8528, Validation F1: 0.9032\n",
      "Epoch 4530, Train Loss: 0.7384, Validation Loss: 1.8458, Validation F1: 0.9033\n",
      "Epoch 4540, Train Loss: 0.7387, Validation Loss: 1.8367, Validation F1: 0.9030\n",
      "Epoch 4550, Train Loss: 0.7387, Validation Loss: 1.8425, Validation F1: 0.9029\n",
      "Epoch 4560, Train Loss: 0.7387, Validation Loss: 1.8490, Validation F1: 0.9036\n",
      "Epoch 4570, Train Loss: 0.7383, Validation Loss: 1.8520, Validation F1: 0.9034\n",
      "Epoch 4580, Train Loss: 0.7389, Validation Loss: 1.8531, Validation F1: 0.9030\n",
      "Epoch 4590, Train Loss: 0.7385, Validation Loss: 1.8516, Validation F1: 0.9030\n",
      "Epoch 4600, Train Loss: 0.7384, Validation Loss: 1.8486, Validation F1: 0.9031\n",
      "Epoch 4610, Train Loss: 0.7384, Validation Loss: 1.8502, Validation F1: 0.9030\n",
      "Epoch 4620, Train Loss: 0.7384, Validation Loss: 1.8500, Validation F1: 0.9030\n",
      "Epoch 4630, Train Loss: 0.7384, Validation Loss: 1.8358, Validation F1: 0.9031\n",
      "Epoch 4640, Train Loss: 0.7382, Validation Loss: 1.8478, Validation F1: 0.9026\n",
      "Epoch 4650, Train Loss: 0.7384, Validation Loss: 1.8463, Validation F1: 0.9030\n",
      "Epoch 4660, Train Loss: 0.7385, Validation Loss: 1.8555, Validation F1: 0.9030\n",
      "Epoch 4670, Train Loss: 0.7383, Validation Loss: 1.8378, Validation F1: 0.9033\n",
      "Epoch 4680, Train Loss: 0.7383, Validation Loss: 1.8436, Validation F1: 0.9029\n",
      "Epoch 4690, Train Loss: 0.7384, Validation Loss: 1.8405, Validation F1: 0.9032\n",
      "Epoch 4700, Train Loss: 0.7385, Validation Loss: 1.8372, Validation F1: 0.9032\n",
      "Epoch 4710, Train Loss: 0.7383, Validation Loss: 1.8482, Validation F1: 0.9031\n",
      "Epoch 4720, Train Loss: 0.7387, Validation Loss: 1.8531, Validation F1: 0.9031\n",
      "Epoch 4730, Train Loss: 0.7384, Validation Loss: 1.8485, Validation F1: 0.9030\n",
      "Epoch 4740, Train Loss: 0.7385, Validation Loss: 1.8436, Validation F1: 0.9029\n",
      "Epoch 4750, Train Loss: 0.7385, Validation Loss: 1.8388, Validation F1: 0.9030\n",
      "Epoch 4760, Train Loss: 0.7385, Validation Loss: 1.8539, Validation F1: 0.9029\n",
      "Epoch 4770, Train Loss: 0.7385, Validation Loss: 1.8433, Validation F1: 0.9030\n",
      "Epoch 4780, Train Loss: 0.7385, Validation Loss: 1.8402, Validation F1: 0.9033\n",
      "Epoch 4790, Train Loss: 0.7387, Validation Loss: 1.8535, Validation F1: 0.9032\n",
      "Epoch 4800, Train Loss: 0.7383, Validation Loss: 1.8461, Validation F1: 0.9030\n",
      "Epoch 4810, Train Loss: 0.7383, Validation Loss: 1.8542, Validation F1: 0.9031\n",
      "Epoch 4820, Train Loss: 0.7382, Validation Loss: 1.8553, Validation F1: 0.9028\n",
      "Epoch 4830, Train Loss: 0.7384, Validation Loss: 1.8525, Validation F1: 0.9031\n",
      "Epoch 4840, Train Loss: 0.7383, Validation Loss: 1.8471, Validation F1: 0.9031\n",
      "Epoch 4850, Train Loss: 0.7383, Validation Loss: 1.8536, Validation F1: 0.9030\n",
      "Epoch 4860, Train Loss: 0.7384, Validation Loss: 1.8541, Validation F1: 0.9030\n",
      "Epoch 4870, Train Loss: 0.7384, Validation Loss: 1.8557, Validation F1: 0.9031\n",
      "Epoch 4880, Train Loss: 0.7386, Validation Loss: 1.8501, Validation F1: 0.9031\n",
      "Epoch 4890, Train Loss: 0.7385, Validation Loss: 1.8407, Validation F1: 0.9030\n",
      "Epoch 4900, Train Loss: 0.7384, Validation Loss: 1.8445, Validation F1: 0.9031\n",
      "Epoch 4910, Train Loss: 0.7383, Validation Loss: 1.8517, Validation F1: 0.9031\n",
      "Epoch 4920, Train Loss: 0.7385, Validation Loss: 1.8551, Validation F1: 0.9031\n",
      "Epoch 4930, Train Loss: 0.7385, Validation Loss: 1.8488, Validation F1: 0.9033\n",
      "Epoch 4940, Train Loss: 0.7385, Validation Loss: 1.8440, Validation F1: 0.9032\n",
      "Epoch 4950, Train Loss: 0.7387, Validation Loss: 1.8388, Validation F1: 0.9031\n",
      "Epoch 4960, Train Loss: 0.7383, Validation Loss: 1.8514, Validation F1: 0.9030\n",
      "Epoch 4970, Train Loss: 0.7383, Validation Loss: 1.8475, Validation F1: 0.9031\n",
      "Epoch 4980, Train Loss: 0.7387, Validation Loss: 1.8590, Validation F1: 0.9032\n",
      "Epoch 4990, Train Loss: 0.7384, Validation Loss: 1.8411, Validation F1: 0.9031\n",
      "Model training completed and saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Extract the best parameters from the grid search\n",
    "best_hidden_dim = 256  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.005  # Replace with the best learning_rate found\n",
    "best_dropout = 0.3  # Replace with the best dropout found\n",
    "epochs = 5000\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "model = EGraphSAGE(node_in_channels=G_pyg_train.num_node_features,\n",
    "                   edge_in_channels=G_pyg_train.num_edge_features,\n",
    "                   hidden_channels=best_hidden_dim,\n",
    "                   dropout=best_dropout,\n",
    "                   out_channels=num_classes).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Compute class weights for the training dataset\n",
    "labels = G_pyg_train.edge_label.cpu().numpy()\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(labels),\n",
    "                                                  y=labels)\n",
    "\n",
    "# Normalize class weights\n",
    "class_weights = th.FloatTensor(class_weights).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "scheduler = th.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "\n",
    "# Move the graph data to the device\n",
    "G_pyg_train = G_pyg_train.to(device)\n",
    "G_pyg_val = G_pyg_val.to(device)\n",
    "\n",
    "G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "# ===== Load checkpoint if exists =====\n",
    "best_f1 = 0\n",
    "start_epoch = 0\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_f1 = checkpoint['best_f1']\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "val_f1_history = []\n",
    "saved_model_epochs = []\n",
    "\n",
    "train_loss_history_path = os.path.join(saves_path, 'train_loss_history.pkl')\n",
    "val_loss_history_path = os.path.join(saves_path, 'val_loss_history.pkl')\n",
    "val_f1_history_path = os.path.join(saves_path, 'val_f1_history.pkl')\n",
    "saved_model_epochs_path = os.path.join(saves_path, 'saved_model_epochs.pkl')\n",
    "\n",
    "if os.path.exists(train_loss_history_path) and os.path.exists(val_loss_history_path) and os.path.exists(val_f1_history_path) and os.path.exists(saved_model_epochs_path):\n",
    "    with open(train_loss_history_path, 'rb') as f:\n",
    "        train_loss_history = pickle.load(f)\n",
    "    with open(val_loss_history_path, 'rb') as f:\n",
    "        val_loss_history = pickle.load(f)\n",
    "    with open(val_f1_history_path, 'rb') as f:\n",
    "        val_f1_history = pickle.load(f)\n",
    "    with open(saved_model_epochs_path, 'rb') as f:\n",
    "        saved_model_epochs = pickle.load(f)\n",
    "\n",
    "# ===== Start Training =====\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    out = model(G_pyg_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(out, G_pyg_train.edge_label)\n",
    "    train_loss = loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        out = model(G_pyg_val)\n",
    "        loss = criterion(out, G_pyg_val.edge_label)\n",
    "        val_loss = loss.item()\n",
    "\n",
    "    val_f1 = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='weighted')\n",
    "    val_f1_micro = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='micro')\n",
    "    val_f1_macro = f1_score(G_pyg_val.edge_label.cpu(), out.argmax(dim=1).cpu(), average='macro')\n",
    "\n",
    "    if epoch % 10 == 0 or val_f1 > best_f1:\n",
    "        # Save checkpoint\n",
    "        th.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_f1': best_f1\n",
    "        }, checkpoint_path)\n",
    "        with open(train_loss_history_path, 'wb') as f:\n",
    "            pickle.dump(train_loss_history, f)\n",
    "        with open(val_loss_history_path, 'wb') as f:\n",
    "            pickle.dump(val_loss_history, f)\n",
    "        with open(val_f1_history_path, 'wb') as f:\n",
    "            pickle.dump(val_f1_history, f)\n",
    "        with open(saved_model_epochs_path, 'wb') as f:\n",
    "            pickle.dump(saved_model_epochs, f)\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1  # Update the best F1 score for this fold\n",
    "        best_model_state = model.state_dict()\n",
    "        th.save(best_model_state, best_model_path)\n",
    "        print(f\"Epoch {epoch} Saved best model. Best F1:\", best_f1)\n",
    "        saved_model_epochs.append(epoch)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}')\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_f1_history.append((val_f1, val_f1_micro, val_f1_macro))\n",
    "\n",
    "# Save the trained model\n",
    "print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a82c058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_process(train_losses, val_losses, val_f1, saved_model_epochs):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Plot Train Loss\n",
    "    axs[0].plot(train_losses, label='Train Loss', color='blue')\n",
    "    axs[0].plot(val_losses, label='Validation Loss', color='red')\n",
    "    axs[0].set_ylabel('Train Loss')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    val_f1_weighted_history = []\n",
    "    val_f1_micro_history = []\n",
    "    val_f1_macro_history = []\n",
    "\n",
    "    for val_f1_weighted, val_f1_micro, val_f1_macro in val_f1:\n",
    "        val_f1_weighted_history.append(val_f1_weighted)\n",
    "        val_f1_micro_history.append(val_f1_micro)\n",
    "        val_f1_macro_history.append(val_f1_macro)\n",
    "    \n",
    "    # Plot Validation F1\n",
    "    axs[1].plot(val_f1_weighted_history, label='Validation F1 Weighted', color='green')\n",
    "    axs[1].plot(val_f1_micro_history, label='Validation F1 Micro', color='blue')\n",
    "    axs[1].plot(val_f1_macro_history, label='Validation F1 Macro', color='red')\n",
    "    average_val_f1 = np.mean(val_f1)\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Validation F1')\n",
    "    axs[1].set_title('Validation F1 Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    print(len(train_losses))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df26e7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_process(train_loss_history[:2000], val_loss_history[:2000], val_f1_history[:2000], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8368fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in G_pyg: 81474\n",
      "Number of node in G_pyg: 54154\n",
      "Shape of node in G_pyg: torch.Size([54154, 52])\n",
      "Shape of edge attr in G_pyg: torch.Size([81474, 52])\n",
      "Shape of edge label in G_pyg: torch.Size([81474])\n"
     ]
    }
   ],
   "source": [
    "G_nx_test, G_pyg_test = create_graph(test_df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/UNSW_NB15/whole_graph_combined_ports/best_model_all_downsampled.pth\n",
      "inference start\n",
      "inference done\n",
      "class_map ['Analysis' 'Backdoors' 'DoS' 'Exploits' 'Fuzzers' 'Generic' 'Normal'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "[[   50    58   246     6     0     0     0     0     0    42]\n",
      " [    2    96   222    13     2     0     0     0    10     4]\n",
      " [   15    95  1834   205    33     6     0    11    52   202]\n",
      " [  131   219  2339  2508   122     8     4    22   132  1194]\n",
      " [   32   143   249   124  2703     2    44     0   185   155]\n",
      " [   26    16   286   229    19 31474     0     8    42   222]\n",
      " [   26     5     0    41   305     0 32837     1    29    37]\n",
      " [   21     8   296    80     4     1     0  1461    13   214]\n",
      " [    0     0     0     0     2     0     1     1   220     3]\n",
      " [    4     0     1     4     0     0     0     1     0    16]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.1629    0.1244    0.1410       402\n",
      "     Backdoors     0.1500    0.2751    0.1941       349\n",
      "           DoS     0.3351    0.7477    0.4628      2453\n",
      "      Exploits     0.7813    0.3755    0.5072      6679\n",
      "       Fuzzers     0.8473    0.7432    0.7919      3637\n",
      "       Generic     0.9995    0.9738    0.9864     32322\n",
      "        Normal     0.9985    0.9867    0.9925     33281\n",
      "Reconnaissance     0.9708    0.6964    0.8110      2098\n",
      "     Shellcode     0.3221    0.9692    0.4835       227\n",
      "         Worms     0.0077    0.6154    0.0151        26\n",
      "\n",
      "      accuracy                         0.8984     81474\n",
      "     macro avg     0.5575    0.6507    0.5386     81474\n",
      "  weighted avg     0.9437    0.8984    0.9114     81474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(G_pyg_test, adversarial=False):\n",
    "\n",
    "    G_pyg_test = G_pyg_test.to(device)\n",
    "    G_pyg_test.edge_label = G_pyg_test.edge_label.to(device)\n",
    "    G_pyg_test.edge_attr = G_pyg_test.edge_attr.to(device)\n",
    "\n",
    "    best_model = EGraphSAGE(node_in_channels=G_pyg_test.num_node_features, \n",
    "                       edge_in_channels=G_pyg_test.num_edge_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=num_classes).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path))\n",
    "    best_model = best_model.to(device)\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "            \n",
    "        try:\n",
    "            out = best_model(G_pyg_test)\n",
    "            \n",
    "        except Exception as forward_error:\n",
    "            print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "    print(\"inference done\")\n",
    "\n",
    "    pred_labels = out.argmax(dim=1).cpu()\n",
    "    all_test_labels = G_pyg_test.edge_label.cpu()\n",
    "\n",
    "    if adversarial:\n",
    "\n",
    "        # Create a boolean mask where the label is NOT equal to the adversarial class\n",
    "        adversarial_mask = all_test_labels == ADVERSARIAL_CLASS_LABEL\n",
    "\n",
    "        # Print the class that the adversarial samples are classified as\n",
    "        cm_adversarial = confusion_matrix(all_test_labels[adversarial_mask], pred_labels[adversarial_mask], labels=range(len(class_map) + 1))\n",
    "        print(\"Adversarial confusion matrix:\", cm_adversarial)\n",
    "\n",
    "        # Apply the mask to both labels and predictions\n",
    "        all_test_labels = all_test_labels[~adversarial_mask]\n",
    "        pred_labels = pred_labels[~adversarial_mask]\n",
    "        \n",
    "        \n",
    "\n",
    "    print(\"class_map\", class_map)\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map)))\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4)\n",
    "    print(report)\n",
    "\n",
    "    \n",
    "eval(G_pyg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcb5e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_traffic_to_attacker(graph, ratio=0.1, num_injected_nodes=1, is_attack=False):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    # 1. Identify attacker nodes\n",
    "    attacker_edges = (edge_label != BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "    attacker_nodes = th.unique(edge_index[:, attacker_edges])\n",
    "    if attacker_nodes.numel() == 0:\n",
    "        raise ValueError(\"No attacker nodes found.\")\n",
    "\n",
    "    # 2. Sample benign edge feature pool\n",
    "    if is_attack:\n",
    "        attack_edges = (edge_label != BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "        inject_edge_attr_pool = edge_attr[attack_edges]\n",
    "    else:\n",
    "        benign_edges = (edge_label == BENIGN_CLASS_LABEL).nonzero(as_tuple=False).squeeze()\n",
    "        inject_edge_attr_pool = edge_attr[benign_edges]\n",
    "\n",
    "    # 3. Inject new nodes\n",
    "    original_num_nodes = x.size(0)\n",
    "\n",
    "    new_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "    x = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "    # 4. Inject edges from injected nodes to attacker nodes\n",
    "    num_to_inject = max(1, int(ratio * num_edges))\n",
    "    new_edges = []\n",
    "    new_attrs = []\n",
    "    new_labels = []\n",
    "\n",
    "    \n",
    "    for _ in range(num_to_inject):\n",
    "        src = random.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "\n",
    "        dst = attacker_nodes[random.randint(0, len(attacker_nodes) - 1)].item()\n",
    "\n",
    "        new_edges.append([src, dst])\n",
    "        attr = inject_edge_attr_pool[random.randint(0, len(inject_edge_attr_pool) - 1)]\n",
    "        new_attrs.append(attr)\n",
    "        new_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    # Create a new empty graph to store the injected edges\n",
    "    new_graph = Data()\n",
    "\n",
    "    # 5. Merge into graph\n",
    "    if new_edges:\n",
    "        new_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "        new_attrs = th.stack(new_attrs)\n",
    "        new_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "        new_graph.edge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "        new_graph.edge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "        new_graph.edge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "        new_graph.x = x\n",
    "\n",
    "        # new_graph.first_injected_node_idx = original_num_nodes # Store injected node indices\n",
    "\n",
    "    return new_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "632c5bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/UNSW_NB15/whole_graph_combined_ports/best_model_all_downsampled.pth\n",
      "inference start\n",
      "inference done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial confusion matrix: [[   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  18  251  483  867  468 4583  240  793  414   30    0]]\n",
      "class_map ['Analysis' 'Backdoors' 'DoS' 'Exploits' 'Fuzzers' 'Generic' 'Normal'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "[[   20     0   313    15     0     0    41    10     0     3]\n",
      " [    1     8   253     4     2    10    67     1     3     0]\n",
      " [    7    11  1813   112    48    11   364    33    17    37]\n",
      " [   53    48  3598  1446   158    73   800   274    35   194]\n",
      " [    9     1  1428    90  1505    10   493    46    35    20]\n",
      " [    9     7 17488   153    41 14424    92    42    17    49]\n",
      " [   19     4    16    41   284     1 32873    20    10    13]\n",
      " [   10     1   968    76    15    12   230   742     3    41]\n",
      " [    0     2    88     8     2    29    15    14    67     2]\n",
      " [    2     0     8     6     1     0     1     4     0     4]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.1538    0.0498    0.0752       402\n",
      "     Backdoors     0.0976    0.0229    0.0371       349\n",
      "           DoS     0.0698    0.7391    0.1276      2453\n",
      "      Exploits     0.7412    0.2165    0.3351      6679\n",
      "       Fuzzers     0.7320    0.4138    0.5287      3637\n",
      "       Generic     0.9900    0.4463    0.6152     32322\n",
      "        Normal     0.9399    0.9877    0.9632     33281\n",
      "Reconnaissance     0.6256    0.3537    0.4519      2098\n",
      "     Shellcode     0.3583    0.2952    0.3237       227\n",
      "         Worms     0.0110    0.1538    0.0206        26\n",
      "\n",
      "      accuracy                         0.6493     81474\n",
      "     macro avg     0.4719    0.3679    0.3478     81474\n",
      "  weighted avg     0.8905    0.6493    0.7055     81474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "G_pyg_test = G_pyg_test.cpu()\n",
    "injected_graph = inject_traffic_to_attacker(G_pyg_test, 0.1, num_injected_nodes=1, is_attack=True)\n",
    "eval(injected_graph, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64c37b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/UNSW_NB15/whole_graph_combined_ports/best_model_all_downsampled.pth\n",
      "inference start\n",
      "inference done\n",
      "Adversarial confusion matrix: [[   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   2   30  154  199   35   29 7625    9   63    1    0]]\n",
      "class_map ['Analysis' 'Backdoors' 'DoS' 'Exploits' 'Fuzzers' 'Generic' 'Normal'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "[[    0    59   122     0     0     0   215     6     0     0]\n",
      " [    0    74    89     7     1     0   175     1     2     0]\n",
      " [    0    90   892    68     5     6  1367    10    13     2]\n",
      " [    0   178  1474   567    35    16  4306    68    31     4]\n",
      " [    6   224   263   124   350     4  2644    16     6     0]\n",
      " [    0    13   165  2030  1043 19307  9738    15    10     1]\n",
      " [    0    22     9    39    63     0 33133     8     6     1]\n",
      " [    0     8   215     0     1     1  1869     4     0     0]\n",
      " [    0     3    19     5     1     1   131     1    65     1]\n",
      " [    0     0     0     0     0     0    24     0     0     2]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.0000    0.0000    0.0000       402\n",
      "     Backdoors     0.1103    0.2120    0.1451       349\n",
      "           DoS     0.2746    0.3636    0.3129      2453\n",
      "      Exploits     0.1996    0.0849    0.1191      6679\n",
      "       Fuzzers     0.2335    0.0962    0.1363      3637\n",
      "       Generic     0.9986    0.5973    0.7475     32322\n",
      "        Normal     0.6181    0.9956    0.7627     33281\n",
      "Reconnaissance     0.0310    0.0019    0.0036      2098\n",
      "     Shellcode     0.4887    0.2863    0.3611       227\n",
      "         Worms     0.1818    0.0769    0.1081        26\n",
      "\n",
      "      accuracy                         0.6676     81474\n",
      "     macro avg     0.3136    0.2715    0.2696     81474\n",
      "  weighted avg     0.6864    0.6676    0.6351     81474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject BENIGN Traffic to Attacker Nodes\n",
    "injected_graph = inject_traffic_to_attacker(G_pyg_test, 0.1, num_injected_nodes=1, is_attack=False)\n",
    "eval(injected_graph, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bf0e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_random_nodes(graph, ratio=0.1, num_injected_nodes=1):\n",
    "\tedge_index = graph.edge_index.clone()\n",
    "\tedge_attr = graph.edge_attr.clone()\n",
    "\tedge_label = graph.edge_label.clone()\n",
    "\tx = graph.x.clone()\n",
    "\n",
    "\tnum_edges = edge_index.size(1)\n",
    "\tfeature_dim = graph.x.size(1)\n",
    "\n",
    "\t# 1. Inject new nodes\n",
    "\toriginal_num_nodes = x.size(0)\n",
    "\tnew_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "\tx = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "\t# 2. Inject random edges\n",
    "\tnum_to_inject = max(1, int(ratio * num_edges))\n",
    "\tnew_edges = []\n",
    "\tnew_attrs = []\n",
    "\tnew_labels = []\n",
    "\n",
    "\tfor _ in range(num_to_inject):\n",
    "\t\tsrc = random.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "\t\tdst = random.randint(0, original_num_nodes - 1)  # to existing nodes\n",
    "\n",
    "\t\tnew_edges.append([src, dst])\n",
    "\t\tattr = edge_attr[random.randint(0, len(edge_attr) - 1)]  # Randomly sample edge attributes\n",
    "\t\tnew_attrs.append(attr)\n",
    "\t\tnew_labels.append(ADVERSARIAL_CLASS_LABEL)  # Assign benign class label to new edges\n",
    "\n",
    "\t# 3. Merge into graph\n",
    "\tif new_edges:\n",
    "\t\tnew_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "\t\tnew_attrs = th.stack(new_attrs)\n",
    "\t\tnew_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "\t\tedge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "\t\tedge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "\t\tedge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "\n",
    "\t# Create a new graph with the injected nodes and edges\n",
    "\tnew_graph = Data(\n",
    "\t\tedge_index=edge_index,\n",
    "\t\tedge_attr=edge_attr,\n",
    "\t\tedge_label=edge_label,\n",
    "\t\tx=x\n",
    "\t)\n",
    "\n",
    "\treturn new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abb63898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/logs/UNSW_NB15/whole_graph_combined_ports/best_model_all_downsampled.pth\n",
      "inference start\n",
      "inference done\n",
      "Adversarial confusion matrix: [[   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  17  161  299  576  176 2077 4235  238  354   14    0]]\n",
      "class_map ['Analysis' 'Backdoors' 'DoS' 'Exploits' 'Fuzzers' 'Generic' 'Normal'\n",
      " 'Reconnaissance' 'Shellcode' 'Worms']\n",
      "[[   28   139   175     3     0     0    30     0     0    27]\n",
      " [    1   166   150     8     2     3    11     2     3     3]\n",
      " [   10   668  1306   167    34     8    60    27    37   136]\n",
      " [  114   902  2050  1974   122    31   403   107    94   882]\n",
      " [   10   285   391   126  2212    19   351    22   121   100]\n",
      " [   21   104   238   182    18 31478    61    20    35   165]\n",
      " [   17    18   416    88   263    11 32425     8    14    21]\n",
      " [   16    87   436   107     3     2   176  1049    73   149]\n",
      " [    0     1    21     3     2     8    19     4   166     3]\n",
      " [    5     1     5     2     0     0     3     2     0     8]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.1261    0.0697    0.0897       402\n",
      "     Backdoors     0.0700    0.4756    0.1221       349\n",
      "           DoS     0.2517    0.5324    0.3418      2453\n",
      "      Exploits     0.7421    0.2956    0.4227      6679\n",
      "       Fuzzers     0.8328    0.6082    0.7030      3637\n",
      "       Generic     0.9974    0.9739    0.9855     32322\n",
      "        Normal     0.9668    0.9743    0.9705     33281\n",
      "Reconnaissance     0.8453    0.5000    0.6283      2098\n",
      "     Shellcode     0.3057    0.7313    0.4312       227\n",
      "         Worms     0.0054    0.3077    0.0105        26\n",
      "\n",
      "      accuracy                         0.8691     81474\n",
      "     macro avg     0.5143    0.5469    0.4705     81474\n",
      "  weighted avg     0.9197    0.8691    0.8821     81474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Random Nodes in the graph\n",
    "injected_graph = inject_random_nodes(G_pyg_test, 0.1, num_injected_nodes=1)\n",
    "eval(injected_graph, adversarial=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
