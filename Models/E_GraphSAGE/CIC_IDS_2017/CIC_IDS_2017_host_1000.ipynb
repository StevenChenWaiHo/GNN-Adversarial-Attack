{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec16c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=====Experiment=====\n",
    "'''\n",
    "DATASET_NAME = \"CIC_IDS_2017\"\n",
    "\n",
    "GRAPH_CONSTRUCTION = 'host'\n",
    "WINDOW_SIZE = 1000\n",
    "\n",
    "MULTICLASS = True\n",
    "\n",
    "LOAD_SAVED = False\n",
    "\n",
    "FIRST_RUN = not LOAD_SAVED\n",
    "\n",
    "from torch_geometric.utils import from_networkx, add_self_loops, degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "# import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import joblib\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Datasets.CIC_IDS_2017.CIC_IDS_2017_config import CIC_IDS_2017_Config as Dataset_Config\n",
    "\n",
    "EXPERIMENT_NAME = f\"strat_window_{GRAPH_CONSTRUCTION}_{WINDOW_SIZE}\"\n",
    "\n",
    "SOURCE_IP_COL_NAME = Dataset_Config.SOURCE_IP_COL_NAME\n",
    "DESTINATION_IP_COL_NAME = Dataset_Config.DESTINATION_IP_COL_NAME\n",
    "SOURCE_PORT_COL_NAME = Dataset_Config.SOURCE_PORT_COL_NAME\n",
    "DESTINATION_PORT_COL_NAME = Dataset_Config.DESTINATION_PORT_COL_NAME\n",
    "\n",
    "ATTACK_CLASS_COL_NAME = Dataset_Config.ATTACK_CLASS_COL_NAME\n",
    "\n",
    "BENIGN_CLASS_NAME = Dataset_Config.BENIGN_CLASS_NAME\n",
    "\n",
    "TIME_COLS = Dataset_Config.TIME_COL_NAMES\n",
    "\n",
    "DROP_COLS = Dataset_Config.DROP_COLS\n",
    "\n",
    "COLS_TO_NORM = Dataset_Config.COLS_TO_NORM\n",
    "CATEGORICAL_COLS = Dataset_Config.CATEGORICAL_COLS\n",
    "\n",
    "label_col = ATTACK_CLASS_COL_NAME   \n",
    "\n",
    "save_path = os.path.join(project_root, f\"Models/E_GraphSAGE/{DATASET_NAME}/saved\", EXPERIMENT_NAME)\n",
    "\n",
    "checkpoint_path = os.path.join(save_path, f\"checkpoints.pth\")\n",
    "best_model_path = os.path.join(save_path, f\"best_model.pth\")\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9ef09a-d405-43b8-971e-fe9e6a592c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    csv_file_name = \"all_raw\"\n",
    "\n",
    "    data = pd.read_csv(os.path.join(project_root, \"Datasets\", f\"{DATASET_NAME}/All/{csv_file_name}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ee112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "BENIGN                        2273097\n",
      "DoS Hulk                       231073\n",
      "PortScan                       158930\n",
      "DDoS                           128027\n",
      "DoS GoldenEye                   10293\n",
      "FTP-Patator                      7938\n",
      "SSH-Patator                      5897\n",
      "DoS slowloris                    5796\n",
      "DoS Slowhttptest                 5499\n",
      "Bot                              1966\n",
      "Web Attack - Brute Force         1507\n",
      "Web Attack - XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack - Sql Injection         21\n",
      "Heartbleed                         11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if FIRST_RUN:\n",
    "    print(data[ATTACK_CLASS_COL_NAME].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449a1af1-1d3d-4179-9628-7c2ec551ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Flow ID', 'Source IP', 'Source Port', 'Destination IP',\n",
      "       'Destination Port', 'Protocol', 'Timestamp', 'Flow Duration',\n",
      "       'Total Length of Fwd Packets', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Std', 'Flow Packets/s', 'Flow IAT Mean',\n",
      "       'Flow IAT Std', 'Flow IAT Min', 'Fwd IAT Min', 'Bwd IAT Mean',\n",
      "       'Fwd PSH Flags', 'SYN Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
      "       'Average Packet Size', 'Fwd Header Length.1', 'Subflow Fwd Packets',\n",
      "       'Subflow Fwd Bytes', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
      "       'Active Mean', 'Active Min', 'Label', 'source_file_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if FIRST_RUN:\n",
    "    data.drop(columns=DROP_COLS,inplace=True)\n",
    "    print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2c690c-86a4-49f7-aa9c-58f94529547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    if GRAPH_CONSTRUCTION == 'endpoint':\n",
    "        data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME].apply(str)\n",
    "        data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME].apply(str)\n",
    "\n",
    "        # # Combine Port and IP\n",
    "        data[SOURCE_PORT_COL_NAME] = data[SOURCE_PORT_COL_NAME].apply(str)\n",
    "        data[DESTINATION_PORT_COL_NAME] = data[DESTINATION_PORT_COL_NAME].apply(str)\n",
    "\n",
    "        data[SOURCE_IP_COL_NAME] = data[SOURCE_IP_COL_NAME] + ':' + data[SOURCE_PORT_COL_NAME]\n",
    "        data[DESTINATION_IP_COL_NAME] = data[DESTINATION_IP_COL_NAME] + ':' + data[DESTINATION_PORT_COL_NAME]\n",
    "        data.drop(columns=[SOURCE_PORT_COL_NAME,DESTINATION_PORT_COL_NAME],inplace=True)\n",
    "\n",
    "        data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "        converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "\n",
    "    elif GRAPH_CONSTRUCTION == 'host':\n",
    "        data = pd.get_dummies(data, columns = CATEGORICAL_COLS) # One Hot Encoding for categorical data\n",
    "        converted_categorical_cols = [col for col in data.columns if col.startswith(tuple(CATEGORICAL_COLS))]\n",
    "        COLS_TO_NORM = COLS_TO_NORM + [SOURCE_PORT_COL_NAME, DESTINATION_PORT_COL_NAME]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GRAPH_CONSTRUCTION value. Use 'host' or 'endpoint'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d96115-31f9-48cb-b3e6-7853d2d253cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    # Clean NaN values\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "    data.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea95177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Bwd Packet Length Min  Subflow Fwd Packets  \\\n",
      "count           2.830743e+06         2.830743e+06   \n",
      "mean            4.104958e+01         9.361160e+00   \n",
      "std             6.886260e+01         7.496728e+02   \n",
      "min             0.000000e+00         1.000000e+00   \n",
      "25%             0.000000e+00         2.000000e+00   \n",
      "50%             0.000000e+00         2.000000e+00   \n",
      "75%             7.700000e+01         5.000000e+00   \n",
      "max             2.896000e+03         2.197590e+05   \n",
      "\n",
      "       Total Length of Fwd Packets  Fwd Packet Length Mean  \\\n",
      "count                 2.830743e+06            2.830743e+06   \n",
      "mean                  5.493024e+02            5.820194e+01   \n",
      "std                   9.993589e+03            1.860912e+02   \n",
      "min                   0.000000e+00            0.000000e+00   \n",
      "25%                   1.200000e+01            6.000000e+00   \n",
      "50%                   6.200000e+01            3.400000e+01   \n",
      "75%                   1.870000e+02            5.000000e+01   \n",
      "max                   1.290000e+07            5.940857e+03   \n",
      "\n",
      "       Total Length of Fwd Packets  Fwd Packet Length Std   Fwd IAT Min  \\\n",
      "count                 2.830743e+06           2.830743e+06  2.830743e+06   \n",
      "mean                  5.493024e+02           6.891013e+01  1.021893e+06   \n",
      "std                   9.993589e+03           2.811871e+02  8.591436e+06   \n",
      "min                   0.000000e+00           0.000000e+00 -1.200000e+01   \n",
      "25%                   1.200000e+01           0.000000e+00  0.000000e+00   \n",
      "50%                   6.200000e+01           0.000000e+00  3.000000e+00   \n",
      "75%                   1.870000e+02           2.616295e+01  4.800000e+01   \n",
      "max                   1.290000e+07           7.125597e+03  1.200000e+08   \n",
      "\n",
      "       Flow IAT Min  Flow IAT Mean  Bwd Packet Length Std  ...  \\\n",
      "count  2.830743e+06   2.830743e+06           2.830743e+06  ...   \n",
      "mean   1.623796e+05   1.298449e+06           3.353257e+02  ...   \n",
      "std    2.950282e+06   4.507944e+06           8.396932e+02  ...   \n",
      "min   -1.400000e+01  -1.300000e+01           0.000000e+00  ...   \n",
      "25%    3.000000e+00   6.366667e+01           0.000000e+00  ...   \n",
      "50%    4.000000e+00   1.143884e+04           0.000000e+00  ...   \n",
      "75%    6.400000e+01   3.374266e+05           7.794054e+01  ...   \n",
      "max    1.200000e+08   1.200000e+08           8.194660e+03  ...   \n",
      "\n",
      "       Subflow Bwd Bytes  Init_Win_bytes_forward  ACK Flag Count  \\\n",
      "count       2.830743e+06            2.830743e+06    2.830743e+06   \n",
      "mean        1.616230e+04            6.989837e+03    3.158443e-01   \n",
      "std         2.263057e+06            1.433873e+04    4.648513e-01   \n",
      "min         0.000000e+00           -1.000000e+00    0.000000e+00   \n",
      "25%         0.000000e+00           -1.000000e+00    0.000000e+00   \n",
      "50%         1.230000e+02            2.510000e+02    0.000000e+00   \n",
      "75%         4.820000e+02            8.192000e+03    1.000000e+00   \n",
      "max         6.554530e+08            6.553500e+04    1.000000e+00   \n",
      "\n",
      "       Fwd PSH Flags  SYN Flag Count  Flow Packets/s  PSH Flag Count  \\\n",
      "count   2.830743e+06    2.830743e+06    2.830743e+06    2.830743e+06   \n",
      "mean    4.644646e-02    4.644646e-02    7.078247e+04    2.980705e-01   \n",
      "std     2.104500e-01    2.104500e-01    2.542966e+05    4.574107e-01   \n",
      "min     0.000000e+00    0.000000e+00   -2.000000e+06    0.000000e+00   \n",
      "25%     0.000000e+00    0.000000e+00    3.341404e+00    0.000000e+00   \n",
      "50%     0.000000e+00    0.000000e+00    1.082163e+02    0.000000e+00   \n",
      "75%     0.000000e+00    0.000000e+00    2.325581e+04    1.000000e+00   \n",
      "max     1.000000e+00    1.000000e+00    4.000000e+06    1.000000e+00   \n",
      "\n",
      "       Average Packet Size   Source Port  Destination Port  \n",
      "count         2.830743e+06  2.830743e+06      2.830743e+06  \n",
      "mean          1.919837e+02  4.112886e+04      8.071483e+03  \n",
      "std           3.318603e+02  2.229494e+04      1.828363e+04  \n",
      "min           0.000000e+00  0.000000e+00      0.000000e+00  \n",
      "25%           7.500000e+00  3.277400e+04      5.300000e+01  \n",
      "50%           7.225000e+01  5.094400e+04      8.000000e+01  \n",
      "75%           1.492639e+02  5.841300e+04      4.430000e+02  \n",
      "max           3.893333e+03  6.553500e+04      6.553500e+04  \n",
      "\n",
      "[8 rows x 26 columns]\n",
      "\n",
      "✅ All other columns processed successfully.\n",
      "Data after normalization:\n"
     ]
    }
   ],
   "source": [
    "if not LOAD_SAVED:\n",
    "    # Normalize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    print(data[COLS_TO_NORM].describe()) # Check if there's any too large value\n",
    "\n",
    "    # Check for numeric issues in the columns before normalization\n",
    "    def check_numeric_issues(df, cols_to_norm):\n",
    "        for col in cols_to_norm:\n",
    "            try:\n",
    "                # Try to coerce to numeric\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Column '{col}' failed with error: {e}\")\n",
    "                print(f\"  - Sample values: {df[col].dropna().unique()[:5]}\")\n",
    "                print(f\"  - Data type: {df[col].dtype}\")\n",
    "                continue\n",
    "\n",
    "        print(\"\\n✅ All other columns processed successfully.\")\n",
    "\n",
    "    check_numeric_issues(data, COLS_TO_NORM)\n",
    "\n",
    "    data[COLS_TO_NORM] = scaler.fit_transform(data[COLS_TO_NORM])\n",
    "\n",
    "    # Save the scaler for future use\n",
    "    scaler_path = os.path.join(save_path, \"scaler.pkl\")\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(\"Data after normalization:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4382030",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED:\n",
    "    # load scaler\n",
    "    scaler_path = os.path.join(save_path, \"scaler.pkl\")\n",
    "    scaler = joblib.load(scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c6e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "Attack label mapping: {'BENIGN': 0, 'Bot': 1, 'DDoS': 2, 'DoS GoldenEye': 3, 'DoS Hulk': 4, 'DoS Slowhttptest': 5, 'DoS slowloris': 6, 'FTP-Patator': 7, 'Heartbleed': 8, 'Infiltration': 9, 'PortScan': 10, 'SSH-Patator': 11, 'Web Attack - Brute Force': 12, 'Web Attack - Sql Injection': 13, 'Web Attack - XSS': 14}\n"
     ]
    }
   ],
   "source": [
    "if FIRST_RUN:\n",
    "    num_classes = 2\n",
    "    class_map = [0, 1]\n",
    "    if MULTICLASS:\n",
    "        le = LabelEncoder()\n",
    "        attack_labels = le.fit_transform(data[ATTACK_CLASS_COL_NAME])\n",
    "        class_map = le.classes_\n",
    "        print(class_map)\n",
    "        print(\"Attack label mapping:\", dict(zip(class_map, range(len(class_map)))))\n",
    "        data[ATTACK_CLASS_COL_NAME] = attack_labels\n",
    "        num_classes = len(class_map)\n",
    "        class_dict = {le.inverse_transform([i])[0]: i for i in range(len(le.classes_))}\n",
    "\n",
    "    class_map_path = os.path.join(save_path, \"class_map.pkl\")\n",
    "    labeller_path = os.path.join(save_path, \"labeller.pkl\")\n",
    "\n",
    "    joblib.dump(le, labeller_path)\n",
    "    joblib.dump(class_map, class_map_path)\n",
    "\n",
    "    BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "    ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75c715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_SAVED:\n",
    "    # Save the class map BENIGN_CLASS_LABEL, ADVERSARIAL_CLASS_LABEL\n",
    "    class_map_path = os.path.join(save_path, \"class_map.pkl\")\n",
    "    labeller_path = os.path.join(save_path, \"labeller.pkl\")\n",
    "\n",
    "    class_map = joblib.load(class_map_path)\n",
    "    le = joblib.load(labeller_path)\n",
    "\n",
    "    BENIGN_CLASS_LABEL = le.transform([BENIGN_CLASS_NAME])[0] if MULTICLASS else 0\n",
    "    ADVERSARIAL_CLASS_LABEL = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35f4cdd-2716-431f-af50-b34cc3d2d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: ['Bwd Packet Length Min', 'Subflow Fwd Packets', 'Total Length of Fwd Packets', 'Fwd Packet Length Mean', 'Total Length of Fwd Packets', 'Fwd Packet Length Std', 'Fwd IAT Min', 'Flow IAT Min', 'Flow IAT Mean', 'Bwd Packet Length Std', 'Subflow Fwd Bytes', 'Flow Duration', 'Flow IAT Std', 'Active Min', 'Active Mean', 'Bwd IAT Mean', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'ACK Flag Count', 'Fwd PSH Flags', 'SYN Flag Count', 'Flow Packets/s', 'PSH Flag Count', 'Average Packet Size', 'Source Port', 'Destination Port', 'Protocol_0', 'Protocol_6', 'Protocol_17']\n",
      "Number of Features: 29\n",
      "                                   Flow ID         Source IP  Source Port  \\\n",
      "0  192.168.10.5-104.16.207.165-54865-443-6  104.16.207.165_0    -1.824892   \n",
      "1    192.168.10.5-104.16.28.216-55054-80-6   104.16.28.216_0    -1.841174   \n",
      "2    192.168.10.5-104.16.28.216-55055-80-6   104.16.28.216_0    -1.841174   \n",
      "3  192.168.10.16-104.17.241.25-46236-443-6   104.17.241.25_0    -1.824892   \n",
      "4  192.168.10.5-104.19.196.102-54863-443-6  104.19.196.102_0    -1.824892   \n",
      "\n",
      "    Destination IP  Destination Port      Timestamp  Flow Duration  \\\n",
      "0   192.168.10.5_0          2.559312  7/7/2017 3:30      -0.439347   \n",
      "1   192.168.10.5_0          2.569649  7/7/2017 3:30      -0.439344   \n",
      "2   192.168.10.5_0          2.569704  7/7/2017 3:30      -0.439345   \n",
      "3  192.168.10.16_0          2.087360  7/7/2017 3:30      -0.439346   \n",
      "4   192.168.10.5_0          2.559203  7/7/2017 3:30      -0.439347   \n",
      "\n",
      "   Total Length of Fwd Packets  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
      "0                    -0.053765               -0.280518              -0.245069   \n",
      "1                    -0.054365               -0.280518              -0.245069   \n",
      "2                    -0.054365               -0.280518              -0.245069   \n",
      "3                    -0.054365               -0.280518              -0.245069   \n",
      "4                    -0.053765               -0.280518              -0.245069   \n",
      "\n",
      "   ...  Subflow Bwd Bytes  Init_Win_bytes_forward  Active Mean  Active Min  \\\n",
      "0  ...          -0.007142               -0.485178    -0.125734   -0.101016   \n",
      "1  ...          -0.007139               -0.485457    -0.125734   -0.101016   \n",
      "2  ...          -0.007139               -0.485457    -0.125734   -0.101016   \n",
      "3  ...          -0.007139               -0.485318    -0.125734   -0.101016   \n",
      "4  ...          -0.007142               -0.485248    -0.125734   -0.101016   \n",
      "\n",
      "   Label  source_file_id  Protocol_0  Protocol_6  Protocol_17  \\\n",
      "0      0               0       False        True        False   \n",
      "1      0               0       False        True        False   \n",
      "2      0               0       False        True        False   \n",
      "3      0               0       False        True        False   \n",
      "4      0               0       False        True        False   \n",
      "\n",
      "                                                   h  \n",
      "0  [-0.5961085535841419, -0.009819165539632076, -...  \n",
      "1  [-0.5089785174086571, -0.01115308106469734, -0...  \n",
      "2  [-0.5089785174086571, -0.01115308106469734, -0...  \n",
      "3  [-0.5089785174086571, -0.01115308106469734, -0...  \n",
      "4  [-0.5961085535841419, -0.009819165539632076, -...  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "if not LOAD_SAVED:\n",
    "    # Maintain the order of the rows in the original dataframe\n",
    "    feature_cols = COLS_TO_NORM + converted_categorical_cols\n",
    "\n",
    "    print('Feature Columns:', feature_cols)\n",
    "    num_features = len(feature_cols)\n",
    "    print('Number of Features:', num_features)\n",
    "\n",
    "    data['h'] = data[ feature_cols ].values.tolist()\n",
    "    print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df):\n",
    "\n",
    "    G_nx = nx.from_pandas_edgelist(df, SOURCE_IP_COL_NAME, DESTINATION_IP_COL_NAME, ['h', label_col], create_using=nx.MultiDiGraph())\n",
    "    \n",
    "    G_pyg = from_networkx(G_nx)\n",
    "\n",
    "    num_nodes = G_pyg.num_nodes\n",
    "    num_edges = G_pyg.num_edges\n",
    "\n",
    "    assert num_edges == G_nx.number_of_edges(), \"Number of edges in PyG graph does not match NetworkX graph.\"\n",
    "\n",
    "    G_pyg.x = th.ones(num_nodes, len(df['h'].iloc[0])) \n",
    "\n",
    "    edge_attr_list = []\n",
    "    edge_label_list = []\n",
    "\n",
    "    for u, v, key, data in G_nx.edges(keys=True, data=True):\n",
    "        edge_attr_list.append(data['h']) \n",
    "        edge_label_list.append(data[label_col]) \n",
    "\n",
    "    G_pyg.edge_attr = th.tensor(edge_attr_list, dtype=th.float32)\n",
    "    G_pyg.edge_label = th.tensor(edge_label_list, dtype=th.long)\n",
    "\n",
    "    return G_pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e650028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class StratifiedGraphDataset:\n",
    "\n",
    "    def __init__(self, X, y, eval=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.total_count = len(self.y)\n",
    "\n",
    "        # Compute class weights\n",
    "        labels = []\n",
    "\n",
    "        for graph in self.X:\n",
    "            labels.append(graph.edge_label.tolist())\n",
    "\n",
    "        labels = np.concatenate(labels)\n",
    "\n",
    "        self.class_counts = Counter(labels)\n",
    "\n",
    "        # Compute the class weights\n",
    "        if not eval:\n",
    "            self.class_weights = class_weight.compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.unique(labels),\n",
    "                y=labels\n",
    "            )\n",
    "\n",
    "    def k_fold_split(self, k: int = 5, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        cv = MultilabelStratifiedShuffleSplit(test_size=test_ratio, random_state=random_state, n_splits=k)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        y_binary = mlb.fit_transform(self.y)\n",
    "\n",
    "        return cv.split(np.zeros(len(self.X)), y_binary)\n",
    "\n",
    "    def graph_train_test_split(self, test_ratio: float = 0.15, random_state: int = 42):\n",
    "        train_idx, test_idx = next(self.k_fold_split(k = 1, test_ratio = test_ratio, random_state = random_state))\n",
    "        \n",
    "        X_train = [self.X[i] for i in train_idx]\n",
    "        X_test = [self.X[i] for i in test_idx]\n",
    "\n",
    "        y_train = [self.y[i] for i in train_idx]\n",
    "        y_test = [self.y[i] for i in test_idx]\n",
    "\n",
    "        return StratifiedGraphDataset(X_train, y_train), StratifiedGraphDataset(X_test, y_test)\n",
    "    \n",
    "    def print_class_distribution_and_weights(self):\n",
    "        # Use the label encoder to inverse transform the class labels\n",
    "        class_counts_named = {cls: count for cls, count in self.class_counts.items()}\n",
    "        class_weights_named = {cls: weight for cls, weight in enumerate(self.class_weights)}\n",
    "        print(\"Class Counts and Weights:\")\n",
    "        for cls_label in class_counts_named.keys():\n",
    "            if not eval:\n",
    "                count = class_counts_named[cls_label]\n",
    "                weight = class_weights_named[cls_label]\n",
    "                print(f\"{cls_label:<2}  {le.inverse_transform([cls_label])[0]:<15}: Count = {count:<10}, Weight = {weight:<10.4f}\")\n",
    "            else:   \n",
    "                count = class_counts_named[cls_label]\n",
    "                print(f\"{cls_label:<2}  {le.inverse_transform([cls_label])[0]:<15}: Count = {count:<10}\")\n",
    "    def __len__(self):\n",
    "        return self.total_count\n",
    "\n",
    "    def __iter__(self):\n",
    "        for g in self.X:\n",
    "            yield g\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.X[idx], self.y[idx]\n",
    "        elif isinstance(idx, slice):\n",
    "            return [self.X[i] for i in range(len(self.X))][idx], [self.y[i] for i in range(len(self.y))][idx]\n",
    "        else:\n",
    "            raise TypeError(\"Index must be an integer or a slice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8988bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    def generate_graph_datasets(\n",
    "        df: pd.DataFrame, \n",
    "        window_size: int = WINDOW_SIZE, \n",
    "        feature_cols=feature_cols,\n",
    "        ordering_cols= TIME_COLS, \n",
    "        label_col=label_col,\n",
    "        build_graph_func=create_graph,\n",
    "        ):\n",
    "\n",
    "        print(\"All Columns: \", df.columns)\n",
    "        print(\"Ordering Columns: \", ordering_cols)\n",
    "        assert all(col in df.columns for col in ordering_cols), \"All timestamp columns are required\"\n",
    "        assert label_col in df.columns, \"Edge label column 'label' is required\"\n",
    "        \n",
    "        df = df.sort_values(ordering_cols).reset_index(drop=True)\n",
    "        window_size = int(window_size)\n",
    "        \n",
    "        df.drop(columns=set(df.columns) - set(feature_cols) - set(label_col))\n",
    "\n",
    "        print(\"Final Columns: \", df.columns)\n",
    "        \n",
    "        label_counts_list = []\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        progress_bar = tqdm(range(0, len(df), window_size), desc=f\"Generating graphs\")\n",
    "        for start in progress_bar:\n",
    "            window_df = df[start: min(start + window_size, len(df))]\n",
    "            contains_label = window_df[label_col].unique()\n",
    "\n",
    "            G_pyg = build_graph_func(window_df)\n",
    "\n",
    "            label_counts = window_df[label_col].value_counts()\n",
    "\n",
    "            label_counts_list.append(label_counts)\n",
    "            X.append(G_pyg)\n",
    "            y.append(contains_label.tolist())\n",
    "\n",
    "        return StratifiedGraphDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491e7421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Columns:  Index(['Flow ID', 'Source IP', 'Source Port', 'Destination IP',\n",
      "       'Destination Port', 'Timestamp', 'Flow Duration',\n",
      "       'Total Length of Fwd Packets', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Std', 'Flow Packets/s', 'Flow IAT Mean',\n",
      "       'Flow IAT Std', 'Flow IAT Min', 'Fwd IAT Min', 'Bwd IAT Mean',\n",
      "       'Fwd PSH Flags', 'SYN Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
      "       'Average Packet Size', 'Fwd Header Length.1', 'Subflow Fwd Packets',\n",
      "       'Subflow Fwd Bytes', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
      "       'Active Mean', 'Active Min', 'Label', 'source_file_id', 'Protocol_0',\n",
      "       'Protocol_6', 'Protocol_17', 'h'],\n",
      "      dtype='object')\n",
      "Ordering Columns:  ['Timestamp']\n",
      "Final Columns:  Index(['Flow ID', 'Source IP', 'Source Port', 'Destination IP',\n",
      "       'Destination Port', 'Timestamp', 'Flow Duration',\n",
      "       'Total Length of Fwd Packets', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Std', 'Flow Packets/s', 'Flow IAT Mean',\n",
      "       'Flow IAT Std', 'Flow IAT Min', 'Fwd IAT Min', 'Bwd IAT Mean',\n",
      "       'Fwd PSH Flags', 'SYN Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
      "       'Average Packet Size', 'Fwd Header Length.1', 'Subflow Fwd Packets',\n",
      "       'Subflow Fwd Bytes', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
      "       'Active Mean', 'Active Min', 'Label', 'source_file_id', 'Protocol_0',\n",
      "       'Protocol_6', 'Protocol_17', 'h'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating graphs: 100%|██████████| 2831/2831 [01:29<00:00, 31.65it/s]\n"
     ]
    }
   ],
   "source": [
    "test_graph_dataset_path = os.path.join(save_path, \"test_graph_dataset.pth\")\n",
    "if FIRST_RUN:\n",
    "    graph_dataset = generate_graph_datasets(data)\n",
    "    full_train_graph_dataset, test_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)\n",
    "    th.save(test_graph_dataset, test_graph_dataset_path)\n",
    "\n",
    "if LOAD_SAVED:\n",
    "    # Save or Load test_graph_dataset\n",
    "    if os.path.exists(test_graph_dataset_path):  \n",
    "        test_graph_dataset = th.load(test_graph_dataset_path, weights_only=False)\n",
    "    else:       \n",
    "        raise FileNotFoundError(f\"File {test_graph_dataset_path} does not exist. Please run the code to generate the dataset first.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365fd330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distrubution: Label\n",
      "0     2273097\n",
      "4      231073\n",
      "10     158930\n",
      "2      128027\n",
      "3       10293\n",
      "7        7938\n",
      "11       5897\n",
      "6        5796\n",
      "5        5499\n",
      "1        1966\n",
      "12       1507\n",
      "14        652\n",
      "9          36\n",
      "13         21\n",
      "8          11\n",
      "Name: count, dtype: int64\n",
      "Number of graphs after downsampling: 2831\n",
      "Class Counts and Weights:\n",
      "0   BENIGN         : Count = 2273097   \n",
      "7   FTP-Patator    : Count = 7938      \n",
      "11  SSH-Patator    : Count = 5897      \n",
      "6   DoS slowloris  : Count = 5796      \n",
      "5   DoS Slowhttptest: Count = 5499      \n",
      "4   DoS Hulk       : Count = 231073    \n",
      "3   DoS GoldenEye  : Count = 10293     \n",
      "8   Heartbleed     : Count = 11        \n",
      "12  Web Attack - Brute Force: Count = 1507      \n",
      "14  Web Attack - XSS: Count = 652       \n",
      "13  Web Attack - Sql Injection: Count = 21        \n",
      "9   Infiltration   : Count = 36        \n",
      "1   Bot            : Count = 1966      \n",
      "10  PortScan       : Count = 158930    \n",
      "2   DDoS           : Count = 128027    \n",
      "Number of training graphs: 2409\n",
      "Class Counts and Weights:\n",
      "0   BENIGN         : Count = 1935029   \n",
      "7   FTP-Patator    : Count = 6796      \n",
      "11  SSH-Patator    : Count = 4875      \n",
      "6   DoS slowloris  : Count = 4930      \n",
      "5   DoS Slowhttptest: Count = 4491      \n",
      "4   DoS Hulk       : Count = 197840    \n",
      "3   DoS GoldenEye  : Count = 8209      \n",
      "8   Heartbleed     : Count = 9         \n",
      "14  Web Attack - XSS: Count = 580       \n",
      "13  Web Attack - Sql Injection: Count = 18        \n",
      "9   Infiltration   : Count = 31        \n",
      "12  Web Attack - Brute Force: Count = 1338      \n",
      "1   Bot            : Count = 1708      \n",
      "10  PortScan       : Count = 134840    \n",
      "2   DDoS           : Count = 108049    \n",
      "Number of testing graphs: 422\n",
      "Class Counts and Weights:\n",
      "0   BENIGN         : Count = 338068    \n",
      "7   FTP-Patator    : Count = 1142      \n",
      "11  SSH-Patator    : Count = 1022      \n",
      "6   DoS slowloris  : Count = 866       \n",
      "5   DoS Slowhttptest: Count = 1008      \n",
      "4   DoS Hulk       : Count = 33233     \n",
      "3   DoS GoldenEye  : Count = 2084      \n",
      "8   Heartbleed     : Count = 2         \n",
      "12  Web Attack - Brute Force: Count = 169       \n",
      "14  Web Attack - XSS: Count = 72        \n",
      "13  Web Attack - Sql Injection: Count = 3         \n",
      "9   Infiltration   : Count = 5         \n",
      "1   Bot            : Count = 258       \n",
      "10  PortScan       : Count = 24090     \n",
      "2   DDoS           : Count = 19978     \n"
     ]
    }
   ],
   "source": [
    "if FIRST_RUN:\n",
    "    print(\"Class Distrubution:\", data[label_col].value_counts())\n",
    "\n",
    "    print(\"Number of graphs after downsampling:\", len(graph_dataset))\n",
    "    graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "    print(\"Number of training graphs:\", len(full_train_graph_dataset))\n",
    "    full_train_graph_dataset.print_class_distribution_and_weights()\n",
    "\n",
    "    print(\"Number of testing graphs:\", len(test_graph_dataset))\n",
    "    test_graph_dataset.print_class_distribution_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41795339-6036-468f-9b9d-2bb68d78ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayerPyG(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_dim, out_channels, activation=F.relu):\n",
    "        super().__init__(aggr='mean')  # mean aggregation\n",
    "        self.W_msg = nn.Linear(in_channels + edge_dim, out_channels)\n",
    "        self.W_apply = nn.Linear(in_channels + out_channels, out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        # edge_attr: [num_edges, edge_dim]\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_j: features of source nodes (neighbours)\n",
    "        msg_input = th.cat([x_j, edge_attr], dim=1)\n",
    "        return self.W_msg(msg_input)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out: [num_nodes, out_channels]\n",
    "        combined = th.cat([x, aggr_out], dim=1)\n",
    "        out = self.W_apply(combined)\n",
    "        return self.activation(out)\n",
    "    \n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.lin = nn.Linear(in_channels * 2, out_channels)\n",
    "\n",
    "    def forward(self, data, z):\n",
    "        row, col = data.edge_index\n",
    "        # Concatenate the features of source and target nodes for each edge\n",
    "        edge_feat = th.cat([z[row], z[col]], dim=1)\n",
    "        return self.lin(edge_feat)\n",
    "\n",
    "class EGraphSAGE(nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super(EGraphSAGE, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGELayerPyG(node_in_channels, edge_in_channels, hidden_channels)\n",
    "        self.conv2 = SAGELayerPyG(hidden_channels, edge_in_channels, hidden_channels)\n",
    "        self.mlp_predictor = MLPPredictor(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return self.mlp_predictor(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca25fef-29d9-40cf-8910-16b24d530693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cccdc850-b98d-4836-b82b-67aa4b9e1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89157faf-e24b-49d6-9c90-6f71dae515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385d37f0-713b-4abc-8d7a-3e768ae9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00a2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    def grid_search(graph_dataset, patience, max_epochs, learning_rates, hidden_dims, drop_outs, folds=3):\n",
    "        global num_features\n",
    "        \n",
    "        best_params = {}\n",
    "        best_f1 = 0\n",
    "        params_results = {}\n",
    "\n",
    "        # Precompute the train and validation graphs for all folds\n",
    "        folds_list = []\n",
    "        for i in range(folds):\n",
    "            train_graph_dataset, val_graph_dataset = graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=i)\n",
    "            folds_list.append((train_graph_dataset, val_graph_dataset))\n",
    "\n",
    "        for lr in learning_rates:\n",
    "            for hidden_dim in hidden_dims:\n",
    "                for drop_out in drop_outs:\n",
    "                    print(f\"Testing with learning rate: {lr}, hidden_dim: {hidden_dim}, drop_out: {drop_out}\")\n",
    "                    fold_f1_scores = []\n",
    "\n",
    "                    for fold, (train_graph_dataset, val_graph_dataset) in enumerate(folds_list):\n",
    "                        print(f\"Fold {fold + 1}\")\n",
    "\n",
    "                        model = EGraphSAGE(node_in_channels=num_features,\n",
    "                                        edge_in_channels=num_features,\n",
    "                                        hidden_channels=hidden_dim,\n",
    "                                        dropout = drop_out,\n",
    "                                        out_channels=num_classes).to(device)\n",
    "\n",
    "                        model.apply(init_weights)\n",
    "\n",
    "                        # Normalize to stabilize training\n",
    "                        class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "                        print(\"Class weights:\", class_weights)\n",
    "\n",
    "                        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                        optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "                        scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                            optimizer,\n",
    "                            mode='min',\n",
    "                            factor=0.6,\n",
    "                            patience=5,\n",
    "                            min_lr=1e-6,\n",
    "                        )\n",
    "\n",
    "                        best_epoch_f1 = 0  # Track the best F1 score for this fold\n",
    "                        best_val_loss = float('inf')  # Track the best val_loss for this fold\n",
    "                        patience_counter = 0\n",
    "\n",
    "                        for epoch in range(max_epochs):\n",
    "                            try:\n",
    "                                train_loss = 0\n",
    "                                val_loss = 0\n",
    "                                num_train_graphs = len(train_graph_dataset)\n",
    "                                num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "                                model.train()\n",
    "                                optimizer.zero_grad()\n",
    "                                for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "                                    G_pyg_train = G_pyg_train.to(device)\n",
    "                                    G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                                    G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "                                    \n",
    "                                    out = model(G_pyg_train)\n",
    "                                    loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                                    train_loss += loss.item()\n",
    "\n",
    "                                    loss.backward()\n",
    "\n",
    "                                optimizer.step()\n",
    "                                \n",
    "\n",
    "                                test_label_list = []\n",
    "                                pred_label_list = []\n",
    "\n",
    "                                model.eval()\n",
    "                                with th.no_grad():\n",
    "                                    for G_pyg_val in tqdm(val_graph_dataset, desc=\"Validation\", leave=False):\n",
    "\n",
    "                                        G_pyg_val = G_pyg_val.to(device)\n",
    "                                        G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                                        G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                                        out = model(G_pyg_val)\n",
    "                                        loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                                        val_loss += loss.item()\n",
    "\n",
    "                                        test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                                        pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "                                test_label = th.cat(test_label_list)\n",
    "                                pred_label = th.cat(pred_label_list)\n",
    "\n",
    "                                val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "                                val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "                                val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "                                # Schedule step\n",
    "                                scheduler.step(val_loss)\n",
    "\n",
    "                                if val_f1 > best_epoch_f1:\n",
    "                                    best_epoch_f1 = val_f1\n",
    "                                    print(f\"Epoch {epoch}/{max_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                                    f\"Val F1 (weighted): {val_f1:.4f}, Micro: {val_f1_micro:.4f}, Macro: {val_f1_macro:.4f} \"\n",
    "                                    f\"(Best Weighted F1 so far: {best_epoch_f1:.4f})\")\n",
    "\n",
    "                                # Early stopping condition\n",
    "                                if val_loss < best_val_loss:\n",
    "                                    best_val_loss = val_loss\n",
    "                                    patience_counter = 0\n",
    "                                else:\n",
    "                                    patience_counter += 1\n",
    "\n",
    "                                if patience_counter >= patience:\n",
    "                                    print(f\"\\n🛑 Early stopping triggered at epoch {epoch}.\")\n",
    "                                    break\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"An error occurred at epoch {epoch}: {str(e)}\")\n",
    "                                break\n",
    "\n",
    "                        fold_f1_scores.append(best_epoch_f1)  # Append the best F1 score for this fold\n",
    "                    \n",
    "                    avg_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "                    params_results[(drop_out, lr, hidden_dim)] = {'folds': fold_f1_scores, 'avg_f1': avg_f1}\n",
    "                    print(f\"Average F1 Score for drop_out {drop_out}, learning rate {lr}, hidden_dim {hidden_dim}: {avg_f1:.4f}\")\n",
    "\n",
    "                    if avg_f1 > best_f1:\n",
    "                        best_f1 = avg_f1\n",
    "                        best_params = {'learning_rate': lr, 'hidden_dim': hidden_dim, 'drop_out': drop_out}\n",
    "\n",
    "        print(f\"Best Parameters: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "        print(\"All results:\", params_results)\n",
    "\n",
    "    # grid_search(\n",
    "    #     full_train_graph_dataset, \n",
    "    #     patience=10,\n",
    "    #     max_epochs=200,\n",
    "    #     learning_rates=[0.001, 0.005, 0.01, 0.05], \n",
    "    #     hidden_dims=[128, 256, 512], \n",
    "    #     drop_outs=[0.2, 0.3, 0.4],\n",
    "    #     folds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b158d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIRST_RUN:\n",
    "    train_graph_dataset, val_graph_dataset = full_train_graph_dataset.graph_train_test_split(test_ratio=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ec4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint():\n",
    "    global epoch, model, optimizer, scheduler, train_loss_history, val_loss_history, val_f1_history, saved_model_epochs, best_f1, patience_counter, best_val_loss, train_ended, max_epochs, patience\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss_history': train_loss_history,\n",
    "        'val_loss_history': val_loss_history,\n",
    "        'val_f1_history': val_f1_history,\n",
    "        'saved_model_epochs': saved_model_epochs,\n",
    "        'best_f1': best_f1,\n",
    "        # 'patience_counter': patience_counter,\n",
    "        # 'best_val_loss': best_val_loss,\n",
    "        'train_ended': train_ended,\n",
    "        'max_epochs': max_epochs,\n",
    "        # 'patience': patience\n",
    "    }\n",
    "    \n",
    "    th.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f52b2fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train graphs:  2044\n",
      "Class weights: tensor([8.3150e-02, 9.3322e+01, 1.4909e+00, 2.0203e+01, 8.1074e-01, 3.3337e+01,\n",
      "        3.1329e+01, 2.3491e+01, 1.7031e+04, 5.4500e+03, 1.1611e+00, 3.2180e+01,\n",
      "        1.2308e+02, 7.5694e+03, 2.6405e+02], device='cuda:0')\n",
      "Resumed training from epoch 341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 39/2044 [00:00<00:05, 389.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341, Train Loss: 0.0467, Validation Loss: 0.0556, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342, Train Loss: 0.0446, Validation Loss: 0.0556, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343, Train Loss: 0.0450, Validation Loss: 0.0556, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344, Train Loss: 0.0482, Validation Loss: 0.0556, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345, Train Loss: 0.0463, Validation Loss: 0.0556, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346, Train Loss: 0.0435, Validation Loss: 0.0556, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347, Train Loss: 0.0441, Validation Loss: 0.0556, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348, Train Loss: 0.0452, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349, Train Loss: 0.0442, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, Train Loss: 0.0472, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351, Train Loss: 0.0476, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352, Train Loss: 0.0425, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353, Train Loss: 0.0461, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354, Train Loss: 0.0427, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355, Train Loss: 0.0460, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356, Train Loss: 0.0439, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357, Train Loss: 0.0455, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358, Train Loss: 0.0442, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359, Train Loss: 0.0474, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360, Train Loss: 0.0458, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361, Train Loss: 0.0467, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362, Train Loss: 0.0442, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363, Train Loss: 0.0446, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364, Train Loss: 0.0451, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365, Train Loss: 0.0449, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366, Train Loss: 0.0469, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367, Train Loss: 0.0447, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368, Train Loss: 0.0434, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369, Train Loss: 0.0472, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370, Train Loss: 0.0452, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371, Train Loss: 0.0430, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372, Train Loss: 0.0441, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373, Train Loss: 0.0455, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374, Train Loss: 0.0467, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375, Train Loss: 0.0457, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376, Train Loss: 0.0444, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377, Train Loss: 0.0455, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378, Train Loss: 0.0486, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379, Train Loss: 0.0464, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380, Train Loss: 0.0442, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381, Train Loss: 0.0455, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382, Train Loss: 0.0449, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383, Train Loss: 0.0438, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384, Train Loss: 0.0456, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385, Train Loss: 0.0456, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386, Train Loss: 0.0457, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387, Train Loss: 0.0460, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388, Train Loss: 0.0448, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389, Train Loss: 0.0433, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390, Train Loss: 0.0454, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391, Train Loss: 0.0445, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392, Train Loss: 0.0450, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393, Train Loss: 0.0486, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394, Train Loss: 0.0465, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395, Train Loss: 0.0451, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396, Train Loss: 0.0455, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397, Train Loss: 0.0438, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398, Train Loss: 0.0448, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399, Train Loss: 0.0443, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, Train Loss: 0.0468, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401, Train Loss: 0.0451, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402, Train Loss: 0.0444, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403, Train Loss: 0.0440, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404, Train Loss: 0.0459, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405, Train Loss: 0.0449, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406, Train Loss: 0.0460, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407, Train Loss: 0.0456, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408, Train Loss: 0.0446, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409, Train Loss: 0.0478, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410, Train Loss: 0.0458, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411, Train Loss: 0.0484, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412, Train Loss: 0.0448, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413, Train Loss: 0.0425, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414, Train Loss: 0.0441, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415, Train Loss: 0.0433, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416, Train Loss: 0.0461, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417, Train Loss: 0.0478, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418, Train Loss: 0.0446, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419, Train Loss: 0.0446, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420, Train Loss: 0.0444, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421, Train Loss: 0.0447, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422, Train Loss: 0.0440, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423, Train Loss: 0.0438, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424, Train Loss: 0.0490, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425, Train Loss: 0.0456, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426, Train Loss: 0.0448, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427, Train Loss: 0.0460, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428, Train Loss: 0.0472, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429, Train Loss: 0.0445, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430, Train Loss: 0.0458, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431, Train Loss: 0.0493, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432, Train Loss: 0.0474, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433, Train Loss: 0.0436, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434, Train Loss: 0.0464, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435, Train Loss: 0.0455, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436, Train Loss: 0.0444, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437, Train Loss: 0.0442, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438, Train Loss: 0.0450, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439, Train Loss: 0.0441, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440, Train Loss: 0.0469, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441, Train Loss: 0.0465, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442, Train Loss: 0.0450, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443, Train Loss: 0.0474, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444, Train Loss: 0.0492, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445, Train Loss: 0.0458, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446, Train Loss: 0.0457, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447, Train Loss: 0.0456, Validation Loss: 0.0555, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448, Train Loss: 0.0449, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449, Train Loss: 0.0443, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450, Train Loss: 0.0460, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451, Train Loss: 0.0468, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452, Train Loss: 0.0440, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453, Train Loss: 0.0478, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454, Train Loss: 0.0454, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455, Train Loss: 0.0474, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456, Train Loss: 0.0479, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457, Train Loss: 0.0471, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458, Train Loss: 0.0454, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459, Train Loss: 0.0463, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460, Train Loss: 0.0449, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461, Train Loss: 0.0459, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462, Train Loss: 0.0470, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463, Train Loss: 0.0474, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464, Train Loss: 0.0458, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465, Train Loss: 0.0460, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466, Train Loss: 0.0446, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467, Train Loss: 0.0451, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468, Train Loss: 0.0464, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469, Train Loss: 0.0439, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470, Train Loss: 0.0458, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471, Train Loss: 0.0486, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472, Train Loss: 0.0459, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473, Train Loss: 0.0451, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474, Train Loss: 0.0452, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475, Train Loss: 0.0470, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476, Train Loss: 0.0424, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477, Train Loss: 0.0441, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478, Train Loss: 0.0440, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479, Train Loss: 0.0454, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480, Train Loss: 0.0425, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481, Train Loss: 0.0445, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482, Train Loss: 0.0447, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483, Train Loss: 0.0430, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484, Train Loss: 0.0445, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485, Train Loss: 0.0456, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486, Train Loss: 0.0469, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487, Train Loss: 0.0462, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488, Train Loss: 0.0475, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489, Train Loss: 0.0440, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490, Train Loss: 0.0497, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491, Train Loss: 0.0461, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492, Train Loss: 0.0451, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493, Train Loss: 0.0464, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494, Train Loss: 0.0430, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495, Train Loss: 0.0455, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496, Train Loss: 0.0448, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497, Train Loss: 0.0436, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498, Train Loss: 0.0449, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499, Train Loss: 0.0465, Validation Loss: 0.0554, Validation F1: 0.9922, Validation F1 Micro: 0.9916, Validation F1 Macro: 0.6887\n",
      "Model training completed and saved.\n"
     ]
    }
   ],
   "source": [
    "# Best parameters from the grid search\n",
    "best_hidden_dim = 512  # Replace with the best hidden_dim found\n",
    "best_learning_rate = 0.005  # Replace with the best learning_rate found\n",
    "best_drop_out = 0.3  # Replace with the best drop_out found\n",
    "if FIRST_RUN:\n",
    "\n",
    "    max_epochs = 500\n",
    "    # patience = 10\n",
    "\n",
    "    print(\"Number of train graphs: \", len(train_graph_dataset))\n",
    "\n",
    "    # Initialize the model with the best parameters\n",
    "    model = EGraphSAGE(node_in_channels=num_features, \n",
    "                    edge_in_channels=num_features,\n",
    "                    hidden_channels=best_hidden_dim,\n",
    "                    dropout = best_drop_out,\n",
    "                    out_channels=num_classes).to(device)\n",
    "\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # Normalize class weights\n",
    "    class_weights = th.FloatTensor(train_graph_dataset.class_weights).to(device)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = th.optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    scheduler = th.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.6,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "    )\n",
    "\n",
    "    # ===== Load checkpoint if exists =====\n",
    "    start_epoch = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    # patience_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    train_ended = False\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_f1_history = []\n",
    "    saved_model_epochs = []\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = th.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "        train_ended = checkpoint['train_ended']\n",
    "        best_f1 = checkpoint['best_f1']\n",
    "\n",
    "        assert max_epochs == checkpoint['max_epochs'], \"Checkpoint max_epochs does not match the current setting.\"\n",
    "        # assert patience == checkpoint['patience'], \"Checkpoint patience does not match the current setting.\"\n",
    "\n",
    "        # patience_counter = checkpoint['patience_counter']\n",
    "        # best_val_loss = checkpoint['best_val_loss']\n",
    "\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "        train_loss_history = checkpoint['train_loss_history']\n",
    "        val_loss_history = checkpoint['val_loss_history']\n",
    "        val_f1_history = checkpoint['val_f1_history']\n",
    "        saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "        print(f\"Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "    if train_ended:\n",
    "        model.load_state_dict(th.load(best_model_path))\n",
    "        print(\"Training has already ended. Loaded the best model state.\")\n",
    "        print(\"Training history loaded successfully.\")\n",
    "\n",
    "    else:\n",
    "        # ===== Start Training =====\n",
    "        num_train_graphs = len(train_graph_dataset)\n",
    "        num_val_graphs = len(val_graph_dataset)\n",
    "\n",
    "        for epoch in range(start_epoch, max_epochs):\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            for G_pyg_train in tqdm(train_graph_dataset, desc=\"Training\", leave=False):\n",
    "\n",
    "                # Move the graph data to the device\n",
    "                G_pyg_train = G_pyg_train.to(device)\n",
    "                G_pyg_train.edge_label = G_pyg_train.edge_label.to(device)\n",
    "                G_pyg_train.edge_attr = G_pyg_train.edge_attr.to(device)\n",
    "\n",
    "                out = model(G_pyg_train)\n",
    "                loss = criterion(out, G_pyg_train.edge_label) / num_train_graphs\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            test_label_list = []\n",
    "            pred_label_list = []\n",
    "\n",
    "            model.eval()\n",
    "            with th.no_grad():\n",
    "                for G_pyg_val in tqdm(val_graph_dataset, desc=\"Evaluation\", leave=False):\n",
    "                    G_pyg_val = G_pyg_val.to(device)\n",
    "                    G_pyg_val.edge_label = G_pyg_val.edge_label.to(device)\n",
    "                    G_pyg_val.edge_attr = G_pyg_val.edge_attr.to(device)\n",
    "\n",
    "                    out = model(G_pyg_val)\n",
    "                    loss = criterion(out, G_pyg_val.edge_label) / num_val_graphs\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    test_label_list.append(G_pyg_val.edge_label.cpu())\n",
    "                    pred_label_list.append(out.argmax(dim=1).cpu())\n",
    "\n",
    "            test_label = th.cat(test_label_list)\n",
    "            pred_label = th.cat(pred_label_list)\n",
    "\n",
    "            val_f1 = f1_score(test_label, pred_label, average='weighted')\n",
    "            val_f1_micro = f1_score(test_label, pred_label, average='micro')\n",
    "            val_f1_macro = f1_score(test_label, pred_label, average='macro')\n",
    "\n",
    "            train_loss_history.append(train_loss)\n",
    "            val_loss_history.append(val_loss)\n",
    "            val_f1_history.append((val_f1, val_f1_micro, val_f1_macro))\n",
    "\n",
    "            # Schedule step\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1  # Update the best F1 score for this fold\n",
    "                best_model_state = model.state_dict()\n",
    "                saved_model_epochs.append(epoch)\n",
    "\n",
    "                save_checkpoint()\n",
    "                th.save(best_model_state, best_model_path)\n",
    "                print(f\"Epoch {epoch} Saved best model. Best F1:\", best_f1)\n",
    "\n",
    "            print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}, Validation F1 Micro: {val_f1_micro:.4f}, Validation F1 Macro: {val_f1_macro:.4f}')\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                save_checkpoint()\n",
    "\n",
    "            # # Early stopping condition\n",
    "            # if val_loss < best_val_loss:\n",
    "            #     best_val_loss = val_loss\n",
    "            #     patience_counter = 0\n",
    "            # else:\n",
    "            #     patience_counter += 1\n",
    "\n",
    "            # if patience_counter >= patience:\n",
    "            #     print(f\"\\n🛑 Early stopping triggered at epoch {epoch}.\")\n",
    "            #     train_ended = True\n",
    "            #     break\n",
    "\n",
    "        # Save the trained model\n",
    "        train_ended = True\n",
    "        save_checkpoint()\n",
    "        print(\"Model training completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f64c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_process():\n",
    "    checkpoint = th.load(checkpoint_path)\n",
    "\n",
    "    train_loss_history = checkpoint['train_loss_history']\n",
    "    val_loss_history = checkpoint['val_loss_history']\n",
    "    val_f1_history = checkpoint['val_f1_history']\n",
    "    saved_model_epochs = checkpoint['saved_model_epochs']\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Plot Train Loss\n",
    "    axs[0].plot(train_loss_history, label='Train Loss', color='blue')\n",
    "    axs[0].plot(val_loss_history, label='Validation Loss', color='red')\n",
    "    axs[0].set_ylabel('Train Loss')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    val_f1_weighted_history = []\n",
    "    val_f1_micro_history = []\n",
    "    val_f1_macro_history = []\n",
    "\n",
    "    for val_f1_weighted, val_f1_micro, val_f1_macro in val_f1_history:\n",
    "        val_f1_weighted_history.append(val_f1_weighted)\n",
    "        val_f1_micro_history.append(val_f1_micro)\n",
    "        val_f1_macro_history.append(val_f1_macro)\n",
    "    \n",
    "    # Plot Validation F1\n",
    "\n",
    "    axs[1].plot(val_f1_weighted_history, label='Validation F1 Weighted', color='green')\n",
    "    axs[1].plot(val_f1_micro_history, label='Validation F1 Micro', color='blue')\n",
    "    axs[1].plot(val_f1_macro_history, label='Validation F1 Macro', color='red')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Validation F1')\n",
    "    axs[1].set_title('Validation F1 Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    # Add scatter for saved model epochs (e.g., F1 weighted here)\n",
    "    axs[1].scatter(saved_model_epochs, [val_f1_weighted_history[i] for i in saved_model_epochs],\n",
    "                   color='black', marker='o', label='Saved Model')\n",
    "    axs[1].legend()\n",
    "\n",
    "    print(len(train_loss_history))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2572f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f060684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average, Min, and Max Degrees Across All Graphs:\n",
      "  Attack Class ['BENIGN']:\n",
      "    Avg Out-Degree (src): 11.2569 | Min: 1 | Max: 966\n",
      "    Avg In-Degree (dst): 7.2127 | Min: 1 | Max: 955\n",
      "    Influence: 17.5687 | Min: 0.0010 | Max: 933155.0668\n",
      "  Attack Class ['Bot']:\n",
      "    Avg Out-Degree (src): 3.6338 | Min: 1 | Max: 29\n",
      "    Avg In-Degree (dst): 5.7333 | Min: 1 | Max: 31\n",
      "    Influence: 2.3031 | Min: 0.0323 | Max: 840.9992\n",
      "  Attack Class ['DDoS']:\n",
      "    Avg Out-Degree (src): 768.3846 | Min: 1 | Max: 1000\n",
      "    Avg In-Degree (dst): 768.3846 | Min: 1 | Max: 1000\n",
      "    Influence: 768.3846 | Min: 0.0010 | Max: 999999.0000\n",
      "  Attack Class ['DoS GoldenEye']:\n",
      "    Avg Out-Degree (src): 694.6667 | Min: 627 | Max: 764\n",
      "    Avg In-Degree (dst): 694.6667 | Min: 627 | Max: 764\n",
      "    Influence: 694.6667 | Min: 514.5668 | Max: 930.9346\n",
      "  Attack Class ['DoS Hulk']:\n",
      "    Avg Out-Degree (src): 852.1282 | Min: 1 | Max: 999\n",
      "    Avg In-Degree (dst): 852.1282 | Min: 1 | Max: 999\n",
      "    Influence: 852.1282 | Min: 0.0010 | Max: 998000.0020\n",
      "  Attack Class ['DoS Slowhttptest']:\n",
      "    Avg Out-Degree (src): 252.0000 | Min: 32 | Max: 538\n",
      "    Avg In-Degree (dst): 252.0000 | Min: 32 | Max: 538\n",
      "    Influence: 252.0000 | Min: 1.9033 | Max: 9045.1247\n",
      "  Attack Class ['DoS slowloris']:\n",
      "    Avg Out-Degree (src): 173.2000 | Min: 91 | Max: 262\n",
      "    Avg In-Degree (dst): 173.2000 | Min: 91 | Max: 262\n",
      "    Influence: 173.2000 | Min: 31.6069 | Max: 754.3297\n",
      "  Attack Class ['FTP-Patator']:\n",
      "    Avg Out-Degree (src): 87.8462 | Min: 1 | Max: 216\n",
      "    Avg In-Degree (dst): 87.8462 | Min: 1 | Max: 216\n",
      "    Influence: 87.8462 | Min: 0.0046 | Max: 46655.9533\n",
      "  Attack Class ['Heartbleed']:\n",
      "    Avg Out-Degree (src): 1.0000 | Min: 1 | Max: 1\n",
      "    Avg In-Degree (dst): 1.0000 | Min: 1 | Max: 1\n",
      "    Influence: 1.0000 | Min: 1.0000 | Max: 1.0000\n",
      "  Attack Class ['Infiltration']:\n",
      "    Avg Out-Degree (src): 1.0000 | Min: 1 | Max: 1\n",
      "    Avg In-Degree (dst): 1.0000 | Min: 1 | Max: 1\n",
      "    Influence: 1.0000 | Min: 1.0000 | Max: 1.0000\n",
      "  Attack Class ['PortScan']:\n",
      "    Avg Out-Degree (src): 830.6897 | Min: 1 | Max: 998\n",
      "    Avg In-Degree (dst): 830.6897 | Min: 1 | Max: 998\n",
      "    Influence: 830.6897 | Min: 0.0010 | Max: 996003.0040\n",
      "  Attack Class ['SSH-Patator']:\n",
      "    Avg Out-Degree (src): 92.9091 | Min: 34 | Max: 148\n",
      "    Avg In-Degree (dst): 92.9091 | Min: 34 | Max: 148\n",
      "    Influence: 92.9091 | Min: 7.8108 | Max: 644.2353\n",
      "  Attack Class ['Web Attack - Brute Force']:\n",
      "    Avg Out-Degree (src): 21.1250 | Min: 4 | Max: 43\n",
      "    Avg In-Degree (dst): 21.1250 | Min: 4 | Max: 43\n",
      "    Influence: 21.1250 | Min: 0.3721 | Max: 462.2499\n",
      "  Attack Class ['Web Attack - Sql Injection']:\n",
      "    Avg Out-Degree (src): 3.0000 | Min: 3 | Max: 3\n",
      "    Avg In-Degree (dst): 3.0000 | Min: 3 | Max: 3\n",
      "    Influence: 3.0000 | Min: 3.0000 | Max: 3.0000\n",
      "  Attack Class ['Web Attack - XSS']:\n",
      "    Avg Out-Degree (src): 36.0000 | Min: 13 | Max: 59\n",
      "    Avg In-Degree (dst): 36.0000 | Min: 13 | Max: 59\n",
      "    Influence: 36.0000 | Min: 2.8644 | Max: 267.7692\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import degree\n",
    "from collections import defaultdict\n",
    "\n",
    "def check_global_avg_degrees_per_class(graph_dataset):\n",
    "    # Dictionaries to hold total degree sums and counts per class\n",
    "    total_out_deg = defaultdict(float)\n",
    "    total_in_deg = defaultdict(float)\n",
    "    count_out_nodes = defaultdict(int)\n",
    "    count_in_nodes = defaultdict(int)\n",
    "    min_out_deg = defaultdict(lambda: float('inf'))\n",
    "    max_out_deg = defaultdict(lambda: float('-inf'))\n",
    "    min_in_deg = defaultdict(lambda: float('inf'))\n",
    "    max_in_deg = defaultdict(lambda: float('-inf'))\n",
    "\n",
    "    for graph in graph_dataset:\n",
    "        edge_index = graph.edge_index\n",
    "        edge_label = graph.edge_label\n",
    "        num_nodes = graph.num_nodes\n",
    "\n",
    "        unique_classes = torch.unique(edge_label)\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            cls = int(cls)\n",
    "            mask = (edge_label == cls)\n",
    "\n",
    "            src_nodes = edge_index[0][mask]\n",
    "            dst_nodes = edge_index[1][mask]\n",
    "\n",
    "            out_deg = degree(src_nodes, num_nodes=num_nodes)\n",
    "            in_deg = degree(dst_nodes, num_nodes=num_nodes)\n",
    "\n",
    "            involved_src = out_deg > 0\n",
    "            involved_dst = in_deg > 0\n",
    "\n",
    "            total_out_deg[cls] += out_deg[involved_src].sum().item()\n",
    "            total_in_deg[cls] += in_deg[involved_dst].sum().item()\n",
    "            count_out_nodes[cls] += involved_src.sum().item()\n",
    "            count_in_nodes[cls] += involved_dst.sum().item()\n",
    "\n",
    "            if involved_src.any():\n",
    "                min_out_deg[cls] = min(min_out_deg[cls], out_deg[involved_src].min().item())\n",
    "                max_out_deg[cls] = max(max_out_deg[cls], out_deg[involved_src].max().item())\n",
    "            if involved_dst.any():\n",
    "                min_in_deg[cls] = min(min_in_deg[cls], in_deg[involved_dst].min().item())\n",
    "                max_in_deg[cls] = max(max_in_deg[cls], in_deg[involved_dst].max().item())\n",
    "\n",
    "    print(\"Average, Min, and Max Degrees Across All Graphs:\")\n",
    "    class_degree_report = {}\n",
    "    for cls in sorted(total_out_deg.keys()):\n",
    "        avg_out = total_out_deg[cls] / count_out_nodes[cls] if count_out_nodes[cls] > 0 else 0.0\n",
    "        avg_in = total_in_deg[cls] / count_in_nodes[cls] if count_in_nodes[cls] > 0 else 0.0\n",
    "        min_out = min_out_deg[cls] if min_out_deg[cls] != float('inf') else 0.0\n",
    "        max_out = max_out_deg[cls] if max_out_deg[cls] != float('-inf') else 0.0\n",
    "        min_in = min_in_deg[cls] if min_in_deg[cls] != float('inf') else 0.0\n",
    "        max_in = max_in_deg[cls] if max_in_deg[cls] != float('-inf') else 0.0\n",
    "\n",
    "        epsilon = 1e-6 # to avoid division by zero\n",
    "        avg_influence = (avg_out ** 2) / ((avg_in + epsilon))\n",
    "        max_influence = (max_out ** 2) / ((min_in + epsilon))\n",
    "        min_influence = (min_out ** 2) / ((max_in + epsilon))\n",
    "\n",
    "        print(f\"  Attack Class {le.inverse_transform([cls])}:\")\n",
    "        print(f\"    Avg Out-Degree (src): {avg_out:.4f} | Min: {min_out:.0f} | Max: {max_out:.0f}\")\n",
    "        print(f\"    Avg In-Degree (dst): {avg_in:.4f} | Min: {min_in:.0f} | Max: {max_in:.0f}\")\n",
    "        print(f\"    Influence: {avg_influence:.4f} | Min: {min_influence:.4f} | Max: {max_influence:.4f}\")\n",
    "\n",
    "        class_degree_report[le.inverse_transform([cls])[0]] = {\n",
    "            \"avg_out\": avg_out,\n",
    "            \"min_out\": min_out,\n",
    "            \"max_out\": max_out,\n",
    "            \"avg_in\": avg_in,\n",
    "            \"min_in\": min_in,\n",
    "            \"max_in\": max_in,\n",
    "            \"avg_influence\": avg_influence,\n",
    "            \"min_influence\": min_influence,\n",
    "            \"max_influence\": max_influence\n",
    "        }\n",
    "\n",
    "    return class_degree_report\n",
    "\n",
    "class_degree_report = check_global_avg_degrees_per_class(test_graph_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "857f271a-612b-4cd6-a85a-e4236dec9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test graphs:  422\n",
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/CIC_IDS_2017/saved/strat_window_host_1000/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9881\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[334173    613     42     26     90     11     35     83      7    136\n",
      "    1642   1050     55     92     13]\n",
      " [     7    247      0      0      0      0      0      0      0      0\n",
      "       4      0      0      0      0]\n",
      " [     0      0  19571      0    407      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0   2084      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0  33232      0      0      0      0      0\n",
      "       0      1      0      0      0]\n",
      " [   538      0      0      0      0    470      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0      0    866      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0   1141      0      0\n",
      "       0      1      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      2      0\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      4\n",
      "       0      0      0      0      0]\n",
      " [   128      0      0      0      0      0      0      0      0      0\n",
      "   23961      1      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0   1022      0      0      0]\n",
      " [     4      0      0      0      0      0      0      0      0      0\n",
      "       0      0    155      0     10]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      3      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      0     13      0     59]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.9980    0.9885    0.9932    338068\n",
      "                       Bot     0.2872    0.9574    0.4419       258\n",
      "                      DDoS     0.9979    0.9796    0.9887     19978\n",
      "             DoS GoldenEye     0.9877    1.0000    0.9938      2084\n",
      "                  DoS Hulk     0.9853    1.0000    0.9926     33233\n",
      "          DoS Slowhttptest     0.9771    0.4663    0.6313      1008\n",
      "             DoS slowloris     0.9612    1.0000    0.9802       866\n",
      "               FTP-Patator     0.9322    0.9991    0.9645      1142\n",
      "                Heartbleed     0.2222    1.0000    0.3636         2\n",
      "              Infiltration     0.0286    0.8000    0.0552         5\n",
      "                  PortScan     0.9357    0.9946    0.9643     24090\n",
      "               SSH-Patator     0.4918    1.0000    0.6594      1022\n",
      "  Web Attack - Brute Force     0.6951    0.9172    0.7908       169\n",
      "Web Attack - Sql Injection     0.0000    0.0000    0.0000         3\n",
      "          Web Attack - XSS     0.7195    0.8194    0.7662        72\n",
      "\n",
      "                  accuracy                         0.9881    422000\n",
      "                 macro avg     0.6813    0.8615    0.7057    422000\n",
      "              weighted avg     0.9912    0.9881    0.9890    422000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_accuracy(pred, labels):\n",
    "    return (pred.argmax(1) == labels).float().mean().item()\n",
    "\n",
    "def eval(dataset, adversarial=False):\n",
    "\n",
    "    # Check if dataset is a list of (data, label) tuples or just data objects\n",
    "    if isinstance(dataset[0], (list, tuple)):\n",
    "        data_obj = dataset[0][0]\n",
    "    else:\n",
    "        data_obj = dataset[0]\n",
    "\n",
    "    num_features = data_obj.edge_attr.shape[1]\n",
    "    best_model = EGraphSAGE(node_in_channels=num_features, \n",
    "                       edge_in_channels=num_features,\n",
    "                       hidden_channels=best_hidden_dim, \n",
    "                       out_channels=len(class_map)).to(device)\n",
    "\n",
    "    print(\"Loading model from\", best_model_path)\n",
    "    best_model.load_state_dict(th.load(best_model_path))\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    print(\"inference start\")\n",
    "    with th.no_grad():\n",
    "        all_pred_logits = []\n",
    "        all_test_labels = []\n",
    "        for G_pyg in tqdm(dataset, desc=\"Evaluation\", leave=False):\n",
    "            try:\n",
    "                # Move the graph data to the device\n",
    "                G_pyg = G_pyg.to(device)\n",
    "                G_pyg.edge_label = G_pyg.edge_label.to(device)\n",
    "                G_pyg.edge_attr = G_pyg.edge_attr.to(device)\n",
    "                out = best_model(G_pyg)\n",
    "                \n",
    "            except Exception as forward_error:\n",
    "                print(f\"Error during forward/backward pass at {forward_error}\")\n",
    "\n",
    "            all_pred_logits.append(out.cpu())\n",
    "            all_test_labels.append(G_pyg.edge_label.cpu())\n",
    "\n",
    "        all_pred_logits = th.cat(all_pred_logits).to(device)\n",
    "        all_test_labels = th.cat(all_test_labels).to(device)\n",
    "        test_accuracy = compute_accuracy(all_pred_logits, all_test_labels)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "        pred_labels = all_pred_logits.argmax(dim=1).cpu()\n",
    "        all_test_labels = all_test_labels.cpu()\n",
    "    \n",
    "    if adversarial:\n",
    "\n",
    "        # Create a boolean mask where the label is NOT equal to the adversarial class\n",
    "        adversarial_mask = all_test_labels == ADVERSARIAL_CLASS_LABEL\n",
    "\n",
    "        # Print the class that the adversarial samples are classified as\n",
    "        cm_adversarial = confusion_matrix(all_test_labels[adversarial_mask], pred_labels[adversarial_mask], labels=range(len(class_map) + 1))\n",
    "        print(\"Adversarial confusion matrix:\", cm_adversarial)\n",
    "\n",
    "        # Apply the mask to both labels and predictions\n",
    "        all_test_labels = all_test_labels[~adversarial_mask]\n",
    "        pred_labels = pred_labels[~adversarial_mask]\n",
    "\n",
    "    print(\"class_map\", class_map)\n",
    "    # Generate a report\n",
    "    cm = confusion_matrix(all_test_labels, pred_labels, labels=range(len(class_map)))\n",
    "    print(cm)\n",
    "\n",
    "    report = classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, labels=range(len(class_map)))\n",
    "    print(report)\n",
    "    \n",
    "    return classification_report(all_test_labels, pred_labels, target_names=class_map, digits=4, output_dict=True, labels=range(len(class_map)))\n",
    "\n",
    "\n",
    "print(\"Number of test graphs: \", len(test_graph_dataset))\n",
    "normal_report = eval(test_graph_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cff736d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_traffic_to_node(graph, ratio=0.1, num_injected_nodes=1, to_node_type='both', random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    # Get all src nodes\n",
    "    if to_node_type == 'src':\n",
    "         to_nodes = edge_index[0]\n",
    "\n",
    "    elif to_node_type == 'dst':\n",
    "         to_nodes = edge_index[1]\n",
    "\n",
    "    elif to_node_type == 'both':\n",
    "         to_nodes = th.cat([edge_index[0], edge_index[1]])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"to_node_type must be 'src', 'dst', or 'both'.\")\n",
    "\n",
    "    original_num_nodes = x.size(0)\n",
    "\n",
    "    new_node_feats = th.ones((num_injected_nodes, feature_dim))\n",
    "    x = th.cat([x, new_node_feats], dim=0)\n",
    "\n",
    "    # 4. Inject edges from injected nodes to attacker nodes\n",
    "    num_to_inject = max(1, int(ratio * num_edges))\n",
    "    new_edges = []\n",
    "    new_attrs = []\n",
    "    new_labels = []\n",
    "    \n",
    "    for i in range(num_to_inject):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per iteration\n",
    "        src = rng.randint(original_num_nodes, original_num_nodes + num_injected_nodes - 1)  # from injected nodes\n",
    "        dst = rng.choice(to_nodes.tolist())  # to existing nodes\n",
    "\n",
    "        new_edges.append([src, dst])\n",
    "        attr = th.rand(feature_dim)  # random feature for the new edge\n",
    "        new_attrs.append(attr)\n",
    "        new_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    # Create a new empty graph to store the injected edges\n",
    "    new_graph = Data()\n",
    "\n",
    "    # 5. Merge into graph\n",
    "    if new_edges:\n",
    "        new_edges = th.tensor(new_edges, dtype=th.long).t().contiguous()\n",
    "        new_attrs = th.stack(new_attrs)\n",
    "        new_labels = th.tensor(new_labels, dtype=th.long)\n",
    "\n",
    "        new_graph.edge_index = th.cat([edge_index, new_edges], dim=1)\n",
    "        new_graph.edge_attr = th.cat([edge_attr, new_attrs], dim=0)\n",
    "        new_graph.edge_label = th.cat([edge_label, new_labels], dim=0)\n",
    "        new_graph.x = x\n",
    "\n",
    "    return new_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c0a4cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/CIC_IDS_2017/saved/strat_window_host_1000/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8151\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [38107   473   879   117  1355   272    44     0     7     4     0    22\n",
      "     17   894     9     0]]\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[337108    260     14     16     37     78     34     14      5    113\n",
      "      19    352      0     18      0]\n",
      " [    40    218      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [ 12018      0   7554      0    406      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   627      0      0   1457      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [  3804      0      0      0  29428      0      0      0      0      0\n",
      "       0      1      0      0      0]\n",
      " [     0      0      0      0      0   1008      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   353      0      0      0      0      0    513      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   354      0      0      0      0      0      0    787      0      0\n",
      "       0      1      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      1      0\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      4\n",
      "       0      0      0      0      0]\n",
      " [ 24090      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   930      0      0      0      0      0      0      0      0      0\n",
      "       0     92      0      0      0]\n",
      " [    11      0      0      0      0      0      0      0      0      0\n",
      "       0      0    148      0     10]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      3      0      0      0]\n",
      " [    13      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0     59]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.8886    0.9972    0.9398    338068\n",
      "                       Bot     0.4561    0.8450    0.5924       258\n",
      "                      DDoS     0.9982    0.3781    0.5485     19978\n",
      "             DoS GoldenEye     0.9891    0.6991    0.8192      2084\n",
      "                  DoS Hulk     0.9852    0.8855    0.9327     33233\n",
      "          DoS Slowhttptest     0.9282    1.0000    0.9628      1008\n",
      "             DoS slowloris     0.9378    0.5924    0.7261       866\n",
      "               FTP-Patator     0.9825    0.6891    0.8101      1142\n",
      "                Heartbleed     0.1667    0.5000    0.2500         2\n",
      "              Infiltration     0.0342    0.8000    0.0656         5\n",
      "                  PortScan     0.0000    0.0000    0.0000     24090\n",
      "               SSH-Patator     0.2049    0.0900    0.1251      1022\n",
      "  Web Attack - Brute Force     1.0000    0.8757    0.9338       169\n",
      "Web Attack - Sql Injection     0.0000    0.0000    0.0000         3\n",
      "          Web Attack - XSS     0.8551    0.8194    0.8369        72\n",
      "\n",
      "                  accuracy                         0.8966    422000\n",
      "                 macro avg     0.6284    0.6114    0.5695    422000\n",
      "              weighted avg     0.8497    0.8966    0.8635    422000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_both_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='both') for g in test_graph_dataset]\n",
    "inject_both_report = eval(inject_both_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "90b60cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/CIC_IDS_2017/saved/strat_window_host_1000/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8021\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [49827    22   106     8   110   194     1     0    10     0     0     6\n",
      "     10   338     8     0]]\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[337173    205     18     14     33    179     41     12      1    111\n",
      "       8    262      0     11      0]\n",
      " [    37    221      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [ 12424      0   7554      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   627      0      0   1457      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [  2806      0      0      0  30427      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0   1008      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   353      0      0      0      0      0    513      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   596      0      0      0      0      0      0    545      0      0\n",
      "       0      1      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      2      0\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      4\n",
      "       0      0      0      0      0]\n",
      " [ 24090      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   930      0      0      0      0      0     92      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [    38      0      0      0      0      0      0      0      0      0\n",
      "       0      0    131      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      3      0]\n",
      " [    13      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0     59]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.8894    0.9974    0.9403    338068\n",
      "                       Bot     0.5188    0.8566    0.6462       258\n",
      "                      DDoS     0.9976    0.3781    0.5484     19978\n",
      "             DoS GoldenEye     0.9905    0.6991    0.8197      2084\n",
      "                  DoS Hulk     0.9989    0.9156    0.9554     33233\n",
      "          DoS Slowhttptest     0.8492    1.0000    0.9185      1008\n",
      "             DoS slowloris     0.7941    0.5924    0.6786       866\n",
      "               FTP-Patator     0.9785    0.4772    0.6416      1142\n",
      "                Heartbleed     0.6667    1.0000    0.8000         2\n",
      "              Infiltration     0.0348    0.8000    0.0667         5\n",
      "                  PortScan     0.0000    0.0000    0.0000     24090\n",
      "               SSH-Patator     0.0000    0.0000    0.0000      1022\n",
      "  Web Attack - Brute Force     1.0000    0.7751    0.8733       169\n",
      "Web Attack - Sql Injection     0.2143    1.0000    0.3529         3\n",
      "          Web Attack - XSS     1.0000    0.8194    0.9008        72\n",
      "\n",
      "                  accuracy                         0.8983    422000\n",
      "                 macro avg     0.6622    0.6874    0.6095    422000\n",
      "              weighted avg     0.8505    0.8983    0.8648    422000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_src_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.12, num_injected_nodes=1, to_node_type='src', random_seed=12) for g in test_graph_dataset]\n",
    "inject_src_report = eval(inject_src_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "70287333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/CIC_IDS_2017/saved/strat_window_host_1000/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9012\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [32295   690  1927   263  3122   372    78     0    89     4  1554   117\n",
      "     17  1665     7     0]]\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[336373    434     26     23     76     27     34     27      9    116\n",
      "      56    780     27     50     10]\n",
      " [    19    235      0      0      0      0      0      0      0      0\n",
      "       4      0      0      0      0]\n",
      " [     0      0  19571      0    407      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0   2084      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0  33232      0      0      0      0      0\n",
      "       0      1      0      0      0]\n",
      " [   538      0      0      0      0    470      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0      0    866      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0   1141      0      0\n",
      "       0      1      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      2      0\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      4\n",
      "       0      0      0      0      0]\n",
      " [   860      0      0      0      0      0      0      0      0      0\n",
      "   23230      0      0      0      0]\n",
      " [   136      0      0      0      0      0      0      0      0      0\n",
      "       0    886      0      0      0]\n",
      " [     4      0      0      0      0      0      0      0      0      0\n",
      "       0      0    165      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      3      0      0      0]\n",
      " [    13      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0     59]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.9954    0.9950    0.9952    338068\n",
      "                       Bot     0.3513    0.9109    0.5070       258\n",
      "                      DDoS     0.9987    0.9796    0.9891     19978\n",
      "             DoS GoldenEye     0.9891    1.0000    0.9945      2084\n",
      "                  DoS Hulk     0.9857    1.0000    0.9928     33233\n",
      "          DoS Slowhttptest     0.9457    0.4663    0.6246      1008\n",
      "             DoS slowloris     0.9622    1.0000    0.9807       866\n",
      "               FTP-Patator     0.9769    0.9991    0.9879      1142\n",
      "                Heartbleed     0.1818    1.0000    0.3077         2\n",
      "              Infiltration     0.0333    0.8000    0.0640         5\n",
      "                  PortScan     0.9974    0.9643    0.9806     24090\n",
      "               SSH-Patator     0.5302    0.8669    0.6580      1022\n",
      "  Web Attack - Brute Force     0.8594    0.9763    0.9141       169\n",
      "Web Attack - Sql Injection     0.0000    0.0000    0.0000         3\n",
      "          Web Attack - XSS     0.8551    0.8194    0.8369        72\n",
      "\n",
      "                  accuracy                         0.9913    422000\n",
      "                 macro avg     0.7108    0.8519    0.7222    422000\n",
      "              weighted avg     0.9930    0.9913    0.9917    422000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Attack Traffic to Attacker Nodes\n",
    "inject_dst_graph_dataset = [inject_traffic_to_node(g.cpu(), 0.1, num_injected_nodes=1, to_node_type='dst') for g in test_graph_dataset]\n",
    "inject_dst_report = eval(inject_dst_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "579e0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Attribute Perturbation\n",
    "def perturb_edge_attributes(graph, affected_edge_ratio=0.1, perturbation_ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    feature_dim = edge_attr.size(1)\n",
    "\n",
    "    # Randomly select edges to perturb\n",
    "    num_to_perturb = max(1, int(affected_edge_ratio * num_edges))\n",
    "    rng = random.Random(random_seed)\n",
    "    indices_to_perturb = rng.sample(range(num_edges), num_to_perturb)\n",
    "\n",
    "    for idx in indices_to_perturb:\n",
    "        # Perturb the edge attributes by adding noise\n",
    "        noise = th.randn(feature_dim) * perturbation_ratio  # Adjust the scale of noise as needed\n",
    "        edge_attr[idx] += noise\n",
    "\n",
    "    # Create a new graph with perturbed attributes\n",
    "    perturbed_graph = Data(edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label, x=graph.x)\n",
    "\n",
    "    return perturbed_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb68c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/CIC_IDS_2017/saved/strat_window_host_1000/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9753\n",
      "Adversarial confusion matrix: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[329640   3871    245     50    479     29     80    179     55    184\n",
      "    2434    541     89     38    154]\n",
      " [    68    184      0      0      0      0      0      0      0      0\n",
      "       5      0      1      0      0]\n",
      " [     0      0  18572      0   1406      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0   2084      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      1      0      0  33232      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0   1008      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0      0    866      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0   1141      0      0\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      1      0\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      4\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0      0      0      0\n",
      "   23961     57     71      0      0]\n",
      " [   295      0      0      0      0      0      0      0      0      0\n",
      "       0    727      0      0      0]\n",
      " [    46      0      0      0      0      0      0      0      0      0\n",
      "      10      0    113      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      0     13      0     59]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.9987    0.9751    0.9868    338068\n",
      "                       Bot     0.0454    0.7132    0.0853       258\n",
      "                      DDoS     0.9870    0.9296    0.9574     19978\n",
      "             DoS GoldenEye     0.9766    1.0000    0.9881      2084\n",
      "                  DoS Hulk     0.9463    1.0000    0.9724     33233\n",
      "          DoS Slowhttptest     0.9720    1.0000    0.9858      1008\n",
      "             DoS slowloris     0.9154    1.0000    0.9558       866\n",
      "               FTP-Patator     0.8644    0.9991    0.9269      1142\n",
      "                Heartbleed     0.0179    0.5000    0.0345         2\n",
      "              Infiltration     0.0213    0.8000    0.0415         5\n",
      "                  PortScan     0.9073    0.9946    0.9490     24090\n",
      "               SSH-Patator     0.5487    0.7114    0.6195      1022\n",
      "  Web Attack - Brute Force     0.3937    0.6686    0.4956       169\n",
      "Web Attack - Sql Injection     0.0000    0.0000    0.0000         3\n",
      "          Web Attack - XSS     0.2770    0.8194    0.4140        72\n",
      "\n",
      "                  accuracy                         0.9753    422000\n",
      "                 macro avg     0.5914    0.8074    0.6275    422000\n",
      "              weighted avg     0.9861    0.9753    0.9801    422000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Edge Attribute Perturbation\n",
    "edge_perturb_graph_dataset = [perturb_edge_attributes(g.cpu(), affected_edge_ratio=1, perturbation_ratio=1) for g in test_graph_dataset]\n",
    "edge_perturb_report = eval(edge_perturb_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dc04f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject Random Edges\n",
    "def inject_random_edges(graph, ratio=0.1, random_seed=42):\n",
    "    edge_index = graph.edge_index.clone()\n",
    "    edge_attr = graph.edge_attr.clone()\n",
    "    edge_label = graph.edge_label.clone()\n",
    "    x = graph.x.clone()\n",
    "\n",
    "    num_nodes = x.size(0)\n",
    "    feature_dim = graph.x.size(1)\n",
    "\n",
    "    new_edge_indices = []\n",
    "    new_edge_attrs = []\n",
    "    new_edge_labels = []\n",
    "\n",
    "    num_edges = edge_index.size(1)\n",
    "    num_injected_edges = max(1, int(ratio * num_edges))\n",
    "\n",
    "    for i in range(num_injected_edges):\n",
    "        rng = random.Random(random_seed + i)  # ensure different seed per edge\n",
    "        src = rng.randint(0, num_nodes - 1)  # Random source node\n",
    "        dst = rng.randint(0, num_nodes - 1)  # Random destination node\n",
    "\n",
    "        new_edge_indices.append([src, dst])\n",
    "        new_edge_attrs.append(th.rand(feature_dim))  # Random feature for the new edge\n",
    "        new_edge_labels.append(ADVERSARIAL_CLASS_LABEL)\n",
    "\n",
    "    if new_edge_indices:\n",
    "        new_edge_indices = th.tensor(new_edge_indices, dtype=th.long).t().contiguous()\n",
    "        new_edge_attrs = th.stack(new_edge_attrs)\n",
    "        new_edge_labels = th.tensor(new_edge_labels, dtype=th.long)\n",
    "\n",
    "        edge_index = th.cat([edge_index, new_edge_indices], dim=1)\n",
    "        edge_attr = th.cat([edge_attr, new_edge_attrs], dim=0)\n",
    "        edge_label = th.cat([edge_label, new_edge_labels], dim=0)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, edge_label=edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b25073bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /vol/bitbucket/shc20/FYP/GNN-Adversarial-Attack/Models/E_GraphSAGE/CIC_IDS_2017/saved/strat_window_host_1000/best_model.pth\n",
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8668\n",
      "Adversarial confusion matrix: [[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0]\n",
      " [39019   102   572   124   606   925   706     0     3    21     6     9\n",
      "      2   105     0     0]]\n",
      "class_map ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator' 'Web Attack - Brute Force' 'Web Attack - Sql Injection'\n",
      " 'Web Attack - XSS']\n",
      "[[335159    630     27     45     97    134     36     27      2    113\n",
      "    1227    463     19     77     12]\n",
      " [    44    214      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0  19571      0    407      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0   2084      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   945      0      0      0  32287      0      0      0      0      0\n",
      "       0      1      0      0      0]\n",
      " [     0      0      0      0      0   1008      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   262      0      0      0      0      0    604      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     1      0      0      0      0      0      0   1141      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      2      0\n",
      "       0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      2\n",
      "       0      0      0      0      0]\n",
      " [ 14900      0      0      0      0      0      0      0      0      0\n",
      "    9190      0      0      0      0]\n",
      " [   138      0      0      0      0      0      0      0      0      0\n",
      "       0    884      0      0      0]\n",
      " [    22      0      0      0      0      0      0      0      0      0\n",
      "       0      0    147      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      3      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      0     13      0     59]]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN     0.9536    0.9914    0.9721    338068\n",
      "                       Bot     0.2536    0.8295    0.3884       258\n",
      "                      DDoS     0.9986    0.9796    0.9890     19978\n",
      "             DoS GoldenEye     0.9789    1.0000    0.9893      2084\n",
      "                  DoS Hulk     0.9846    0.9715    0.9780     33233\n",
      "          DoS Slowhttptest     0.8827    1.0000    0.9377      1008\n",
      "             DoS slowloris     0.9437    0.6975    0.8021       866\n",
      "               FTP-Patator     0.9769    0.9991    0.9879      1142\n",
      "                Heartbleed     0.5000    1.0000    0.6667         2\n",
      "              Infiltration     0.0174    0.4000    0.0333         5\n",
      "                  PortScan     0.8822    0.3815    0.5326     24090\n",
      "               SSH-Patator     0.6543    0.8650    0.7450      1022\n",
      "  Web Attack - Brute Force     0.8212    0.8698    0.8448       169\n",
      "Web Attack - Sql Injection     0.0000    0.0000    0.0000         3\n",
      "          Web Attack - XSS     0.8310    0.8194    0.8252        72\n",
      "\n",
      "                  accuracy                         0.9534    422000\n",
      "                 macro avg     0.7119    0.7870    0.7128    422000\n",
      "              weighted avg     0.9528    0.9534    0.9470    422000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inject Random Edges\n",
    "random_edge_graph_dataset = [inject_random_edges(g.cpu(), 0.1) for g in test_graph_dataset]\n",
    "random_edge_report = eval(random_edge_graph_dataset, adversarial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e8c66190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Overall Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e9577\">\n",
       "  <caption>Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e9577_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_e9577_level0_col1\" class=\"col_heading level0 col1\" >Min Influence</th>\n",
       "      <th id=\"T_e9577_level0_col2\" class=\"col_heading level0 col2\" >Avg Influence</th>\n",
       "      <th id=\"T_e9577_level0_col3\" class=\"col_heading level0 col3\" >Max Influence</th>\n",
       "      <th id=\"T_e9577_level0_col4\" class=\"col_heading level0 col4\" >Normal precision</th>\n",
       "      <th id=\"T_e9577_level0_col5\" class=\"col_heading level0 col5\" >To Both precision</th>\n",
       "      <th id=\"T_e9577_level0_col6\" class=\"col_heading level0 col6\" >To Both precision Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col7\" class=\"col_heading level0 col7\" >To Src precision</th>\n",
       "      <th id=\"T_e9577_level0_col8\" class=\"col_heading level0 col8\" >To Src precision Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col9\" class=\"col_heading level0 col9\" >To Dst precision</th>\n",
       "      <th id=\"T_e9577_level0_col10\" class=\"col_heading level0 col10\" >To Dst precision Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col11\" class=\"col_heading level0 col11\" >Edge Perturbation precision</th>\n",
       "      <th id=\"T_e9577_level0_col12\" class=\"col_heading level0 col12\" >Edge Perturbation precision Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col13\" class=\"col_heading level0 col13\" >Random Edge precision</th>\n",
       "      <th id=\"T_e9577_level0_col14\" class=\"col_heading level0 col14\" >Random Edge precision Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col15\" class=\"col_heading level0 col15\" >Normal recall</th>\n",
       "      <th id=\"T_e9577_level0_col16\" class=\"col_heading level0 col16\" >To Both recall</th>\n",
       "      <th id=\"T_e9577_level0_col17\" class=\"col_heading level0 col17\" >To Both recall Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col18\" class=\"col_heading level0 col18\" >To Src recall</th>\n",
       "      <th id=\"T_e9577_level0_col19\" class=\"col_heading level0 col19\" >To Src recall Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col20\" class=\"col_heading level0 col20\" >To Dst recall</th>\n",
       "      <th id=\"T_e9577_level0_col21\" class=\"col_heading level0 col21\" >To Dst recall Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col22\" class=\"col_heading level0 col22\" >Edge Perturbation recall</th>\n",
       "      <th id=\"T_e9577_level0_col23\" class=\"col_heading level0 col23\" >Edge Perturbation recall Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col24\" class=\"col_heading level0 col24\" >Random Edge recall</th>\n",
       "      <th id=\"T_e9577_level0_col25\" class=\"col_heading level0 col25\" >Random Edge recall Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col26\" class=\"col_heading level0 col26\" >Normal f1-score</th>\n",
       "      <th id=\"T_e9577_level0_col27\" class=\"col_heading level0 col27\" >To Both f1-score</th>\n",
       "      <th id=\"T_e9577_level0_col28\" class=\"col_heading level0 col28\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col29\" class=\"col_heading level0 col29\" >To Src f1-score</th>\n",
       "      <th id=\"T_e9577_level0_col30\" class=\"col_heading level0 col30\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col31\" class=\"col_heading level0 col31\" >To Dst f1-score</th>\n",
       "      <th id=\"T_e9577_level0_col32\" class=\"col_heading level0 col32\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col33\" class=\"col_heading level0 col33\" >Edge Perturbation f1-score</th>\n",
       "      <th id=\"T_e9577_level0_col34\" class=\"col_heading level0 col34\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col35\" class=\"col_heading level0 col35\" >Random Edge f1-score</th>\n",
       "      <th id=\"T_e9577_level0_col36\" class=\"col_heading level0 col36\" >Random Edge f1-score Drop (%)</th>\n",
       "      <th id=\"T_e9577_level0_col37\" class=\"col_heading level0 col37\" >support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e9577_row0_col0\" class=\"data row0 col0\" >BENIGN</td>\n",
       "      <td id=\"T_e9577_row0_col1\" class=\"data row0 col1\" >0.00</td>\n",
       "      <td id=\"T_e9577_row0_col2\" class=\"data row0 col2\" >17.57</td>\n",
       "      <td id=\"T_e9577_row0_col3\" class=\"data row0 col3\" >933155.07</td>\n",
       "      <td id=\"T_e9577_row0_col4\" class=\"data row0 col4\" >1.00</td>\n",
       "      <td id=\"T_e9577_row0_col5\" class=\"data row0 col5\" >0.89</td>\n",
       "      <td id=\"T_e9577_row0_col6\" class=\"data row0 col6\" >10.96</td>\n",
       "      <td id=\"T_e9577_row0_col7\" class=\"data row0 col7\" >0.89</td>\n",
       "      <td id=\"T_e9577_row0_col8\" class=\"data row0 col8\" >10.88</td>\n",
       "      <td id=\"T_e9577_row0_col9\" class=\"data row0 col9\" >1.00</td>\n",
       "      <td id=\"T_e9577_row0_col10\" class=\"data row0 col10\" >0.26</td>\n",
       "      <td id=\"T_e9577_row0_col11\" class=\"data row0 col11\" >1.00</td>\n",
       "      <td id=\"T_e9577_row0_col12\" class=\"data row0 col12\" >-0.08</td>\n",
       "      <td id=\"T_e9577_row0_col13\" class=\"data row0 col13\" >0.95</td>\n",
       "      <td id=\"T_e9577_row0_col14\" class=\"data row0 col14\" >4.45</td>\n",
       "      <td id=\"T_e9577_row0_col15\" class=\"data row0 col15\" >0.99</td>\n",
       "      <td id=\"T_e9577_row0_col16\" class=\"data row0 col16\" >1.00</td>\n",
       "      <td id=\"T_e9577_row0_col17\" class=\"data row0 col17\" >-0.88</td>\n",
       "      <td id=\"T_e9577_row0_col18\" class=\"data row0 col18\" >1.00</td>\n",
       "      <td id=\"T_e9577_row0_col19\" class=\"data row0 col19\" >-0.90</td>\n",
       "      <td id=\"T_e9577_row0_col20\" class=\"data row0 col20\" >0.99</td>\n",
       "      <td id=\"T_e9577_row0_col21\" class=\"data row0 col21\" >-0.66</td>\n",
       "      <td id=\"T_e9577_row0_col22\" class=\"data row0 col22\" >0.98</td>\n",
       "      <td id=\"T_e9577_row0_col23\" class=\"data row0 col23\" >1.36</td>\n",
       "      <td id=\"T_e9577_row0_col24\" class=\"data row0 col24\" >0.99</td>\n",
       "      <td id=\"T_e9577_row0_col25\" class=\"data row0 col25\" >-0.30</td>\n",
       "      <td id=\"T_e9577_row0_col26\" class=\"data row0 col26\" >0.99</td>\n",
       "      <td id=\"T_e9577_row0_col27\" class=\"data row0 col27\" >0.94</td>\n",
       "      <td id=\"T_e9577_row0_col28\" class=\"data row0 col28\" >5.38</td>\n",
       "      <td id=\"T_e9577_row0_col29\" class=\"data row0 col29\" >0.94</td>\n",
       "      <td id=\"T_e9577_row0_col30\" class=\"data row0 col30\" >5.33</td>\n",
       "      <td id=\"T_e9577_row0_col31\" class=\"data row0 col31\" >1.00</td>\n",
       "      <td id=\"T_e9577_row0_col32\" class=\"data row0 col32\" >-0.20</td>\n",
       "      <td id=\"T_e9577_row0_col33\" class=\"data row0 col33\" >0.99</td>\n",
       "      <td id=\"T_e9577_row0_col34\" class=\"data row0 col34\" >0.65</td>\n",
       "      <td id=\"T_e9577_row0_col35\" class=\"data row0 col35\" >0.97</td>\n",
       "      <td id=\"T_e9577_row0_col36\" class=\"data row0 col36\" >2.12</td>\n",
       "      <td id=\"T_e9577_row0_col37\" class=\"data row0 col37\" >338068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e9577_row1_col0\" class=\"data row1 col0\" >Bot</td>\n",
       "      <td id=\"T_e9577_row1_col1\" class=\"data row1 col1\" >0.03</td>\n",
       "      <td id=\"T_e9577_row1_col2\" class=\"data row1 col2\" >2.30</td>\n",
       "      <td id=\"T_e9577_row1_col3\" class=\"data row1 col3\" >841.00</td>\n",
       "      <td id=\"T_e9577_row1_col4\" class=\"data row1 col4\" >0.29</td>\n",
       "      <td id=\"T_e9577_row1_col5\" class=\"data row1 col5\" >0.46</td>\n",
       "      <td id=\"T_e9577_row1_col6\" class=\"data row1 col6\" >-58.79</td>\n",
       "      <td id=\"T_e9577_row1_col7\" class=\"data row1 col7\" >0.52</td>\n",
       "      <td id=\"T_e9577_row1_col8\" class=\"data row1 col8\" >-80.63</td>\n",
       "      <td id=\"T_e9577_row1_col9\" class=\"data row1 col9\" >0.35</td>\n",
       "      <td id=\"T_e9577_row1_col10\" class=\"data row1 col10\" >-22.30</td>\n",
       "      <td id=\"T_e9577_row1_col11\" class=\"data row1 col11\" >0.05</td>\n",
       "      <td id=\"T_e9577_row1_col12\" class=\"data row1 col12\" >84.20</td>\n",
       "      <td id=\"T_e9577_row1_col13\" class=\"data row1 col13\" >0.25</td>\n",
       "      <td id=\"T_e9577_row1_col14\" class=\"data row1 col14\" >11.72</td>\n",
       "      <td id=\"T_e9577_row1_col15\" class=\"data row1 col15\" >0.96</td>\n",
       "      <td id=\"T_e9577_row1_col16\" class=\"data row1 col16\" >0.84</td>\n",
       "      <td id=\"T_e9577_row1_col17\" class=\"data row1 col17\" >11.74</td>\n",
       "      <td id=\"T_e9577_row1_col18\" class=\"data row1 col18\" >0.86</td>\n",
       "      <td id=\"T_e9577_row1_col19\" class=\"data row1 col19\" >10.53</td>\n",
       "      <td id=\"T_e9577_row1_col20\" class=\"data row1 col20\" >0.91</td>\n",
       "      <td id=\"T_e9577_row1_col21\" class=\"data row1 col21\" >4.86</td>\n",
       "      <td id=\"T_e9577_row1_col22\" class=\"data row1 col22\" >0.71</td>\n",
       "      <td id=\"T_e9577_row1_col23\" class=\"data row1 col23\" >25.51</td>\n",
       "      <td id=\"T_e9577_row1_col24\" class=\"data row1 col24\" >0.83</td>\n",
       "      <td id=\"T_e9577_row1_col25\" class=\"data row1 col25\" >13.36</td>\n",
       "      <td id=\"T_e9577_row1_col26\" class=\"data row1 col26\" >0.44</td>\n",
       "      <td id=\"T_e9577_row1_col27\" class=\"data row1 col27\" >0.59</td>\n",
       "      <td id=\"T_e9577_row1_col28\" class=\"data row1 col28\" >-34.07</td>\n",
       "      <td id=\"T_e9577_row1_col29\" class=\"data row1 col29\" >0.65</td>\n",
       "      <td id=\"T_e9577_row1_col30\" class=\"data row1 col30\" >-46.24</td>\n",
       "      <td id=\"T_e9577_row1_col31\" class=\"data row1 col31\" >0.51</td>\n",
       "      <td id=\"T_e9577_row1_col32\" class=\"data row1 col32\" >-14.74</td>\n",
       "      <td id=\"T_e9577_row1_col33\" class=\"data row1 col33\" >0.09</td>\n",
       "      <td id=\"T_e9577_row1_col34\" class=\"data row1 col34\" >80.69</td>\n",
       "      <td id=\"T_e9577_row1_col35\" class=\"data row1 col35\" >0.39</td>\n",
       "      <td id=\"T_e9577_row1_col36\" class=\"data row1 col36\" >12.10</td>\n",
       "      <td id=\"T_e9577_row1_col37\" class=\"data row1 col37\" >258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e9577_row2_col0\" class=\"data row2 col0\" >DDoS</td>\n",
       "      <td id=\"T_e9577_row2_col1\" class=\"data row2 col1\" >0.00</td>\n",
       "      <td id=\"T_e9577_row2_col2\" class=\"data row2 col2\" >768.38</td>\n",
       "      <td id=\"T_e9577_row2_col3\" class=\"data row2 col3\" >999999.00</td>\n",
       "      <td id=\"T_e9577_row2_col4\" class=\"data row2 col4\" >1.00</td>\n",
       "      <td id=\"T_e9577_row2_col5\" class=\"data row2 col5\" >1.00</td>\n",
       "      <td id=\"T_e9577_row2_col6\" class=\"data row2 col6\" >-0.03</td>\n",
       "      <td id=\"T_e9577_row2_col7\" class=\"data row2 col7\" >1.00</td>\n",
       "      <td id=\"T_e9577_row2_col8\" class=\"data row2 col8\" >0.02</td>\n",
       "      <td id=\"T_e9577_row2_col9\" class=\"data row2 col9\" >1.00</td>\n",
       "      <td id=\"T_e9577_row2_col10\" class=\"data row2 col10\" >-0.08</td>\n",
       "      <td id=\"T_e9577_row2_col11\" class=\"data row2 col11\" >0.99</td>\n",
       "      <td id=\"T_e9577_row2_col12\" class=\"data row2 col12\" >1.09</td>\n",
       "      <td id=\"T_e9577_row2_col13\" class=\"data row2 col13\" >1.00</td>\n",
       "      <td id=\"T_e9577_row2_col14\" class=\"data row2 col14\" >-0.08</td>\n",
       "      <td id=\"T_e9577_row2_col15\" class=\"data row2 col15\" >0.98</td>\n",
       "      <td id=\"T_e9577_row2_col16\" class=\"data row2 col16\" >0.38</td>\n",
       "      <td id=\"T_e9577_row2_col17\" class=\"data row2 col17\" >61.40</td>\n",
       "      <td id=\"T_e9577_row2_col18\" class=\"data row2 col18\" >0.38</td>\n",
       "      <td id=\"T_e9577_row2_col19\" class=\"data row2 col19\" >61.40</td>\n",
       "      <td id=\"T_e9577_row2_col20\" class=\"data row2 col20\" >0.98</td>\n",
       "      <td id=\"T_e9577_row2_col21\" class=\"data row2 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row2_col22\" class=\"data row2 col22\" >0.93</td>\n",
       "      <td id=\"T_e9577_row2_col23\" class=\"data row2 col23\" >5.10</td>\n",
       "      <td id=\"T_e9577_row2_col24\" class=\"data row2 col24\" >0.98</td>\n",
       "      <td id=\"T_e9577_row2_col25\" class=\"data row2 col25\" >0.00</td>\n",
       "      <td id=\"T_e9577_row2_col26\" class=\"data row2 col26\" >0.99</td>\n",
       "      <td id=\"T_e9577_row2_col27\" class=\"data row2 col27\" >0.55</td>\n",
       "      <td id=\"T_e9577_row2_col28\" class=\"data row2 col28\" >44.52</td>\n",
       "      <td id=\"T_e9577_row2_col29\" class=\"data row2 col29\" >0.55</td>\n",
       "      <td id=\"T_e9577_row2_col30\" class=\"data row2 col30\" >44.53</td>\n",
       "      <td id=\"T_e9577_row2_col31\" class=\"data row2 col31\" >0.99</td>\n",
       "      <td id=\"T_e9577_row2_col32\" class=\"data row2 col32\" >-0.04</td>\n",
       "      <td id=\"T_e9577_row2_col33\" class=\"data row2 col33\" >0.96</td>\n",
       "      <td id=\"T_e9577_row2_col34\" class=\"data row2 col34\" >3.16</td>\n",
       "      <td id=\"T_e9577_row2_col35\" class=\"data row2 col35\" >0.99</td>\n",
       "      <td id=\"T_e9577_row2_col36\" class=\"data row2 col36\" >-0.04</td>\n",
       "      <td id=\"T_e9577_row2_col37\" class=\"data row2 col37\" >19978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e9577_row3_col0\" class=\"data row3 col0\" >DoS GoldenEye</td>\n",
       "      <td id=\"T_e9577_row3_col1\" class=\"data row3 col1\" >514.57</td>\n",
       "      <td id=\"T_e9577_row3_col2\" class=\"data row3 col2\" >694.67</td>\n",
       "      <td id=\"T_e9577_row3_col3\" class=\"data row3 col3\" >930.93</td>\n",
       "      <td id=\"T_e9577_row3_col4\" class=\"data row3 col4\" >0.99</td>\n",
       "      <td id=\"T_e9577_row3_col5\" class=\"data row3 col5\" >0.99</td>\n",
       "      <td id=\"T_e9577_row3_col6\" class=\"data row3 col6\" >-0.15</td>\n",
       "      <td id=\"T_e9577_row3_col7\" class=\"data row3 col7\" >0.99</td>\n",
       "      <td id=\"T_e9577_row3_col8\" class=\"data row3 col8\" >-0.28</td>\n",
       "      <td id=\"T_e9577_row3_col9\" class=\"data row3 col9\" >0.99</td>\n",
       "      <td id=\"T_e9577_row3_col10\" class=\"data row3 col10\" >-0.14</td>\n",
       "      <td id=\"T_e9577_row3_col11\" class=\"data row3 col11\" >0.98</td>\n",
       "      <td id=\"T_e9577_row3_col12\" class=\"data row3 col12\" >1.12</td>\n",
       "      <td id=\"T_e9577_row3_col13\" class=\"data row3 col13\" >0.98</td>\n",
       "      <td id=\"T_e9577_row3_col14\" class=\"data row3 col14\" >0.89</td>\n",
       "      <td id=\"T_e9577_row3_col15\" class=\"data row3 col15\" >1.00</td>\n",
       "      <td id=\"T_e9577_row3_col16\" class=\"data row3 col16\" >0.70</td>\n",
       "      <td id=\"T_e9577_row3_col17\" class=\"data row3 col17\" >30.09</td>\n",
       "      <td id=\"T_e9577_row3_col18\" class=\"data row3 col18\" >0.70</td>\n",
       "      <td id=\"T_e9577_row3_col19\" class=\"data row3 col19\" >30.09</td>\n",
       "      <td id=\"T_e9577_row3_col20\" class=\"data row3 col20\" >1.00</td>\n",
       "      <td id=\"T_e9577_row3_col21\" class=\"data row3 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row3_col22\" class=\"data row3 col22\" >1.00</td>\n",
       "      <td id=\"T_e9577_row3_col23\" class=\"data row3 col23\" >0.00</td>\n",
       "      <td id=\"T_e9577_row3_col24\" class=\"data row3 col24\" >1.00</td>\n",
       "      <td id=\"T_e9577_row3_col25\" class=\"data row3 col25\" >0.00</td>\n",
       "      <td id=\"T_e9577_row3_col26\" class=\"data row3 col26\" >0.99</td>\n",
       "      <td id=\"T_e9577_row3_col27\" class=\"data row3 col27\" >0.82</td>\n",
       "      <td id=\"T_e9577_row3_col28\" class=\"data row3 col28\" >17.57</td>\n",
       "      <td id=\"T_e9577_row3_col29\" class=\"data row3 col29\" >0.82</td>\n",
       "      <td id=\"T_e9577_row3_col30\" class=\"data row3 col30\" >17.52</td>\n",
       "      <td id=\"T_e9577_row3_col31\" class=\"data row3 col31\" >0.99</td>\n",
       "      <td id=\"T_e9577_row3_col32\" class=\"data row3 col32\" >-0.07</td>\n",
       "      <td id=\"T_e9577_row3_col33\" class=\"data row3 col33\" >0.99</td>\n",
       "      <td id=\"T_e9577_row3_col34\" class=\"data row3 col34\" >0.57</td>\n",
       "      <td id=\"T_e9577_row3_col35\" class=\"data row3 col35\" >0.99</td>\n",
       "      <td id=\"T_e9577_row3_col36\" class=\"data row3 col36\" >0.45</td>\n",
       "      <td id=\"T_e9577_row3_col37\" class=\"data row3 col37\" >2084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e9577_row4_col0\" class=\"data row4 col0\" >DoS Hulk</td>\n",
       "      <td id=\"T_e9577_row4_col1\" class=\"data row4 col1\" >0.00</td>\n",
       "      <td id=\"T_e9577_row4_col2\" class=\"data row4 col2\" >852.13</td>\n",
       "      <td id=\"T_e9577_row4_col3\" class=\"data row4 col3\" >998000.00</td>\n",
       "      <td id=\"T_e9577_row4_col4\" class=\"data row4 col4\" >0.99</td>\n",
       "      <td id=\"T_e9577_row4_col5\" class=\"data row4 col5\" >0.99</td>\n",
       "      <td id=\"T_e9577_row4_col6\" class=\"data row4 col6\" >0.01</td>\n",
       "      <td id=\"T_e9577_row4_col7\" class=\"data row4 col7\" >1.00</td>\n",
       "      <td id=\"T_e9577_row4_col8\" class=\"data row4 col8\" >-1.39</td>\n",
       "      <td id=\"T_e9577_row4_col9\" class=\"data row4 col9\" >0.99</td>\n",
       "      <td id=\"T_e9577_row4_col10\" class=\"data row4 col10\" >-0.04</td>\n",
       "      <td id=\"T_e9577_row4_col11\" class=\"data row4 col11\" >0.95</td>\n",
       "      <td id=\"T_e9577_row4_col12\" class=\"data row4 col12\" >3.95</td>\n",
       "      <td id=\"T_e9577_row4_col13\" class=\"data row4 col13\" >0.98</td>\n",
       "      <td id=\"T_e9577_row4_col14\" class=\"data row4 col14\" >0.06</td>\n",
       "      <td id=\"T_e9577_row4_col15\" class=\"data row4 col15\" >1.00</td>\n",
       "      <td id=\"T_e9577_row4_col16\" class=\"data row4 col16\" >0.89</td>\n",
       "      <td id=\"T_e9577_row4_col17\" class=\"data row4 col17\" >11.45</td>\n",
       "      <td id=\"T_e9577_row4_col18\" class=\"data row4 col18\" >0.92</td>\n",
       "      <td id=\"T_e9577_row4_col19\" class=\"data row4 col19\" >8.44</td>\n",
       "      <td id=\"T_e9577_row4_col20\" class=\"data row4 col20\" >1.00</td>\n",
       "      <td id=\"T_e9577_row4_col21\" class=\"data row4 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row4_col22\" class=\"data row4 col22\" >1.00</td>\n",
       "      <td id=\"T_e9577_row4_col23\" class=\"data row4 col23\" >0.00</td>\n",
       "      <td id=\"T_e9577_row4_col24\" class=\"data row4 col24\" >0.97</td>\n",
       "      <td id=\"T_e9577_row4_col25\" class=\"data row4 col25\" >2.84</td>\n",
       "      <td id=\"T_e9577_row4_col26\" class=\"data row4 col26\" >0.99</td>\n",
       "      <td id=\"T_e9577_row4_col27\" class=\"data row4 col27\" >0.93</td>\n",
       "      <td id=\"T_e9577_row4_col28\" class=\"data row4 col28\" >6.03</td>\n",
       "      <td id=\"T_e9577_row4_col29\" class=\"data row4 col29\" >0.96</td>\n",
       "      <td id=\"T_e9577_row4_col30\" class=\"data row4 col30\" >3.74</td>\n",
       "      <td id=\"T_e9577_row4_col31\" class=\"data row4 col31\" >0.99</td>\n",
       "      <td id=\"T_e9577_row4_col32\" class=\"data row4 col32\" >-0.02</td>\n",
       "      <td id=\"T_e9577_row4_col33\" class=\"data row4 col33\" >0.97</td>\n",
       "      <td id=\"T_e9577_row4_col34\" class=\"data row4 col34\" >2.03</td>\n",
       "      <td id=\"T_e9577_row4_col35\" class=\"data row4 col35\" >0.98</td>\n",
       "      <td id=\"T_e9577_row4_col36\" class=\"data row4 col36\" >1.46</td>\n",
       "      <td id=\"T_e9577_row4_col37\" class=\"data row4 col37\" >33233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e9577_row5_col0\" class=\"data row5 col0\" >DoS Slowhttptest</td>\n",
       "      <td id=\"T_e9577_row5_col1\" class=\"data row5 col1\" >1.90</td>\n",
       "      <td id=\"T_e9577_row5_col2\" class=\"data row5 col2\" >252.00</td>\n",
       "      <td id=\"T_e9577_row5_col3\" class=\"data row5 col3\" >9045.12</td>\n",
       "      <td id=\"T_e9577_row5_col4\" class=\"data row5 col4\" >0.98</td>\n",
       "      <td id=\"T_e9577_row5_col5\" class=\"data row5 col5\" >0.93</td>\n",
       "      <td id=\"T_e9577_row5_col6\" class=\"data row5 col6\" >5.01</td>\n",
       "      <td id=\"T_e9577_row5_col7\" class=\"data row5 col7\" >0.85</td>\n",
       "      <td id=\"T_e9577_row5_col8\" class=\"data row5 col8\" >13.09</td>\n",
       "      <td id=\"T_e9577_row5_col9\" class=\"data row5 col9\" >0.95</td>\n",
       "      <td id=\"T_e9577_row5_col10\" class=\"data row5 col10\" >3.22</td>\n",
       "      <td id=\"T_e9577_row5_col11\" class=\"data row5 col11\" >0.97</td>\n",
       "      <td id=\"T_e9577_row5_col12\" class=\"data row5 col12\" >0.52</td>\n",
       "      <td id=\"T_e9577_row5_col13\" class=\"data row5 col13\" >0.88</td>\n",
       "      <td id=\"T_e9577_row5_col14\" class=\"data row5 col14\" >9.67</td>\n",
       "      <td id=\"T_e9577_row5_col15\" class=\"data row5 col15\" >0.47</td>\n",
       "      <td id=\"T_e9577_row5_col16\" class=\"data row5 col16\" >1.00</td>\n",
       "      <td id=\"T_e9577_row5_col17\" class=\"data row5 col17\" >-114.47</td>\n",
       "      <td id=\"T_e9577_row5_col18\" class=\"data row5 col18\" >1.00</td>\n",
       "      <td id=\"T_e9577_row5_col19\" class=\"data row5 col19\" >-114.47</td>\n",
       "      <td id=\"T_e9577_row5_col20\" class=\"data row5 col20\" >0.47</td>\n",
       "      <td id=\"T_e9577_row5_col21\" class=\"data row5 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row5_col22\" class=\"data row5 col22\" >1.00</td>\n",
       "      <td id=\"T_e9577_row5_col23\" class=\"data row5 col23\" >-114.47</td>\n",
       "      <td id=\"T_e9577_row5_col24\" class=\"data row5 col24\" >1.00</td>\n",
       "      <td id=\"T_e9577_row5_col25\" class=\"data row5 col25\" >-114.47</td>\n",
       "      <td id=\"T_e9577_row5_col26\" class=\"data row5 col26\" >0.63</td>\n",
       "      <td id=\"T_e9577_row5_col27\" class=\"data row5 col27\" >0.96</td>\n",
       "      <td id=\"T_e9577_row5_col28\" class=\"data row5 col28\" >-52.50</td>\n",
       "      <td id=\"T_e9577_row5_col29\" class=\"data row5 col29\" >0.92</td>\n",
       "      <td id=\"T_e9577_row5_col30\" class=\"data row5 col30\" >-45.49</td>\n",
       "      <td id=\"T_e9577_row5_col31\" class=\"data row5 col31\" >0.62</td>\n",
       "      <td id=\"T_e9577_row5_col32\" class=\"data row5 col32\" >1.06</td>\n",
       "      <td id=\"T_e9577_row5_col33\" class=\"data row5 col33\" >0.99</td>\n",
       "      <td id=\"T_e9577_row5_col34\" class=\"data row5 col34\" >-56.16</td>\n",
       "      <td id=\"T_e9577_row5_col35\" class=\"data row5 col35\" >0.94</td>\n",
       "      <td id=\"T_e9577_row5_col36\" class=\"data row5 col36\" >-48.53</td>\n",
       "      <td id=\"T_e9577_row5_col37\" class=\"data row5 col37\" >1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e9577_row6_col0\" class=\"data row6 col0\" >DoS slowloris</td>\n",
       "      <td id=\"T_e9577_row6_col1\" class=\"data row6 col1\" >31.61</td>\n",
       "      <td id=\"T_e9577_row6_col2\" class=\"data row6 col2\" >173.20</td>\n",
       "      <td id=\"T_e9577_row6_col3\" class=\"data row6 col3\" >754.33</td>\n",
       "      <td id=\"T_e9577_row6_col4\" class=\"data row6 col4\" >0.96</td>\n",
       "      <td id=\"T_e9577_row6_col5\" class=\"data row6 col5\" >0.94</td>\n",
       "      <td id=\"T_e9577_row6_col6\" class=\"data row6 col6\" >2.43</td>\n",
       "      <td id=\"T_e9577_row6_col7\" class=\"data row6 col7\" >0.79</td>\n",
       "      <td id=\"T_e9577_row6_col8\" class=\"data row6 col8\" >17.38</td>\n",
       "      <td id=\"T_e9577_row6_col9\" class=\"data row6 col9\" >0.96</td>\n",
       "      <td id=\"T_e9577_row6_col10\" class=\"data row6 col10\" >-0.11</td>\n",
       "      <td id=\"T_e9577_row6_col11\" class=\"data row6 col11\" >0.92</td>\n",
       "      <td id=\"T_e9577_row6_col12\" class=\"data row6 col12\" >4.76</td>\n",
       "      <td id=\"T_e9577_row6_col13\" class=\"data row6 col13\" >0.94</td>\n",
       "      <td id=\"T_e9577_row6_col14\" class=\"data row6 col14\" >1.81</td>\n",
       "      <td id=\"T_e9577_row6_col15\" class=\"data row6 col15\" >1.00</td>\n",
       "      <td id=\"T_e9577_row6_col16\" class=\"data row6 col16\" >0.59</td>\n",
       "      <td id=\"T_e9577_row6_col17\" class=\"data row6 col17\" >40.76</td>\n",
       "      <td id=\"T_e9577_row6_col18\" class=\"data row6 col18\" >0.59</td>\n",
       "      <td id=\"T_e9577_row6_col19\" class=\"data row6 col19\" >40.76</td>\n",
       "      <td id=\"T_e9577_row6_col20\" class=\"data row6 col20\" >1.00</td>\n",
       "      <td id=\"T_e9577_row6_col21\" class=\"data row6 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row6_col22\" class=\"data row6 col22\" >1.00</td>\n",
       "      <td id=\"T_e9577_row6_col23\" class=\"data row6 col23\" >0.00</td>\n",
       "      <td id=\"T_e9577_row6_col24\" class=\"data row6 col24\" >0.70</td>\n",
       "      <td id=\"T_e9577_row6_col25\" class=\"data row6 col25\" >30.25</td>\n",
       "      <td id=\"T_e9577_row6_col26\" class=\"data row6 col26\" >0.98</td>\n",
       "      <td id=\"T_e9577_row6_col27\" class=\"data row6 col27\" >0.73</td>\n",
       "      <td id=\"T_e9577_row6_col28\" class=\"data row6 col28\" >25.92</td>\n",
       "      <td id=\"T_e9577_row6_col29\" class=\"data row6 col29\" >0.68</td>\n",
       "      <td id=\"T_e9577_row6_col30\" class=\"data row6 col30\" >30.77</td>\n",
       "      <td id=\"T_e9577_row6_col31\" class=\"data row6 col31\" >0.98</td>\n",
       "      <td id=\"T_e9577_row6_col32\" class=\"data row6 col32\" >-0.06</td>\n",
       "      <td id=\"T_e9577_row6_col33\" class=\"data row6 col33\" >0.96</td>\n",
       "      <td id=\"T_e9577_row6_col34\" class=\"data row6 col34\" >2.48</td>\n",
       "      <td id=\"T_e9577_row6_col35\" class=\"data row6 col35\" >0.80</td>\n",
       "      <td id=\"T_e9577_row6_col36\" class=\"data row6 col36\" >18.17</td>\n",
       "      <td id=\"T_e9577_row6_col37\" class=\"data row6 col37\" >866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e9577_row7_col0\" class=\"data row7 col0\" >FTP-Patator</td>\n",
       "      <td id=\"T_e9577_row7_col1\" class=\"data row7 col1\" >0.00</td>\n",
       "      <td id=\"T_e9577_row7_col2\" class=\"data row7 col2\" >87.85</td>\n",
       "      <td id=\"T_e9577_row7_col3\" class=\"data row7 col3\" >46655.95</td>\n",
       "      <td id=\"T_e9577_row7_col4\" class=\"data row7 col4\" >0.93</td>\n",
       "      <td id=\"T_e9577_row7_col5\" class=\"data row7 col5\" >0.98</td>\n",
       "      <td id=\"T_e9577_row7_col6\" class=\"data row7 col6\" >-5.40</td>\n",
       "      <td id=\"T_e9577_row7_col7\" class=\"data row7 col7\" >0.98</td>\n",
       "      <td id=\"T_e9577_row7_col8\" class=\"data row7 col8\" >-4.96</td>\n",
       "      <td id=\"T_e9577_row7_col9\" class=\"data row7 col9\" >0.98</td>\n",
       "      <td id=\"T_e9577_row7_col10\" class=\"data row7 col10\" >-4.79</td>\n",
       "      <td id=\"T_e9577_row7_col11\" class=\"data row7 col11\" >0.86</td>\n",
       "      <td id=\"T_e9577_row7_col12\" class=\"data row7 col12\" >7.27</td>\n",
       "      <td id=\"T_e9577_row7_col13\" class=\"data row7 col13\" >0.98</td>\n",
       "      <td id=\"T_e9577_row7_col14\" class=\"data row7 col14\" >-4.79</td>\n",
       "      <td id=\"T_e9577_row7_col15\" class=\"data row7 col15\" >1.00</td>\n",
       "      <td id=\"T_e9577_row7_col16\" class=\"data row7 col16\" >0.69</td>\n",
       "      <td id=\"T_e9577_row7_col17\" class=\"data row7 col17\" >31.03</td>\n",
       "      <td id=\"T_e9577_row7_col18\" class=\"data row7 col18\" >0.48</td>\n",
       "      <td id=\"T_e9577_row7_col19\" class=\"data row7 col19\" >52.23</td>\n",
       "      <td id=\"T_e9577_row7_col20\" class=\"data row7 col20\" >1.00</td>\n",
       "      <td id=\"T_e9577_row7_col21\" class=\"data row7 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row7_col22\" class=\"data row7 col22\" >1.00</td>\n",
       "      <td id=\"T_e9577_row7_col23\" class=\"data row7 col23\" >0.00</td>\n",
       "      <td id=\"T_e9577_row7_col24\" class=\"data row7 col24\" >1.00</td>\n",
       "      <td id=\"T_e9577_row7_col25\" class=\"data row7 col25\" >0.00</td>\n",
       "      <td id=\"T_e9577_row7_col26\" class=\"data row7 col26\" >0.96</td>\n",
       "      <td id=\"T_e9577_row7_col27\" class=\"data row7 col27\" >0.81</td>\n",
       "      <td id=\"T_e9577_row7_col28\" class=\"data row7 col28\" >16.01</td>\n",
       "      <td id=\"T_e9577_row7_col29\" class=\"data row7 col29\" >0.64</td>\n",
       "      <td id=\"T_e9577_row7_col30\" class=\"data row7 col30\" >33.48</td>\n",
       "      <td id=\"T_e9577_row7_col31\" class=\"data row7 col31\" >0.99</td>\n",
       "      <td id=\"T_e9577_row7_col32\" class=\"data row7 col32\" >-2.42</td>\n",
       "      <td id=\"T_e9577_row7_col33\" class=\"data row7 col33\" >0.93</td>\n",
       "      <td id=\"T_e9577_row7_col34\" class=\"data row7 col34\" >3.90</td>\n",
       "      <td id=\"T_e9577_row7_col35\" class=\"data row7 col35\" >0.99</td>\n",
       "      <td id=\"T_e9577_row7_col36\" class=\"data row7 col36\" >-2.42</td>\n",
       "      <td id=\"T_e9577_row7_col37\" class=\"data row7 col37\" >1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e9577_row8_col0\" class=\"data row8 col0\" >Heartbleed</td>\n",
       "      <td id=\"T_e9577_row8_col1\" class=\"data row8 col1\" >1.00</td>\n",
       "      <td id=\"T_e9577_row8_col2\" class=\"data row8 col2\" >1.00</td>\n",
       "      <td id=\"T_e9577_row8_col3\" class=\"data row8 col3\" >1.00</td>\n",
       "      <td id=\"T_e9577_row8_col4\" class=\"data row8 col4\" >0.22</td>\n",
       "      <td id=\"T_e9577_row8_col5\" class=\"data row8 col5\" >0.17</td>\n",
       "      <td id=\"T_e9577_row8_col6\" class=\"data row8 col6\" >25.00</td>\n",
       "      <td id=\"T_e9577_row8_col7\" class=\"data row8 col7\" >0.67</td>\n",
       "      <td id=\"T_e9577_row8_col8\" class=\"data row8 col8\" >-200.00</td>\n",
       "      <td id=\"T_e9577_row8_col9\" class=\"data row8 col9\" >0.18</td>\n",
       "      <td id=\"T_e9577_row8_col10\" class=\"data row8 col10\" >18.18</td>\n",
       "      <td id=\"T_e9577_row8_col11\" class=\"data row8 col11\" >0.02</td>\n",
       "      <td id=\"T_e9577_row8_col12\" class=\"data row8 col12\" >91.96</td>\n",
       "      <td id=\"T_e9577_row8_col13\" class=\"data row8 col13\" >0.50</td>\n",
       "      <td id=\"T_e9577_row8_col14\" class=\"data row8 col14\" >-125.00</td>\n",
       "      <td id=\"T_e9577_row8_col15\" class=\"data row8 col15\" >1.00</td>\n",
       "      <td id=\"T_e9577_row8_col16\" class=\"data row8 col16\" >0.50</td>\n",
       "      <td id=\"T_e9577_row8_col17\" class=\"data row8 col17\" >50.00</td>\n",
       "      <td id=\"T_e9577_row8_col18\" class=\"data row8 col18\" >1.00</td>\n",
       "      <td id=\"T_e9577_row8_col19\" class=\"data row8 col19\" >0.00</td>\n",
       "      <td id=\"T_e9577_row8_col20\" class=\"data row8 col20\" >1.00</td>\n",
       "      <td id=\"T_e9577_row8_col21\" class=\"data row8 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row8_col22\" class=\"data row8 col22\" >0.50</td>\n",
       "      <td id=\"T_e9577_row8_col23\" class=\"data row8 col23\" >50.00</td>\n",
       "      <td id=\"T_e9577_row8_col24\" class=\"data row8 col24\" >1.00</td>\n",
       "      <td id=\"T_e9577_row8_col25\" class=\"data row8 col25\" >0.00</td>\n",
       "      <td id=\"T_e9577_row8_col26\" class=\"data row8 col26\" >0.36</td>\n",
       "      <td id=\"T_e9577_row8_col27\" class=\"data row8 col27\" >0.25</td>\n",
       "      <td id=\"T_e9577_row8_col28\" class=\"data row8 col28\" >31.25</td>\n",
       "      <td id=\"T_e9577_row8_col29\" class=\"data row8 col29\" >0.80</td>\n",
       "      <td id=\"T_e9577_row8_col30\" class=\"data row8 col30\" >-120.00</td>\n",
       "      <td id=\"T_e9577_row8_col31\" class=\"data row8 col31\" >0.31</td>\n",
       "      <td id=\"T_e9577_row8_col32\" class=\"data row8 col32\" >15.38</td>\n",
       "      <td id=\"T_e9577_row8_col33\" class=\"data row8 col33\" >0.03</td>\n",
       "      <td id=\"T_e9577_row8_col34\" class=\"data row8 col34\" >90.52</td>\n",
       "      <td id=\"T_e9577_row8_col35\" class=\"data row8 col35\" >0.67</td>\n",
       "      <td id=\"T_e9577_row8_col36\" class=\"data row8 col36\" >-83.33</td>\n",
       "      <td id=\"T_e9577_row8_col37\" class=\"data row8 col37\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e9577_row9_col0\" class=\"data row9 col0\" >Infiltration</td>\n",
       "      <td id=\"T_e9577_row9_col1\" class=\"data row9 col1\" >1.00</td>\n",
       "      <td id=\"T_e9577_row9_col2\" class=\"data row9 col2\" >1.00</td>\n",
       "      <td id=\"T_e9577_row9_col3\" class=\"data row9 col3\" >1.00</td>\n",
       "      <td id=\"T_e9577_row9_col4\" class=\"data row9 col4\" >0.03</td>\n",
       "      <td id=\"T_e9577_row9_col5\" class=\"data row9 col5\" >0.03</td>\n",
       "      <td id=\"T_e9577_row9_col6\" class=\"data row9 col6\" >-19.66</td>\n",
       "      <td id=\"T_e9577_row9_col7\" class=\"data row9 col7\" >0.03</td>\n",
       "      <td id=\"T_e9577_row9_col8\" class=\"data row9 col8\" >-21.74</td>\n",
       "      <td id=\"T_e9577_row9_col9\" class=\"data row9 col9\" >0.03</td>\n",
       "      <td id=\"T_e9577_row9_col10\" class=\"data row9 col10\" >-16.67</td>\n",
       "      <td id=\"T_e9577_row9_col11\" class=\"data row9 col11\" >0.02</td>\n",
       "      <td id=\"T_e9577_row9_col12\" class=\"data row9 col12\" >25.53</td>\n",
       "      <td id=\"T_e9577_row9_col13\" class=\"data row9 col13\" >0.02</td>\n",
       "      <td id=\"T_e9577_row9_col14\" class=\"data row9 col14\" >39.13</td>\n",
       "      <td id=\"T_e9577_row9_col15\" class=\"data row9 col15\" >0.80</td>\n",
       "      <td id=\"T_e9577_row9_col16\" class=\"data row9 col16\" >0.80</td>\n",
       "      <td id=\"T_e9577_row9_col17\" class=\"data row9 col17\" >0.00</td>\n",
       "      <td id=\"T_e9577_row9_col18\" class=\"data row9 col18\" >0.80</td>\n",
       "      <td id=\"T_e9577_row9_col19\" class=\"data row9 col19\" >0.00</td>\n",
       "      <td id=\"T_e9577_row9_col20\" class=\"data row9 col20\" >0.80</td>\n",
       "      <td id=\"T_e9577_row9_col21\" class=\"data row9 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row9_col22\" class=\"data row9 col22\" >0.80</td>\n",
       "      <td id=\"T_e9577_row9_col23\" class=\"data row9 col23\" >0.00</td>\n",
       "      <td id=\"T_e9577_row9_col24\" class=\"data row9 col24\" >0.40</td>\n",
       "      <td id=\"T_e9577_row9_col25\" class=\"data row9 col25\" >50.00</td>\n",
       "      <td id=\"T_e9577_row9_col26\" class=\"data row9 col26\" >0.06</td>\n",
       "      <td id=\"T_e9577_row9_col27\" class=\"data row9 col27\" >0.07</td>\n",
       "      <td id=\"T_e9577_row9_col28\" class=\"data row9 col28\" >-18.85</td>\n",
       "      <td id=\"T_e9577_row9_col29\" class=\"data row9 col29\" >0.07</td>\n",
       "      <td id=\"T_e9577_row9_col30\" class=\"data row9 col30\" >-20.83</td>\n",
       "      <td id=\"T_e9577_row9_col31\" class=\"data row9 col31\" >0.06</td>\n",
       "      <td id=\"T_e9577_row9_col32\" class=\"data row9 col32\" >-16.00</td>\n",
       "      <td id=\"T_e9577_row9_col33\" class=\"data row9 col33\" >0.04</td>\n",
       "      <td id=\"T_e9577_row9_col34\" class=\"data row9 col34\" >24.87</td>\n",
       "      <td id=\"T_e9577_row9_col35\" class=\"data row9 col35\" >0.03</td>\n",
       "      <td id=\"T_e9577_row9_col36\" class=\"data row9 col36\" >39.58</td>\n",
       "      <td id=\"T_e9577_row9_col37\" class=\"data row9 col37\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_e9577_row10_col0\" class=\"data row10 col0\" >PortScan</td>\n",
       "      <td id=\"T_e9577_row10_col1\" class=\"data row10 col1\" >0.00</td>\n",
       "      <td id=\"T_e9577_row10_col2\" class=\"data row10 col2\" >830.69</td>\n",
       "      <td id=\"T_e9577_row10_col3\" class=\"data row10 col3\" >996003.00</td>\n",
       "      <td id=\"T_e9577_row10_col4\" class=\"data row10 col4\" >0.94</td>\n",
       "      <td id=\"T_e9577_row10_col5\" class=\"data row10 col5\" >0.00</td>\n",
       "      <td id=\"T_e9577_row10_col6\" class=\"data row10 col6\" >100.00</td>\n",
       "      <td id=\"T_e9577_row10_col7\" class=\"data row10 col7\" >0.00</td>\n",
       "      <td id=\"T_e9577_row10_col8\" class=\"data row10 col8\" >100.00</td>\n",
       "      <td id=\"T_e9577_row10_col9\" class=\"data row10 col9\" >1.00</td>\n",
       "      <td id=\"T_e9577_row10_col10\" class=\"data row10 col10\" >-6.59</td>\n",
       "      <td id=\"T_e9577_row10_col11\" class=\"data row10 col11\" >0.91</td>\n",
       "      <td id=\"T_e9577_row10_col12\" class=\"data row10 col12\" >3.04</td>\n",
       "      <td id=\"T_e9577_row10_col13\" class=\"data row10 col13\" >0.88</td>\n",
       "      <td id=\"T_e9577_row10_col14\" class=\"data row10 col14\" >5.72</td>\n",
       "      <td id=\"T_e9577_row10_col15\" class=\"data row10 col15\" >0.99</td>\n",
       "      <td id=\"T_e9577_row10_col16\" class=\"data row10 col16\" >0.00</td>\n",
       "      <td id=\"T_e9577_row10_col17\" class=\"data row10 col17\" >100.00</td>\n",
       "      <td id=\"T_e9577_row10_col18\" class=\"data row10 col18\" >0.00</td>\n",
       "      <td id=\"T_e9577_row10_col19\" class=\"data row10 col19\" >100.00</td>\n",
       "      <td id=\"T_e9577_row10_col20\" class=\"data row10 col20\" >0.96</td>\n",
       "      <td id=\"T_e9577_row10_col21\" class=\"data row10 col21\" >3.05</td>\n",
       "      <td id=\"T_e9577_row10_col22\" class=\"data row10 col22\" >0.99</td>\n",
       "      <td id=\"T_e9577_row10_col23\" class=\"data row10 col23\" >0.00</td>\n",
       "      <td id=\"T_e9577_row10_col24\" class=\"data row10 col24\" >0.38</td>\n",
       "      <td id=\"T_e9577_row10_col25\" class=\"data row10 col25\" >61.65</td>\n",
       "      <td id=\"T_e9577_row10_col26\" class=\"data row10 col26\" >0.96</td>\n",
       "      <td id=\"T_e9577_row10_col27\" class=\"data row10 col27\" >0.00</td>\n",
       "      <td id=\"T_e9577_row10_col28\" class=\"data row10 col28\" >100.00</td>\n",
       "      <td id=\"T_e9577_row10_col29\" class=\"data row10 col29\" >0.00</td>\n",
       "      <td id=\"T_e9577_row10_col30\" class=\"data row10 col30\" >100.00</td>\n",
       "      <td id=\"T_e9577_row10_col31\" class=\"data row10 col31\" >0.98</td>\n",
       "      <td id=\"T_e9577_row10_col32\" class=\"data row10 col32\" >-1.69</td>\n",
       "      <td id=\"T_e9577_row10_col33\" class=\"data row10 col33\" >0.95</td>\n",
       "      <td id=\"T_e9577_row10_col34\" class=\"data row10 col34\" >1.59</td>\n",
       "      <td id=\"T_e9577_row10_col35\" class=\"data row10 col35\" >0.53</td>\n",
       "      <td id=\"T_e9577_row10_col36\" class=\"data row10 col36\" >44.76</td>\n",
       "      <td id=\"T_e9577_row10_col37\" class=\"data row10 col37\" >24090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_e9577_row11_col0\" class=\"data row11 col0\" >SSH-Patator</td>\n",
       "      <td id=\"T_e9577_row11_col1\" class=\"data row11 col1\" >7.81</td>\n",
       "      <td id=\"T_e9577_row11_col2\" class=\"data row11 col2\" >92.91</td>\n",
       "      <td id=\"T_e9577_row11_col3\" class=\"data row11 col3\" >644.24</td>\n",
       "      <td id=\"T_e9577_row11_col4\" class=\"data row11 col4\" >0.49</td>\n",
       "      <td id=\"T_e9577_row11_col5\" class=\"data row11 col5\" >0.20</td>\n",
       "      <td id=\"T_e9577_row11_col6\" class=\"data row11 col6\" >58.34</td>\n",
       "      <td id=\"T_e9577_row11_col7\" class=\"data row11 col7\" >0.00</td>\n",
       "      <td id=\"T_e9577_row11_col8\" class=\"data row11 col8\" >100.00</td>\n",
       "      <td id=\"T_e9577_row11_col9\" class=\"data row11 col9\" >0.53</td>\n",
       "      <td id=\"T_e9577_row11_col10\" class=\"data row11 col10\" >-7.81</td>\n",
       "      <td id=\"T_e9577_row11_col11\" class=\"data row11 col11\" >0.55</td>\n",
       "      <td id=\"T_e9577_row11_col12\" class=\"data row11 col12\" >-11.56</td>\n",
       "      <td id=\"T_e9577_row11_col13\" class=\"data row11 col13\" >0.65</td>\n",
       "      <td id=\"T_e9577_row11_col14\" class=\"data row11 col14\" >-33.04</td>\n",
       "      <td id=\"T_e9577_row11_col15\" class=\"data row11 col15\" >1.00</td>\n",
       "      <td id=\"T_e9577_row11_col16\" class=\"data row11 col16\" >0.09</td>\n",
       "      <td id=\"T_e9577_row11_col17\" class=\"data row11 col17\" >91.00</td>\n",
       "      <td id=\"T_e9577_row11_col18\" class=\"data row11 col18\" >0.00</td>\n",
       "      <td id=\"T_e9577_row11_col19\" class=\"data row11 col19\" >100.00</td>\n",
       "      <td id=\"T_e9577_row11_col20\" class=\"data row11 col20\" >0.87</td>\n",
       "      <td id=\"T_e9577_row11_col21\" class=\"data row11 col21\" >13.31</td>\n",
       "      <td id=\"T_e9577_row11_col22\" class=\"data row11 col22\" >0.71</td>\n",
       "      <td id=\"T_e9577_row11_col23\" class=\"data row11 col23\" >28.86</td>\n",
       "      <td id=\"T_e9577_row11_col24\" class=\"data row11 col24\" >0.86</td>\n",
       "      <td id=\"T_e9577_row11_col25\" class=\"data row11 col25\" >13.50</td>\n",
       "      <td id=\"T_e9577_row11_col26\" class=\"data row11 col26\" >0.66</td>\n",
       "      <td id=\"T_e9577_row11_col27\" class=\"data row11 col27\" >0.13</td>\n",
       "      <td id=\"T_e9577_row11_col28\" class=\"data row11 col28\" >81.03</td>\n",
       "      <td id=\"T_e9577_row11_col29\" class=\"data row11 col29\" >0.00</td>\n",
       "      <td id=\"T_e9577_row11_col30\" class=\"data row11 col30\" >100.00</td>\n",
       "      <td id=\"T_e9577_row11_col31\" class=\"data row11 col31\" >0.66</td>\n",
       "      <td id=\"T_e9577_row11_col32\" class=\"data row11 col32\" >0.21</td>\n",
       "      <td id=\"T_e9577_row11_col33\" class=\"data row11 col33\" >0.62</td>\n",
       "      <td id=\"T_e9577_row11_col34\" class=\"data row11 col34\" >6.04</td>\n",
       "      <td id=\"T_e9577_row11_col35\" class=\"data row11 col35\" >0.75</td>\n",
       "      <td id=\"T_e9577_row11_col36\" class=\"data row11 col36\" >-13.00</td>\n",
       "      <td id=\"T_e9577_row11_col37\" class=\"data row11 col37\" >1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_e9577_row12_col0\" class=\"data row12 col0\" >Web Attack - Brute Force</td>\n",
       "      <td id=\"T_e9577_row12_col1\" class=\"data row12 col1\" >0.37</td>\n",
       "      <td id=\"T_e9577_row12_col2\" class=\"data row12 col2\" >21.12</td>\n",
       "      <td id=\"T_e9577_row12_col3\" class=\"data row12 col3\" >462.25</td>\n",
       "      <td id=\"T_e9577_row12_col4\" class=\"data row12 col4\" >0.70</td>\n",
       "      <td id=\"T_e9577_row12_col5\" class=\"data row12 col5\" >1.00</td>\n",
       "      <td id=\"T_e9577_row12_col6\" class=\"data row12 col6\" >-43.87</td>\n",
       "      <td id=\"T_e9577_row12_col7\" class=\"data row12 col7\" >1.00</td>\n",
       "      <td id=\"T_e9577_row12_col8\" class=\"data row12 col8\" >-43.87</td>\n",
       "      <td id=\"T_e9577_row12_col9\" class=\"data row12 col9\" >0.86</td>\n",
       "      <td id=\"T_e9577_row12_col10\" class=\"data row12 col10\" >-23.64</td>\n",
       "      <td id=\"T_e9577_row12_col11\" class=\"data row12 col11\" >0.39</td>\n",
       "      <td id=\"T_e9577_row12_col12\" class=\"data row12 col12\" >43.35</td>\n",
       "      <td id=\"T_e9577_row12_col13\" class=\"data row12 col13\" >0.82</td>\n",
       "      <td id=\"T_e9577_row12_col14\" class=\"data row12 col14\" >-18.15</td>\n",
       "      <td id=\"T_e9577_row12_col15\" class=\"data row12 col15\" >0.92</td>\n",
       "      <td id=\"T_e9577_row12_col16\" class=\"data row12 col16\" >0.88</td>\n",
       "      <td id=\"T_e9577_row12_col17\" class=\"data row12 col17\" >4.52</td>\n",
       "      <td id=\"T_e9577_row12_col18\" class=\"data row12 col18\" >0.78</td>\n",
       "      <td id=\"T_e9577_row12_col19\" class=\"data row12 col19\" >15.48</td>\n",
       "      <td id=\"T_e9577_row12_col20\" class=\"data row12 col20\" >0.98</td>\n",
       "      <td id=\"T_e9577_row12_col21\" class=\"data row12 col21\" >-6.45</td>\n",
       "      <td id=\"T_e9577_row12_col22\" class=\"data row12 col22\" >0.67</td>\n",
       "      <td id=\"T_e9577_row12_col23\" class=\"data row12 col23\" >27.10</td>\n",
       "      <td id=\"T_e9577_row12_col24\" class=\"data row12 col24\" >0.87</td>\n",
       "      <td id=\"T_e9577_row12_col25\" class=\"data row12 col25\" >5.16</td>\n",
       "      <td id=\"T_e9577_row12_col26\" class=\"data row12 col26\" >0.79</td>\n",
       "      <td id=\"T_e9577_row12_col27\" class=\"data row12 col27\" >0.93</td>\n",
       "      <td id=\"T_e9577_row12_col28\" class=\"data row12 col28\" >-18.07</td>\n",
       "      <td id=\"T_e9577_row12_col29\" class=\"data row12 col29\" >0.87</td>\n",
       "      <td id=\"T_e9577_row12_col30\" class=\"data row12 col30\" >-10.43</td>\n",
       "      <td id=\"T_e9577_row12_col31\" class=\"data row12 col31\" >0.91</td>\n",
       "      <td id=\"T_e9577_row12_col32\" class=\"data row12 col32\" >-15.59</td>\n",
       "      <td id=\"T_e9577_row12_col33\" class=\"data row12 col33\" >0.50</td>\n",
       "      <td id=\"T_e9577_row12_col34\" class=\"data row12 col34\" >37.33</td>\n",
       "      <td id=\"T_e9577_row12_col35\" class=\"data row12 col35\" >0.84</td>\n",
       "      <td id=\"T_e9577_row12_col36\" class=\"data row12 col36\" >-6.83</td>\n",
       "      <td id=\"T_e9577_row12_col37\" class=\"data row12 col37\" >169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_e9577_row13_col0\" class=\"data row13 col0\" >Web Attack - Sql Injection</td>\n",
       "      <td id=\"T_e9577_row13_col1\" class=\"data row13 col1\" >3.00</td>\n",
       "      <td id=\"T_e9577_row13_col2\" class=\"data row13 col2\" >3.00</td>\n",
       "      <td id=\"T_e9577_row13_col3\" class=\"data row13 col3\" >3.00</td>\n",
       "      <td id=\"T_e9577_row13_col4\" class=\"data row13 col4\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col5\" class=\"data row13 col5\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col6\" class=\"data row13 col6\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col7\" class=\"data row13 col7\" >0.21</td>\n",
       "      <td id=\"T_e9577_row13_col8\" class=\"data row13 col8\" >-214285714285.71</td>\n",
       "      <td id=\"T_e9577_row13_col9\" class=\"data row13 col9\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col10\" class=\"data row13 col10\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col11\" class=\"data row13 col11\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col12\" class=\"data row13 col12\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col13\" class=\"data row13 col13\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col14\" class=\"data row13 col14\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col15\" class=\"data row13 col15\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col16\" class=\"data row13 col16\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col17\" class=\"data row13 col17\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col18\" class=\"data row13 col18\" >1.00</td>\n",
       "      <td id=\"T_e9577_row13_col19\" class=\"data row13 col19\" >-1000000000000.00</td>\n",
       "      <td id=\"T_e9577_row13_col20\" class=\"data row13 col20\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col21\" class=\"data row13 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col22\" class=\"data row13 col22\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col23\" class=\"data row13 col23\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col24\" class=\"data row13 col24\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col25\" class=\"data row13 col25\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col26\" class=\"data row13 col26\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col27\" class=\"data row13 col27\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col28\" class=\"data row13 col28\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col29\" class=\"data row13 col29\" >0.35</td>\n",
       "      <td id=\"T_e9577_row13_col30\" class=\"data row13 col30\" >-352941176470.59</td>\n",
       "      <td id=\"T_e9577_row13_col31\" class=\"data row13 col31\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col32\" class=\"data row13 col32\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col33\" class=\"data row13 col33\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col34\" class=\"data row13 col34\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col35\" class=\"data row13 col35\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col36\" class=\"data row13 col36\" >0.00</td>\n",
       "      <td id=\"T_e9577_row13_col37\" class=\"data row13 col37\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_e9577_row14_col0\" class=\"data row14 col0\" >Web Attack - XSS</td>\n",
       "      <td id=\"T_e9577_row14_col1\" class=\"data row14 col1\" >2.86</td>\n",
       "      <td id=\"T_e9577_row14_col2\" class=\"data row14 col2\" >36.00</td>\n",
       "      <td id=\"T_e9577_row14_col3\" class=\"data row14 col3\" >267.77</td>\n",
       "      <td id=\"T_e9577_row14_col4\" class=\"data row14 col4\" >0.72</td>\n",
       "      <td id=\"T_e9577_row14_col5\" class=\"data row14 col5\" >0.86</td>\n",
       "      <td id=\"T_e9577_row14_col6\" class=\"data row14 col6\" >-18.84</td>\n",
       "      <td id=\"T_e9577_row14_col7\" class=\"data row14 col7\" >1.00</td>\n",
       "      <td id=\"T_e9577_row14_col8\" class=\"data row14 col8\" >-38.98</td>\n",
       "      <td id=\"T_e9577_row14_col9\" class=\"data row14 col9\" >0.86</td>\n",
       "      <td id=\"T_e9577_row14_col10\" class=\"data row14 col10\" >-18.84</td>\n",
       "      <td id=\"T_e9577_row14_col11\" class=\"data row14 col11\" >0.28</td>\n",
       "      <td id=\"T_e9577_row14_col12\" class=\"data row14 col12\" >61.50</td>\n",
       "      <td id=\"T_e9577_row14_col13\" class=\"data row14 col13\" >0.83</td>\n",
       "      <td id=\"T_e9577_row14_col14\" class=\"data row14 col14\" >-15.49</td>\n",
       "      <td id=\"T_e9577_row14_col15\" class=\"data row14 col15\" >0.82</td>\n",
       "      <td id=\"T_e9577_row14_col16\" class=\"data row14 col16\" >0.82</td>\n",
       "      <td id=\"T_e9577_row14_col17\" class=\"data row14 col17\" >0.00</td>\n",
       "      <td id=\"T_e9577_row14_col18\" class=\"data row14 col18\" >0.82</td>\n",
       "      <td id=\"T_e9577_row14_col19\" class=\"data row14 col19\" >0.00</td>\n",
       "      <td id=\"T_e9577_row14_col20\" class=\"data row14 col20\" >0.82</td>\n",
       "      <td id=\"T_e9577_row14_col21\" class=\"data row14 col21\" >0.00</td>\n",
       "      <td id=\"T_e9577_row14_col22\" class=\"data row14 col22\" >0.82</td>\n",
       "      <td id=\"T_e9577_row14_col23\" class=\"data row14 col23\" >0.00</td>\n",
       "      <td id=\"T_e9577_row14_col24\" class=\"data row14 col24\" >0.82</td>\n",
       "      <td id=\"T_e9577_row14_col25\" class=\"data row14 col25\" >0.00</td>\n",
       "      <td id=\"T_e9577_row14_col26\" class=\"data row14 col26\" >0.77</td>\n",
       "      <td id=\"T_e9577_row14_col27\" class=\"data row14 col27\" >0.84</td>\n",
       "      <td id=\"T_e9577_row14_col28\" class=\"data row14 col28\" >-9.22</td>\n",
       "      <td id=\"T_e9577_row14_col29\" class=\"data row14 col29\" >0.90</td>\n",
       "      <td id=\"T_e9577_row14_col30\" class=\"data row14 col30\" >-17.56</td>\n",
       "      <td id=\"T_e9577_row14_col31\" class=\"data row14 col31\" >0.84</td>\n",
       "      <td id=\"T_e9577_row14_col32\" class=\"data row14 col32\" >-9.22</td>\n",
       "      <td id=\"T_e9577_row14_col33\" class=\"data row14 col33\" >0.41</td>\n",
       "      <td id=\"T_e9577_row14_col34\" class=\"data row14 col34\" >45.96</td>\n",
       "      <td id=\"T_e9577_row14_col35\" class=\"data row14 col35\" >0.83</td>\n",
       "      <td id=\"T_e9577_row14_col36\" class=\"data row14 col36\" >-7.69</td>\n",
       "      <td id=\"T_e9577_row14_col37\" class=\"data row14 col37\" >72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_e9577_row15_col0\" class=\"data row15 col0\" >macro avg</td>\n",
       "      <td id=\"T_e9577_row15_col1\" class=\"data row15 col1\" >0.00</td>\n",
       "      <td id=\"T_e9577_row15_col2\" class=\"data row15 col2\" >0.00</td>\n",
       "      <td id=\"T_e9577_row15_col3\" class=\"data row15 col3\" >0.00</td>\n",
       "      <td id=\"T_e9577_row15_col4\" class=\"data row15 col4\" >0.68</td>\n",
       "      <td id=\"T_e9577_row15_col5\" class=\"data row15 col5\" >0.63</td>\n",
       "      <td id=\"T_e9577_row15_col6\" class=\"data row15 col6\" >7.76</td>\n",
       "      <td id=\"T_e9577_row15_col7\" class=\"data row15 col7\" >0.66</td>\n",
       "      <td id=\"T_e9577_row15_col8\" class=\"data row15 col8\" >2.80</td>\n",
       "      <td id=\"T_e9577_row15_col9\" class=\"data row15 col9\" >0.71</td>\n",
       "      <td id=\"T_e9577_row15_col10\" class=\"data row15 col10\" >-4.33</td>\n",
       "      <td id=\"T_e9577_row15_col11\" class=\"data row15 col11\" >0.59</td>\n",
       "      <td id=\"T_e9577_row15_col12\" class=\"data row15 col12\" >13.19</td>\n",
       "      <td id=\"T_e9577_row15_col13\" class=\"data row15 col13\" >0.71</td>\n",
       "      <td id=\"T_e9577_row15_col14\" class=\"data row15 col14\" >-4.49</td>\n",
       "      <td id=\"T_e9577_row15_col15\" class=\"data row15 col15\" >0.86</td>\n",
       "      <td id=\"T_e9577_row15_col16\" class=\"data row15 col16\" >0.61</td>\n",
       "      <td id=\"T_e9577_row15_col17\" class=\"data row15 col17\" >29.02</td>\n",
       "      <td id=\"T_e9577_row15_col18\" class=\"data row15 col18\" >0.69</td>\n",
       "      <td id=\"T_e9577_row15_col19\" class=\"data row15 col19\" >20.21</td>\n",
       "      <td id=\"T_e9577_row15_col20\" class=\"data row15 col20\" >0.85</td>\n",
       "      <td id=\"T_e9577_row15_col21\" class=\"data row15 col21\" >1.12</td>\n",
       "      <td id=\"T_e9577_row15_col22\" class=\"data row15 col22\" >0.81</td>\n",
       "      <td id=\"T_e9577_row15_col23\" class=\"data row15 col23\" >6.28</td>\n",
       "      <td id=\"T_e9577_row15_col24\" class=\"data row15 col24\" >0.79</td>\n",
       "      <td id=\"T_e9577_row15_col25\" class=\"data row15 col25\" >8.65</td>\n",
       "      <td id=\"T_e9577_row15_col26\" class=\"data row15 col26\" >0.71</td>\n",
       "      <td id=\"T_e9577_row15_col27\" class=\"data row15 col27\" >0.57</td>\n",
       "      <td id=\"T_e9577_row15_col28\" class=\"data row15 col28\" >19.30</td>\n",
       "      <td id=\"T_e9577_row15_col29\" class=\"data row15 col29\" >0.61</td>\n",
       "      <td id=\"T_e9577_row15_col30\" class=\"data row15 col30\" >13.63</td>\n",
       "      <td id=\"T_e9577_row15_col31\" class=\"data row15 col31\" >0.72</td>\n",
       "      <td id=\"T_e9577_row15_col32\" class=\"data row15 col32\" >-2.34</td>\n",
       "      <td id=\"T_e9577_row15_col33\" class=\"data row15 col33\" >0.63</td>\n",
       "      <td id=\"T_e9577_row15_col34\" class=\"data row15 col34\" >11.08</td>\n",
       "      <td id=\"T_e9577_row15_col35\" class=\"data row15 col35\" >0.71</td>\n",
       "      <td id=\"T_e9577_row15_col36\" class=\"data row15 col36\" >-1.01</td>\n",
       "      <td id=\"T_e9577_row15_col37\" class=\"data row15 col37\" >422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9577_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_e9577_row16_col0\" class=\"data row16 col0\" >weighted avg</td>\n",
       "      <td id=\"T_e9577_row16_col1\" class=\"data row16 col1\" >0.00</td>\n",
       "      <td id=\"T_e9577_row16_col2\" class=\"data row16 col2\" >0.00</td>\n",
       "      <td id=\"T_e9577_row16_col3\" class=\"data row16 col3\" >0.00</td>\n",
       "      <td id=\"T_e9577_row16_col4\" class=\"data row16 col4\" >0.99</td>\n",
       "      <td id=\"T_e9577_row16_col5\" class=\"data row16 col5\" >0.85</td>\n",
       "      <td id=\"T_e9577_row16_col6\" class=\"data row16 col6\" >14.27</td>\n",
       "      <td id=\"T_e9577_row16_col7\" class=\"data row16 col7\" >0.85</td>\n",
       "      <td id=\"T_e9577_row16_col8\" class=\"data row16 col8\" >14.19</td>\n",
       "      <td id=\"T_e9577_row16_col9\" class=\"data row16 col9\" >0.99</td>\n",
       "      <td id=\"T_e9577_row16_col10\" class=\"data row16 col10\" >-0.18</td>\n",
       "      <td id=\"T_e9577_row16_col11\" class=\"data row16 col11\" >0.99</td>\n",
       "      <td id=\"T_e9577_row16_col12\" class=\"data row16 col12\" >0.52</td>\n",
       "      <td id=\"T_e9577_row16_col13\" class=\"data row16 col13\" >0.95</td>\n",
       "      <td id=\"T_e9577_row16_col14\" class=\"data row16 col14\" >3.87</td>\n",
       "      <td id=\"T_e9577_row16_col15\" class=\"data row16 col15\" >0.99</td>\n",
       "      <td id=\"T_e9577_row16_col16\" class=\"data row16 col16\" >0.90</td>\n",
       "      <td id=\"T_e9577_row16_col17\" class=\"data row16 col17\" >9.26</td>\n",
       "      <td id=\"T_e9577_row16_col18\" class=\"data row16 col18\" >0.90</td>\n",
       "      <td id=\"T_e9577_row16_col19\" class=\"data row16 col19\" >9.09</td>\n",
       "      <td id=\"T_e9577_row16_col20\" class=\"data row16 col20\" >0.99</td>\n",
       "      <td id=\"T_e9577_row16_col21\" class=\"data row16 col21\" >-0.32</td>\n",
       "      <td id=\"T_e9577_row16_col22\" class=\"data row16 col22\" >0.98</td>\n",
       "      <td id=\"T_e9577_row16_col23\" class=\"data row16 col23\" >1.29</td>\n",
       "      <td id=\"T_e9577_row16_col24\" class=\"data row16 col24\" >0.95</td>\n",
       "      <td id=\"T_e9577_row16_col25\" class=\"data row16 col25\" >3.51</td>\n",
       "      <td id=\"T_e9577_row16_col26\" class=\"data row16 col26\" >0.99</td>\n",
       "      <td id=\"T_e9577_row16_col27\" class=\"data row16 col27\" >0.86</td>\n",
       "      <td id=\"T_e9577_row16_col28\" class=\"data row16 col28\" >12.69</td>\n",
       "      <td id=\"T_e9577_row16_col29\" class=\"data row16 col29\" >0.86</td>\n",
       "      <td id=\"T_e9577_row16_col30\" class=\"data row16 col30\" >12.56</td>\n",
       "      <td id=\"T_e9577_row16_col31\" class=\"data row16 col31\" >0.99</td>\n",
       "      <td id=\"T_e9577_row16_col32\" class=\"data row16 col32\" >-0.27</td>\n",
       "      <td id=\"T_e9577_row16_col33\" class=\"data row16 col33\" >0.98</td>\n",
       "      <td id=\"T_e9577_row16_col34\" class=\"data row16 col34\" >0.90</td>\n",
       "      <td id=\"T_e9577_row16_col35\" class=\"data row16 col35\" >0.95</td>\n",
       "      <td id=\"T_e9577_row16_col36\" class=\"data row16 col36\" >4.25</td>\n",
       "      <td id=\"T_e9577_row16_col37\" class=\"data row16 col37\" >422000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7e42533831d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_overall_metrics(baseline_report, adversarial_reports, class_degree_report):\n",
    "    rows = []   \n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    eplison = 1e-10  # To avoid division by zero\n",
    "\n",
    "    for label in list(class_map) + ['macro avg', 'weighted avg']:\n",
    "        row = {\"Class\": label}\n",
    "        row['Class'] = label\n",
    "        row['Min Influence'] = class_degree_report[label]['min_influence'] if label in class_degree_report else 0.0\n",
    "        row['Avg Influence'] = class_degree_report[label]['avg_influence'] if label in class_degree_report else 0.0\n",
    "        row['Max Influence'] = class_degree_report[label]['max_influence'] if label in class_degree_report else 0.0\n",
    "        for metric in metrics:\n",
    "            baseline_val = baseline_report[label][metric]\n",
    "            row[f\"Normal {metric}\"] = baseline_val\n",
    "            for name, report in adversarial_reports.items():\n",
    "                adv_val = report[label][metric]\n",
    "                row[f\"{name} {metric}\"] = adv_val\n",
    "                row[f\"{name} {metric} Drop (%)\"] = ((baseline_val - adv_val) / (baseline_val + eplison)) * 100\n",
    "        row['support'] = int(baseline_report[label]['support'])\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "adversarial_reports = {\n",
    "    \"To Both\": inject_both_report,\n",
    "    \"To Src\": inject_src_report,\n",
    "    \"To Dst\": inject_dst_report,\n",
    "    \"Edge Perturbation\": edge_perturb_report,\n",
    "    \"Random Edge\": random_edge_report,\n",
    "}\n",
    "\n",
    "comparison_df = compare_overall_metrics(normal_report, adversarial_reports, class_degree_report)\n",
    "\n",
    "class_col = comparison_df['Class']\n",
    "support_df = comparison_df['support']\n",
    "normal_cols = [col for col in comparison_df.columns if col.startswith('Normal')] \n",
    "influence_cols = [col for col in comparison_df.columns if col.endswith('Influence')] \n",
    "influence_df = comparison_df[influence_cols]\n",
    "f1_cols = [col for col in comparison_df.columns if col.endswith('f1-score')]\n",
    "f1_drop_cols = [col for col in comparison_df.columns if col.endswith('f1-score Drop (%)')]\n",
    "\n",
    "baselines_df = pd.concat([class_col, support_df, influence_df], axis=1)\n",
    "\n",
    "f1_df = pd.concat([baselines_df, comparison_df[f1_cols]], axis=1)\n",
    "f1_drop_df = pd.concat([baselines_df, comparison_df[f1_drop_cols]], axis=1)\n",
    "\n",
    "print(\"Comparison of Overall Metrics:\")\n",
    "display(comparison_df.style.set_caption(\"Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3725caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ff129_row0_col5, #T_ff129_row0_col8, #T_ff129_row0_col9, #T_ff129_row2_col10, #T_ff129_row3_col5, #T_ff129_row3_col8, #T_ff129_row3_col9, #T_ff129_row3_col10, #T_ff129_row4_col5, #T_ff129_row4_col7, #T_ff129_row4_col8, #T_ff129_row5_col6, #T_ff129_row5_col9, #T_ff129_row7_col10, #T_ff129_row16_col8 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row0_col6 {\n",
       "  background-color: #004c1e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row0_col7, #T_ff129_row0_col10, #T_ff129_row4_col9 {\n",
       "  background-color: #00491d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row1_col5 {\n",
       "  background-color: #88ce87;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row1_col6 {\n",
       "  background-color: #45ad5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row1_col7 {\n",
       "  background-color: #349d53;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row1_col8 {\n",
       "  background-color: #70c274;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row1_col9 {\n",
       "  background-color: #ebf7e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row1_col10 {\n",
       "  background-color: #9bd696;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row2_col5, #T_ff129_row2_col8, #T_ff129_row7_col8, #T_ff129_row16_col5 {\n",
       "  background-color: #00451c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row2_col6 {\n",
       "  background-color: #58b668;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row2_col7 {\n",
       "  background-color: #56b567;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row2_col9, #T_ff129_row4_col6, #T_ff129_row7_col5, #T_ff129_row10_col5, #T_ff129_row12_col6 {\n",
       "  background-color: #004d1f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row3_col6 {\n",
       "  background-color: #077331;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row3_col7 {\n",
       "  background-color: #05712f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row4_col10, #T_ff129_row16_col9 {\n",
       "  background-color: #00471c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row5_col5, #T_ff129_row15_col9 {\n",
       "  background-color: #3fa85b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row5_col7 {\n",
       "  background-color: #005020;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row5_col8, #T_ff129_row11_col9 {\n",
       "  background-color: #40aa5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row5_col10 {\n",
       "  background-color: #005522;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row6_col5, #T_ff129_row6_col8, #T_ff129_row10_col8 {\n",
       "  background-color: #00481d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row6_col6 {\n",
       "  background-color: #218944;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row6_col7, #T_ff129_row15_col5 {\n",
       "  background-color: #2d954d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row6_col9 {\n",
       "  background-color: #004e1f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row6_col10 {\n",
       "  background-color: #127c39;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row7_col6, #T_ff129_row14_col8 {\n",
       "  background-color: #097532;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row7_col7 {\n",
       "  background-color: #369f54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row7_col9 {\n",
       "  background-color: #005723;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row8_col5 {\n",
       "  background-color: #a4da9e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row8_col6 {\n",
       "  background-color: #c4e8bd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row8_col7 {\n",
       "  background-color: #0a7633;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row8_col8 {\n",
       "  background-color: #b5e1ae;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row8_col9, #T_ff129_row9_col10 {\n",
       "  background-color: #f2faf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row8_col10 {\n",
       "  background-color: #359e53;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row9_col5 {\n",
       "  background-color: #eff9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row9_col6, #T_ff129_row9_col7 {\n",
       "  background-color: #edf8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row9_col8 {\n",
       "  background-color: #eef8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row9_col9 {\n",
       "  background-color: #f1faee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row10_col6, #T_ff129_row10_col7, #T_ff129_row11_col7, #T_ff129_row13_col5, #T_ff129_row13_col6, #T_ff129_row13_col8, #T_ff129_row13_col9, #T_ff129_row13_col10 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row10_col9, #T_ff129_row16_col10 {\n",
       "  background-color: #005120;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row10_col10 {\n",
       "  background-color: #65bd6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row11_col5, #T_ff129_row11_col8 {\n",
       "  background-color: #38a156;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row11_col6 {\n",
       "  background-color: #e4f5df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row11_col10 {\n",
       "  background-color: #228a44;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row12_col5 {\n",
       "  background-color: #16803c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row12_col7 {\n",
       "  background-color: #005f26;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row12_col8 {\n",
       "  background-color: #005e26;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row12_col9 {\n",
       "  background-color: #73c476;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row12_col10 {\n",
       "  background-color: #067230;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row13_col7 {\n",
       "  background-color: #a3da9d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row14_col5 {\n",
       "  background-color: #1d8640;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row14_col6 {\n",
       "  background-color: #016e2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row14_col7 {\n",
       "  background-color: #005622;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row14_col9 {\n",
       "  background-color: #91d28e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ff129_row14_col10 {\n",
       "  background-color: #0b7734;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row15_col6 {\n",
       "  background-color: #4eb264;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row15_col7 {\n",
       "  background-color: #3ea75a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row15_col8 {\n",
       "  background-color: #29914a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row15_col10 {\n",
       "  background-color: #2a924a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row16_col6 {\n",
       "  background-color: #006529;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff129_row16_col7 {\n",
       "  background-color: #006328;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ff129\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ff129_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_ff129_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_ff129_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_ff129_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_ff129_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_ff129_level0_col5\" class=\"col_heading level0 col5\" >Normal f1-score</th>\n",
       "      <th id=\"T_ff129_level0_col6\" class=\"col_heading level0 col6\" >To Both f1-score</th>\n",
       "      <th id=\"T_ff129_level0_col7\" class=\"col_heading level0 col7\" >To Src f1-score</th>\n",
       "      <th id=\"T_ff129_level0_col8\" class=\"col_heading level0 col8\" >To Dst f1-score</th>\n",
       "      <th id=\"T_ff129_level0_col9\" class=\"col_heading level0 col9\" >Edge Perturbation f1-score</th>\n",
       "      <th id=\"T_ff129_level0_col10\" class=\"col_heading level0 col10\" >Random Edge f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ff129_row0_col0\" class=\"data row0 col0\" >BENIGN</td>\n",
       "      <td id=\"T_ff129_row0_col1\" class=\"data row0 col1\" >338068</td>\n",
       "      <td id=\"T_ff129_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_ff129_row0_col3\" class=\"data row0 col3\" >17.57</td>\n",
       "      <td id=\"T_ff129_row0_col4\" class=\"data row0 col4\" >933155.07</td>\n",
       "      <td id=\"T_ff129_row0_col5\" class=\"data row0 col5\" >0.99</td>\n",
       "      <td id=\"T_ff129_row0_col6\" class=\"data row0 col6\" >0.94</td>\n",
       "      <td id=\"T_ff129_row0_col7\" class=\"data row0 col7\" >0.94</td>\n",
       "      <td id=\"T_ff129_row0_col8\" class=\"data row0 col8\" >1.00</td>\n",
       "      <td id=\"T_ff129_row0_col9\" class=\"data row0 col9\" >0.99</td>\n",
       "      <td id=\"T_ff129_row0_col10\" class=\"data row0 col10\" >0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ff129_row1_col0\" class=\"data row1 col0\" >Bot</td>\n",
       "      <td id=\"T_ff129_row1_col1\" class=\"data row1 col1\" >258</td>\n",
       "      <td id=\"T_ff129_row1_col2\" class=\"data row1 col2\" >0.03</td>\n",
       "      <td id=\"T_ff129_row1_col3\" class=\"data row1 col3\" >2.30</td>\n",
       "      <td id=\"T_ff129_row1_col4\" class=\"data row1 col4\" >841.00</td>\n",
       "      <td id=\"T_ff129_row1_col5\" class=\"data row1 col5\" >0.44</td>\n",
       "      <td id=\"T_ff129_row1_col6\" class=\"data row1 col6\" >0.59</td>\n",
       "      <td id=\"T_ff129_row1_col7\" class=\"data row1 col7\" >0.65</td>\n",
       "      <td id=\"T_ff129_row1_col8\" class=\"data row1 col8\" >0.51</td>\n",
       "      <td id=\"T_ff129_row1_col9\" class=\"data row1 col9\" >0.09</td>\n",
       "      <td id=\"T_ff129_row1_col10\" class=\"data row1 col10\" >0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ff129_row2_col0\" class=\"data row2 col0\" >DDoS</td>\n",
       "      <td id=\"T_ff129_row2_col1\" class=\"data row2 col1\" >19978</td>\n",
       "      <td id=\"T_ff129_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_ff129_row2_col3\" class=\"data row2 col3\" >768.38</td>\n",
       "      <td id=\"T_ff129_row2_col4\" class=\"data row2 col4\" >999999.00</td>\n",
       "      <td id=\"T_ff129_row2_col5\" class=\"data row2 col5\" >0.99</td>\n",
       "      <td id=\"T_ff129_row2_col6\" class=\"data row2 col6\" >0.55</td>\n",
       "      <td id=\"T_ff129_row2_col7\" class=\"data row2 col7\" >0.55</td>\n",
       "      <td id=\"T_ff129_row2_col8\" class=\"data row2 col8\" >0.99</td>\n",
       "      <td id=\"T_ff129_row2_col9\" class=\"data row2 col9\" >0.96</td>\n",
       "      <td id=\"T_ff129_row2_col10\" class=\"data row2 col10\" >0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ff129_row3_col0\" class=\"data row3 col0\" >DoS GoldenEye</td>\n",
       "      <td id=\"T_ff129_row3_col1\" class=\"data row3 col1\" >2084</td>\n",
       "      <td id=\"T_ff129_row3_col2\" class=\"data row3 col2\" >514.57</td>\n",
       "      <td id=\"T_ff129_row3_col3\" class=\"data row3 col3\" >694.67</td>\n",
       "      <td id=\"T_ff129_row3_col4\" class=\"data row3 col4\" >930.93</td>\n",
       "      <td id=\"T_ff129_row3_col5\" class=\"data row3 col5\" >0.99</td>\n",
       "      <td id=\"T_ff129_row3_col6\" class=\"data row3 col6\" >0.82</td>\n",
       "      <td id=\"T_ff129_row3_col7\" class=\"data row3 col7\" >0.82</td>\n",
       "      <td id=\"T_ff129_row3_col8\" class=\"data row3 col8\" >0.99</td>\n",
       "      <td id=\"T_ff129_row3_col9\" class=\"data row3 col9\" >0.99</td>\n",
       "      <td id=\"T_ff129_row3_col10\" class=\"data row3 col10\" >0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ff129_row4_col0\" class=\"data row4 col0\" >DoS Hulk</td>\n",
       "      <td id=\"T_ff129_row4_col1\" class=\"data row4 col1\" >33233</td>\n",
       "      <td id=\"T_ff129_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_ff129_row4_col3\" class=\"data row4 col3\" >852.13</td>\n",
       "      <td id=\"T_ff129_row4_col4\" class=\"data row4 col4\" >998000.00</td>\n",
       "      <td id=\"T_ff129_row4_col5\" class=\"data row4 col5\" >0.99</td>\n",
       "      <td id=\"T_ff129_row4_col6\" class=\"data row4 col6\" >0.93</td>\n",
       "      <td id=\"T_ff129_row4_col7\" class=\"data row4 col7\" >0.96</td>\n",
       "      <td id=\"T_ff129_row4_col8\" class=\"data row4 col8\" >0.99</td>\n",
       "      <td id=\"T_ff129_row4_col9\" class=\"data row4 col9\" >0.97</td>\n",
       "      <td id=\"T_ff129_row4_col10\" class=\"data row4 col10\" >0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ff129_row5_col0\" class=\"data row5 col0\" >DoS Slowhttptest</td>\n",
       "      <td id=\"T_ff129_row5_col1\" class=\"data row5 col1\" >1008</td>\n",
       "      <td id=\"T_ff129_row5_col2\" class=\"data row5 col2\" >1.90</td>\n",
       "      <td id=\"T_ff129_row5_col3\" class=\"data row5 col3\" >252.00</td>\n",
       "      <td id=\"T_ff129_row5_col4\" class=\"data row5 col4\" >9045.12</td>\n",
       "      <td id=\"T_ff129_row5_col5\" class=\"data row5 col5\" >0.63</td>\n",
       "      <td id=\"T_ff129_row5_col6\" class=\"data row5 col6\" >0.96</td>\n",
       "      <td id=\"T_ff129_row5_col7\" class=\"data row5 col7\" >0.92</td>\n",
       "      <td id=\"T_ff129_row5_col8\" class=\"data row5 col8\" >0.62</td>\n",
       "      <td id=\"T_ff129_row5_col9\" class=\"data row5 col9\" >0.99</td>\n",
       "      <td id=\"T_ff129_row5_col10\" class=\"data row5 col10\" >0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ff129_row6_col0\" class=\"data row6 col0\" >DoS slowloris</td>\n",
       "      <td id=\"T_ff129_row6_col1\" class=\"data row6 col1\" >866</td>\n",
       "      <td id=\"T_ff129_row6_col2\" class=\"data row6 col2\" >31.61</td>\n",
       "      <td id=\"T_ff129_row6_col3\" class=\"data row6 col3\" >173.20</td>\n",
       "      <td id=\"T_ff129_row6_col4\" class=\"data row6 col4\" >754.33</td>\n",
       "      <td id=\"T_ff129_row6_col5\" class=\"data row6 col5\" >0.98</td>\n",
       "      <td id=\"T_ff129_row6_col6\" class=\"data row6 col6\" >0.73</td>\n",
       "      <td id=\"T_ff129_row6_col7\" class=\"data row6 col7\" >0.68</td>\n",
       "      <td id=\"T_ff129_row6_col8\" class=\"data row6 col8\" >0.98</td>\n",
       "      <td id=\"T_ff129_row6_col9\" class=\"data row6 col9\" >0.96</td>\n",
       "      <td id=\"T_ff129_row6_col10\" class=\"data row6 col10\" >0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ff129_row7_col0\" class=\"data row7 col0\" >FTP-Patator</td>\n",
       "      <td id=\"T_ff129_row7_col1\" class=\"data row7 col1\" >1142</td>\n",
       "      <td id=\"T_ff129_row7_col2\" class=\"data row7 col2\" >0.00</td>\n",
       "      <td id=\"T_ff129_row7_col3\" class=\"data row7 col3\" >87.85</td>\n",
       "      <td id=\"T_ff129_row7_col4\" class=\"data row7 col4\" >46655.95</td>\n",
       "      <td id=\"T_ff129_row7_col5\" class=\"data row7 col5\" >0.96</td>\n",
       "      <td id=\"T_ff129_row7_col6\" class=\"data row7 col6\" >0.81</td>\n",
       "      <td id=\"T_ff129_row7_col7\" class=\"data row7 col7\" >0.64</td>\n",
       "      <td id=\"T_ff129_row7_col8\" class=\"data row7 col8\" >0.99</td>\n",
       "      <td id=\"T_ff129_row7_col9\" class=\"data row7 col9\" >0.93</td>\n",
       "      <td id=\"T_ff129_row7_col10\" class=\"data row7 col10\" >0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ff129_row8_col0\" class=\"data row8 col0\" >Heartbleed</td>\n",
       "      <td id=\"T_ff129_row8_col1\" class=\"data row8 col1\" >2</td>\n",
       "      <td id=\"T_ff129_row8_col2\" class=\"data row8 col2\" >1.00</td>\n",
       "      <td id=\"T_ff129_row8_col3\" class=\"data row8 col3\" >1.00</td>\n",
       "      <td id=\"T_ff129_row8_col4\" class=\"data row8 col4\" >1.00</td>\n",
       "      <td id=\"T_ff129_row8_col5\" class=\"data row8 col5\" >0.36</td>\n",
       "      <td id=\"T_ff129_row8_col6\" class=\"data row8 col6\" >0.25</td>\n",
       "      <td id=\"T_ff129_row8_col7\" class=\"data row8 col7\" >0.80</td>\n",
       "      <td id=\"T_ff129_row8_col8\" class=\"data row8 col8\" >0.31</td>\n",
       "      <td id=\"T_ff129_row8_col9\" class=\"data row8 col9\" >0.03</td>\n",
       "      <td id=\"T_ff129_row8_col10\" class=\"data row8 col10\" >0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ff129_row9_col0\" class=\"data row9 col0\" >Infiltration</td>\n",
       "      <td id=\"T_ff129_row9_col1\" class=\"data row9 col1\" >5</td>\n",
       "      <td id=\"T_ff129_row9_col2\" class=\"data row9 col2\" >1.00</td>\n",
       "      <td id=\"T_ff129_row9_col3\" class=\"data row9 col3\" >1.00</td>\n",
       "      <td id=\"T_ff129_row9_col4\" class=\"data row9 col4\" >1.00</td>\n",
       "      <td id=\"T_ff129_row9_col5\" class=\"data row9 col5\" >0.06</td>\n",
       "      <td id=\"T_ff129_row9_col6\" class=\"data row9 col6\" >0.07</td>\n",
       "      <td id=\"T_ff129_row9_col7\" class=\"data row9 col7\" >0.07</td>\n",
       "      <td id=\"T_ff129_row9_col8\" class=\"data row9 col8\" >0.06</td>\n",
       "      <td id=\"T_ff129_row9_col9\" class=\"data row9 col9\" >0.04</td>\n",
       "      <td id=\"T_ff129_row9_col10\" class=\"data row9 col10\" >0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ff129_row10_col0\" class=\"data row10 col0\" >PortScan</td>\n",
       "      <td id=\"T_ff129_row10_col1\" class=\"data row10 col1\" >24090</td>\n",
       "      <td id=\"T_ff129_row10_col2\" class=\"data row10 col2\" >0.00</td>\n",
       "      <td id=\"T_ff129_row10_col3\" class=\"data row10 col3\" >830.69</td>\n",
       "      <td id=\"T_ff129_row10_col4\" class=\"data row10 col4\" >996003.00</td>\n",
       "      <td id=\"T_ff129_row10_col5\" class=\"data row10 col5\" >0.96</td>\n",
       "      <td id=\"T_ff129_row10_col6\" class=\"data row10 col6\" >0.00</td>\n",
       "      <td id=\"T_ff129_row10_col7\" class=\"data row10 col7\" >0.00</td>\n",
       "      <td id=\"T_ff129_row10_col8\" class=\"data row10 col8\" >0.98</td>\n",
       "      <td id=\"T_ff129_row10_col9\" class=\"data row10 col9\" >0.95</td>\n",
       "      <td id=\"T_ff129_row10_col10\" class=\"data row10 col10\" >0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ff129_row11_col0\" class=\"data row11 col0\" >SSH-Patator</td>\n",
       "      <td id=\"T_ff129_row11_col1\" class=\"data row11 col1\" >1022</td>\n",
       "      <td id=\"T_ff129_row11_col2\" class=\"data row11 col2\" >7.81</td>\n",
       "      <td id=\"T_ff129_row11_col3\" class=\"data row11 col3\" >92.91</td>\n",
       "      <td id=\"T_ff129_row11_col4\" class=\"data row11 col4\" >644.24</td>\n",
       "      <td id=\"T_ff129_row11_col5\" class=\"data row11 col5\" >0.66</td>\n",
       "      <td id=\"T_ff129_row11_col6\" class=\"data row11 col6\" >0.13</td>\n",
       "      <td id=\"T_ff129_row11_col7\" class=\"data row11 col7\" >0.00</td>\n",
       "      <td id=\"T_ff129_row11_col8\" class=\"data row11 col8\" >0.66</td>\n",
       "      <td id=\"T_ff129_row11_col9\" class=\"data row11 col9\" >0.62</td>\n",
       "      <td id=\"T_ff129_row11_col10\" class=\"data row11 col10\" >0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ff129_row12_col0\" class=\"data row12 col0\" >Web Attack - Brute Force</td>\n",
       "      <td id=\"T_ff129_row12_col1\" class=\"data row12 col1\" >169</td>\n",
       "      <td id=\"T_ff129_row12_col2\" class=\"data row12 col2\" >0.37</td>\n",
       "      <td id=\"T_ff129_row12_col3\" class=\"data row12 col3\" >21.12</td>\n",
       "      <td id=\"T_ff129_row12_col4\" class=\"data row12 col4\" >462.25</td>\n",
       "      <td id=\"T_ff129_row12_col5\" class=\"data row12 col5\" >0.79</td>\n",
       "      <td id=\"T_ff129_row12_col6\" class=\"data row12 col6\" >0.93</td>\n",
       "      <td id=\"T_ff129_row12_col7\" class=\"data row12 col7\" >0.87</td>\n",
       "      <td id=\"T_ff129_row12_col8\" class=\"data row12 col8\" >0.91</td>\n",
       "      <td id=\"T_ff129_row12_col9\" class=\"data row12 col9\" >0.50</td>\n",
       "      <td id=\"T_ff129_row12_col10\" class=\"data row12 col10\" >0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ff129_row13_col0\" class=\"data row13 col0\" >Web Attack - Sql Injection</td>\n",
       "      <td id=\"T_ff129_row13_col1\" class=\"data row13 col1\" >3</td>\n",
       "      <td id=\"T_ff129_row13_col2\" class=\"data row13 col2\" >3.00</td>\n",
       "      <td id=\"T_ff129_row13_col3\" class=\"data row13 col3\" >3.00</td>\n",
       "      <td id=\"T_ff129_row13_col4\" class=\"data row13 col4\" >3.00</td>\n",
       "      <td id=\"T_ff129_row13_col5\" class=\"data row13 col5\" >0.00</td>\n",
       "      <td id=\"T_ff129_row13_col6\" class=\"data row13 col6\" >0.00</td>\n",
       "      <td id=\"T_ff129_row13_col7\" class=\"data row13 col7\" >0.35</td>\n",
       "      <td id=\"T_ff129_row13_col8\" class=\"data row13 col8\" >0.00</td>\n",
       "      <td id=\"T_ff129_row13_col9\" class=\"data row13 col9\" >0.00</td>\n",
       "      <td id=\"T_ff129_row13_col10\" class=\"data row13 col10\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ff129_row14_col0\" class=\"data row14 col0\" >Web Attack - XSS</td>\n",
       "      <td id=\"T_ff129_row14_col1\" class=\"data row14 col1\" >72</td>\n",
       "      <td id=\"T_ff129_row14_col2\" class=\"data row14 col2\" >2.86</td>\n",
       "      <td id=\"T_ff129_row14_col3\" class=\"data row14 col3\" >36.00</td>\n",
       "      <td id=\"T_ff129_row14_col4\" class=\"data row14 col4\" >267.77</td>\n",
       "      <td id=\"T_ff129_row14_col5\" class=\"data row14 col5\" >0.77</td>\n",
       "      <td id=\"T_ff129_row14_col6\" class=\"data row14 col6\" >0.84</td>\n",
       "      <td id=\"T_ff129_row14_col7\" class=\"data row14 col7\" >0.90</td>\n",
       "      <td id=\"T_ff129_row14_col8\" class=\"data row14 col8\" >0.84</td>\n",
       "      <td id=\"T_ff129_row14_col9\" class=\"data row14 col9\" >0.41</td>\n",
       "      <td id=\"T_ff129_row14_col10\" class=\"data row14 col10\" >0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ff129_row15_col0\" class=\"data row15 col0\" >macro avg</td>\n",
       "      <td id=\"T_ff129_row15_col1\" class=\"data row15 col1\" >422000</td>\n",
       "      <td id=\"T_ff129_row15_col2\" class=\"data row15 col2\" >0.00</td>\n",
       "      <td id=\"T_ff129_row15_col3\" class=\"data row15 col3\" >0.00</td>\n",
       "      <td id=\"T_ff129_row15_col4\" class=\"data row15 col4\" >0.00</td>\n",
       "      <td id=\"T_ff129_row15_col5\" class=\"data row15 col5\" >0.71</td>\n",
       "      <td id=\"T_ff129_row15_col6\" class=\"data row15 col6\" >0.57</td>\n",
       "      <td id=\"T_ff129_row15_col7\" class=\"data row15 col7\" >0.61</td>\n",
       "      <td id=\"T_ff129_row15_col8\" class=\"data row15 col8\" >0.72</td>\n",
       "      <td id=\"T_ff129_row15_col9\" class=\"data row15 col9\" >0.63</td>\n",
       "      <td id=\"T_ff129_row15_col10\" class=\"data row15 col10\" >0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff129_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ff129_row16_col0\" class=\"data row16 col0\" >weighted avg</td>\n",
       "      <td id=\"T_ff129_row16_col1\" class=\"data row16 col1\" >422000</td>\n",
       "      <td id=\"T_ff129_row16_col2\" class=\"data row16 col2\" >0.00</td>\n",
       "      <td id=\"T_ff129_row16_col3\" class=\"data row16 col3\" >0.00</td>\n",
       "      <td id=\"T_ff129_row16_col4\" class=\"data row16 col4\" >0.00</td>\n",
       "      <td id=\"T_ff129_row16_col5\" class=\"data row16 col5\" >0.99</td>\n",
       "      <td id=\"T_ff129_row16_col6\" class=\"data row16 col6\" >0.86</td>\n",
       "      <td id=\"T_ff129_row16_col7\" class=\"data row16 col7\" >0.86</td>\n",
       "      <td id=\"T_ff129_row16_col8\" class=\"data row16 col8\" >0.99</td>\n",
       "      <td id=\"T_ff129_row16_col9\" class=\"data row16 col9\" >0.98</td>\n",
       "      <td id=\"T_ff129_row16_col10\" class=\"data row16 col10\" >0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7e425270e450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check F1 Scores\n",
    "display(f1_df.style.background_gradient(cmap='Greens', subset=f1_cols, axis=0).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4e5c86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d37fe_row0_col5 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d37fe_row0_col6 {\n",
       "  background-color: #6b010e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d37fe_row0_col7 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d37fe_row0_col8 {\n",
       "  background-color: #fee6da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d37fe_row0_col9 {\n",
       "  background-color: #fc9b7c;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d37fe\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d37fe_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_d37fe_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_d37fe_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_d37fe_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_d37fe_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_d37fe_level0_col5\" class=\"col_heading level0 col5\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_d37fe_level0_col6\" class=\"col_heading level0 col6\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_d37fe_level0_col7\" class=\"col_heading level0 col7\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_d37fe_level0_col8\" class=\"col_heading level0 col8\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_d37fe_level0_col9\" class=\"col_heading level0 col9\" >Random Edge f1-score Drop (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d37fe_level0_row0\" class=\"row_heading level0 row0\" >16</th>\n",
       "      <td id=\"T_d37fe_row0_col0\" class=\"data row0 col0\" >weighted avg</td>\n",
       "      <td id=\"T_d37fe_row0_col1\" class=\"data row0 col1\" >422000</td>\n",
       "      <td id=\"T_d37fe_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_d37fe_row0_col3\" class=\"data row0 col3\" >0.00</td>\n",
       "      <td id=\"T_d37fe_row0_col4\" class=\"data row0 col4\" >0.00</td>\n",
       "      <td id=\"T_d37fe_row0_col5\" class=\"data row0 col5\" >12.69</td>\n",
       "      <td id=\"T_d37fe_row0_col6\" class=\"data row0 col6\" >12.56</td>\n",
       "      <td id=\"T_d37fe_row0_col7\" class=\"data row0 col7\" >-0.27</td>\n",
       "      <td id=\"T_d37fe_row0_col8\" class=\"data row0 col8\" >0.90</td>\n",
       "      <td id=\"T_d37fe_row0_col9\" class=\"data row0 col9\" >4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7e42611fd6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Drops per Adversarial Attack\n",
    "display(f1_drop_df[f1_drop_df['Class'] == 'weighted avg'].style.background_gradient(cmap='Reds', subset=f1_drop_cols, axis=None).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bb8033d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2d515_row0_col5 {\n",
       "  background-color: #fc9070;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row0_col6, #T_2d515_row1_col6, #T_2d515_row2_col6, #T_2d515_row3_col6, #T_2d515_row4_col6, #T_2d515_row5_col6, #T_2d515_row6_col6, #T_2d515_row7_col6, #T_2d515_row8_col6, #T_2d515_row8_col7, #T_2d515_row8_col8, #T_2d515_row9_col6, #T_2d515_row10_col5, #T_2d515_row10_col6, #T_2d515_row10_col9, #T_2d515_row11_col6, #T_2d515_row12_col6, #T_2d515_row14_col6, #T_2d515_row15_col6, #T_2d515_row16_col6 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row0_col7, #T_2d515_row16_col7 {\n",
       "  background-color: #fb694a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row0_col8, #T_2d515_row3_col8, #T_2d515_row16_col8 {\n",
       "  background-color: #fc8e6e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row0_col9 {\n",
       "  background-color: #e32f27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row1_col5 {\n",
       "  background-color: #fee1d4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row1_col7 {\n",
       "  background-color: #ffeee7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row1_col8 {\n",
       "  background-color: #880811;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row1_col9 {\n",
       "  background-color: #cc191e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row2_col5 {\n",
       "  background-color: #ec382b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row2_col7, #T_2d515_row4_col7, #T_2d515_row6_col7, #T_2d515_row13_col7 {\n",
       "  background-color: #fa6648;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row2_col8 {\n",
       "  background-color: #fc8969;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row2_col9, #T_2d515_row13_col9 {\n",
       "  background-color: #e83429;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row3_col5, #T_2d515_row15_col8 {\n",
       "  background-color: #fb7757;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row3_col7 {\n",
       "  background-color: #fa6849;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row3_col9 {\n",
       "  background-color: #e63328;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row4_col5, #T_2d515_row13_col8 {\n",
       "  background-color: #fc8f6f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row4_col8 {\n",
       "  background-color: #fc8b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row4_col9 {\n",
       "  background-color: #e43027;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row5_col5, #T_2d515_row5_col8, #T_2d515_row8_col9, #T_2d515_row9_col7, #T_2d515_row13_col6 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row5_col7 {\n",
       "  background-color: #f7593f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row5_col9 {\n",
       "  background-color: #fcb499;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row6_col5 {\n",
       "  background-color: #fa6547;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row6_col8 {\n",
       "  background-color: #fc8a6a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row6_col9 {\n",
       "  background-color: #be151a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row7_col5 {\n",
       "  background-color: #fb7a5a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row7_col7 {\n",
       "  background-color: #fc8060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row7_col8 {\n",
       "  background-color: #fc8767;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row7_col9 {\n",
       "  background-color: #ed392b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row8_col5, #T_2d515_row11_col9 {\n",
       "  background-color: #f6583e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row9_col5 {\n",
       "  background-color: #fcc4ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row9_col8 {\n",
       "  background-color: #f6563d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row9_col9 {\n",
       "  background-color: #7a0510;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row10_col7 {\n",
       "  background-color: #fb7858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row10_col8 {\n",
       "  background-color: #fc8d6d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row11_col5 {\n",
       "  background-color: #a30f15;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row11_col7 {\n",
       "  background-color: #f96346;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row11_col8 {\n",
       "  background-color: #fc8262;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row12_col5 {\n",
       "  background-color: #fcc3ab;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row12_col7 {\n",
       "  background-color: #fff3ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row12_col8 {\n",
       "  background-color: #eb372a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row12_col9 {\n",
       "  background-color: #f24633;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row13_col5 {\n",
       "  background-color: #fc9c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row14_col5 {\n",
       "  background-color: #fcb095;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row14_col7 {\n",
       "  background-color: #fdc5ae;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2d515_row14_col8 {\n",
       "  background-color: #da2723;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row14_col9 {\n",
       "  background-color: #f24734;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row15_col5 {\n",
       "  background-color: #fb7353;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row15_col7 {\n",
       "  background-color: #fc7f5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row15_col9 {\n",
       "  background-color: #ea362a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row16_col5 {\n",
       "  background-color: #fc8161;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d515_row16_col9 {\n",
       "  background-color: #dd2a25;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2d515\">\n",
       "  <caption>Percentage Drop in Metrics Under Adversarial Attacks</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2d515_level0_col0\" class=\"col_heading level0 col0\" >Class</th>\n",
       "      <th id=\"T_2d515_level0_col1\" class=\"col_heading level0 col1\" >support</th>\n",
       "      <th id=\"T_2d515_level0_col2\" class=\"col_heading level0 col2\" >Min Influence</th>\n",
       "      <th id=\"T_2d515_level0_col3\" class=\"col_heading level0 col3\" >Avg Influence</th>\n",
       "      <th id=\"T_2d515_level0_col4\" class=\"col_heading level0 col4\" >Max Influence</th>\n",
       "      <th id=\"T_2d515_level0_col5\" class=\"col_heading level0 col5\" >To Both f1-score Drop (%)</th>\n",
       "      <th id=\"T_2d515_level0_col6\" class=\"col_heading level0 col6\" >To Src f1-score Drop (%)</th>\n",
       "      <th id=\"T_2d515_level0_col7\" class=\"col_heading level0 col7\" >To Dst f1-score Drop (%)</th>\n",
       "      <th id=\"T_2d515_level0_col8\" class=\"col_heading level0 col8\" >Edge Perturbation f1-score Drop (%)</th>\n",
       "      <th id=\"T_2d515_level0_col9\" class=\"col_heading level0 col9\" >Random Edge f1-score Drop (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2d515_row0_col0\" class=\"data row0 col0\" >BENIGN</td>\n",
       "      <td id=\"T_2d515_row0_col1\" class=\"data row0 col1\" >338068</td>\n",
       "      <td id=\"T_2d515_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_2d515_row0_col3\" class=\"data row0 col3\" >17.57</td>\n",
       "      <td id=\"T_2d515_row0_col4\" class=\"data row0 col4\" >933155.07</td>\n",
       "      <td id=\"T_2d515_row0_col5\" class=\"data row0 col5\" >5.38</td>\n",
       "      <td id=\"T_2d515_row0_col6\" class=\"data row0 col6\" >5.33</td>\n",
       "      <td id=\"T_2d515_row0_col7\" class=\"data row0 col7\" >-0.20</td>\n",
       "      <td id=\"T_2d515_row0_col8\" class=\"data row0 col8\" >0.65</td>\n",
       "      <td id=\"T_2d515_row0_col9\" class=\"data row0 col9\" >2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2d515_row1_col0\" class=\"data row1 col0\" >Bot</td>\n",
       "      <td id=\"T_2d515_row1_col1\" class=\"data row1 col1\" >258</td>\n",
       "      <td id=\"T_2d515_row1_col2\" class=\"data row1 col2\" >0.03</td>\n",
       "      <td id=\"T_2d515_row1_col3\" class=\"data row1 col3\" >2.30</td>\n",
       "      <td id=\"T_2d515_row1_col4\" class=\"data row1 col4\" >841.00</td>\n",
       "      <td id=\"T_2d515_row1_col5\" class=\"data row1 col5\" >-34.07</td>\n",
       "      <td id=\"T_2d515_row1_col6\" class=\"data row1 col6\" >-46.24</td>\n",
       "      <td id=\"T_2d515_row1_col7\" class=\"data row1 col7\" >-14.74</td>\n",
       "      <td id=\"T_2d515_row1_col8\" class=\"data row1 col8\" >80.69</td>\n",
       "      <td id=\"T_2d515_row1_col9\" class=\"data row1 col9\" >12.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2d515_row2_col0\" class=\"data row2 col0\" >DDoS</td>\n",
       "      <td id=\"T_2d515_row2_col1\" class=\"data row2 col1\" >19978</td>\n",
       "      <td id=\"T_2d515_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_2d515_row2_col3\" class=\"data row2 col3\" >768.38</td>\n",
       "      <td id=\"T_2d515_row2_col4\" class=\"data row2 col4\" >999999.00</td>\n",
       "      <td id=\"T_2d515_row2_col5\" class=\"data row2 col5\" >44.52</td>\n",
       "      <td id=\"T_2d515_row2_col6\" class=\"data row2 col6\" >44.53</td>\n",
       "      <td id=\"T_2d515_row2_col7\" class=\"data row2 col7\" >-0.04</td>\n",
       "      <td id=\"T_2d515_row2_col8\" class=\"data row2 col8\" >3.16</td>\n",
       "      <td id=\"T_2d515_row2_col9\" class=\"data row2 col9\" >-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2d515_row3_col0\" class=\"data row3 col0\" >DoS GoldenEye</td>\n",
       "      <td id=\"T_2d515_row3_col1\" class=\"data row3 col1\" >2084</td>\n",
       "      <td id=\"T_2d515_row3_col2\" class=\"data row3 col2\" >514.57</td>\n",
       "      <td id=\"T_2d515_row3_col3\" class=\"data row3 col3\" >694.67</td>\n",
       "      <td id=\"T_2d515_row3_col4\" class=\"data row3 col4\" >930.93</td>\n",
       "      <td id=\"T_2d515_row3_col5\" class=\"data row3 col5\" >17.57</td>\n",
       "      <td id=\"T_2d515_row3_col6\" class=\"data row3 col6\" >17.52</td>\n",
       "      <td id=\"T_2d515_row3_col7\" class=\"data row3 col7\" >-0.07</td>\n",
       "      <td id=\"T_2d515_row3_col8\" class=\"data row3 col8\" >0.57</td>\n",
       "      <td id=\"T_2d515_row3_col9\" class=\"data row3 col9\" >0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2d515_row4_col0\" class=\"data row4 col0\" >DoS Hulk</td>\n",
       "      <td id=\"T_2d515_row4_col1\" class=\"data row4 col1\" >33233</td>\n",
       "      <td id=\"T_2d515_row4_col2\" class=\"data row4 col2\" >0.00</td>\n",
       "      <td id=\"T_2d515_row4_col3\" class=\"data row4 col3\" >852.13</td>\n",
       "      <td id=\"T_2d515_row4_col4\" class=\"data row4 col4\" >998000.00</td>\n",
       "      <td id=\"T_2d515_row4_col5\" class=\"data row4 col5\" >6.03</td>\n",
       "      <td id=\"T_2d515_row4_col6\" class=\"data row4 col6\" >3.74</td>\n",
       "      <td id=\"T_2d515_row4_col7\" class=\"data row4 col7\" >-0.02</td>\n",
       "      <td id=\"T_2d515_row4_col8\" class=\"data row4 col8\" >2.03</td>\n",
       "      <td id=\"T_2d515_row4_col9\" class=\"data row4 col9\" >1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_2d515_row5_col0\" class=\"data row5 col0\" >DoS Slowhttptest</td>\n",
       "      <td id=\"T_2d515_row5_col1\" class=\"data row5 col1\" >1008</td>\n",
       "      <td id=\"T_2d515_row5_col2\" class=\"data row5 col2\" >1.90</td>\n",
       "      <td id=\"T_2d515_row5_col3\" class=\"data row5 col3\" >252.00</td>\n",
       "      <td id=\"T_2d515_row5_col4\" class=\"data row5 col4\" >9045.12</td>\n",
       "      <td id=\"T_2d515_row5_col5\" class=\"data row5 col5\" >-52.50</td>\n",
       "      <td id=\"T_2d515_row5_col6\" class=\"data row5 col6\" >-45.49</td>\n",
       "      <td id=\"T_2d515_row5_col7\" class=\"data row5 col7\" >1.06</td>\n",
       "      <td id=\"T_2d515_row5_col8\" class=\"data row5 col8\" >-56.16</td>\n",
       "      <td id=\"T_2d515_row5_col9\" class=\"data row5 col9\" >-48.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_2d515_row6_col0\" class=\"data row6 col0\" >DoS slowloris</td>\n",
       "      <td id=\"T_2d515_row6_col1\" class=\"data row6 col1\" >866</td>\n",
       "      <td id=\"T_2d515_row6_col2\" class=\"data row6 col2\" >31.61</td>\n",
       "      <td id=\"T_2d515_row6_col3\" class=\"data row6 col3\" >173.20</td>\n",
       "      <td id=\"T_2d515_row6_col4\" class=\"data row6 col4\" >754.33</td>\n",
       "      <td id=\"T_2d515_row6_col5\" class=\"data row6 col5\" >25.92</td>\n",
       "      <td id=\"T_2d515_row6_col6\" class=\"data row6 col6\" >30.77</td>\n",
       "      <td id=\"T_2d515_row6_col7\" class=\"data row6 col7\" >-0.06</td>\n",
       "      <td id=\"T_2d515_row6_col8\" class=\"data row6 col8\" >2.48</td>\n",
       "      <td id=\"T_2d515_row6_col9\" class=\"data row6 col9\" >18.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_2d515_row7_col0\" class=\"data row7 col0\" >FTP-Patator</td>\n",
       "      <td id=\"T_2d515_row7_col1\" class=\"data row7 col1\" >1142</td>\n",
       "      <td id=\"T_2d515_row7_col2\" class=\"data row7 col2\" >0.00</td>\n",
       "      <td id=\"T_2d515_row7_col3\" class=\"data row7 col3\" >87.85</td>\n",
       "      <td id=\"T_2d515_row7_col4\" class=\"data row7 col4\" >46655.95</td>\n",
       "      <td id=\"T_2d515_row7_col5\" class=\"data row7 col5\" >16.01</td>\n",
       "      <td id=\"T_2d515_row7_col6\" class=\"data row7 col6\" >33.48</td>\n",
       "      <td id=\"T_2d515_row7_col7\" class=\"data row7 col7\" >-2.42</td>\n",
       "      <td id=\"T_2d515_row7_col8\" class=\"data row7 col8\" >3.90</td>\n",
       "      <td id=\"T_2d515_row7_col9\" class=\"data row7 col9\" >-2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_2d515_row8_col0\" class=\"data row8 col0\" >Heartbleed</td>\n",
       "      <td id=\"T_2d515_row8_col1\" class=\"data row8 col1\" >2</td>\n",
       "      <td id=\"T_2d515_row8_col2\" class=\"data row8 col2\" >1.00</td>\n",
       "      <td id=\"T_2d515_row8_col3\" class=\"data row8 col3\" >1.00</td>\n",
       "      <td id=\"T_2d515_row8_col4\" class=\"data row8 col4\" >1.00</td>\n",
       "      <td id=\"T_2d515_row8_col5\" class=\"data row8 col5\" >31.25</td>\n",
       "      <td id=\"T_2d515_row8_col6\" class=\"data row8 col6\" >-120.00</td>\n",
       "      <td id=\"T_2d515_row8_col7\" class=\"data row8 col7\" >15.38</td>\n",
       "      <td id=\"T_2d515_row8_col8\" class=\"data row8 col8\" >90.52</td>\n",
       "      <td id=\"T_2d515_row8_col9\" class=\"data row8 col9\" >-83.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_2d515_row9_col0\" class=\"data row9 col0\" >Infiltration</td>\n",
       "      <td id=\"T_2d515_row9_col1\" class=\"data row9 col1\" >5</td>\n",
       "      <td id=\"T_2d515_row9_col2\" class=\"data row9 col2\" >1.00</td>\n",
       "      <td id=\"T_2d515_row9_col3\" class=\"data row9 col3\" >1.00</td>\n",
       "      <td id=\"T_2d515_row9_col4\" class=\"data row9 col4\" >1.00</td>\n",
       "      <td id=\"T_2d515_row9_col5\" class=\"data row9 col5\" >-18.85</td>\n",
       "      <td id=\"T_2d515_row9_col6\" class=\"data row9 col6\" >-20.83</td>\n",
       "      <td id=\"T_2d515_row9_col7\" class=\"data row9 col7\" >-16.00</td>\n",
       "      <td id=\"T_2d515_row9_col8\" class=\"data row9 col8\" >24.87</td>\n",
       "      <td id=\"T_2d515_row9_col9\" class=\"data row9 col9\" >39.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_2d515_row10_col0\" class=\"data row10 col0\" >PortScan</td>\n",
       "      <td id=\"T_2d515_row10_col1\" class=\"data row10 col1\" >24090</td>\n",
       "      <td id=\"T_2d515_row10_col2\" class=\"data row10 col2\" >0.00</td>\n",
       "      <td id=\"T_2d515_row10_col3\" class=\"data row10 col3\" >830.69</td>\n",
       "      <td id=\"T_2d515_row10_col4\" class=\"data row10 col4\" >996003.00</td>\n",
       "      <td id=\"T_2d515_row10_col5\" class=\"data row10 col5\" >100.00</td>\n",
       "      <td id=\"T_2d515_row10_col6\" class=\"data row10 col6\" >100.00</td>\n",
       "      <td id=\"T_2d515_row10_col7\" class=\"data row10 col7\" >-1.69</td>\n",
       "      <td id=\"T_2d515_row10_col8\" class=\"data row10 col8\" >1.59</td>\n",
       "      <td id=\"T_2d515_row10_col9\" class=\"data row10 col9\" >44.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_2d515_row11_col0\" class=\"data row11 col0\" >SSH-Patator</td>\n",
       "      <td id=\"T_2d515_row11_col1\" class=\"data row11 col1\" >1022</td>\n",
       "      <td id=\"T_2d515_row11_col2\" class=\"data row11 col2\" >7.81</td>\n",
       "      <td id=\"T_2d515_row11_col3\" class=\"data row11 col3\" >92.91</td>\n",
       "      <td id=\"T_2d515_row11_col4\" class=\"data row11 col4\" >644.24</td>\n",
       "      <td id=\"T_2d515_row11_col5\" class=\"data row11 col5\" >81.03</td>\n",
       "      <td id=\"T_2d515_row11_col6\" class=\"data row11 col6\" >100.00</td>\n",
       "      <td id=\"T_2d515_row11_col7\" class=\"data row11 col7\" >0.21</td>\n",
       "      <td id=\"T_2d515_row11_col8\" class=\"data row11 col8\" >6.04</td>\n",
       "      <td id=\"T_2d515_row11_col9\" class=\"data row11 col9\" >-13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_2d515_row12_col0\" class=\"data row12 col0\" >Web Attack - Brute Force</td>\n",
       "      <td id=\"T_2d515_row12_col1\" class=\"data row12 col1\" >169</td>\n",
       "      <td id=\"T_2d515_row12_col2\" class=\"data row12 col2\" >0.37</td>\n",
       "      <td id=\"T_2d515_row12_col3\" class=\"data row12 col3\" >21.12</td>\n",
       "      <td id=\"T_2d515_row12_col4\" class=\"data row12 col4\" >462.25</td>\n",
       "      <td id=\"T_2d515_row12_col5\" class=\"data row12 col5\" >-18.07</td>\n",
       "      <td id=\"T_2d515_row12_col6\" class=\"data row12 col6\" >-10.43</td>\n",
       "      <td id=\"T_2d515_row12_col7\" class=\"data row12 col7\" >-15.59</td>\n",
       "      <td id=\"T_2d515_row12_col8\" class=\"data row12 col8\" >37.33</td>\n",
       "      <td id=\"T_2d515_row12_col9\" class=\"data row12 col9\" >-6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_2d515_row13_col0\" class=\"data row13 col0\" >Web Attack - Sql Injection</td>\n",
       "      <td id=\"T_2d515_row13_col1\" class=\"data row13 col1\" >3</td>\n",
       "      <td id=\"T_2d515_row13_col2\" class=\"data row13 col2\" >3.00</td>\n",
       "      <td id=\"T_2d515_row13_col3\" class=\"data row13 col3\" >3.00</td>\n",
       "      <td id=\"T_2d515_row13_col4\" class=\"data row13 col4\" >3.00</td>\n",
       "      <td id=\"T_2d515_row13_col5\" class=\"data row13 col5\" >0.00</td>\n",
       "      <td id=\"T_2d515_row13_col6\" class=\"data row13 col6\" >-352941176470.59</td>\n",
       "      <td id=\"T_2d515_row13_col7\" class=\"data row13 col7\" >0.00</td>\n",
       "      <td id=\"T_2d515_row13_col8\" class=\"data row13 col8\" >0.00</td>\n",
       "      <td id=\"T_2d515_row13_col9\" class=\"data row13 col9\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_2d515_row14_col0\" class=\"data row14 col0\" >Web Attack - XSS</td>\n",
       "      <td id=\"T_2d515_row14_col1\" class=\"data row14 col1\" >72</td>\n",
       "      <td id=\"T_2d515_row14_col2\" class=\"data row14 col2\" >2.86</td>\n",
       "      <td id=\"T_2d515_row14_col3\" class=\"data row14 col3\" >36.00</td>\n",
       "      <td id=\"T_2d515_row14_col4\" class=\"data row14 col4\" >267.77</td>\n",
       "      <td id=\"T_2d515_row14_col5\" class=\"data row14 col5\" >-9.22</td>\n",
       "      <td id=\"T_2d515_row14_col6\" class=\"data row14 col6\" >-17.56</td>\n",
       "      <td id=\"T_2d515_row14_col7\" class=\"data row14 col7\" >-9.22</td>\n",
       "      <td id=\"T_2d515_row14_col8\" class=\"data row14 col8\" >45.96</td>\n",
       "      <td id=\"T_2d515_row14_col9\" class=\"data row14 col9\" >-7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_2d515_row15_col0\" class=\"data row15 col0\" >macro avg</td>\n",
       "      <td id=\"T_2d515_row15_col1\" class=\"data row15 col1\" >422000</td>\n",
       "      <td id=\"T_2d515_row15_col2\" class=\"data row15 col2\" >0.00</td>\n",
       "      <td id=\"T_2d515_row15_col3\" class=\"data row15 col3\" >0.00</td>\n",
       "      <td id=\"T_2d515_row15_col4\" class=\"data row15 col4\" >0.00</td>\n",
       "      <td id=\"T_2d515_row15_col5\" class=\"data row15 col5\" >19.30</td>\n",
       "      <td id=\"T_2d515_row15_col6\" class=\"data row15 col6\" >13.63</td>\n",
       "      <td id=\"T_2d515_row15_col7\" class=\"data row15 col7\" >-2.34</td>\n",
       "      <td id=\"T_2d515_row15_col8\" class=\"data row15 col8\" >11.08</td>\n",
       "      <td id=\"T_2d515_row15_col9\" class=\"data row15 col9\" >-1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d515_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_2d515_row16_col0\" class=\"data row16 col0\" >weighted avg</td>\n",
       "      <td id=\"T_2d515_row16_col1\" class=\"data row16 col1\" >422000</td>\n",
       "      <td id=\"T_2d515_row16_col2\" class=\"data row16 col2\" >0.00</td>\n",
       "      <td id=\"T_2d515_row16_col3\" class=\"data row16 col3\" >0.00</td>\n",
       "      <td id=\"T_2d515_row16_col4\" class=\"data row16 col4\" >0.00</td>\n",
       "      <td id=\"T_2d515_row16_col5\" class=\"data row16 col5\" >12.69</td>\n",
       "      <td id=\"T_2d515_row16_col6\" class=\"data row16 col6\" >12.56</td>\n",
       "      <td id=\"T_2d515_row16_col7\" class=\"data row16 col7\" >-0.27</td>\n",
       "      <td id=\"T_2d515_row16_col8\" class=\"data row16 col8\" >0.90</td>\n",
       "      <td id=\"T_2d515_row16_col9\" class=\"data row16 col9\" >4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7e42513ad550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Drops per Class\n",
    "display(f1_drop_df.style.background_gradient(cmap='Reds', subset=f1_drop_cols).set_caption(\"Percentage Drop in Metrics Under Adversarial Attacks\").format({col: \"{:.2f}\" for col in comparison_df.columns if col not in ['Class', 'support']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "852b5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BENIGN': {'out_degree': (1.0, 11.26, 966.0),\n",
      "            'in_degree': (1.0, 7.21, 955.0),\n",
      "            'support': 338068,\n",
      "            'normal_f1': 0.99,\n",
      "            'to_both_f1': 0.94,\n",
      "            'to_src_f1': 0.94,\n",
      "            'to_dst_f1': 1.0,\n",
      "            'edge_perturb_f1': 0.99,\n",
      "            'random_edge_f1': 0.97},\n",
      " 'Bot': {'out_degree': (1.0, 3.63, 29.0),\n",
      "         'in_degree': (1.0, 5.73, 31.0),\n",
      "         'support': 258,\n",
      "         'normal_f1': 0.44,\n",
      "         'to_both_f1': 0.59,\n",
      "         'to_src_f1': 0.65,\n",
      "         'to_dst_f1': 0.51,\n",
      "         'edge_perturb_f1': 0.09,\n",
      "         'random_edge_f1': 0.39},\n",
      " 'DDoS': {'out_degree': (1.0, 768.38, 1000.0),\n",
      "          'in_degree': (1.0, 768.38, 1000.0),\n",
      "          'support': 19978,\n",
      "          'normal_f1': 0.99,\n",
      "          'to_both_f1': 0.55,\n",
      "          'to_src_f1': 0.55,\n",
      "          'to_dst_f1': 0.99,\n",
      "          'edge_perturb_f1': 0.96,\n",
      "          'random_edge_f1': 0.99},\n",
      " 'DoS GoldenEye': {'out_degree': (627.0, 694.67, 764.0),\n",
      "                   'in_degree': (627.0, 694.67, 764.0),\n",
      "                   'support': 2084,\n",
      "                   'normal_f1': 0.99,\n",
      "                   'to_both_f1': 0.82,\n",
      "                   'to_src_f1': 0.82,\n",
      "                   'to_dst_f1': 0.99,\n",
      "                   'edge_perturb_f1': 0.99,\n",
      "                   'random_edge_f1': 0.99},\n",
      " 'DoS Hulk': {'out_degree': (1.0, 852.13, 999.0),\n",
      "              'in_degree': (1.0, 852.13, 999.0),\n",
      "              'support': 33233,\n",
      "              'normal_f1': 0.99,\n",
      "              'to_both_f1': 0.93,\n",
      "              'to_src_f1': 0.96,\n",
      "              'to_dst_f1': 0.99,\n",
      "              'edge_perturb_f1': 0.97,\n",
      "              'random_edge_f1': 0.98},\n",
      " 'DoS Slowhttptest': {'out_degree': (32.0, 252.0, 538.0),\n",
      "                      'in_degree': (32.0, 252.0, 538.0),\n",
      "                      'support': 1008,\n",
      "                      'normal_f1': 0.63,\n",
      "                      'to_both_f1': 0.96,\n",
      "                      'to_src_f1': 0.92,\n",
      "                      'to_dst_f1': 0.62,\n",
      "                      'edge_perturb_f1': 0.99,\n",
      "                      'random_edge_f1': 0.94},\n",
      " 'DoS slowloris': {'out_degree': (91.0, 173.2, 262.0),\n",
      "                   'in_degree': (91.0, 173.2, 262.0),\n",
      "                   'support': 866,\n",
      "                   'normal_f1': 0.98,\n",
      "                   'to_both_f1': 0.73,\n",
      "                   'to_src_f1': 0.68,\n",
      "                   'to_dst_f1': 0.98,\n",
      "                   'edge_perturb_f1': 0.96,\n",
      "                   'random_edge_f1': 0.8},\n",
      " 'FTP-Patator': {'out_degree': (1.0, 87.85, 216.0),\n",
      "                 'in_degree': (1.0, 87.85, 216.0),\n",
      "                 'support': 1142,\n",
      "                 'normal_f1': 0.96,\n",
      "                 'to_both_f1': 0.81,\n",
      "                 'to_src_f1': 0.64,\n",
      "                 'to_dst_f1': 0.99,\n",
      "                 'edge_perturb_f1': 0.93,\n",
      "                 'random_edge_f1': 0.99},\n",
      " 'Heartbleed': {'out_degree': (1.0, 1.0, 1.0),\n",
      "                'in_degree': (1.0, 1.0, 1.0),\n",
      "                'support': 2,\n",
      "                'normal_f1': 0.36,\n",
      "                'to_both_f1': 0.25,\n",
      "                'to_src_f1': 0.8,\n",
      "                'to_dst_f1': 0.31,\n",
      "                'edge_perturb_f1': 0.03,\n",
      "                'random_edge_f1': 0.67},\n",
      " 'Infiltration': {'out_degree': (1.0, 1.0, 1.0),\n",
      "                  'in_degree': (1.0, 1.0, 1.0),\n",
      "                  'support': 5,\n",
      "                  'normal_f1': 0.06,\n",
      "                  'to_both_f1': 0.07,\n",
      "                  'to_src_f1': 0.07,\n",
      "                  'to_dst_f1': 0.06,\n",
      "                  'edge_perturb_f1': 0.04,\n",
      "                  'random_edge_f1': 0.03},\n",
      " 'PortScan': {'out_degree': (1.0, 830.69, 998.0),\n",
      "              'in_degree': (1.0, 830.69, 998.0),\n",
      "              'support': 24090,\n",
      "              'normal_f1': 0.96,\n",
      "              'to_both_f1': 0.0,\n",
      "              'to_src_f1': 0.0,\n",
      "              'to_dst_f1': 0.98,\n",
      "              'edge_perturb_f1': 0.95,\n",
      "              'random_edge_f1': 0.53},\n",
      " 'SSH-Patator': {'out_degree': (34.0, 92.91, 148.0),\n",
      "                 'in_degree': (34.0, 92.91, 148.0),\n",
      "                 'support': 1022,\n",
      "                 'normal_f1': 0.66,\n",
      "                 'to_both_f1': 0.13,\n",
      "                 'to_src_f1': 0.0,\n",
      "                 'to_dst_f1': 0.66,\n",
      "                 'edge_perturb_f1': 0.62,\n",
      "                 'random_edge_f1': 0.75},\n",
      " 'Web Attack - Brute Force': {'out_degree': (4.0, 21.12, 43.0),\n",
      "                              'in_degree': (4.0, 21.12, 43.0),\n",
      "                              'support': 169,\n",
      "                              'normal_f1': 0.79,\n",
      "                              'to_both_f1': 0.93,\n",
      "                              'to_src_f1': 0.87,\n",
      "                              'to_dst_f1': 0.91,\n",
      "                              'edge_perturb_f1': 0.5,\n",
      "                              'random_edge_f1': 0.84},\n",
      " 'Web Attack - Sql Injection': {'out_degree': (3.0, 3.0, 3.0),\n",
      "                                'in_degree': (3.0, 3.0, 3.0),\n",
      "                                'support': 3,\n",
      "                                'normal_f1': 0.0,\n",
      "                                'to_both_f1': 0.0,\n",
      "                                'to_src_f1': 0.35,\n",
      "                                'to_dst_f1': 0.0,\n",
      "                                'edge_perturb_f1': 0.0,\n",
      "                                'random_edge_f1': 0.0},\n",
      " 'Web Attack - XSS': {'out_degree': (13.0, 36.0, 59.0),\n",
      "                      'in_degree': (13.0, 36.0, 59.0),\n",
      "                      'support': 72,\n",
      "                      'normal_f1': 0.77,\n",
      "                      'to_both_f1': 0.84,\n",
      "                      'to_src_f1': 0.9,\n",
      "                      'to_dst_f1': 0.84,\n",
      "                      'edge_perturb_f1': 0.41,\n",
      "                      'random_edge_f1': 0.83},\n",
      " 'Macro Average': {'support': 422000,\n",
      "                   'normal_f1': 0.71,\n",
      "                   'to_both_f1': 0.57,\n",
      "                   'to_src_f1': 0.61,\n",
      "                   'to_dst_f1': 0.72,\n",
      "                   'edge_perturb_f1': 0.63,\n",
      "                   'random_edge_f1': 0.71},\n",
      " 'Weighted Average': {'support': 422000,\n",
      "                      'normal_f1': 0.99,\n",
      "                      'to_both_f1': 0.86,\n",
      "                      'to_src_f1': 0.86,\n",
      "                      'to_dst_f1': 0.99,\n",
      "                      'edge_perturb_f1': 0.98,\n",
      "                      'random_edge_f1': 0.95}}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pformat\n",
    "\n",
    "def round_tuple(t):\n",
    "    return tuple(round(x, 2) for x in t)\n",
    "\n",
    "def print_results(class_degree_report, comparison_df):\n",
    "    report_dict = defaultdict(dict)\n",
    "\n",
    "    for class_name, metrics in class_degree_report.items():\n",
    "        report_dict[class_name] = {\n",
    "            \"out_degree\": round_tuple((metrics['min_out'], metrics['avg_out'], metrics['max_out'])),\n",
    "            \"in_degree\": round_tuple((metrics['min_in'], metrics['avg_in'], metrics['max_in']))\n",
    "        }\n",
    "\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        class_name = row['Class']\n",
    "        if class_name == 'weighted avg':\n",
    "            class_name = 'Weighted Average'\n",
    "        if class_name == 'macro avg':\n",
    "            class_name = 'Macro Average'\n",
    "        report_dict[class_name].update({\n",
    "            \"support\": row['support'],\n",
    "            \"normal_f1\": round(row['Normal f1-score'], 2),\n",
    "            \"to_both_f1\": round(row['To Both f1-score'], 2),\n",
    "            \"to_src_f1\": round(row['To Src f1-score'], 2),\n",
    "            \"to_dst_f1\": round(row['To Dst f1-score'], 2),\n",
    "            \"edge_perturb_f1\": round(row['Edge Perturbation f1-score'], 2),\n",
    "            \"random_edge_f1\": round(row['Random Edge f1-score'], 2),\n",
    "        })\n",
    "\n",
    "    print(pformat(dict(report_dict), sort_dicts=False, indent=1))\n",
    "\n",
    "print_results(class_degree_report, comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
